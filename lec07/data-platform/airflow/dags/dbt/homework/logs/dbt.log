[0m17:27:24.877291 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f59da0236d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f59d91e23a0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f59d9dc0220>]}


============================== 17:27:24.890012 | e32f58cb-83e3-4138-99ff-4da093c4303c ==============================
[0m17:27:24.890012 [info ] [MainThread]: Running with dbt=1.9.4
[0m17:27:24.892136 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': '/opt/airflow/dags/dbt', 'debug': 'False', 'fail_fast': 'False', 'log_path': '/opt/airflow/dags/dbt/homework/logs', 'version_check': 'True', 'warn_error': 'None', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'empty': 'None', 'log_format': 'default', 'invocation_command': 'dbt deps --profiles-dir /opt/airflow/dags/dbt --project-dir /opt/airflow/dags/dbt/homework', 'static_parser': 'True', 'introspect': 'True', 'target_path': 'None', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'send_anonymous_usage_stats': 'True'}
[0m17:27:25.244844 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'e32f58cb-83e3-4138-99ff-4da093c4303c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f59d92290d0>]}
[0m17:27:25.488903 [debug] [MainThread]: Set downloads directory='/tmp/dbt-downloads-3xef1c53'
[0m17:27:25.490941 [debug] [MainThread]: Making package index registry request: GET https://hub.getdbt.com/api/v1/index.json
[0m17:27:25.744583 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff83386e6a0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff832981eb0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff832981e50>]}


============================== 17:27:25.758681 | 7549f981-a816-47b7-b4fa-20ce5c2b8d1f ==============================
[0m17:27:25.758681 [info ] [MainThread]: Running with dbt=1.9.4
[0m17:27:25.767369 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': '/opt/airflow/dags/dbt', 'version_check': 'True', 'debug': 'False', 'log_path': '/opt/airflow/dags/dbt/homework/logs', 'warn_error': 'None', 'fail_fast': 'False', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'empty': 'None', 'log_format': 'default', 'invocation_command': 'dbt deps --profiles-dir /opt/airflow/dags/dbt --project-dir /opt/airflow/dags/dbt/homework', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'static_parser': 'True', 'target_path': 'None', 'introspect': 'True', 'send_anonymous_usage_stats': 'True'}
[0m17:27:25.958775 [debug] [MainThread]: Response from registry index: GET https://hub.getdbt.com/api/v1/index.json 200
[0m17:27:25.961094 [debug] [MainThread]: Making package registry request: GET https://hub.getdbt.com/api/v1/Matts52/dbt_ml_inline_preprocessing.json
[0m17:27:26.050096 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '7549f981-a816-47b7-b4fa-20ce5c2b8d1f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff8328fd280>]}
[0m17:27:26.095876 [debug] [MainThread]: Set downloads directory='/tmp/dbt-downloads-n0mc0rk3'
[0m17:27:26.098267 [debug] [MainThread]: Making package index registry request: GET https://hub.getdbt.com/api/v1/index.json
[0m17:27:26.267643 [debug] [MainThread]: Response from registry: GET https://hub.getdbt.com/api/v1/Matts52/dbt_ml_inline_preprocessing.json 200
[0m17:27:26.271300 [debug] [MainThread]: Response from registry index: GET https://hub.getdbt.com/api/v1/index.json 200
[0m17:27:26.272098 [debug] [MainThread]: Making package registry request: GET https://hub.getdbt.com/api/v1/dbt-labs/dbt_utils.json
[0m17:27:26.273902 [debug] [MainThread]: Making package registry request: GET https://hub.getdbt.com/api/v1/Matts52/dbt_ml_inline_preprocessing.json
[0m17:27:26.378164 [debug] [MainThread]: Response from registry: GET https://hub.getdbt.com/api/v1/Matts52/dbt_ml_inline_preprocessing.json 200
[0m17:27:26.381293 [debug] [MainThread]: Making package registry request: GET https://hub.getdbt.com/api/v1/dbt-labs/dbt_utils.json
[0m17:27:26.490394 [debug] [MainThread]: Response from registry: GET https://hub.getdbt.com/api/v1/dbt-labs/dbt_utils.json 200
[0m17:27:26.490542 [debug] [MainThread]: Response from registry: GET https://hub.getdbt.com/api/v1/dbt-labs/dbt_utils.json 200
[0m17:27:26.501164 [info ] [MainThread]: Installing Matts52/dbt_ml_inline_preprocessing
[0m17:27:26.501286 [info ] [MainThread]: Installing Matts52/dbt_ml_inline_preprocessing
[0m17:27:27.822740 [error] [MainThread]: Encountered an error:
[Errno 2] No such file or directory: 'dbt_packages/dbt-ml-inline-preprocessing-0.2.4/integration_tests/models/test_rare_category_encode.sql'
[0m17:27:27.823349 [info ] [MainThread]: Installed from version 0.2.4
[0m17:27:27.825758 [info ] [MainThread]: Up to date!
[0m17:27:27.828149 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'package', 'label': '7549f981-a816-47b7-b4fa-20ce5c2b8d1f', 'property_': 'install', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff8328dc2e0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff832871310>]}
[0m17:27:27.828540 [error] [MainThread]: Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/dbt/cli/requires.py", line 153, in wrapper
    result, success = func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.9/site-packages/dbt/cli/requires.py", line 103, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.9/site-packages/dbt/cli/requires.py", line 218, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.9/site-packages/dbt/cli/requires.py", line 264, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.9/site-packages/dbt/cli/main.py", line 455, in deps
    results = task.run()
  File "/home/airflow/.local/lib/python3.9/site-packages/dbt/task/deps.py", line 254, in run
    package.install(self.project, renderer)
  File "/home/airflow/.local/lib/python3.9/site-packages/dbt/deps/registry.py", line 63, in install
    self._install(project, renderer)
  File "/home/airflow/.local/lib/python3.9/site-packages/dbt/deps/base.py", line 121, in _install
    connection_exception_retry(download_untar_fn, 5)
  File "/home/airflow/.local/lib/python3.9/site-packages/dbt_common/utils/connection.py", line 21, in connection_exception_retry
    return fn()
  File "/home/airflow/.local/lib/python3.9/site-packages/dbt/deps/base.py", line 133, in download_and_untar
    system.untar_package(tar_path, deps_path, package_name)
  File "/home/airflow/.local/lib/python3.9/site-packages/dbt_common/clients/system.py", line 641, in untar_package
    safe_extract(tarball, dest_dir)
  File "/home/airflow/.local/lib/python3.9/site-packages/dbt_common/clients/system.py", line 634, in safe_extract
    tarball.extractall(path, members=members)
  File "/usr/local/lib/python3.9/tarfile.py", line 2045, in extractall
    self.extract(tarinfo, path, set_attrs=not tarinfo.isdir(),
  File "/usr/local/lib/python3.9/tarfile.py", line 2086, in extract
    self._extract_member(tarinfo, os.path.join(path, tarinfo.name),
  File "/usr/local/lib/python3.9/tarfile.py", line 2159, in _extract_member
    self.makefile(tarinfo, targetpath)
  File "/usr/local/lib/python3.9/tarfile.py", line 2200, in makefile
    with bltn_open(targetpath, "wb") as target:
FileNotFoundError: [Errno 2] No such file or directory: 'dbt_packages/dbt-ml-inline-preprocessing-0.2.4/integration_tests/models/test_rare_category_encode.sql'

[0m17:27:27.830560 [info ] [MainThread]: Installing dbt-labs/dbt_utils
[0m17:27:27.833840 [debug] [MainThread]: Resource report: {"command_name": "deps", "command_success": false, "command_wall_clock_time": 3.1185374, "process_in_blocks": "6864", "process_kernel_time": 0.318081, "process_mem_max_rss": "95404", "process_out_blocks": "6880", "process_user_time": 4.25434}
[0m17:27:27.836873 [debug] [MainThread]: Command `dbt deps` failed at 17:27:27.836491 after 3.12 seconds
[0m17:27:27.839929 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f59da0236d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f59d9e625e0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f59d8f6e4f0>]}
[0m17:27:27.842651 [debug] [MainThread]: Flushing usage events
[0m17:27:28.417253 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m17:27:32.173376 [info ] [MainThread]: Installed from version 1.3.0
[0m17:27:32.175012 [info ] [MainThread]: Up to date!
[0m17:27:32.176946 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'package', 'label': '7549f981-a816-47b7-b4fa-20ce5c2b8d1f', 'property_': 'install', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff8328dc2e0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff834c8ee80>]}
[0m17:27:32.179921 [debug] [MainThread]: Resource report: {"command_name": "deps", "command_success": true, "command_wall_clock_time": 6.5959196, "process_in_blocks": "64", "process_kernel_time": 0.482729, "process_mem_max_rss": "95252", "process_out_blocks": "7048", "process_user_time": 4.525585}
[0m17:27:32.182072 [debug] [MainThread]: Command `dbt deps` succeeded at 17:27:32.181808 after 6.60 seconds
[0m17:27:32.183974 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff83386e6a0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff8336a2e20>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff832871310>]}
[0m17:27:32.185821 [debug] [MainThread]: Flushing usage events
[0m17:27:32.702277 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m17:29:13.332748 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fed65690a90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fed647b1460>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fed647b1400>]}


============================== 17:29:13.346250 | 04a005f5-d778-4672-bab9-0523f4274257 ==============================
[0m17:29:13.346250 [info ] [MainThread]: Running with dbt=1.9.4
[0m17:29:13.348504 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'debug': 'False', 'fail_fast': 'False', 'log_path': '/opt/airflow/dags/dbt/homework/logs', 'version_check': 'True', 'profiles_dir': '/opt/airflow/dags/dbt', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'empty': 'False', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'invocation_command': 'dbt --profile homework run --project-dir=/opt/airflow/dags/dbt/homework --vars {"is_test": false, "data_date": "2025-04-22"}', 'log_format': 'default', 'introspect': 'True', 'target_path': 'None', 'static_parser': 'True', 'send_anonymous_usage_stats': 'True'}
[0m17:29:13.371492 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f7d0a24fa00>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f7d093703d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f7d09370370>]}


============================== 17:29:13.385239 | 35df404d-b3f0-44f8-bc10-fbd105d6f71b ==============================
[0m17:29:13.385239 [info ] [MainThread]: Running with dbt=1.9.4
[0m17:29:13.387612 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'fail_fast': 'False', 'debug': 'False', 'log_path': '/opt/airflow/dags/dbt/homework/logs', 'version_check': 'True', 'profiles_dir': '/opt/airflow/dags/dbt', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'empty': 'False', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'static_parser': 'True', 'introspect': 'True', 'invocation_command': 'dbt --profile homework run --project-dir=/opt/airflow/dags/dbt/homework --vars {"is_test": false, "data_date": "2025-04-23"}', 'target_path': 'None', 'log_format': 'default', 'send_anonymous_usage_stats': 'True'}
[0m17:29:13.824273 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '04a005f5-d778-4672-bab9-0523f4274257', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fed62fd75b0>]}
[0m17:29:13.857332 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '35df404d-b3f0-44f8-bc10-fbd105d6f71b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f7d093b8220>]}
[0m17:29:13.964858 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '04a005f5-d778-4672-bab9-0523f4274257', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fed6550da60>]}
[0m17:29:13.967689 [info ] [MainThread]: Registered adapter: postgres=1.9.0
[0m17:29:14.004651 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '35df404d-b3f0-44f8-bc10-fbd105d6f71b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f7d09334f10>]}
[0m17:29:14.007223 [info ] [MainThread]: Registered adapter: postgres=1.9.0
[0m17:29:14.259394 [debug] [MainThread]: checksum: b4b46bb6a239f66694dfdd44ef1792882cb61f2fd7b1ea66b3c7a170d2bb602d, vars: {'data_date': '2025-04-22', 'is_test': False}, profile: homework, target: , version: 1.9.4
[0m17:29:14.324832 [debug] [MainThread]: checksum: f5df654a850f4b74beb13fbe0c7d8863b5b1a20bd535c3ac287d70e390b64d41, vars: {'data_date': '2025-04-23', 'is_test': False}, profile: homework, target: , version: 1.9.4
[0m17:29:14.596218 [info ] [MainThread]: Unable to do partial parsing because config vars, config profile, or config target have changed
[0m17:29:14.598067 [debug] [MainThread]: previous checksum: b4b46bb6a239f66694dfdd44ef1792882cb61f2fd7b1ea66b3c7a170d2bb602d, current checksum: f5df654a850f4b74beb13fbe0c7d8863b5b1a20bd535c3ac287d70e390b64d41
[0m17:29:14.599710 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'partial_parser', 'label': '04a005f5-d778-4672-bab9-0523f4274257', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fed64ece2e0>]}
[0m17:29:15.426915 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m17:29:15.428516 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m17:29:15.446682 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 1 unused configuration paths:
- seeds.homework.iris_dataset
[0m17:29:15.595126 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '35df404d-b3f0-44f8-bc10-fbd105d6f71b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f7d0769b130>]}
[0m17:29:15.929660 [debug] [MainThread]: Wrote artifact WritableManifest to /opt/airflow/dags/dbt/homework/target/manifest.json
[0m17:29:15.949899 [debug] [MainThread]: Wrote artifact SemanticManifest to /opt/airflow/dags/dbt/homework/target/semantic_manifest.json
[0m17:29:15.990595 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '35df404d-b3f0-44f8-bc10-fbd105d6f71b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f7d0763b3d0>]}
[0m17:29:15.992971 [info ] [MainThread]: Found 2 models, 1 source, 587 macros
[0m17:29:15.994699 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '35df404d-b3f0-44f8-bc10-fbd105d6f71b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f7d093d75b0>]}
[0m17:29:15.998362 [info ] [MainThread]: 
[0m17:29:16.000116 [info ] [MainThread]: Concurrency: 4 threads (target='dev')
[0m17:29:16.002849 [info ] [MainThread]: 
[0m17:29:16.008832 [debug] [MainThread]: Acquiring new postgres connection 'master'
[0m17:29:16.021203 [debug] [ThreadPool]: Acquiring new postgres connection 'list_analytics'
[0m17:29:16.104613 [debug] [ThreadPool]: Using postgres connection "list_analytics"
[0m17:29:16.106660 [debug] [ThreadPool]: On list_analytics: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "homework", "target_name": "dev", "connection_name": "list_analytics"} */

    select distinct nspname from pg_namespace
  
[0m17:29:16.108404 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m17:29:16.125756 [debug] [ThreadPool]: SQL status: SELECT 6 in 0.017 seconds
[0m17:29:16.129368 [debug] [ThreadPool]: On list_analytics: Close
[0m17:29:16.132068 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_analytics, now create_analytics_homework)
[0m17:29:16.134149 [debug] [ThreadPool]: Creating schema "database: "analytics"
schema: "homework"
"
[0m17:29:16.148551 [debug] [ThreadPool]: Using postgres connection "create_analytics_homework"
[0m17:29:16.150313 [debug] [ThreadPool]: On create_analytics_homework: BEGIN
[0m17:29:16.151977 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m17:29:16.165520 [debug] [ThreadPool]: SQL status: BEGIN in 0.013 seconds
[0m17:29:16.167178 [debug] [ThreadPool]: Using postgres connection "create_analytics_homework"
[0m17:29:16.168691 [debug] [ThreadPool]: On create_analytics_homework: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "homework", "target_name": "dev", "connection_name": "create_analytics_homework"} */
create schema if not exists "homework"
[0m17:29:16.173927 [debug] [ThreadPool]: Postgres adapter: Postgres error: permission denied for database analytics

[0m17:29:16.176183 [debug] [ThreadPool]: On create_analytics_homework: ROLLBACK
[0m17:29:16.179604 [debug] [ThreadPool]: Postgres adapter: Error running SQL: macro create_schema
[0m17:29:16.181724 [debug] [ThreadPool]: Postgres adapter: Rolling back transaction.
[0m17:29:16.183831 [debug] [ThreadPool]: On create_analytics_homework: Close
[0m17:29:16.187825 [debug] [MainThread]: Connection 'master' was properly closed.
[0m17:29:16.190670 [debug] [MainThread]: Connection 'create_analytics_homework' was properly closed.
[0m17:29:16.192638 [info ] [MainThread]: 
[0m17:29:16.194449 [info ] [MainThread]: Finished running  in 0 hours 0 minutes and 0.19 seconds (0.19s).
[0m17:29:16.196444 [error] [MainThread]: Encountered an error:
Database Error
  permission denied for database analytics
[0m17:29:16.199389 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": false, "command_wall_clock_time": 2.9831705, "process_in_blocks": "3464", "process_kernel_time": 0.339623, "process_mem_max_rss": "109920", "process_out_blocks": "0", "process_user_time": 5.174257}
[0m17:29:16.201485 [debug] [MainThread]: Command `dbt run` failed at 17:29:16.201276 after 2.99 seconds
[0m17:29:16.205032 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f7d0a24fa00>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f7d093eec40>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f7d09a3fa60>]}
[0m17:29:16.207264 [debug] [MainThread]: Flushing usage events
[0m17:29:16.754601 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m17:29:19.393805 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 1 unused configuration paths:
- seeds.homework.iris_dataset
[0m17:29:19.416932 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '04a005f5-d778-4672-bab9-0523f4274257', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fed62ca4130>]}
[0m17:29:19.607676 [debug] [MainThread]: Wrote artifact WritableManifest to /opt/airflow/dags/dbt/homework/target/manifest.json
[0m17:29:19.623502 [debug] [MainThread]: Wrote artifact SemanticManifest to /opt/airflow/dags/dbt/homework/target/semantic_manifest.json
[0m17:29:19.649167 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '04a005f5-d778-4672-bab9-0523f4274257', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fed62c850d0>]}
[0m17:29:19.650966 [info ] [MainThread]: Found 2 models, 1 source, 587 macros
[0m17:29:19.652176 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '04a005f5-d778-4672-bab9-0523f4274257', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fed61b333d0>]}
[0m17:29:19.654819 [info ] [MainThread]: 
[0m17:29:19.656064 [info ] [MainThread]: Concurrency: 4 threads (target='dev')
[0m17:29:19.657462 [info ] [MainThread]: 
[0m17:29:19.659185 [debug] [MainThread]: Acquiring new postgres connection 'master'
[0m17:29:19.666707 [debug] [ThreadPool]: Acquiring new postgres connection 'list_analytics'
[0m17:29:19.710013 [debug] [ThreadPool]: Using postgres connection "list_analytics"
[0m17:29:19.712022 [debug] [ThreadPool]: On list_analytics: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "homework", "target_name": "dev", "connection_name": "list_analytics"} */

    select distinct nspname from pg_namespace
  
[0m17:29:19.713790 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m17:29:19.724375 [debug] [ThreadPool]: SQL status: SELECT 6 in 0.010 seconds
[0m17:29:19.727403 [debug] [ThreadPool]: On list_analytics: Close
[0m17:29:19.729847 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_analytics, now create_analytics_homework)
[0m17:29:19.732313 [debug] [ThreadPool]: Creating schema "database: "analytics"
schema: "homework"
"
[0m17:29:19.742974 [debug] [ThreadPool]: Using postgres connection "create_analytics_homework"
[0m17:29:19.744822 [debug] [ThreadPool]: On create_analytics_homework: BEGIN
[0m17:29:19.746549 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m17:29:19.755842 [debug] [ThreadPool]: SQL status: BEGIN in 0.009 seconds
[0m17:29:19.757714 [debug] [ThreadPool]: Using postgres connection "create_analytics_homework"
[0m17:29:19.759463 [debug] [ThreadPool]: On create_analytics_homework: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "homework", "target_name": "dev", "connection_name": "create_analytics_homework"} */
create schema if not exists "homework"
[0m17:29:19.761804 [debug] [ThreadPool]: Postgres adapter: Postgres error: permission denied for database analytics

[0m17:29:19.763272 [debug] [ThreadPool]: On create_analytics_homework: ROLLBACK
[0m17:29:19.765187 [debug] [ThreadPool]: Postgres adapter: Error running SQL: macro create_schema
[0m17:29:19.766760 [debug] [ThreadPool]: Postgres adapter: Rolling back transaction.
[0m17:29:19.768307 [debug] [ThreadPool]: On create_analytics_homework: Close
[0m17:29:19.770785 [debug] [MainThread]: Connection 'master' was properly closed.
[0m17:29:19.772645 [debug] [MainThread]: Connection 'create_analytics_homework' was properly closed.
[0m17:29:19.774134 [info ] [MainThread]: 
[0m17:29:19.775717 [info ] [MainThread]: Finished running  in 0 hours 0 minutes and 0.12 seconds (0.12s).
[0m17:29:19.777708 [error] [MainThread]: Encountered an error:
Database Error
  permission denied for database analytics
[0m17:29:19.779863 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": false, "command_wall_clock_time": 6.6149225, "process_in_blocks": "5392", "process_kernel_time": 0.301111, "process_mem_max_rss": "118300", "process_out_blocks": "0", "process_user_time": 8.802505}
[0m17:29:19.781583 [debug] [MainThread]: Command `dbt run` failed at 17:29:19.781438 after 6.62 seconds
[0m17:29:19.783329 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fed65690a90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fed61a5eca0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fed619a96d0>]}
[0m17:29:19.784912 [debug] [MainThread]: Flushing usage events
[0m17:29:20.297981 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m17:29:40.550719 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f1655a3aa90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f1654b5b460>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f1654b5b400>]}


============================== 17:29:40.570721 | 5e3b4651-3c96-4543-ad1e-29e1f05222e9 ==============================
[0m17:29:40.570721 [info ] [MainThread]: Running with dbt=1.9.4
[0m17:29:40.575035 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'version_check': 'True', 'fail_fast': 'False', 'log_path': '/opt/airflow/dags/dbt/homework/logs', 'debug': 'False', 'profiles_dir': '/opt/airflow/dags/dbt', 'use_colors': 'True', 'use_experimental_parser': 'False', 'empty': 'False', 'quiet': 'False', 'no_print': 'None', 'log_format': 'default', 'static_parser': 'True', 'introspect': 'True', 'invocation_command': 'dbt --profile homework run --project-dir=/opt/airflow/dags/dbt/homework --vars {"is_test": false, "data_date": "2025-04-22"}', 'target_path': 'None', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'send_anonymous_usage_stats': 'True'}
[0m17:29:40.564191 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f07568319d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f07559523a0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0755952340>]}


============================== 17:29:40.589765 | 191fa5ff-05a2-4d82-b663-0da4f84e0855 ==============================
[0m17:29:40.589765 [info ] [MainThread]: Running with dbt=1.9.4
[0m17:29:40.596277 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'debug': 'False', 'version_check': 'True', 'log_path': '/opt/airflow/dags/dbt/homework/logs', 'profiles_dir': '/opt/airflow/dags/dbt', 'fail_fast': 'False', 'use_colors': 'True', 'use_experimental_parser': 'False', 'empty': 'False', 'quiet': 'False', 'no_print': 'None', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'introspect': 'True', 'log_format': 'default', 'invocation_command': 'dbt --profile homework run --project-dir=/opt/airflow/dags/dbt/homework --vars {"is_test": false, "data_date": "2025-04-23"}', 'target_path': 'None', 'static_parser': 'True', 'send_anonymous_usage_stats': 'True'}
[0m17:29:41.384559 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '191fa5ff-05a2-4d82-b663-0da4f84e0855', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0754149760>]}
[0m17:29:41.390105 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '5e3b4651-3c96-4543-ad1e-29e1f05222e9', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f16533815b0>]}
[0m17:29:41.559370 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '191fa5ff-05a2-4d82-b663-0da4f84e0855', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f075597ddc0>]}
[0m17:29:41.562136 [info ] [MainThread]: Registered adapter: postgres=1.9.0
[0m17:29:41.566811 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '5e3b4651-3c96-4543-ad1e-29e1f05222e9', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f16558b7a60>]}
[0m17:29:41.569896 [info ] [MainThread]: Registered adapter: postgres=1.9.0
[0m17:29:41.982788 [debug] [MainThread]: checksum: f5df654a850f4b74beb13fbe0c7d8863b5b1a20bd535c3ac287d70e390b64d41, vars: {'data_date': '2025-04-23', 'is_test': False}, profile: homework, target: , version: 1.9.4
[0m17:29:42.001074 [debug] [MainThread]: checksum: b4b46bb6a239f66694dfdd44ef1792882cb61f2fd7b1ea66b3c7a170d2bb602d, vars: {'data_date': '2025-04-22', 'is_test': False}, profile: homework, target: , version: 1.9.4
[0m17:29:42.397852 [info ] [MainThread]: Unable to do partial parsing because config vars, config profile, or config target have changed
[0m17:29:42.400177 [debug] [MainThread]: previous checksum: f5df654a850f4b74beb13fbe0c7d8863b5b1a20bd535c3ac287d70e390b64d41, current checksum: b4b46bb6a239f66694dfdd44ef1792882cb61f2fd7b1ea66b3c7a170d2bb602d
[0m17:29:42.402486 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'partial_parser', 'label': '191fa5ff-05a2-4d82-b663-0da4f84e0855', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0756076e80>]}
[0m17:29:43.290845 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m17:29:43.293173 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m17:29:43.309452 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 1 unused configuration paths:
- seeds.homework.iris_dataset
[0m17:29:43.422099 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '5e3b4651-3c96-4543-ad1e-29e1f05222e9', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f1652e86130>]}
[0m17:29:43.817329 [debug] [MainThread]: Wrote artifact WritableManifest to /opt/airflow/dags/dbt/homework/target/manifest.json
[0m17:29:43.842788 [debug] [MainThread]: Wrote artifact SemanticManifest to /opt/airflow/dags/dbt/homework/target/semantic_manifest.json
[0m17:29:43.905491 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '5e3b4651-3c96-4543-ad1e-29e1f05222e9', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f16532753d0>]}
[0m17:29:43.909589 [info ] [MainThread]: Found 2 models, 1 source, 587 macros
[0m17:29:43.913642 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '5e3b4651-3c96-4543-ad1e-29e1f05222e9', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f1654bc0970>]}
[0m17:29:43.917937 [info ] [MainThread]: 
[0m17:29:43.920990 [info ] [MainThread]: Concurrency: 4 threads (target='dev')
[0m17:29:43.924527 [info ] [MainThread]: 
[0m17:29:43.931561 [debug] [MainThread]: Acquiring new postgres connection 'master'
[0m17:29:43.951395 [debug] [ThreadPool]: Acquiring new postgres connection 'list_analytics'
[0m17:29:44.059271 [debug] [ThreadPool]: Using postgres connection "list_analytics"
[0m17:29:44.062483 [debug] [ThreadPool]: On list_analytics: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "homework", "target_name": "dev", "connection_name": "list_analytics"} */

    select distinct nspname from pg_namespace
  
[0m17:29:44.064836 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m17:29:44.082419 [debug] [ThreadPool]: SQL status: SELECT 6 in 0.018 seconds
[0m17:29:44.087024 [debug] [ThreadPool]: On list_analytics: Close
[0m17:29:44.090488 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_analytics, now create_analytics_homework)
[0m17:29:44.093825 [debug] [ThreadPool]: Creating schema "database: "analytics"
schema: "homework"
"
[0m17:29:44.114191 [debug] [ThreadPool]: Using postgres connection "create_analytics_homework"
[0m17:29:44.116423 [debug] [ThreadPool]: On create_analytics_homework: BEGIN
[0m17:29:44.118332 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m17:29:44.132633 [debug] [ThreadPool]: SQL status: BEGIN in 0.014 seconds
[0m17:29:44.134947 [debug] [ThreadPool]: Using postgres connection "create_analytics_homework"
[0m17:29:44.136888 [debug] [ThreadPool]: On create_analytics_homework: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "homework", "target_name": "dev", "connection_name": "create_analytics_homework"} */
create schema if not exists "homework"
[0m17:29:44.139462 [debug] [ThreadPool]: Postgres adapter: Postgres error: permission denied for database analytics

[0m17:29:44.141551 [debug] [ThreadPool]: On create_analytics_homework: ROLLBACK
[0m17:29:44.144640 [debug] [ThreadPool]: Postgres adapter: Error running SQL: macro create_schema
[0m17:29:44.146589 [debug] [ThreadPool]: Postgres adapter: Rolling back transaction.
[0m17:29:44.148833 [debug] [ThreadPool]: On create_analytics_homework: Close
[0m17:29:44.152344 [debug] [MainThread]: Connection 'master' was properly closed.
[0m17:29:44.154996 [debug] [MainThread]: Connection 'create_analytics_homework' was properly closed.
[0m17:29:44.156855 [info ] [MainThread]: 
[0m17:29:44.160539 [info ] [MainThread]: Finished running  in 0 hours 0 minutes and 0.23 seconds (0.23s).
[0m17:29:44.162864 [error] [MainThread]: Encountered an error:
Database Error
  permission denied for database analytics
[0m17:29:44.165968 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": false, "command_wall_clock_time": 3.8056831, "process_in_blocks": "24", "process_kernel_time": 0.480501, "process_mem_max_rss": "110100", "process_out_blocks": "0", "process_user_time": 8.989383}
[0m17:29:44.168387 [debug] [MainThread]: Command `dbt run` failed at 17:29:44.168143 after 3.81 seconds
[0m17:29:44.170586 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f1655a3aa90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f1654bd9190>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f1652591970>]}
[0m17:29:44.172462 [debug] [MainThread]: Flushing usage events
[0m17:29:44.743793 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m17:29:48.663968 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 1 unused configuration paths:
- seeds.homework.iris_dataset
[0m17:29:48.699952 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '191fa5ff-05a2-4d82-b663-0da4f84e0855', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0753df1130>]}
[0m17:29:48.968571 [debug] [MainThread]: Wrote artifact WritableManifest to /opt/airflow/dags/dbt/homework/target/manifest.json
[0m17:29:48.988979 [debug] [MainThread]: Wrote artifact SemanticManifest to /opt/airflow/dags/dbt/homework/target/semantic_manifest.json
[0m17:29:49.025600 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '191fa5ff-05a2-4d82-b663-0da4f84e0855', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0757549ac0>]}
[0m17:29:49.029340 [info ] [MainThread]: Found 2 models, 1 source, 587 macros
[0m17:29:49.031923 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '191fa5ff-05a2-4d82-b663-0da4f84e0855', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0753dd6400>]}
[0m17:29:49.036030 [info ] [MainThread]: 
[0m17:29:49.039000 [info ] [MainThread]: Concurrency: 4 threads (target='dev')
[0m17:29:49.041142 [info ] [MainThread]: 
[0m17:29:49.044257 [debug] [MainThread]: Acquiring new postgres connection 'master'
[0m17:29:49.062980 [debug] [ThreadPool]: Acquiring new postgres connection 'list_analytics'
[0m17:29:49.135886 [debug] [ThreadPool]: Using postgres connection "list_analytics"
[0m17:29:49.137654 [debug] [ThreadPool]: On list_analytics: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "homework", "target_name": "dev", "connection_name": "list_analytics"} */

    select distinct nspname from pg_namespace
  
[0m17:29:49.139332 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m17:29:49.154401 [debug] [ThreadPool]: SQL status: SELECT 6 in 0.015 seconds
[0m17:29:49.158167 [debug] [ThreadPool]: On list_analytics: Close
[0m17:29:49.160993 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_analytics, now create_analytics_homework)
[0m17:29:49.163967 [debug] [ThreadPool]: Creating schema "database: "analytics"
schema: "homework"
"
[0m17:29:49.182864 [debug] [ThreadPool]: Using postgres connection "create_analytics_homework"
[0m17:29:49.185296 [debug] [ThreadPool]: On create_analytics_homework: BEGIN
[0m17:29:49.187145 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m17:29:49.205166 [debug] [ThreadPool]: SQL status: BEGIN in 0.018 seconds
[0m17:29:49.208260 [debug] [ThreadPool]: Using postgres connection "create_analytics_homework"
[0m17:29:49.216130 [debug] [ThreadPool]: On create_analytics_homework: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "homework", "target_name": "dev", "connection_name": "create_analytics_homework"} */
create schema if not exists "homework"
[0m17:29:49.220678 [debug] [ThreadPool]: Postgres adapter: Postgres error: permission denied for database analytics

[0m17:29:49.225024 [debug] [ThreadPool]: On create_analytics_homework: ROLLBACK
[0m17:29:49.233172 [debug] [ThreadPool]: Postgres adapter: Error running SQL: macro create_schema
[0m17:29:49.237322 [debug] [ThreadPool]: Postgres adapter: Rolling back transaction.
[0m17:29:49.240428 [debug] [ThreadPool]: On create_analytics_homework: Close
[0m17:29:49.244896 [debug] [MainThread]: Connection 'master' was properly closed.
[0m17:29:49.251556 [debug] [MainThread]: Connection 'create_analytics_homework' was properly closed.
[0m17:29:49.254582 [info ] [MainThread]: 
[0m17:29:49.258041 [info ] [MainThread]: Finished running  in 0 hours 0 minutes and 0.21 seconds (0.21s).
[0m17:29:49.262305 [error] [MainThread]: Encountered an error:
Database Error
  permission denied for database analytics
[0m17:29:49.269243 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": false, "command_wall_clock_time": 8.906182, "process_in_blocks": "864", "process_kernel_time": 0.672032, "process_mem_max_rss": "116484", "process_out_blocks": "0", "process_user_time": 13.881992}
[0m17:29:49.273486 [debug] [MainThread]: Command `dbt run` failed at 17:29:49.272935 after 8.91 seconds
[0m17:29:49.281355 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f07568319d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f07529febe0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0752949610>]}
[0m17:29:49.286462 [debug] [MainThread]: Flushing usage events
[0m17:29:49.860745 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m17:30:20.284277 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fcf07959a60>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fcf06a7a400>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fcf06a7a3a0>]}


============================== 17:30:20.307405 | d851a83c-8f46-4d78-bbb1-dd9c19a9953f ==============================
[0m17:30:20.307405 [info ] [MainThread]: Running with dbt=1.9.4
[0m17:30:20.310876 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': '/opt/airflow/dags/dbt', 'version_check': 'True', 'fail_fast': 'False', 'log_path': '/opt/airflow/dags/dbt/homework/logs', 'warn_error': 'None', 'debug': 'False', 'use_colors': 'True', 'use_experimental_parser': 'False', 'empty': 'False', 'quiet': 'False', 'no_print': 'None', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'introspect': 'True', 'log_format': 'default', 'static_parser': 'True', 'target_path': 'None', 'invocation_command': 'dbt --profile homework run --project-dir=/opt/airflow/dags/dbt/homework --vars {"is_test": false, "data_date": "2025-04-22"}', 'send_anonymous_usage_stats': 'True'}
[0m17:30:20.389481 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f69c4b02a30>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f69c3c23400>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f69c3c233a0>]}


============================== 17:30:20.412957 | 243d68cc-1999-49d8-99a3-5203767fbe39 ==============================
[0m17:30:20.412957 [info ] [MainThread]: Running with dbt=1.9.4
[0m17:30:20.417062 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'version_check': 'True', 'debug': 'False', 'log_path': '/opt/airflow/dags/dbt/homework/logs', 'fail_fast': 'False', 'profiles_dir': '/opt/airflow/dags/dbt', 'use_colors': 'True', 'use_experimental_parser': 'False', 'empty': 'False', 'quiet': 'False', 'no_print': 'None', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'static_parser': 'True', 'log_format': 'default', 'invocation_command': 'dbt --profile homework run --project-dir=/opt/airflow/dags/dbt/homework --vars {"is_test": false, "data_date": "2025-04-23"}', 'target_path': 'None', 'introspect': 'True', 'send_anonymous_usage_stats': 'True'}
[0m17:30:21.246499 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'd851a83c-8f46-4d78-bbb1-dd9c19a9953f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fcf051b28b0>]}
[0m17:30:21.349532 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '243d68cc-1999-49d8-99a3-5203767fbe39', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f69c233e3d0>]}
[0m17:30:21.517691 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': 'd851a83c-8f46-4d78-bbb1-dd9c19a9953f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fcf05244190>]}
[0m17:30:21.525093 [info ] [MainThread]: Registered adapter: postgres=1.9.0
[0m17:30:21.673245 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '243d68cc-1999-49d8-99a3-5203767fbe39', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f69c3e43400>]}
[0m17:30:21.681277 [info ] [MainThread]: Registered adapter: postgres=1.9.0
[0m17:30:22.165407 [debug] [MainThread]: checksum: b4b46bb6a239f66694dfdd44ef1792882cb61f2fd7b1ea66b3c7a170d2bb602d, vars: {'data_date': '2025-04-22', 'is_test': False}, profile: homework, target: , version: 1.9.4
[0m17:30:22.321442 [debug] [MainThread]: checksum: f5df654a850f4b74beb13fbe0c7d8863b5b1a20bd535c3ac287d70e390b64d41, vars: {'data_date': '2025-04-23', 'is_test': False}, profile: homework, target: , version: 1.9.4
[0m17:30:22.730404 [info ] [MainThread]: Unable to do partial parsing because config vars, config profile, or config target have changed
[0m17:30:22.733523 [debug] [MainThread]: previous checksum: b4b46bb6a239f66694dfdd44ef1792882cb61f2fd7b1ea66b3c7a170d2bb602d, current checksum: f5df654a850f4b74beb13fbe0c7d8863b5b1a20bd535c3ac287d70e390b64d41
[0m17:30:22.736021 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'partial_parser', 'label': 'd851a83c-8f46-4d78-bbb1-dd9c19a9953f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fcf07197d90>]}
[0m17:30:24.606041 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m17:30:24.611221 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m17:30:24.637753 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 1 unused configuration paths:
- seeds.homework.iris_dataset
[0m17:30:24.801958 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '243d68cc-1999-49d8-99a3-5203767fbe39', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f69c1f4f130>]}
[0m17:30:25.485891 [debug] [MainThread]: Wrote artifact WritableManifest to /opt/airflow/dags/dbt/homework/target/manifest.json
[0m17:30:25.515127 [debug] [MainThread]: Wrote artifact SemanticManifest to /opt/airflow/dags/dbt/homework/target/semantic_manifest.json
[0m17:30:25.573805 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '243d68cc-1999-49d8-99a3-5203767fbe39', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f69c1eefcd0>]}
[0m17:30:25.576669 [info ] [MainThread]: Found 2 models, 1 source, 587 macros
[0m17:30:25.578681 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '243d68cc-1999-49d8-99a3-5203767fbe39', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f69c3cb1f40>]}
[0m17:30:25.583559 [info ] [MainThread]: 
[0m17:30:25.585875 [info ] [MainThread]: Concurrency: 4 threads (target='dev')
[0m17:30:25.588384 [info ] [MainThread]: 
[0m17:30:25.590840 [debug] [MainThread]: Acquiring new postgres connection 'master'
[0m17:30:25.609066 [debug] [ThreadPool]: Acquiring new postgres connection 'list_analytics'
[0m17:30:25.731397 [debug] [ThreadPool]: Using postgres connection "list_analytics"
[0m17:30:25.733775 [debug] [ThreadPool]: On list_analytics: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "homework", "target_name": "dev", "connection_name": "list_analytics"} */

    select distinct nspname from pg_namespace
  
[0m17:30:25.736737 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m17:30:25.759344 [debug] [ThreadPool]: SQL status: SELECT 6 in 0.023 seconds
[0m17:30:25.764063 [debug] [ThreadPool]: On list_analytics: Close
[0m17:30:25.768314 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_analytics, now create_analytics_homework)
[0m17:30:25.771672 [debug] [ThreadPool]: Creating schema "database: "analytics"
schema: "homework"
"
[0m17:30:25.798407 [debug] [ThreadPool]: Using postgres connection "create_analytics_homework"
[0m17:30:25.801008 [debug] [ThreadPool]: On create_analytics_homework: BEGIN
[0m17:30:25.804088 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m17:30:25.820939 [debug] [ThreadPool]: SQL status: BEGIN in 0.017 seconds
[0m17:30:25.823587 [debug] [ThreadPool]: Using postgres connection "create_analytics_homework"
[0m17:30:25.827525 [debug] [ThreadPool]: On create_analytics_homework: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "homework", "target_name": "dev", "connection_name": "create_analytics_homework"} */
create schema if not exists "homework"
[0m17:30:25.831290 [debug] [ThreadPool]: Postgres adapter: Postgres error: permission denied for database analytics

[0m17:30:25.834072 [debug] [ThreadPool]: On create_analytics_homework: ROLLBACK
[0m17:30:25.837503 [debug] [ThreadPool]: Postgres adapter: Error running SQL: macro create_schema
[0m17:30:25.840260 [debug] [ThreadPool]: Postgres adapter: Rolling back transaction.
[0m17:30:25.845612 [debug] [ThreadPool]: On create_analytics_homework: Close
[0m17:30:25.852426 [debug] [MainThread]: Connection 'master' was properly closed.
[0m17:30:25.855359 [debug] [MainThread]: Connection 'create_analytics_homework' was properly closed.
[0m17:30:25.859800 [info ] [MainThread]: 
[0m17:30:25.862959 [info ] [MainThread]: Finished running  in 0 hours 0 minutes and 0.27 seconds (0.27s).
[0m17:30:25.866915 [error] [MainThread]: Encountered an error:
Database Error
  permission denied for database analytics
[0m17:30:25.872099 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": false, "command_wall_clock_time": 5.815928, "process_in_blocks": "0", "process_kernel_time": 0.540746, "process_mem_max_rss": "110352", "process_out_blocks": "0", "process_user_time": 9.162653}
[0m17:30:25.876422 [debug] [MainThread]: Command `dbt run` failed at 17:30:25.875930 after 5.82 seconds
[0m17:30:25.879543 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f69c4b02a30>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f69c3ca12b0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f69c1ed9850>]}
[0m17:30:25.882799 [debug] [MainThread]: Flushing usage events
[0m17:30:26.592064 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m17:30:29.779903 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 1 unused configuration paths:
- seeds.homework.iris_dataset
[0m17:30:29.816202 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'd851a83c-8f46-4d78-bbb1-dd9c19a9953f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fcf04f23130>]}
[0m17:30:30.118735 [debug] [MainThread]: Wrote artifact WritableManifest to /opt/airflow/dags/dbt/homework/target/manifest.json
[0m17:30:30.140860 [debug] [MainThread]: Wrote artifact SemanticManifest to /opt/airflow/dags/dbt/homework/target/semantic_manifest.json
[0m17:30:30.184140 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'd851a83c-8f46-4d78-bbb1-dd9c19a9953f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fceefb9e130>]}
[0m17:30:30.186636 [info ] [MainThread]: Found 2 models, 1 source, 587 macros
[0m17:30:30.188553 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'd851a83c-8f46-4d78-bbb1-dd9c19a9953f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fcf05244190>]}
[0m17:30:30.192545 [info ] [MainThread]: 
[0m17:30:30.194525 [info ] [MainThread]: Concurrency: 4 threads (target='dev')
[0m17:30:30.197358 [info ] [MainThread]: 
[0m17:30:30.200224 [debug] [MainThread]: Acquiring new postgres connection 'master'
[0m17:30:30.216467 [debug] [ThreadPool]: Acquiring new postgres connection 'list_analytics'
[0m17:30:30.296880 [debug] [ThreadPool]: Using postgres connection "list_analytics"
[0m17:30:30.299202 [debug] [ThreadPool]: On list_analytics: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "homework", "target_name": "dev", "connection_name": "list_analytics"} */

    select distinct nspname from pg_namespace
  
[0m17:30:30.301096 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m17:30:30.316657 [debug] [ThreadPool]: SQL status: SELECT 6 in 0.016 seconds
[0m17:30:30.320874 [debug] [ThreadPool]: On list_analytics: Close
[0m17:30:30.324143 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_analytics, now create_analytics_homework)
[0m17:30:30.327382 [debug] [ThreadPool]: Creating schema "database: "analytics"
schema: "homework"
"
[0m17:30:30.344966 [debug] [ThreadPool]: Using postgres connection "create_analytics_homework"
[0m17:30:30.347466 [debug] [ThreadPool]: On create_analytics_homework: BEGIN
[0m17:30:30.349287 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m17:30:30.363469 [debug] [ThreadPool]: SQL status: BEGIN in 0.014 seconds
[0m17:30:30.366546 [debug] [ThreadPool]: Using postgres connection "create_analytics_homework"
[0m17:30:30.368801 [debug] [ThreadPool]: On create_analytics_homework: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "homework", "target_name": "dev", "connection_name": "create_analytics_homework"} */
create schema if not exists "homework"
[0m17:30:30.371655 [debug] [ThreadPool]: Postgres adapter: Postgres error: permission denied for database analytics

[0m17:30:30.373955 [debug] [ThreadPool]: On create_analytics_homework: ROLLBACK
[0m17:30:30.376288 [debug] [ThreadPool]: Postgres adapter: Error running SQL: macro create_schema
[0m17:30:30.378096 [debug] [ThreadPool]: Postgres adapter: Rolling back transaction.
[0m17:30:30.380496 [debug] [ThreadPool]: On create_analytics_homework: Close
[0m17:30:30.384109 [debug] [MainThread]: Connection 'master' was properly closed.
[0m17:30:30.386238 [debug] [MainThread]: Connection 'create_analytics_homework' was properly closed.
[0m17:30:30.388142 [info ] [MainThread]: 
[0m17:30:30.390129 [info ] [MainThread]: Finished running  in 0 hours 0 minutes and 0.19 seconds (0.19s).
[0m17:30:30.392373 [error] [MainThread]: Encountered an error:
Database Error
  permission denied for database analytics
[0m17:30:30.395410 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": false, "command_wall_clock_time": 10.439213, "process_in_blocks": "184", "process_kernel_time": 0.667749, "process_mem_max_rss": "118388", "process_out_blocks": "0", "process_user_time": 13.574256}
[0m17:30:30.398323 [debug] [MainThread]: Command `dbt run` failed at 17:30:30.398023 after 10.44 seconds
[0m17:30:30.400756 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fcf07959a60>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fceefafb2b0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fceefa46670>]}
[0m17:30:30.402787 [debug] [MainThread]: Flushing usage events
[0m17:30:30.916357 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m17:53:42.627132 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fe89c1446d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fe89b3023a0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fe89bee0220>]}


============================== 17:53:42.644509 | 5e2fb552-5236-40c3-ac89-b63c3c489844 ==============================
[0m17:53:42.644509 [info ] [MainThread]: Running with dbt=1.9.4
[0m17:53:42.647696 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'version_check': 'True', 'profiles_dir': '/opt/airflow/dags/dbt', 'log_path': '/opt/airflow/dags/dbt/homework/logs', 'fail_fast': 'False', 'debug': 'False', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'empty': 'None', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'static_parser': 'True', 'introspect': 'True', 'invocation_command': 'dbt deps --profiles-dir /opt/airflow/dags/dbt --project-dir /opt/airflow/dags/dbt/homework', 'target_path': 'None', 'log_format': 'default', 'send_anonymous_usage_stats': 'True'}
[0m17:53:42.996027 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f96ace3d670>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f96abf57f10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f96abf57eb0>]}


============================== 17:53:43.008008 | 4444fed1-0fad-47ab-a705-c77adab39894 ==============================
[0m17:53:43.008008 [info ] [MainThread]: Running with dbt=1.9.4
[0m17:53:43.010633 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': '/opt/airflow/dags/dbt', 'debug': 'False', 'fail_fast': 'False', 'log_path': '/opt/airflow/dags/dbt/homework/logs', 'warn_error': 'None', 'version_check': 'True', 'use_colors': 'True', 'use_experimental_parser': 'False', 'empty': 'None', 'quiet': 'False', 'no_print': 'None', 'log_format': 'default', 'introspect': 'True', 'invocation_command': 'dbt deps --profiles-dir /opt/airflow/dags/dbt --project-dir /opt/airflow/dags/dbt/homework', 'static_parser': 'True', 'target_path': 'None', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'send_anonymous_usage_stats': 'True'}
[0m17:53:43.029026 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '5e2fb552-5236-40c3-ac89-b63c3c489844', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fe89b3490d0>]}
[0m17:53:43.333541 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '4444fed1-0fad-47ab-a705-c77adab39894', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f96ac641490>]}
[0m17:53:43.384375 [error] [MainThread]: Encountered an error:
[Errno 2] No such file or directory: 'data_events_20180102.csv'
[0m17:53:43.387983 [error] [MainThread]: Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/dbt/cli/requires.py", line 153, in wrapper
    result, success = func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.9/site-packages/dbt/cli/requires.py", line 103, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.9/site-packages/dbt/cli/requires.py", line 218, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.9/site-packages/dbt/cli/requires.py", line 264, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.9/site-packages/dbt/cli/main.py", line 455, in deps
    results = task.run()
  File "/home/airflow/.local/lib/python3.9/site-packages/dbt/task/deps.py", line 227, in run
    system.rmtree(self.project.packages_install_path)
  File "/home/airflow/.local/lib/python3.9/site-packages/dbt_common/clients/system.py", line 715, in rmtree
    return shutil.rmtree(path, onerror=chmod_and_retry)
  File "/usr/local/lib/python3.9/shutil.py", line 734, in rmtree
    _rmtree_safe_fd(fd, path, onerror)
  File "/usr/local/lib/python3.9/shutil.py", line 667, in _rmtree_safe_fd
    _rmtree_safe_fd(dirfd, fullname, onerror)
  File "/usr/local/lib/python3.9/shutil.py", line 667, in _rmtree_safe_fd
    _rmtree_safe_fd(dirfd, fullname, onerror)
  File "/usr/local/lib/python3.9/shutil.py", line 667, in _rmtree_safe_fd
    _rmtree_safe_fd(dirfd, fullname, onerror)
  [Previous line repeated 1 more time]
  File "/usr/local/lib/python3.9/shutil.py", line 690, in _rmtree_safe_fd
    onerror(os.unlink, fullname, sys.exc_info())
  File "/usr/local/lib/python3.9/shutil.py", line 688, in _rmtree_safe_fd
    os.unlink(entry.name, dir_fd=topfd)
FileNotFoundError: [Errno 2] No such file or directory: 'data_events_20180102.csv'

[0m17:53:43.391691 [debug] [MainThread]: Resource report: {"command_name": "deps", "command_success": false, "command_wall_clock_time": 0.97654253, "process_in_blocks": "4592", "process_kernel_time": 0.439994, "process_mem_max_rss": "92144", "process_out_blocks": "5744", "process_user_time": 5.13993}
[0m17:53:43.393865 [debug] [MainThread]: Command `dbt deps` failed at 17:53:43.393658 after 0.98 seconds
[0m17:53:43.395659 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fe89c1446d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fe89b147e20>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fe89b0dd580>]}
[0m17:53:43.397449 [debug] [MainThread]: Flushing usage events
[0m17:53:43.960022 [debug] [MainThread]: Set downloads directory='/tmp/dbt-downloads-m4_jz8rd'
[0m17:53:43.963583 [debug] [MainThread]: Making package index registry request: GET https://hub.getdbt.com/api/v1/index.json
[0m17:53:43.993957 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m17:53:44.222261 [debug] [MainThread]: Response from registry index: GET https://hub.getdbt.com/api/v1/index.json 200
[0m17:53:44.226201 [debug] [MainThread]: Making package registry request: GET https://hub.getdbt.com/api/v1/Matts52/dbt_ml_inline_preprocessing.json
[0m17:53:44.483078 [debug] [MainThread]: Response from registry: GET https://hub.getdbt.com/api/v1/Matts52/dbt_ml_inline_preprocessing.json 200
[0m17:53:44.487595 [debug] [MainThread]: Making package registry request: GET https://hub.getdbt.com/api/v1/dbt-labs/dbt_utils.json
[0m17:53:44.691633 [debug] [MainThread]: Response from registry: GET https://hub.getdbt.com/api/v1/dbt-labs/dbt_utils.json 200
[0m17:53:44.708336 [info ] [MainThread]: Installing Matts52/dbt_ml_inline_preprocessing
[0m17:53:47.707704 [info ] [MainThread]: Installed from version 0.2.4
[0m17:53:47.709841 [info ] [MainThread]: Up to date!
[0m17:53:47.712221 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'package', 'label': '4444fed1-0fad-47ab-a705-c77adab39894', 'property_': 'install', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f96acc54160>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f96abd87d00>]}
[0m17:53:47.714490 [info ] [MainThread]: Installing dbt-labs/dbt_utils
[0m17:53:52.530262 [info ] [MainThread]: Installed from version 1.3.0
[0m17:53:52.531770 [info ] [MainThread]: Up to date!
[0m17:53:52.533401 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'package', 'label': '4444fed1-0fad-47ab-a705-c77adab39894', 'property_': 'install', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f96acc54160>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f96abe471f0>]}
[0m17:53:52.536213 [debug] [MainThread]: Resource report: {"command_name": "deps", "command_success": true, "command_wall_clock_time": 9.745281, "process_in_blocks": "0", "process_kernel_time": 0.69584, "process_mem_max_rss": "95324", "process_out_blocks": "7048", "process_user_time": 5.588133}
[0m17:53:52.538002 [debug] [MainThread]: Command `dbt deps` succeeded at 17:53:52.537800 after 9.75 seconds
[0m17:53:52.539480 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f96ace3d670>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f96ae347370>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f96abf1f9d0>]}
[0m17:53:52.540871 [debug] [MainThread]: Flushing usage events
[0m17:53:53.070686 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m17:55:26.691560 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f44eba60a30>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f44eab81400>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f44eab813a0>]}


============================== 17:55:26.713593 | 06f86d62-5c2b-4d4d-b531-f607035cdc3c ==============================
[0m17:55:26.713593 [info ] [MainThread]: Running with dbt=1.9.4
[0m17:55:26.716536 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'version_check': 'True', 'profiles_dir': '/opt/airflow/dags/dbt', 'log_path': '/opt/airflow/dags/dbt/homework/logs', 'fail_fast': 'False', 'debug': 'False', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'empty': 'False', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'introspect': 'True', 'static_parser': 'True', 'invocation_command': 'dbt --profile homework run --project-dir=/opt/airflow/dags/dbt/homework --vars {"is_test": false, "data_date": "2025-04-23"}', 'target_path': 'None', 'log_format': 'default', 'send_anonymous_usage_stats': 'True'}
[0m17:55:26.700996 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f68909b3a60>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f688fad4490>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f688fad4430>]}


============================== 17:55:26.724901 | 3a39fe5d-7cfb-4424-8e42-0479b25a09c6 ==============================
[0m17:55:26.724901 [info ] [MainThread]: Running with dbt=1.9.4
[0m17:55:26.728085 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': '/opt/airflow/dags/dbt', 'version_check': 'True', 'warn_error': 'None', 'log_path': '/opt/airflow/dags/dbt/homework/logs', 'debug': 'False', 'fail_fast': 'False', 'use_colors': 'True', 'use_experimental_parser': 'False', 'empty': 'False', 'quiet': 'False', 'no_print': 'None', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'introspect': 'True', 'static_parser': 'True', 'invocation_command': 'dbt --profile homework run --project-dir=/opt/airflow/dags/dbt/homework --vars {"is_test": false, "data_date": "2025-04-22"}', 'target_path': 'None', 'log_format': 'default', 'send_anonymous_usage_stats': 'True'}
[0m17:55:27.440821 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '06f86d62-5c2b-4d4d-b531-f607035cdc3c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f44e929c3d0>]}
[0m17:55:27.461773 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '3a39fe5d-7cfb-4424-8e42-0479b25a09c6', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f688fb52dc0>]}
[0m17:55:27.669774 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '06f86d62-5c2b-4d4d-b531-f607035cdc3c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f44eada1400>]}
[0m17:55:27.674700 [info ] [MainThread]: Registered adapter: postgres=1.9.0
[0m17:55:27.701585 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '3a39fe5d-7cfb-4424-8e42-0479b25a09c6', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f688fb14070>]}
[0m17:55:27.705713 [info ] [MainThread]: Registered adapter: postgres=1.9.0
[0m17:55:28.092011 [debug] [MainThread]: checksum: f5df654a850f4b74beb13fbe0c7d8863b5b1a20bd535c3ac287d70e390b64d41, vars: {'data_date': '2025-04-23', 'is_test': False}, profile: homework, target: , version: 1.9.4
[0m17:55:28.123684 [debug] [MainThread]: checksum: b4b46bb6a239f66694dfdd44ef1792882cb61f2fd7b1ea66b3c7a170d2bb602d, vars: {'data_date': '2025-04-22', 'is_test': False}, profile: homework, target: , version: 1.9.4
[0m17:55:28.583116 [info ] [MainThread]: Unable to do partial parsing because config vars, config profile, or config target have changed
[0m17:55:28.586109 [debug] [MainThread]: previous checksum: f5df654a850f4b74beb13fbe0c7d8863b5b1a20bd535c3ac287d70e390b64d41, current checksum: b4b46bb6a239f66694dfdd44ef1792882cb61f2fd7b1ea66b3c7a170d2bb602d
[0m17:55:28.591067 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'partial_parser', 'label': '06f86d62-5c2b-4d4d-b531-f607035cdc3c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f44eb8ac700>]}
[0m17:55:29.478982 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m17:55:29.480778 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m17:55:29.502635 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 1 unused configuration paths:
- seeds.homework.iris_dataset
[0m17:55:29.675837 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '3a39fe5d-7cfb-4424-8e42-0479b25a09c6', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f688de00130>]}
[0m17:55:30.063851 [debug] [MainThread]: Wrote artifact WritableManifest to /opt/airflow/dags/dbt/homework/target/manifest.json
[0m17:55:30.094191 [debug] [MainThread]: Wrote artifact SemanticManifest to /opt/airflow/dags/dbt/homework/target/semantic_manifest.json
[0m17:55:30.142361 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '3a39fe5d-7cfb-4424-8e42-0479b25a09c6', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f688e26ac40>]}
[0m17:55:30.147763 [info ] [MainThread]: Found 2 models, 1 source, 587 macros
[0m17:55:30.150277 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '3a39fe5d-7cfb-4424-8e42-0479b25a09c6', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6891daabe0>]}
[0m17:55:30.154816 [info ] [MainThread]: 
[0m17:55:30.159908 [info ] [MainThread]: Concurrency: 4 threads (target='dev')
[0m17:55:30.164349 [info ] [MainThread]: 
[0m17:55:30.168693 [debug] [MainThread]: Acquiring new postgres connection 'master'
[0m17:55:30.194894 [debug] [ThreadPool]: Acquiring new postgres connection 'list_analytics'
[0m17:55:30.286473 [debug] [ThreadPool]: Using postgres connection "list_analytics"
[0m17:55:30.288102 [debug] [ThreadPool]: On list_analytics: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "homework", "target_name": "dev", "connection_name": "list_analytics"} */

    select distinct nspname from pg_namespace
  
[0m17:55:30.290141 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m17:55:30.307499 [debug] [ThreadPool]: SQL status: SELECT 6 in 0.017 seconds
[0m17:55:30.310833 [debug] [ThreadPool]: On list_analytics: Close
[0m17:55:30.313338 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_analytics, now create_analytics_homework)
[0m17:55:30.315841 [debug] [ThreadPool]: Creating schema "database: "analytics"
schema: "homework"
"
[0m17:55:30.338640 [debug] [ThreadPool]: Using postgres connection "create_analytics_homework"
[0m17:55:30.341421 [debug] [ThreadPool]: On create_analytics_homework: BEGIN
[0m17:55:30.344377 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m17:55:30.361366 [debug] [ThreadPool]: SQL status: BEGIN in 0.017 seconds
[0m17:55:30.364403 [debug] [ThreadPool]: Using postgres connection "create_analytics_homework"
[0m17:55:30.367135 [debug] [ThreadPool]: On create_analytics_homework: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "homework", "target_name": "dev", "connection_name": "create_analytics_homework"} */
create schema if not exists "homework"
[0m17:55:30.371200 [debug] [ThreadPool]: Postgres adapter: Postgres error: permission denied for database analytics

[0m17:55:30.374023 [debug] [ThreadPool]: On create_analytics_homework: ROLLBACK
[0m17:55:30.377627 [debug] [ThreadPool]: Postgres adapter: Error running SQL: macro create_schema
[0m17:55:30.379990 [debug] [ThreadPool]: Postgres adapter: Rolling back transaction.
[0m17:55:30.382366 [debug] [ThreadPool]: On create_analytics_homework: Close
[0m17:55:30.386540 [debug] [MainThread]: Connection 'master' was properly closed.
[0m17:55:30.390579 [debug] [MainThread]: Connection 'create_analytics_homework' was properly closed.
[0m17:55:30.393647 [info ] [MainThread]: 
[0m17:55:30.397277 [info ] [MainThread]: Finished running  in 0 hours 0 minutes and 0.23 seconds (0.23s).
[0m17:55:30.400532 [error] [MainThread]: Encountered an error:
Database Error
  permission denied for database analytics
[0m17:55:30.405648 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": false, "command_wall_clock_time": 3.8949175, "process_in_blocks": "2336", "process_kernel_time": 0.549751, "process_mem_max_rss": "110300", "process_out_blocks": "0", "process_user_time": 7.466628}
[0m17:55:30.409991 [debug] [MainThread]: Command `dbt run` failed at 17:55:30.409570 after 3.90 seconds
[0m17:55:30.413367 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f68909b3a60>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f688fb52280>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f688de37b80>]}
[0m17:55:30.416531 [debug] [MainThread]: Flushing usage events
[0m17:55:31.656138 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m17:55:34.294494 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 1 unused configuration paths:
- seeds.homework.iris_dataset
[0m17:55:34.330679 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '06f86d62-5c2b-4d4d-b531-f607035cdc3c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f44e9033130>]}
[0m17:55:34.695350 [debug] [MainThread]: Wrote artifact WritableManifest to /opt/airflow/dags/dbt/homework/target/manifest.json
[0m17:55:34.717964 [debug] [MainThread]: Wrote artifact SemanticManifest to /opt/airflow/dags/dbt/homework/target/semantic_manifest.json
[0m17:55:34.765921 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '06f86d62-5c2b-4d4d-b531-f607035cdc3c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f44e80ea880>]}
[0m17:55:34.769363 [info ] [MainThread]: Found 2 models, 1 source, 587 macros
[0m17:55:34.772082 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '06f86d62-5c2b-4d4d-b531-f607035cdc3c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f44e80ea8b0>]}
[0m17:55:34.778047 [info ] [MainThread]: 
[0m17:55:34.780919 [info ] [MainThread]: Concurrency: 4 threads (target='dev')
[0m17:55:34.782909 [info ] [MainThread]: 
[0m17:55:34.785449 [debug] [MainThread]: Acquiring new postgres connection 'master'
[0m17:55:34.799225 [debug] [ThreadPool]: Acquiring new postgres connection 'list_analytics'
[0m17:55:34.872481 [debug] [ThreadPool]: Using postgres connection "list_analytics"
[0m17:55:34.874120 [debug] [ThreadPool]: On list_analytics: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "homework", "target_name": "dev", "connection_name": "list_analytics"} */

    select distinct nspname from pg_namespace
  
[0m17:55:34.875794 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m17:55:34.888978 [debug] [ThreadPool]: SQL status: SELECT 6 in 0.013 seconds
[0m17:55:34.892380 [debug] [ThreadPool]: On list_analytics: Close
[0m17:55:34.895568 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_analytics, now create_analytics_homework)
[0m17:55:34.897700 [debug] [ThreadPool]: Creating schema "database: "analytics"
schema: "homework"
"
[0m17:55:34.910369 [debug] [ThreadPool]: Using postgres connection "create_analytics_homework"
[0m17:55:34.912660 [debug] [ThreadPool]: On create_analytics_homework: BEGIN
[0m17:55:34.914358 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m17:55:34.925721 [debug] [ThreadPool]: SQL status: BEGIN in 0.011 seconds
[0m17:55:34.927682 [debug] [ThreadPool]: Using postgres connection "create_analytics_homework"
[0m17:55:34.929637 [debug] [ThreadPool]: On create_analytics_homework: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "homework", "target_name": "dev", "connection_name": "create_analytics_homework"} */
create schema if not exists "homework"
[0m17:55:34.932138 [debug] [ThreadPool]: Postgres adapter: Postgres error: permission denied for database analytics

[0m17:55:34.933885 [debug] [ThreadPool]: On create_analytics_homework: ROLLBACK
[0m17:55:34.936346 [debug] [ThreadPool]: Postgres adapter: Error running SQL: macro create_schema
[0m17:55:34.938274 [debug] [ThreadPool]: Postgres adapter: Rolling back transaction.
[0m17:55:34.940041 [debug] [ThreadPool]: On create_analytics_homework: Close
[0m17:55:34.943728 [debug] [MainThread]: Connection 'master' was properly closed.
[0m17:55:34.946104 [debug] [MainThread]: Connection 'create_analytics_homework' was properly closed.
[0m17:55:34.947879 [info ] [MainThread]: 
[0m17:55:34.949774 [info ] [MainThread]: Finished running  in 0 hours 0 minutes and 0.16 seconds (0.16s).
[0m17:55:34.951982 [error] [MainThread]: Encountered an error:
Database Error
  permission denied for database analytics
[0m17:55:34.954574 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": false, "command_wall_clock_time": 8.441347, "process_in_blocks": "368", "process_kernel_time": 0.511524, "process_mem_max_rss": "118144", "process_out_blocks": "0", "process_user_time": 12.20498}
[0m17:55:34.956779 [debug] [MainThread]: Command `dbt run` failed at 17:55:34.956520 after 8.44 seconds
[0m17:55:34.959223 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f44eba60a30>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f44d3bfbc10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f44d3b46670>]}
[0m17:55:34.962162 [debug] [MainThread]: Flushing usage events
[0m17:55:35.475597 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m17:58:56.201305 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fab4edaca60>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fab4decd430>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fab4decd3d0>]}


============================== 17:58:56.213952 | 665329cc-4187-45e1-a18e-360560a8b87c ==============================
[0m17:58:56.213952 [info ] [MainThread]: Running with dbt=1.9.4
[0m17:58:56.216173 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': '/opt/airflow/dags/dbt', 'debug': 'False', 'fail_fast': 'False', 'log_path': '/opt/airflow/dags/dbt/homework/logs', 'warn_error': 'None', 'version_check': 'True', 'use_colors': 'True', 'use_experimental_parser': 'False', 'empty': 'False', 'quiet': 'False', 'no_print': 'None', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'static_parser': 'True', 'log_format': 'default', 'invocation_command': 'dbt --profile homework run --project-dir=/opt/airflow/dags/dbt/homework --models staging --vars {"is_test": false, "data_date": "2025-04-22"}', 'target_path': 'None', 'introspect': 'True', 'send_anonymous_usage_stats': 'True'}
[0m17:58:56.706198 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '665329cc-4187-45e1-a18e-360560a8b87c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fab507a1370>]}
[0m17:58:56.837980 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '665329cc-4187-45e1-a18e-360560a8b87c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fab4c6bcf70>]}
[0m17:58:56.840378 [info ] [MainThread]: Registered adapter: postgres=1.9.0
[0m17:58:57.140363 [debug] [MainThread]: checksum: b4b46bb6a239f66694dfdd44ef1792882cb61f2fd7b1ea66b3c7a170d2bb602d, vars: {'data_date': '2025-04-22', 'is_test': False}, profile: homework, target: , version: 1.9.4
[0m17:58:57.425667 [info ] [MainThread]: Unable to do partial parsing because config vars, config profile, or config target have changed
[0m17:58:57.428287 [debug] [MainThread]: previous checksum: b4b46bb6a239f66694dfdd44ef1792882cb61f2fd7b1ea66b3c7a170d2bb602d, current checksum: f5df654a850f4b74beb13fbe0c7d8863b5b1a20bd535c3ac287d70e390b64d41
[0m17:58:57.430087 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'partial_parser', 'label': '665329cc-4187-45e1-a18e-360560a8b87c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fab4e5ead90>]}
[0m17:59:03.901196 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 1 unused configuration paths:
- seeds.homework.iris_dataset
[0m17:59:03.929650 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '665329cc-4187-45e1-a18e-360560a8b87c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fab4c32f130>]}
[0m17:59:04.181274 [debug] [MainThread]: Wrote artifact WritableManifest to /opt/airflow/dags/dbt/homework/target/manifest.json
[0m17:59:04.201855 [debug] [MainThread]: Wrote artifact SemanticManifest to /opt/airflow/dags/dbt/homework/target/semantic_manifest.json
[0m17:59:04.232761 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '665329cc-4187-45e1-a18e-360560a8b87c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fab4b042c40>]}
[0m17:59:04.235275 [info ] [MainThread]: Found 2 models, 1 source, 587 macros
[0m17:59:04.236897 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '665329cc-4187-45e1-a18e-360560a8b87c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fab4afccdf0>]}
[0m17:59:04.240072 [info ] [MainThread]: 
[0m17:59:04.241562 [info ] [MainThread]: Concurrency: 4 threads (target='dev')
[0m17:59:04.243134 [info ] [MainThread]: 
[0m17:59:04.244933 [debug] [MainThread]: Acquiring new postgres connection 'master'
[0m17:59:04.247432 [debug] [ThreadPool]: Acquiring new postgres connection 'list_analytics'
[0m17:59:04.306218 [debug] [ThreadPool]: Using postgres connection "list_analytics"
[0m17:59:04.309643 [debug] [ThreadPool]: On list_analytics: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "homework", "target_name": "dev", "connection_name": "list_analytics"} */

    select distinct nspname from pg_namespace
  
[0m17:59:04.311830 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m17:59:04.332034 [debug] [ThreadPool]: SQL status: SELECT 6 in 0.020 seconds
[0m17:59:04.339275 [debug] [ThreadPool]: On list_analytics: Close
[0m17:59:04.343541 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_analytics, now create_analytics_homework)
[0m17:59:04.348039 [debug] [ThreadPool]: Creating schema "database: "analytics"
schema: "homework"
"
[0m17:59:04.373057 [debug] [ThreadPool]: Using postgres connection "create_analytics_homework"
[0m17:59:04.376557 [debug] [ThreadPool]: On create_analytics_homework: BEGIN
[0m17:59:04.379424 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m17:59:04.398201 [debug] [ThreadPool]: SQL status: BEGIN in 0.019 seconds
[0m17:59:04.400502 [debug] [ThreadPool]: Using postgres connection "create_analytics_homework"
[0m17:59:04.402731 [debug] [ThreadPool]: On create_analytics_homework: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "homework", "target_name": "dev", "connection_name": "create_analytics_homework"} */
create schema if not exists "homework"
[0m17:59:04.405080 [debug] [ThreadPool]: Postgres adapter: Postgres error: permission denied for database analytics

[0m17:59:04.407105 [debug] [ThreadPool]: On create_analytics_homework: ROLLBACK
[0m17:59:04.409617 [debug] [ThreadPool]: Postgres adapter: Error running SQL: macro create_schema
[0m17:59:04.411419 [debug] [ThreadPool]: Postgres adapter: Rolling back transaction.
[0m17:59:04.413387 [debug] [ThreadPool]: On create_analytics_homework: Close
[0m17:59:04.417944 [debug] [MainThread]: Connection 'master' was properly closed.
[0m17:59:04.420237 [debug] [MainThread]: Connection 'create_analytics_homework' was properly closed.
[0m17:59:04.422596 [info ] [MainThread]: 
[0m17:59:04.425303 [info ] [MainThread]: Finished running  in 0 hours 0 minutes and 0.18 seconds (0.18s).
[0m17:59:04.429027 [error] [MainThread]: Encountered an error:
Database Error
  permission denied for database analytics
[0m17:59:04.431934 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": false, "command_wall_clock_time": 8.390564, "process_in_blocks": "0", "process_kernel_time": 0.560795, "process_mem_max_rss": "116392", "process_out_blocks": "0", "process_user_time": 9.643676}
[0m17:59:04.435108 [debug] [MainThread]: Command `dbt run` failed at 17:59:04.434742 after 8.39 seconds
[0m17:59:04.437550 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fab4edaca60>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fab4af79c40>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fab4aec3340>]}
[0m17:59:04.439357 [debug] [MainThread]: Flushing usage events
[0m17:59:05.008650 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m18:00:54.313620 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f7b44f37610>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f7b44050ca0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f7b44050c40>]}


============================== 18:00:54.325167 | 1476f389-7df9-4f44-a19c-ba689dfb9803 ==============================
[0m18:00:54.325167 [info ] [MainThread]: Running with dbt=1.9.4
[0m18:00:54.327613 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'fail_fast': 'False', 'version_check': 'True', 'log_path': '/opt/airflow/dags/dbt/homework/logs', 'debug': 'False', 'profiles_dir': '/opt/airflow/dags/dbt', 'use_colors': 'True', 'use_experimental_parser': 'False', 'empty': 'None', 'quiet': 'False', 'no_print': 'None', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'static_parser': 'True', 'introspect': 'True', 'invocation_command': 'dbt deps --profiles-dir /opt/airflow/dags/dbt --project-dir /opt/airflow/dags/dbt/homework', 'target_path': 'None', 'log_format': 'default', 'send_anonymous_usage_stats': 'True'}
[0m18:00:54.563465 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '1476f389-7df9-4f44-a19c-ba689dfb9803', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f7b470332e0>]}
[0m18:00:54.842769 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f75bb2bc640>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f75ba3d6d90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f75ba3d6d30>]}


============================== 18:00:54.854455 | a907966b-3214-41bc-917e-9e08e810d9c9 ==============================
[0m18:00:54.854455 [info ] [MainThread]: Running with dbt=1.9.4
[0m18:00:54.857151 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'version_check': 'True', 'debug': 'False', 'log_path': '/opt/airflow/dags/dbt/homework/logs', 'profiles_dir': '/opt/airflow/dags/dbt', 'fail_fast': 'False', 'use_colors': 'True', 'use_experimental_parser': 'False', 'empty': 'None', 'quiet': 'False', 'no_print': 'None', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'static_parser': 'True', 'introspect': 'True', 'log_format': 'default', 'target_path': 'None', 'invocation_command': 'dbt deps --profiles-dir /opt/airflow/dags/dbt --project-dir /opt/airflow/dags/dbt/homework', 'send_anonymous_usage_stats': 'True'}
[0m18:00:55.187275 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'a907966b-3214-41bc-917e-9e08e810d9c9', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f75bb073310>]}
[0m18:00:55.223656 [error] [MainThread]: Encountered an error:
[Errno 2] No such file or directory: 'dbt_packages'
[0m18:00:55.227160 [error] [MainThread]: Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/dbt/cli/requires.py", line 153, in wrapper
    result, success = func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.9/site-packages/dbt/cli/requires.py", line 103, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.9/site-packages/dbt/cli/requires.py", line 218, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.9/site-packages/dbt/cli/requires.py", line 264, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.9/site-packages/dbt/cli/main.py", line 455, in deps
    results = task.run()
  File "/home/airflow/.local/lib/python3.9/site-packages/dbt/task/deps.py", line 227, in run
    system.rmtree(self.project.packages_install_path)
  File "/home/airflow/.local/lib/python3.9/site-packages/dbt_common/clients/system.py", line 715, in rmtree
    return shutil.rmtree(path, onerror=chmod_and_retry)
  File "/usr/local/lib/python3.9/shutil.py", line 740, in rmtree
    onerror(os.rmdir, path, sys.exc_info())
  File "/usr/local/lib/python3.9/shutil.py", line 738, in rmtree
    os.rmdir(path)
FileNotFoundError: [Errno 2] No such file or directory: 'dbt_packages'

[0m18:00:55.229922 [debug] [MainThread]: Resource report: {"command_name": "deps", "command_success": false, "command_wall_clock_time": 0.5439716, "process_in_blocks": "32", "process_kernel_time": 0.219997, "process_mem_max_rss": "92376", "process_out_blocks": "5744", "process_user_time": 3.729954}
[0m18:00:55.231926 [debug] [MainThread]: Command `dbt deps` failed at 18:00:55.231734 after 0.55 seconds
[0m18:00:55.233582 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f75bb2bc640>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f75ba2bfdf0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f75ba2bffd0>]}
[0m18:00:55.233430 [debug] [MainThread]: Set downloads directory='/tmp/dbt-downloads-74bh4lqt'
[0m18:00:55.235593 [debug] [MainThread]: Flushing usage events
[0m18:00:55.235627 [debug] [MainThread]: Making package index registry request: GET https://hub.getdbt.com/api/v1/index.json
[0m18:00:55.420979 [debug] [MainThread]: Response from registry index: GET https://hub.getdbt.com/api/v1/index.json 200
[0m18:00:55.426126 [debug] [MainThread]: Making package registry request: GET https://hub.getdbt.com/api/v1/Matts52/dbt_ml_inline_preprocessing.json
[0m18:00:55.683584 [debug] [MainThread]: Response from registry: GET https://hub.getdbt.com/api/v1/Matts52/dbt_ml_inline_preprocessing.json 200
[0m18:00:55.691029 [debug] [MainThread]: Making package registry request: GET https://hub.getdbt.com/api/v1/dbt-labs/dbt_utils.json
[0m18:00:55.815353 [debug] [MainThread]: Response from registry: GET https://hub.getdbt.com/api/v1/dbt-labs/dbt_utils.json 200
[0m18:00:55.817878 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m18:00:55.828249 [info ] [MainThread]: Installing Matts52/dbt_ml_inline_preprocessing
[0m18:00:57.637967 [info ] [MainThread]: Installed from version 0.2.4
[0m18:00:57.640427 [info ] [MainThread]: Up to date!
[0m18:00:57.642826 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'package', 'label': '1476f389-7df9-4f44-a19c-ba689dfb9803', 'property_': 'install', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f7b44da4fa0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f7b43e990d0>]}
[0m18:00:57.645159 [info ] [MainThread]: Installing dbt-labs/dbt_utils
[0m18:01:02.639926 [info ] [MainThread]: Installed from version 1.3.0
[0m18:01:02.641908 [info ] [MainThread]: Up to date!
[0m18:01:02.643854 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'package', 'label': '1476f389-7df9-4f44-a19c-ba689dfb9803', 'property_': 'install', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f7b44da4fa0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f7b43f41070>]}
[0m18:01:02.647155 [debug] [MainThread]: Resource report: {"command_name": "deps", "command_success": true, "command_wall_clock_time": 8.474752, "process_in_blocks": "168", "process_kernel_time": 0.544392, "process_mem_max_rss": "95260", "process_out_blocks": "7048", "process_user_time": 4.264411}
[0m18:01:02.649359 [debug] [MainThread]: Command `dbt deps` succeeded at 18:01:02.649059 after 8.48 seconds
[0m18:01:02.651128 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f7b44f37610>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f7b44d6a340>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f7b43fab220>]}
[0m18:01:02.652952 [debug] [MainThread]: Flushing usage events
[0m18:01:03.157676 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m18:03:00.177810 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f5cc45b69d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f5cc36d73a0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f5cc36d7340>]}


============================== 18:03:00.191779 | eb9b8c67-e7d7-421a-a774-a3e193cd7f94 ==============================
[0m18:03:00.191779 [info ] [MainThread]: Running with dbt=1.9.4
[0m18:03:00.195289 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'version_check': 'True', 'debug': 'False', 'log_path': '/opt/airflow/dags/dbt/homework/logs', 'profiles_dir': '/opt/airflow/dags/dbt', 'fail_fast': 'False', 'use_colors': 'True', 'use_experimental_parser': 'False', 'empty': 'False', 'quiet': 'False', 'no_print': 'None', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'introspect': 'True', 'static_parser': 'True', 'invocation_command': 'dbt --profile homework run --project-dir=/opt/airflow/dags/dbt/homework --models staging --vars {"is_test": false, "data_date": "2025-04-22"}', 'target_path': 'None', 'log_format': 'default', 'send_anonymous_usage_stats': 'True'}
[0m18:03:00.803418 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'eb9b8c67-e7d7-421a-a774-a3e193cd7f94', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f5cc37068b0>]}
[0m18:03:01.071763 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': 'eb9b8c67-e7d7-421a-a774-a3e193cd7f94', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f5cc3706310>]}
[0m18:03:01.079111 [info ] [MainThread]: Registered adapter: postgres=1.9.0
[0m18:03:01.672661 [debug] [MainThread]: checksum: b4b46bb6a239f66694dfdd44ef1792882cb61f2fd7b1ea66b3c7a170d2bb602d, vars: {'data_date': '2025-04-22', 'is_test': False}, profile: homework, target: , version: 1.9.4
[0m18:03:02.226606 [info ] [MainThread]: Unable to do partial parsing because profile has changed
[0m18:03:02.228570 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'partial_parser', 'label': 'eb9b8c67-e7d7-421a-a774-a3e193cd7f94', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f5cc3dfae80>]}
[0m18:03:07.514880 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 1 unused configuration paths:
- seeds.homework.iris_dataset
[0m18:03:07.549118 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'eb9b8c67-e7d7-421a-a774-a3e193cd7f94', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f5cc1b38130>]}
[0m18:03:07.803968 [debug] [MainThread]: Wrote artifact WritableManifest to /opt/airflow/dags/dbt/homework/target/manifest.json
[0m18:03:07.824551 [debug] [MainThread]: Wrote artifact SemanticManifest to /opt/airflow/dags/dbt/homework/target/semantic_manifest.json
[0m18:03:07.857493 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'eb9b8c67-e7d7-421a-a774-a3e193cd7f94', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f5cc082b1f0>]}
[0m18:03:07.859449 [info ] [MainThread]: Found 2 models, 1 source, 587 macros
[0m18:03:07.861066 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'eb9b8c67-e7d7-421a-a774-a3e193cd7f94', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f5cc5411d00>]}
[0m18:03:07.863809 [info ] [MainThread]: 
[0m18:03:07.865484 [info ] [MainThread]: Concurrency: 4 threads (target='dev')
[0m18:03:07.866949 [info ] [MainThread]: 
[0m18:03:07.869757 [debug] [MainThread]: Acquiring new postgres connection 'master'
[0m18:03:07.872493 [debug] [ThreadPool]: Acquiring new postgres connection 'list_analytics'
[0m18:03:07.933766 [debug] [ThreadPool]: Using postgres connection "list_analytics"
[0m18:03:07.936160 [debug] [ThreadPool]: On list_analytics: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "homework", "target_name": "dev", "connection_name": "list_analytics"} */

    select distinct nspname from pg_namespace
  
[0m18:03:07.938457 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m18:03:07.953383 [debug] [ThreadPool]: SQL status: SELECT 6 in 0.015 seconds
[0m18:03:07.957015 [debug] [ThreadPool]: On list_analytics: Close
[0m18:03:07.968472 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_analytics, now list_analytics_analytics)
[0m18:03:07.982856 [debug] [ThreadPool]: Using postgres connection "list_analytics_analytics"
[0m18:03:07.984999 [debug] [ThreadPool]: On list_analytics_analytics: BEGIN
[0m18:03:07.987020 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m18:03:07.999536 [debug] [ThreadPool]: SQL status: BEGIN in 0.012 seconds
[0m18:03:08.001684 [debug] [ThreadPool]: Using postgres connection "list_analytics_analytics"
[0m18:03:08.003998 [debug] [ThreadPool]: On list_analytics_analytics: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "homework", "target_name": "dev", "connection_name": "list_analytics_analytics"} */
select
      'analytics' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'analytics'
    union all
    select
      'analytics' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'analytics'
    union all
    select
      'analytics' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'analytics'
  
[0m18:03:08.009908 [debug] [ThreadPool]: SQL status: SELECT 1 in 0.004 seconds
[0m18:03:08.013810 [debug] [ThreadPool]: On list_analytics_analytics: ROLLBACK
[0m18:03:08.016050 [debug] [ThreadPool]: On list_analytics_analytics: Close
[0m18:03:08.029433 [debug] [MainThread]: Using postgres connection "master"
[0m18:03:08.031060 [debug] [MainThread]: On master: BEGIN
[0m18:03:08.032894 [debug] [MainThread]: Opening a new connection, currently in state init
[0m18:03:08.045313 [debug] [MainThread]: SQL status: BEGIN in 0.012 seconds
[0m18:03:08.047690 [debug] [MainThread]: Using postgres connection "master"
[0m18:03:08.049853 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "homework", "target_name": "dev", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select distinct
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v', 'm')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
[0m18:03:08.057525 [debug] [MainThread]: SQL status: SELECT 0 in 0.005 seconds
[0m18:03:08.061355 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'eb9b8c67-e7d7-421a-a774-a3e193cd7f94', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f5cc079d910>]}
[0m18:03:08.063508 [debug] [MainThread]: On master: ROLLBACK
[0m18:03:08.065928 [debug] [MainThread]: Using postgres connection "master"
[0m18:03:08.067921 [debug] [MainThread]: On master: BEGIN
[0m18:03:08.071159 [debug] [MainThread]: SQL status: BEGIN in 0.001 seconds
[0m18:03:08.073285 [debug] [MainThread]: On master: COMMIT
[0m18:03:08.075333 [debug] [MainThread]: Using postgres connection "master"
[0m18:03:08.077232 [debug] [MainThread]: On master: COMMIT
[0m18:03:08.079575 [debug] [MainThread]: SQL status: COMMIT in 0.000 seconds
[0m18:03:08.081468 [debug] [MainThread]: On master: Close
[0m18:03:08.093529 [debug] [Thread-1  ]: Began running node model.homework.stg_iris
[0m18:03:08.096004 [info ] [Thread-1  ]: 1 of 1 START sql view model analytics.stg_iris ................................. [RUN]
[0m18:03:08.098483 [debug] [Thread-1  ]: Re-using an available connection from the pool (formerly list_analytics_analytics, now model.homework.stg_iris)
[0m18:03:08.100591 [debug] [Thread-1  ]: Began compiling node model.homework.stg_iris
[0m18:03:08.124903 [debug] [Thread-1  ]: Writing injected SQL for node "model.homework.stg_iris"
[0m18:03:08.150320 [debug] [Thread-1  ]: Began executing node model.homework.stg_iris
[0m18:03:08.247520 [debug] [Thread-1  ]: Writing runtime sql for node "model.homework.stg_iris"
[0m18:03:08.278671 [debug] [Thread-1  ]: Using postgres connection "model.homework.stg_iris"
[0m18:03:08.281114 [debug] [Thread-1  ]: On model.homework.stg_iris: BEGIN
[0m18:03:08.283446 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
[0m18:03:08.299838 [debug] [Thread-1  ]: SQL status: BEGIN in 0.016 seconds
[0m18:03:08.303518 [debug] [Thread-1  ]: Using postgres connection "model.homework.stg_iris"
[0m18:03:08.306289 [debug] [Thread-1  ]: On model.homework.stg_iris: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "homework", "target_name": "dev", "node_id": "model.homework.stg_iris"} */

  create view "analytics"."analytics"."stg_iris__dbt_tmp"
    
    
  as (
    with source as (
    select * from "analytics"."analytics"."iris_dataset"
)

select
    sepal_length,
    sepal_width,
    petal_length,
    petal_width,
    species
from source
  );
[0m18:03:08.311770 [debug] [Thread-1  ]: SQL status: CREATE VIEW in 0.003 seconds
[0m18:03:08.343804 [debug] [Thread-1  ]: Using postgres connection "model.homework.stg_iris"
[0m18:03:08.346846 [debug] [Thread-1  ]: On model.homework.stg_iris: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "homework", "target_name": "dev", "node_id": "model.homework.stg_iris"} */
alter table "analytics"."analytics"."stg_iris__dbt_tmp" rename to "stg_iris"
[0m18:03:08.350693 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.001 seconds
[0m18:03:08.410346 [debug] [Thread-1  ]: On model.homework.stg_iris: COMMIT
[0m18:03:08.412907 [debug] [Thread-1  ]: Using postgres connection "model.homework.stg_iris"
[0m18:03:08.415509 [debug] [Thread-1  ]: On model.homework.stg_iris: COMMIT
[0m18:03:08.422115 [debug] [Thread-1  ]: SQL status: COMMIT in 0.004 seconds
[0m18:03:08.450615 [debug] [Thread-1  ]: Applying DROP to: "analytics"."analytics"."stg_iris__dbt_backup"
[0m18:03:08.476874 [debug] [Thread-1  ]: Using postgres connection "model.homework.stg_iris"
[0m18:03:08.479603 [debug] [Thread-1  ]: On model.homework.stg_iris: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "homework", "target_name": "dev", "node_id": "model.homework.stg_iris"} */
drop view if exists "analytics"."analytics"."stg_iris__dbt_backup" cascade
[0m18:03:08.483274 [debug] [Thread-1  ]: SQL status: DROP VIEW in 0.001 seconds
[0m18:03:08.496501 [debug] [Thread-1  ]: On model.homework.stg_iris: Close
[0m18:03:08.506002 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'eb9b8c67-e7d7-421a-a774-a3e193cd7f94', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f5cc5fbe820>]}
[0m18:03:08.509857 [info ] [Thread-1  ]: 1 of 1 OK created sql view model analytics.stg_iris ............................ [[32mCREATE VIEW[0m in 0.40s]
[0m18:03:08.513685 [debug] [Thread-1  ]: Finished running node model.homework.stg_iris
[0m18:03:08.520750 [debug] [MainThread]: Using postgres connection "master"
[0m18:03:08.524412 [debug] [MainThread]: On master: BEGIN
[0m18:03:08.527873 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m18:03:08.550716 [debug] [MainThread]: SQL status: BEGIN in 0.023 seconds
[0m18:03:08.556614 [debug] [MainThread]: On master: COMMIT
[0m18:03:08.559461 [debug] [MainThread]: Using postgres connection "master"
[0m18:03:08.562362 [debug] [MainThread]: On master: COMMIT
[0m18:03:08.565152 [debug] [MainThread]: SQL status: COMMIT in 0.000 seconds
[0m18:03:08.567713 [debug] [MainThread]: On master: Close
[0m18:03:08.571413 [debug] [MainThread]: Connection 'master' was properly closed.
[0m18:03:08.574425 [debug] [MainThread]: Connection 'model.homework.stg_iris' was properly closed.
[0m18:03:08.576946 [info ] [MainThread]: 
[0m18:03:08.579347 [info ] [MainThread]: Finished running 1 view model in 0 hours 0 minutes and 0.71 seconds (0.71s).
[0m18:03:08.583719 [debug] [MainThread]: Command end result
[0m18:03:08.723544 [debug] [MainThread]: Wrote artifact WritableManifest to /opt/airflow/dags/dbt/homework/target/manifest.json
[0m18:03:08.736701 [debug] [MainThread]: Wrote artifact SemanticManifest to /opt/airflow/dags/dbt/homework/target/semantic_manifest.json
[0m18:03:08.775263 [debug] [MainThread]: Wrote artifact RunExecutionResult to /opt/airflow/dags/dbt/homework/target/run_results.json
[0m18:03:08.778201 [info ] [MainThread]: 
[0m18:03:08.780977 [info ] [MainThread]: [32mCompleted successfully[0m
[0m18:03:08.783740 [info ] [MainThread]: 
[0m18:03:08.788686 [info ] [MainThread]: Done. PASS=1 WARN=0 ERROR=0 SKIP=0 TOTAL=1
[0m18:03:08.793580 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": true, "command_wall_clock_time": 8.91392, "process_in_blocks": "16", "process_kernel_time": 0.497422, "process_mem_max_rss": "118220", "process_out_blocks": "0", "process_user_time": 10.565245}
[0m18:03:08.797252 [debug] [MainThread]: Command `dbt run` succeeded at 18:03:08.796878 after 8.92 seconds
[0m18:03:08.800568 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f5cc45b69d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f5cc44194f0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f5cc082b1f0>]}
[0m18:03:08.805905 [debug] [MainThread]: Flushing usage events
[0m18:03:09.371821 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m18:03:15.110386 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f9f29cb5a30>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f9f28dd64f0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f9f28dd6490>]}


============================== 18:03:15.121625 | 4caf9a4f-defb-45a0-bf68-cb29119a0f7e ==============================
[0m18:03:15.121625 [info ] [MainThread]: Running with dbt=1.9.4
[0m18:03:15.124506 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'version_check': 'True', 'debug': 'False', 'log_path': '/opt/airflow/dags/dbt/homework/logs', 'profiles_dir': '/opt/airflow/dags/dbt', 'fail_fast': 'True', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'empty': 'None', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'introspect': 'True', 'static_parser': 'True', 'invocation_command': 'dbt --profile homework test --project-dir=/opt/airflow/dags/dbt/homework --vars {"is_test": false, "data_date": "2025-04-22"} --fail-fast', 'target_path': 'None', 'log_format': 'default', 'send_anonymous_usage_stats': 'True'}
[0m18:03:15.577202 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '4caf9a4f-defb-45a0-bf68-cb29119a0f7e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f9f275e7760>]}
[0m18:03:15.726499 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '4caf9a4f-defb-45a0-bf68-cb29119a0f7e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f9f294ff820>]}
[0m18:03:15.728963 [info ] [MainThread]: Registered adapter: postgres=1.9.0
[0m18:03:16.002095 [debug] [MainThread]: checksum: b4b46bb6a239f66694dfdd44ef1792882cb61f2fd7b1ea66b3c7a170d2bb602d, vars: {'data_date': '2025-04-22', 'is_test': False}, profile: homework, target: , version: 1.9.4
[0m18:03:18.285719 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m18:03:18.287302 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m18:03:18.304198 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 1 unused configuration paths:
- seeds.homework.iris_dataset
[0m18:03:18.395318 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '4caf9a4f-defb-45a0-bf68-cb29119a0f7e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f9f27104130>]}
[0m18:03:18.716264 [debug] [MainThread]: Wrote artifact WritableManifest to /opt/airflow/dags/dbt/homework/target/manifest.json
[0m18:03:18.737500 [debug] [MainThread]: Wrote artifact SemanticManifest to /opt/airflow/dags/dbt/homework/target/semantic_manifest.json
[0m18:03:18.788337 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '4caf9a4f-defb-45a0-bf68-cb29119a0f7e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f9f2704a6a0>]}
[0m18:03:18.790611 [info ] [MainThread]: Found 2 models, 1 source, 587 macros
[0m18:03:18.792536 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '4caf9a4f-defb-45a0-bf68-cb29119a0f7e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f9f28e3d1f0>]}
[0m18:03:18.796960 [warn ] [MainThread]: Nothing to do. Try checking your model configs and model specification args
[0m18:03:18.801883 [debug] [MainThread]: Command end result
[0m18:03:18.947112 [debug] [MainThread]: Wrote artifact WritableManifest to /opt/airflow/dags/dbt/homework/target/manifest.json
[0m18:03:18.958383 [debug] [MainThread]: Wrote artifact SemanticManifest to /opt/airflow/dags/dbt/homework/target/semantic_manifest.json
[0m18:03:18.973324 [debug] [MainThread]: Wrote artifact RunExecutionResult to /opt/airflow/dags/dbt/homework/target/run_results.json
[0m18:03:18.975854 [debug] [MainThread]: Resource report: {"command_name": "test", "command_success": true, "command_wall_clock_time": 4.0294504, "process_in_blocks": "0", "process_kernel_time": 0.367749, "process_mem_max_rss": "104636", "process_out_blocks": "0", "process_user_time": 5.277703}
[0m18:03:18.978442 [debug] [MainThread]: Command `dbt test` succeeded at 18:03:18.977855 after 4.03 seconds
[0m18:03:18.980502 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f9f29cb5a30>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f9f29afb2b0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f9f27139f40>]}
[0m18:03:18.982501 [debug] [MainThread]: Flushing usage events
[0m18:03:19.494567 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m18:03:27.197195 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f52ff4f9a90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f52fe61a460>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f52fe61a400>]}


============================== 18:03:27.211028 | 8fbd6f1a-150e-4fc8-b99d-97e1a683b5b1 ==============================
[0m18:03:27.211028 [info ] [MainThread]: Running with dbt=1.9.4
[0m18:03:27.214038 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'fail_fast': 'False', 'profiles_dir': '/opt/airflow/dags/dbt', 'log_path': '/opt/airflow/dags/dbt/homework/logs', 'debug': 'False', 'version_check': 'True', 'use_colors': 'True', 'use_experimental_parser': 'False', 'empty': 'False', 'quiet': 'False', 'no_print': 'None', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'invocation_command': 'dbt --profile homework run --project-dir=/opt/airflow/dags/dbt/homework --models staging --vars {"is_test": false, "data_date": "2025-04-23"}', 'log_format': 'default', 'introspect': 'True', 'target_path': 'None', 'static_parser': 'True', 'send_anonymous_usage_stats': 'True'}
[0m18:03:27.664714 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '8fbd6f1a-150e-4fc8-b99d-97e1a683b5b1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f52fcdecee0>]}
[0m18:03:27.804525 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '8fbd6f1a-150e-4fc8-b99d-97e1a683b5b1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f52fe65a550>]}
[0m18:03:27.807018 [info ] [MainThread]: Registered adapter: postgres=1.9.0
[0m18:03:28.102493 [debug] [MainThread]: checksum: f5df654a850f4b74beb13fbe0c7d8863b5b1a20bd535c3ac287d70e390b64d41, vars: {'data_date': '2025-04-23', 'is_test': False}, profile: homework, target: , version: 1.9.4
[0m18:03:28.366784 [info ] [MainThread]: Unable to do partial parsing because config vars, config profile, or config target have changed
[0m18:03:28.369281 [debug] [MainThread]: previous checksum: f5df654a850f4b74beb13fbe0c7d8863b5b1a20bd535c3ac287d70e390b64d41, current checksum: b4b46bb6a239f66694dfdd44ef1792882cb61f2fd7b1ea66b3c7a170d2bb602d
[0m18:03:28.371080 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'partial_parser', 'label': '8fbd6f1a-150e-4fc8-b99d-97e1a683b5b1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f52fed372e0>]}
[0m18:03:34.284566 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 1 unused configuration paths:
- seeds.homework.iris_dataset
[0m18:03:34.317432 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '8fbd6f1a-150e-4fc8-b99d-97e1a683b5b1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f52fca88130>]}
[0m18:03:34.611213 [debug] [MainThread]: Wrote artifact WritableManifest to /opt/airflow/dags/dbt/homework/target/manifest.json
[0m18:03:34.638111 [debug] [MainThread]: Wrote artifact SemanticManifest to /opt/airflow/dags/dbt/homework/target/semantic_manifest.json
[0m18:03:34.693406 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '8fbd6f1a-150e-4fc8-b99d-97e1a683b5b1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f52ef8d1c70>]}
[0m18:03:34.696675 [info ] [MainThread]: Found 2 models, 1 source, 587 macros
[0m18:03:34.699479 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '8fbd6f1a-150e-4fc8-b99d-97e1a683b5b1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f52ef92b280>]}
[0m18:03:34.704470 [info ] [MainThread]: 
[0m18:03:34.707970 [info ] [MainThread]: Concurrency: 4 threads (target='dev')
[0m18:03:34.710420 [info ] [MainThread]: 
[0m18:03:34.713713 [debug] [MainThread]: Acquiring new postgres connection 'master'
[0m18:03:34.718180 [debug] [ThreadPool]: Acquiring new postgres connection 'list_analytics'
[0m18:03:34.833137 [debug] [ThreadPool]: Using postgres connection "list_analytics"
[0m18:03:34.835817 [debug] [ThreadPool]: On list_analytics: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "homework", "target_name": "dev", "connection_name": "list_analytics"} */

    select distinct nspname from pg_namespace
  
[0m18:03:34.839292 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m18:03:34.865642 [debug] [ThreadPool]: SQL status: SELECT 6 in 0.026 seconds
[0m18:03:34.870654 [debug] [ThreadPool]: On list_analytics: Close
[0m18:03:34.895007 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_analytics, now list_analytics_analytics)
[0m18:03:34.927692 [debug] [ThreadPool]: Using postgres connection "list_analytics_analytics"
[0m18:03:34.930044 [debug] [ThreadPool]: On list_analytics_analytics: BEGIN
[0m18:03:34.932574 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m18:03:34.949732 [debug] [ThreadPool]: SQL status: BEGIN in 0.017 seconds
[0m18:03:34.952193 [debug] [ThreadPool]: Using postgres connection "list_analytics_analytics"
[0m18:03:34.954769 [debug] [ThreadPool]: On list_analytics_analytics: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "homework", "target_name": "dev", "connection_name": "list_analytics_analytics"} */
select
      'analytics' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'analytics'
    union all
    select
      'analytics' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'analytics'
    union all
    select
      'analytics' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'analytics'
  
[0m18:03:34.964776 [debug] [ThreadPool]: SQL status: SELECT 2 in 0.007 seconds
[0m18:03:34.969531 [debug] [ThreadPool]: On list_analytics_analytics: ROLLBACK
[0m18:03:34.972133 [debug] [ThreadPool]: On list_analytics_analytics: Close
[0m18:03:34.995877 [debug] [MainThread]: Using postgres connection "master"
[0m18:03:34.998452 [debug] [MainThread]: On master: BEGIN
[0m18:03:35.000661 [debug] [MainThread]: Opening a new connection, currently in state init
[0m18:03:35.016545 [debug] [MainThread]: SQL status: BEGIN in 0.016 seconds
[0m18:03:35.018589 [debug] [MainThread]: Using postgres connection "master"
[0m18:03:35.020976 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "homework", "target_name": "dev", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select distinct
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v', 'm')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
[0m18:03:35.036627 [debug] [MainThread]: SQL status: SELECT 1 in 0.013 seconds
[0m18:03:35.041529 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '8fbd6f1a-150e-4fc8-b99d-97e1a683b5b1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f52fce403d0>]}
[0m18:03:35.044378 [debug] [MainThread]: On master: ROLLBACK
[0m18:03:35.046908 [debug] [MainThread]: Using postgres connection "master"
[0m18:03:35.048838 [debug] [MainThread]: On master: BEGIN
[0m18:03:35.051054 [debug] [MainThread]: SQL status: BEGIN in 0.001 seconds
[0m18:03:35.052892 [debug] [MainThread]: On master: COMMIT
[0m18:03:35.054515 [debug] [MainThread]: Using postgres connection "master"
[0m18:03:35.056100 [debug] [MainThread]: On master: COMMIT
[0m18:03:35.059587 [debug] [MainThread]: SQL status: COMMIT in 0.001 seconds
[0m18:03:35.061540 [debug] [MainThread]: On master: Close
[0m18:03:35.071467 [debug] [Thread-1  ]: Began running node model.homework.stg_iris
[0m18:03:35.074489 [info ] [Thread-1  ]: 1 of 1 START sql view model analytics.stg_iris ................................. [RUN]
[0m18:03:35.076528 [debug] [Thread-1  ]: Re-using an available connection from the pool (formerly list_analytics_analytics, now model.homework.stg_iris)
[0m18:03:35.078175 [debug] [Thread-1  ]: Began compiling node model.homework.stg_iris
[0m18:03:35.098900 [debug] [Thread-1  ]: Writing injected SQL for node "model.homework.stg_iris"
[0m18:03:35.110185 [debug] [Thread-1  ]: Began executing node model.homework.stg_iris
[0m18:03:35.212694 [debug] [Thread-1  ]: Writing runtime sql for node "model.homework.stg_iris"
[0m18:03:35.225104 [debug] [Thread-1  ]: Using postgres connection "model.homework.stg_iris"
[0m18:03:35.226967 [debug] [Thread-1  ]: On model.homework.stg_iris: BEGIN
[0m18:03:35.228606 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
[0m18:03:35.241413 [debug] [Thread-1  ]: SQL status: BEGIN in 0.012 seconds
[0m18:03:35.243360 [debug] [Thread-1  ]: Using postgres connection "model.homework.stg_iris"
[0m18:03:35.245113 [debug] [Thread-1  ]: On model.homework.stg_iris: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "homework", "target_name": "dev", "node_id": "model.homework.stg_iris"} */

  create view "analytics"."analytics"."stg_iris__dbt_tmp"
    
    
  as (
    with source as (
    select * from "analytics"."analytics"."iris_dataset"
)

select
    sepal_length,
    sepal_width,
    petal_length,
    petal_width,
    species
from source
  );
[0m18:03:35.248880 [debug] [Thread-1  ]: SQL status: CREATE VIEW in 0.002 seconds
[0m18:03:35.266486 [debug] [Thread-1  ]: Using postgres connection "model.homework.stg_iris"
[0m18:03:35.269092 [debug] [Thread-1  ]: On model.homework.stg_iris: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "homework", "target_name": "dev", "node_id": "model.homework.stg_iris"} */
alter table "analytics"."analytics"."stg_iris" rename to "stg_iris__dbt_backup"
[0m18:03:35.271400 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.001 seconds
[0m18:03:35.281447 [debug] [Thread-1  ]: Using postgres connection "model.homework.stg_iris"
[0m18:03:35.283395 [debug] [Thread-1  ]: On model.homework.stg_iris: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "homework", "target_name": "dev", "node_id": "model.homework.stg_iris"} */
alter table "analytics"."analytics"."stg_iris__dbt_tmp" rename to "stg_iris"
[0m18:03:35.285643 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.001 seconds
[0m18:03:35.324888 [debug] [Thread-1  ]: On model.homework.stg_iris: COMMIT
[0m18:03:35.326915 [debug] [Thread-1  ]: Using postgres connection "model.homework.stg_iris"
[0m18:03:35.328617 [debug] [Thread-1  ]: On model.homework.stg_iris: COMMIT
[0m18:03:35.333784 [debug] [Thread-1  ]: SQL status: COMMIT in 0.003 seconds
[0m18:03:35.349173 [debug] [Thread-1  ]: Applying DROP to: "analytics"."analytics"."stg_iris__dbt_backup"
[0m18:03:35.362094 [debug] [Thread-1  ]: Using postgres connection "model.homework.stg_iris"
[0m18:03:35.363896 [debug] [Thread-1  ]: On model.homework.stg_iris: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "homework", "target_name": "dev", "node_id": "model.homework.stg_iris"} */
drop view if exists "analytics"."analytics"."stg_iris__dbt_backup" cascade
[0m18:03:35.369470 [debug] [Thread-1  ]: SQL status: DROP VIEW in 0.004 seconds
[0m18:03:35.376876 [debug] [Thread-1  ]: On model.homework.stg_iris: Close
[0m18:03:35.382800 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '8fbd6f1a-150e-4fc8-b99d-97e1a683b5b1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f52eece1370>]}
[0m18:03:35.385311 [info ] [Thread-1  ]: 1 of 1 OK created sql view model analytics.stg_iris ............................ [[32mCREATE VIEW[0m in 0.30s]
[0m18:03:35.387934 [debug] [Thread-1  ]: Finished running node model.homework.stg_iris
[0m18:03:35.392674 [debug] [MainThread]: Using postgres connection "master"
[0m18:03:35.394434 [debug] [MainThread]: On master: BEGIN
[0m18:03:35.396353 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m18:03:35.409951 [debug] [MainThread]: SQL status: BEGIN in 0.014 seconds
[0m18:03:35.411593 [debug] [MainThread]: On master: COMMIT
[0m18:03:35.413473 [debug] [MainThread]: Using postgres connection "master"
[0m18:03:35.415499 [debug] [MainThread]: On master: COMMIT
[0m18:03:35.417679 [debug] [MainThread]: SQL status: COMMIT in 0.000 seconds
[0m18:03:35.419254 [debug] [MainThread]: On master: Close
[0m18:03:35.421122 [debug] [MainThread]: Connection 'master' was properly closed.
[0m18:03:35.423297 [debug] [MainThread]: Connection 'model.homework.stg_iris' was properly closed.
[0m18:03:35.425496 [info ] [MainThread]: 
[0m18:03:35.427297 [info ] [MainThread]: Finished running 1 view model in 0 hours 0 minutes and 0.71 seconds (0.71s).
[0m18:03:35.429468 [debug] [MainThread]: Command end result
[0m18:03:35.536696 [debug] [MainThread]: Wrote artifact WritableManifest to /opt/airflow/dags/dbt/homework/target/manifest.json
[0m18:03:35.544455 [debug] [MainThread]: Wrote artifact SemanticManifest to /opt/airflow/dags/dbt/homework/target/semantic_manifest.json
[0m18:03:35.563669 [debug] [MainThread]: Wrote artifact RunExecutionResult to /opt/airflow/dags/dbt/homework/target/run_results.json
[0m18:03:35.565079 [info ] [MainThread]: 
[0m18:03:35.566663 [info ] [MainThread]: [32mCompleted successfully[0m
[0m18:03:35.568038 [info ] [MainThread]: 
[0m18:03:35.569518 [info ] [MainThread]: Done. PASS=1 WARN=0 ERROR=0 SKIP=0 TOTAL=1
[0m18:03:35.571892 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": true, "command_wall_clock_time": 8.552422, "process_in_blocks": "0", "process_kernel_time": 0.536993, "process_mem_max_rss": "122232", "process_out_blocks": "0", "process_user_time": 9.566441}
[0m18:03:35.573746 [debug] [MainThread]: Command `dbt run` succeeded at 18:03:35.573425 after 8.55 seconds
[0m18:03:35.576039 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f52ff4f9a90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f52ff376460>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f52ef8d1c70>]}
[0m18:03:35.577907 [debug] [MainThread]: Flushing usage events
[0m18:03:36.110564 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m18:03:42.526211 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f5c5da6ea00>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f5c5cb8f550>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f5c5cb8f4f0>]}


============================== 18:03:42.545583 | 102d8e56-f41b-4117-8957-19a40c0bb9a1 ==============================
[0m18:03:42.545583 [info ] [MainThread]: Running with dbt=1.9.4
[0m18:03:42.550413 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'debug': 'False', 'profiles_dir': '/opt/airflow/dags/dbt', 'log_path': '/opt/airflow/dags/dbt/homework/logs', 'fail_fast': 'True', 'version_check': 'True', 'use_colors': 'True', 'use_experimental_parser': 'False', 'empty': 'None', 'quiet': 'False', 'no_print': 'None', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'introspect': 'True', 'log_format': 'default', 'invocation_command': 'dbt --profile homework test --project-dir=/opt/airflow/dags/dbt/homework --vars {"is_test": false, "data_date": "2025-04-23"} --fail-fast', 'target_path': 'None', 'static_parser': 'True', 'send_anonymous_usage_stats': 'True'}
[0m18:03:43.036311 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '102d8e56-f41b-4117-8957-19a40c0bb9a1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f5c5b356610>]}
[0m18:03:43.183813 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '102d8e56-f41b-4117-8957-19a40c0bb9a1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f5c5b2d09d0>]}
[0m18:03:43.186246 [info ] [MainThread]: Registered adapter: postgres=1.9.0
[0m18:03:43.465600 [debug] [MainThread]: checksum: f5df654a850f4b74beb13fbe0c7d8863b5b1a20bd535c3ac287d70e390b64d41, vars: {'data_date': '2025-04-23', 'is_test': False}, profile: homework, target: , version: 1.9.4
[0m18:03:45.114888 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m18:03:45.116999 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m18:03:45.132010 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 1 unused configuration paths:
- seeds.homework.iris_dataset
[0m18:03:45.221441 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '102d8e56-f41b-4117-8957-19a40c0bb9a1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f5c5aebf130>]}
[0m18:03:45.545459 [debug] [MainThread]: Wrote artifact WritableManifest to /opt/airflow/dags/dbt/homework/target/manifest.json
[0m18:03:45.566603 [debug] [MainThread]: Wrote artifact SemanticManifest to /opt/airflow/dags/dbt/homework/target/semantic_manifest.json
[0m18:03:45.616781 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '102d8e56-f41b-4117-8957-19a40c0bb9a1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f5c5ad9c070>]}
[0m18:03:45.619156 [info ] [MainThread]: Found 2 models, 1 source, 587 macros
[0m18:03:45.621198 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '102d8e56-f41b-4117-8957-19a40c0bb9a1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f5c5b2a9a90>]}
[0m18:03:45.624803 [warn ] [MainThread]: Nothing to do. Try checking your model configs and model specification args
[0m18:03:45.629791 [debug] [MainThread]: Command end result
[0m18:03:45.742212 [debug] [MainThread]: Wrote artifact WritableManifest to /opt/airflow/dags/dbt/homework/target/manifest.json
[0m18:03:45.753648 [debug] [MainThread]: Wrote artifact SemanticManifest to /opt/airflow/dags/dbt/homework/target/semantic_manifest.json
[0m18:03:45.767300 [debug] [MainThread]: Wrote artifact RunExecutionResult to /opt/airflow/dags/dbt/homework/target/run_results.json
[0m18:03:45.770393 [debug] [MainThread]: Resource report: {"command_name": "test", "command_success": true, "command_wall_clock_time": 3.3893633, "process_in_blocks": "0", "process_kernel_time": 0.322395, "process_mem_max_rss": "104524", "process_out_blocks": "0", "process_user_time": 5.410206}
[0m18:03:45.772636 [debug] [MainThread]: Command `dbt test` succeeded at 18:03:45.772448 after 3.39 seconds
[0m18:03:45.774765 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f5c5da6ea00>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f5c5d8ec250>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f5c5b2dbe80>]}
[0m18:03:45.776653 [debug] [MainThread]: Flushing usage events
[0m18:03:46.362823 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m18:04:53.881776 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f2ab670ca90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f2ab582d430>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f2ab582d3d0>]}


============================== 18:04:53.894070 | 5c5a0867-4f7d-4912-8872-1c4e2fbbf11d ==============================
[0m18:04:53.894070 [info ] [MainThread]: Running with dbt=1.9.4
[0m18:04:53.896327 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'debug': 'False', 'profiles_dir': '/opt/airflow/dags/dbt', 'log_path': '/opt/airflow/dags/dbt/homework/logs', 'fail_fast': 'False', 'version_check': 'True', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'empty': 'False', 'log_format': 'default', 'invocation_command': 'dbt --profile homework run --project-dir=/opt/airflow/dags/dbt/homework --vars {"is_test": false, "data_date": "2025-04-23"}', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'static_parser': 'True', 'target_path': 'None', 'introspect': 'True', 'send_anonymous_usage_stats': 'True'}
[0m18:04:54.393114 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '5c5a0867-4f7d-4912-8872-1c4e2fbbf11d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f2ab8101370>]}
[0m18:04:54.537340 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '5c5a0867-4f7d-4912-8872-1c4e2fbbf11d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f2ab4045e20>]}
[0m18:04:54.540626 [info ] [MainThread]: Registered adapter: postgres=1.9.0
[0m18:04:54.833082 [debug] [MainThread]: checksum: f5df654a850f4b74beb13fbe0c7d8863b5b1a20bd535c3ac287d70e390b64d41, vars: {'data_date': '2025-04-23', 'is_test': False}, profile: homework, target: , version: 1.9.4
[0m18:04:56.770680 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m18:04:56.772287 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m18:04:56.787246 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 1 unused configuration paths:
- seeds.homework.iris_dataset
[0m18:04:56.882108 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '5c5a0867-4f7d-4912-8872-1c4e2fbbf11d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f2ab3b59130>]}
[0m18:04:57.207663 [debug] [MainThread]: Wrote artifact WritableManifest to /opt/airflow/dags/dbt/homework/target/manifest.json
[0m18:04:57.228610 [debug] [MainThread]: Wrote artifact SemanticManifest to /opt/airflow/dags/dbt/homework/target/semantic_manifest.json
[0m18:04:57.261174 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '5c5a0867-4f7d-4912-8872-1c4e2fbbf11d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f2ab58927f0>]}
[0m18:04:57.263055 [info ] [MainThread]: Found 2 models, 1 source, 587 macros
[0m18:04:57.264833 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '5c5a0867-4f7d-4912-8872-1c4e2fbbf11d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f2ab7411b80>]}
[0m18:04:57.268146 [info ] [MainThread]: 
[0m18:04:57.269643 [info ] [MainThread]: Concurrency: 4 threads (target='dev')
[0m18:04:57.271124 [info ] [MainThread]: 
[0m18:04:57.273412 [debug] [MainThread]: Acquiring new postgres connection 'master'
[0m18:04:57.284270 [debug] [ThreadPool]: Acquiring new postgres connection 'list_analytics'
[0m18:04:57.358882 [debug] [ThreadPool]: Using postgres connection "list_analytics"
[0m18:04:57.360489 [debug] [ThreadPool]: On list_analytics: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "homework", "target_name": "dev", "connection_name": "list_analytics"} */

    select distinct nspname from pg_namespace
  
[0m18:04:57.362081 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m18:04:57.375142 [debug] [ThreadPool]: SQL status: SELECT 6 in 0.013 seconds
[0m18:04:57.380163 [debug] [ThreadPool]: On list_analytics: Close
[0m18:04:57.383711 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_analytics, now list_analytics_analytics)
[0m18:04:57.403933 [debug] [ThreadPool]: Using postgres connection "list_analytics_analytics"
[0m18:04:57.405633 [debug] [ThreadPool]: On list_analytics_analytics: BEGIN
[0m18:04:57.407730 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m18:04:57.418642 [debug] [ThreadPool]: SQL status: BEGIN in 0.011 seconds
[0m18:04:57.420324 [debug] [ThreadPool]: Using postgres connection "list_analytics_analytics"
[0m18:04:57.422154 [debug] [ThreadPool]: On list_analytics_analytics: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "homework", "target_name": "dev", "connection_name": "list_analytics_analytics"} */
select
      'analytics' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'analytics'
    union all
    select
      'analytics' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'analytics'
    union all
    select
      'analytics' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'analytics'
  
[0m18:04:57.428360 [debug] [ThreadPool]: SQL status: SELECT 2 in 0.004 seconds
[0m18:04:57.432013 [debug] [ThreadPool]: On list_analytics_analytics: ROLLBACK
[0m18:04:57.434045 [debug] [ThreadPool]: On list_analytics_analytics: Close
[0m18:04:57.445955 [debug] [MainThread]: Using postgres connection "master"
[0m18:04:57.447726 [debug] [MainThread]: On master: BEGIN
[0m18:04:57.449360 [debug] [MainThread]: Opening a new connection, currently in state init
[0m18:04:57.460636 [debug] [MainThread]: SQL status: BEGIN in 0.011 seconds
[0m18:04:57.462491 [debug] [MainThread]: Using postgres connection "master"
[0m18:04:57.464462 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "homework", "target_name": "dev", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select distinct
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v', 'm')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
[0m18:04:57.475922 [debug] [MainThread]: SQL status: SELECT 1 in 0.009 seconds
[0m18:04:57.479639 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '5c5a0867-4f7d-4912-8872-1c4e2fbbf11d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f2ab30e29d0>]}
[0m18:04:57.481415 [debug] [MainThread]: On master: ROLLBACK
[0m18:04:57.483329 [debug] [MainThread]: Using postgres connection "master"
[0m18:04:57.485027 [debug] [MainThread]: On master: BEGIN
[0m18:04:57.487017 [debug] [MainThread]: SQL status: BEGIN in 0.000 seconds
[0m18:04:57.488482 [debug] [MainThread]: On master: COMMIT
[0m18:04:57.490128 [debug] [MainThread]: Using postgres connection "master"
[0m18:04:57.492175 [debug] [MainThread]: On master: COMMIT
[0m18:04:57.494139 [debug] [MainThread]: SQL status: COMMIT in 0.000 seconds
[0m18:04:57.495853 [debug] [MainThread]: On master: Close
[0m18:04:57.503996 [debug] [Thread-1  ]: Began running node model.homework.stg_iris
[0m18:04:57.506297 [info ] [Thread-1  ]: 1 of 2 START sql view model analytics.stg_iris ................................. [RUN]
[0m18:04:57.508870 [debug] [Thread-1  ]: Re-using an available connection from the pool (formerly list_analytics_analytics, now model.homework.stg_iris)
[0m18:04:57.510729 [debug] [Thread-1  ]: Began compiling node model.homework.stg_iris
[0m18:04:57.530808 [debug] [Thread-1  ]: Writing injected SQL for node "model.homework.stg_iris"
[0m18:04:57.544186 [debug] [Thread-1  ]: Began executing node model.homework.stg_iris
[0m18:04:57.633282 [debug] [Thread-1  ]: Writing runtime sql for node "model.homework.stg_iris"
[0m18:04:57.646224 [debug] [Thread-1  ]: Using postgres connection "model.homework.stg_iris"
[0m18:04:57.648430 [debug] [Thread-1  ]: On model.homework.stg_iris: BEGIN
[0m18:04:57.650349 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
[0m18:04:57.662323 [debug] [Thread-1  ]: SQL status: BEGIN in 0.012 seconds
[0m18:04:57.664265 [debug] [Thread-1  ]: Using postgres connection "model.homework.stg_iris"
[0m18:04:57.666208 [debug] [Thread-1  ]: On model.homework.stg_iris: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "homework", "target_name": "dev", "node_id": "model.homework.stg_iris"} */

  create view "analytics"."analytics"."stg_iris__dbt_tmp"
    
    
  as (
    with source as (
    select * from "analytics"."analytics"."iris_dataset"
)

select
    sepal_length,
    sepal_width,
    petal_length,
    petal_width,
    species
from source
  );
[0m18:04:57.670054 [debug] [Thread-1  ]: SQL status: CREATE VIEW in 0.002 seconds
[0m18:04:57.687831 [debug] [Thread-1  ]: Using postgres connection "model.homework.stg_iris"
[0m18:04:57.689761 [debug] [Thread-1  ]: On model.homework.stg_iris: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "homework", "target_name": "dev", "node_id": "model.homework.stg_iris"} */
alter table "analytics"."analytics"."stg_iris" rename to "stg_iris__dbt_backup"
[0m18:04:57.692708 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.001 seconds
[0m18:04:57.701764 [debug] [Thread-1  ]: Using postgres connection "model.homework.stg_iris"
[0m18:04:57.704538 [debug] [Thread-1  ]: On model.homework.stg_iris: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "homework", "target_name": "dev", "node_id": "model.homework.stg_iris"} */
alter table "analytics"."analytics"."stg_iris__dbt_tmp" rename to "stg_iris"
[0m18:04:57.707177 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.001 seconds
[0m18:04:57.751672 [debug] [Thread-1  ]: On model.homework.stg_iris: COMMIT
[0m18:04:57.753936 [debug] [Thread-1  ]: Using postgres connection "model.homework.stg_iris"
[0m18:04:57.755928 [debug] [Thread-1  ]: On model.homework.stg_iris: COMMIT
[0m18:04:57.761802 [debug] [Thread-1  ]: SQL status: COMMIT in 0.003 seconds
[0m18:04:57.780986 [debug] [Thread-1  ]: Applying DROP to: "analytics"."analytics"."stg_iris__dbt_backup"
[0m18:04:57.795765 [debug] [Thread-1  ]: Using postgres connection "model.homework.stg_iris"
[0m18:04:57.797976 [debug] [Thread-1  ]: On model.homework.stg_iris: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "homework", "target_name": "dev", "node_id": "model.homework.stg_iris"} */
drop view if exists "analytics"."analytics"."stg_iris__dbt_backup" cascade
[0m18:04:57.804334 [debug] [Thread-1  ]: SQL status: DROP VIEW in 0.004 seconds
[0m18:04:57.812555 [debug] [Thread-1  ]: On model.homework.stg_iris: Close
[0m18:04:57.818270 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '5c5a0867-4f7d-4912-8872-1c4e2fbbf11d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f2ab3017070>]}
[0m18:04:57.820975 [info ] [Thread-1  ]: 1 of 2 OK created sql view model analytics.stg_iris ............................ [[32mCREATE VIEW[0m in 0.31s]
[0m18:04:57.824409 [debug] [Thread-1  ]: Finished running node model.homework.stg_iris
[0m18:04:57.828652 [debug] [Thread-3  ]: Began running node model.homework.iris_processed
[0m18:04:57.831570 [info ] [Thread-3  ]: 2 of 2 START sql table model analytics.iris_processed .......................... [RUN]
[0m18:04:57.834270 [debug] [Thread-3  ]: Acquiring new postgres connection 'model.homework.iris_processed'
[0m18:04:57.836405 [debug] [Thread-3  ]: Began compiling node model.homework.iris_processed
[0m18:04:57.905827 [debug] [Thread-3  ]: Using postgres connection "model.homework.iris_processed"
[0m18:04:57.908252 [debug] [Thread-3  ]: On model.homework.iris_processed: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "homework", "target_name": "dev", "node_id": "model.homework.iris_processed"} */

        select percentile_cont(0.5) within group (order by sepal_length ) from "analytics"."analytics"."stg_iris"
    
[0m18:04:57.910264 [debug] [Thread-3  ]: Opening a new connection, currently in state init
[0m18:04:57.925192 [debug] [Thread-3  ]: SQL status: SELECT 1 in 0.014 seconds
[0m18:04:57.929998 [debug] [Thread-3  ]: Using postgres connection "model.homework.iris_processed"
[0m18:04:57.932394 [debug] [Thread-3  ]: On model.homework.iris_processed: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "homework", "target_name": "dev", "node_id": "model.homework.iris_processed"} */

        select percentile_cont(0.5 - 0.5/2) within group (order by sepal_length ) from "analytics"."analytics"."stg_iris"
    
[0m18:04:57.935477 [debug] [Thread-3  ]: SQL status: SELECT 1 in 0.001 seconds
[0m18:04:57.939485 [debug] [Thread-3  ]: Using postgres connection "model.homework.iris_processed"
[0m18:04:57.941873 [debug] [Thread-3  ]: On model.homework.iris_processed: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "homework", "target_name": "dev", "node_id": "model.homework.iris_processed"} */

        select percentile_cont(0.5 + 0.5/2) within group (order by sepal_length ) from "analytics"."analytics"."stg_iris"
    
[0m18:04:57.945126 [debug] [Thread-3  ]: SQL status: SELECT 1 in 0.001 seconds
[0m18:04:57.970933 [debug] [Thread-3  ]: Using postgres connection "model.homework.iris_processed"
[0m18:04:57.973215 [debug] [Thread-3  ]: On model.homework.iris_processed: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "homework", "target_name": "dev", "node_id": "model.homework.iris_processed"} */

        select percentile_cont(0.5) within group (order by sepal_width ) from "analytics"."analytics"."stg_iris"
    
[0m18:04:57.977257 [debug] [Thread-3  ]: SQL status: SELECT 1 in 0.001 seconds
[0m18:04:57.983607 [debug] [Thread-3  ]: Using postgres connection "model.homework.iris_processed"
[0m18:04:57.986432 [debug] [Thread-3  ]: On model.homework.iris_processed: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "homework", "target_name": "dev", "node_id": "model.homework.iris_processed"} */

        select percentile_cont(0.5 - 0.5/2) within group (order by sepal_width ) from "analytics"."analytics"."stg_iris"
    
[0m18:04:57.989975 [debug] [Thread-3  ]: SQL status: SELECT 1 in 0.001 seconds
[0m18:04:57.996261 [debug] [Thread-3  ]: Using postgres connection "model.homework.iris_processed"
[0m18:04:57.998543 [debug] [Thread-3  ]: On model.homework.iris_processed: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "homework", "target_name": "dev", "node_id": "model.homework.iris_processed"} */

        select percentile_cont(0.5 + 0.5/2) within group (order by sepal_width ) from "analytics"."analytics"."stg_iris"
    
[0m18:04:58.001416 [debug] [Thread-3  ]: SQL status: SELECT 1 in 0.001 seconds
[0m18:04:58.012904 [debug] [Thread-3  ]: Using postgres connection "model.homework.iris_processed"
[0m18:04:58.015570 [debug] [Thread-3  ]: On model.homework.iris_processed: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "homework", "target_name": "dev", "node_id": "model.homework.iris_processed"} */

        select percentile_cont(0.5) within group (order by petal_length ) from "analytics"."analytics"."stg_iris"
    
[0m18:04:58.018359 [debug] [Thread-3  ]: SQL status: SELECT 1 in 0.001 seconds
[0m18:04:58.023540 [debug] [Thread-3  ]: Using postgres connection "model.homework.iris_processed"
[0m18:04:58.027219 [debug] [Thread-3  ]: On model.homework.iris_processed: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "homework", "target_name": "dev", "node_id": "model.homework.iris_processed"} */

        select percentile_cont(0.5 - 0.5/2) within group (order by petal_length ) from "analytics"."analytics"."stg_iris"
    
[0m18:04:58.030697 [debug] [Thread-3  ]: SQL status: SELECT 1 in 0.001 seconds
[0m18:04:58.035753 [debug] [Thread-3  ]: Using postgres connection "model.homework.iris_processed"
[0m18:04:58.038466 [debug] [Thread-3  ]: On model.homework.iris_processed: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "homework", "target_name": "dev", "node_id": "model.homework.iris_processed"} */

        select percentile_cont(0.5 + 0.5/2) within group (order by petal_length ) from "analytics"."analytics"."stg_iris"
    
[0m18:04:58.042812 [debug] [Thread-3  ]: SQL status: SELECT 1 in 0.002 seconds
[0m18:04:58.050521 [debug] [Thread-3  ]: Using postgres connection "model.homework.iris_processed"
[0m18:04:58.052605 [debug] [Thread-3  ]: On model.homework.iris_processed: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "homework", "target_name": "dev", "node_id": "model.homework.iris_processed"} */

        select percentile_cont(0.5) within group (order by petal_width ) from "analytics"."analytics"."stg_iris"
    
[0m18:04:58.055246 [debug] [Thread-3  ]: SQL status: SELECT 1 in 0.001 seconds
[0m18:04:58.061055 [debug] [Thread-3  ]: Using postgres connection "model.homework.iris_processed"
[0m18:04:58.063104 [debug] [Thread-3  ]: On model.homework.iris_processed: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "homework", "target_name": "dev", "node_id": "model.homework.iris_processed"} */

        select percentile_cont(0.5 - 0.5/2) within group (order by petal_width ) from "analytics"."analytics"."stg_iris"
    
[0m18:04:58.065988 [debug] [Thread-3  ]: SQL status: SELECT 1 in 0.001 seconds
[0m18:04:58.070426 [debug] [Thread-3  ]: Using postgres connection "model.homework.iris_processed"
[0m18:04:58.072317 [debug] [Thread-3  ]: On model.homework.iris_processed: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "homework", "target_name": "dev", "node_id": "model.homework.iris_processed"} */

        select percentile_cont(0.5 + 0.5/2) within group (order by petal_width ) from "analytics"."analytics"."stg_iris"
    
[0m18:04:58.076086 [debug] [Thread-3  ]: SQL status: SELECT 1 in 0.001 seconds
[0m18:04:58.105779 [debug] [Thread-3  ]: Using postgres connection "model.homework.iris_processed"
[0m18:04:58.108075 [debug] [Thread-3  ]: On model.homework.iris_processed: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "homework", "target_name": "dev", "node_id": "model.homework.iris_processed"} */

            select percentile_cont(0.5) within group (order by sepal_length ) from "analytics"."analytics"."stg_iris"
        
[0m18:04:58.110900 [debug] [Thread-3  ]: SQL status: SELECT 1 in 0.001 seconds
[0m18:04:58.116239 [debug] [Thread-3  ]: Using postgres connection "model.homework.iris_processed"
[0m18:04:58.118082 [debug] [Thread-3  ]: On model.homework.iris_processed: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "homework", "target_name": "dev", "node_id": "model.homework.iris_processed"} */

            select percentile_cont(0.5) within group (order by sepal_width ) from "analytics"."analytics"."stg_iris"
        
[0m18:04:58.120160 [debug] [Thread-3  ]: SQL status: SELECT 1 in 0.000 seconds
[0m18:04:58.125503 [debug] [Thread-3  ]: Using postgres connection "model.homework.iris_processed"
[0m18:04:58.127369 [debug] [Thread-3  ]: On model.homework.iris_processed: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "homework", "target_name": "dev", "node_id": "model.homework.iris_processed"} */

            select percentile_cont(0.5) within group (order by petal_length ) from "analytics"."analytics"."stg_iris"
        
[0m18:04:58.129795 [debug] [Thread-3  ]: SQL status: SELECT 1 in 0.001 seconds
[0m18:04:58.136079 [debug] [Thread-3  ]: Using postgres connection "model.homework.iris_processed"
[0m18:04:58.137851 [debug] [Thread-3  ]: On model.homework.iris_processed: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "homework", "target_name": "dev", "node_id": "model.homework.iris_processed"} */

            select percentile_cont(0.5) within group (order by petal_width ) from "analytics"."analytics"."stg_iris"
        
[0m18:04:58.140124 [debug] [Thread-3  ]: SQL status: SELECT 1 in 0.001 seconds
[0m18:04:58.229094 [debug] [Thread-3  ]: Using postgres connection "model.homework.iris_processed"
[0m18:04:58.231866 [debug] [Thread-3  ]: On model.homework.iris_processed: BEGIN
[0m18:04:58.235064 [debug] [Thread-3  ]: SQL status: BEGIN in 0.000 seconds
[0m18:04:58.237101 [debug] [Thread-3  ]: Using postgres connection "model.homework.iris_processed"
[0m18:04:58.239852 [debug] [Thread-3  ]: On model.homework.iris_processed: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "homework", "target_name": "dev", "node_id": "model.homework.iris_processed"} */
select
                species as value

            from "analytics"."analytics"."stg_iris"

            
            where species is not null  and true
            

            group by species
            order by species

            

        
[0m18:04:58.244520 [debug] [Thread-3  ]: SQL status: SELECT 3 in 0.001 seconds
[0m18:04:58.256863 [debug] [Thread-3  ]: Writing injected SQL for node "model.homework.iris_processed"
[0m18:04:58.273781 [debug] [Thread-3  ]: Began executing node model.homework.iris_processed
[0m18:04:58.336272 [debug] [Thread-3  ]: Writing runtime sql for node "model.homework.iris_processed"
[0m18:04:58.383485 [debug] [Thread-3  ]: Using postgres connection "model.homework.iris_processed"
[0m18:04:58.386992 [debug] [Thread-3  ]: On model.homework.iris_processed: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "homework", "target_name": "dev", "node_id": "model.homework.iris_processed"} */

  
    

  create  table "analytics"."analytics"."iris_processed__dbt_tmp"
  
  
    as
  
  (
    

with import_iris as (
    select *
    from "analytics"."analytics"."stg_iris"
)
select
    sepal_length,
    sepal_width,
    petal_length,
    petal_width,
    -- K Bins Discretization
    
        

    
        NTILE(5) over (order by sepal_length)
    

 as sepal_length_quantile_bin,
        

    
        
        floor(
        (
            sepal_length - (min(sepal_length) over ())
        )
        /
        (
            ((max(sepal_length) over ()) - (min(sepal_length) over ())) / 4::float
        )
        ) + 1
    

 as sepal_length_uniform_bin,
    
        

    
        NTILE(5) over (order by sepal_width)
    

 as sepal_width_quantile_bin,
        

    
        
        floor(
        (
            sepal_width - (min(sepal_width) over ())
        )
        /
        (
            ((max(sepal_width) over ()) - (min(sepal_width) over ())) / 4::float
        )
        ) + 1
    

 as sepal_width_uniform_bin,
    
        

    
        NTILE(5) over (order by petal_length)
    

 as petal_length_quantile_bin,
        

    
        
        floor(
        (
            petal_length - (min(petal_length) over ())
        )
        /
        (
            ((max(petal_length) over ()) - (min(petal_length) over ())) / 4::float
        )
        ) + 1
    

 as petal_length_uniform_bin,
    
        

    
        NTILE(5) over (order by petal_width)
    

 as petal_width_quantile_bin,
        

    
        
        floor(
        (
            petal_width - (min(petal_width) over ())
        )
        /
        (
            ((max(petal_width) over ()) - (min(petal_width) over ())) / 4::float
        )
        ) + 1
    

 as petal_width_uniform_bin,
    
-- Scaling
    
        

    

    
    
    

    
    
    

    (
        sepal_length - 5.8
    )
    /
    (
        6.4 - 5.1
    )

 as sepal_length_robust_scaled,
        

    (sepal_length) / (max(abs(sepal_length)) over ())::FLOAT

 as sepal_length_max_absolute_scaled,
        

    
    (
        ((sepal_length) - (min(sepal_length) over ()))
        /
        ((max(sepal_length) over ()) - (min(sepal_length) over ()))::FLOAT
    )
    *
    (1.0 - 0.0)
    +
    0.0

 as sepal_length_max_min_max_scaled,
    
        

    

    
    
    

    
    
    

    (
        sepal_width - 3.0
    )
    /
    (
        3.3 - 2.8
    )

 as sepal_width_robust_scaled,
        

    (sepal_width) / (max(abs(sepal_width)) over ())::FLOAT

 as sepal_width_max_absolute_scaled,
        

    
    (
        ((sepal_width) - (min(sepal_width) over ()))
        /
        ((max(sepal_width) over ()) - (min(sepal_width) over ()))::FLOAT
    )
    *
    (1.0 - 0.0)
    +
    0.0

 as sepal_width_max_min_max_scaled,
    
        

    

    
    
    

    
    
    

    (
        petal_length - 4.35
    )
    /
    (
        5.1 - 1.6
    )

 as petal_length_robust_scaled,
        

    (petal_length) / (max(abs(petal_length)) over ())::FLOAT

 as petal_length_max_absolute_scaled,
        

    
    (
        ((petal_length) - (min(petal_length) over ()))
        /
        ((max(petal_length) over ()) - (min(petal_length) over ()))::FLOAT
    )
    *
    (1.0 - 0.0)
    +
    0.0

 as petal_length_max_min_max_scaled,
    
        

    

    
    
    

    
    
    

    (
        petal_width - 1.3
    )
    /
    (
        1.8 - 0.3
    )

 as petal_width_robust_scaled,
        

    (petal_width) / (max(abs(petal_width)) over ())::FLOAT

 as petal_width_max_absolute_scaled,
        

    
    (
        ((petal_width) - (min(petal_width) over ()))
        /
        ((max(petal_width) over ()) - (min(petal_width) over ()))::FLOAT
    )
    *
    (1.0 - 0.0)
    +
    0.0

 as petal_width_max_min_max_scaled,
    

    -- Log Transformation
    
        

    case
        when sepal_length is null or sepal_length + 0 <= 0 then null
        else log(10, sepal_length + 0)
    end

 as sepal_length_logged,
    
        

    case
        when sepal_width is null or sepal_width + 0 <= 0 then null
        else log(10, sepal_width + 0)
    end

 as sepal_width_logged,
    
        

    case
        when petal_length is null or petal_length + 0 <= 0 then null
        else log(10, petal_length + 0)
    end

 as petal_length_logged,
    
        

    case
        when petal_width is null or petal_width + 0 <= 0 then null
        else log(10, petal_width + 0)
    end

 as petal_width_logged,
    

    -- Binarization
    
        

    

    
        

        
    

    case
        when sepal_length >=
            
                5.8
            
            then 1
        else 0
    end

 as sepal_length_binarized,
    
        

    

    
        

        
    

    case
        when sepal_width >=
            
                3.0
            
            then 1
        else 0
    end

 as sepal_width_binarized,
    
        

    

    
        

        
    

    case
        when petal_length >=
            
                4.35
            
            then 1
        else 0
    end

 as petal_length_binarized,
    
        

    

    
        

        
    

    case
        when petal_width >=
            
                1.3
            
            then 1
        else 0
    end

 as petal_width_binarized,
    

    -- Standardization
    
        

    
    (
        (sepal_length - avg(sepal_length) over ())
        /
        (stddev(sepal_length) over ())::FLOAT
    )
    *
    1
    +
    0

 as sepal_length_standardized,
    
        

    
    (
        (sepal_width - avg(sepal_width) over ())
        /
        (stddev(sepal_width) over ())::FLOAT
    )
    *
    1
    +
    0

 as sepal_width_standardized,
    
        

    
    (
        (petal_length - avg(petal_length) over ())
        /
        (stddev(petal_length) over ())::FLOAT
    )
    *
    1
    +
    0

 as petal_length_standardized,
    
        

    
    (
        (petal_width - avg(petal_width) over ())
        /
        (stddev(petal_width) over ())::FLOAT
    )
    *
    1
    +
    0

 as petal_width_standardized,
    
-- Interactions
    
        
            
            
            

    
        (sepal_length * sepal_width)
    

 as sepal_length_x_sepal_width_interaction,
            

    
        (sepal_length + sepal_width)
    

 as sepal_length_plus_sepal_width_interaction,
        
            
            
            

    
        (sepal_length * petal_length)
    

 as sepal_length_x_petal_length_interaction,
            

    
        (sepal_length + petal_length)
    

 as sepal_length_plus_petal_length_interaction,
        
            
            
            

    
        (sepal_length * petal_width)
    

 as sepal_length_x_petal_width_interaction,
            

    
        (sepal_length + petal_width)
    

 as sepal_length_plus_petal_width_interaction,
        
    
        
            
            
            

    
        (sepal_width * petal_length)
    

 as sepal_width_x_petal_length_interaction,
            

    
        (sepal_width + petal_length)
    

 as sepal_width_plus_petal_length_interaction,
        
            
            
            

    
        (sepal_width * petal_width)
    

 as sepal_width_x_petal_width_interaction,
            

    
        (sepal_width + petal_width)
    

 as sepal_width_plus_petal_width_interaction,
        
    
        
            
            
            

    
        (petal_length * petal_width)
    

 as petal_length_x_petal_width_interaction,
            

    
        (petal_length + petal_width)
    

 as petal_length_plus_petal_width_interaction,
        
    
        
    
species,    
    -- Label Encoding
    

    dense_rank() over (order by species) - 1

 as species_label_encoded,
    -- One Hot Encoding
    

    

    
        
    

    

    

        case
            when species = 'setosa' then 1
            else 0
        end as is_species__setosa,

    

        case
            when species = 'versicolor' then 1
            else 0
        end as is_species__versicolor,

    

        case
            when species = 'virginica' then 1
            else 0
        end as is_species__virginica,

    

    case
        when species is null then 1
        else 0
    end as is_species__


from "analytics"."analytics"."stg_iris"
  );
  
[0m18:04:58.393707 [debug] [Thread-3  ]: Postgres adapter: Postgres error: function log(integer, double precision) does not exist
LINE 294:         else log(10, sepal_length + 0)
                       ^
HINT:  No function matches the given name and argument types. You might need to add explicit type casts.

[0m18:04:58.395917 [debug] [Thread-3  ]: On model.homework.iris_processed: ROLLBACK
[0m18:04:58.398407 [debug] [Thread-3  ]: On model.homework.iris_processed: Close
[0m18:04:58.403627 [debug] [Thread-3  ]: Database Error in model iris_processed (models/mart/iris_processed.sql)
  function log(integer, double precision) does not exist
  LINE 294:         else log(10, sepal_length + 0)
                         ^
  HINT:  No function matches the given name and argument types. You might need to add explicit type casts.
  compiled code at target/run/homework/models/mart/iris_processed.sql
[0m18:04:58.405992 [debug] [Thread-3  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '5c5a0867-4f7d-4912-8872-1c4e2fbbf11d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f2ab30170a0>]}
[0m18:04:58.408934 [error] [Thread-3  ]: 2 of 2 ERROR creating sql table model analytics.iris_processed ................. [[31mERROR[0m in 0.57s]
[0m18:04:58.412085 [debug] [Thread-3  ]: Finished running node model.homework.iris_processed
[0m18:04:58.414433 [debug] [Thread-7  ]: Marking all children of 'model.homework.iris_processed' to be skipped because of status 'error'.  Reason: Database Error in model iris_processed (models/mart/iris_processed.sql)
  function log(integer, double precision) does not exist
  LINE 294:         else log(10, sepal_length + 0)
                         ^
  HINT:  No function matches the given name and argument types. You might need to add explicit type casts.
  compiled code at target/run/homework/models/mart/iris_processed.sql.
[0m18:04:58.418348 [debug] [MainThread]: Using postgres connection "master"
[0m18:04:58.420169 [debug] [MainThread]: On master: BEGIN
[0m18:04:58.421790 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m18:04:58.433042 [debug] [MainThread]: SQL status: BEGIN in 0.011 seconds
[0m18:04:58.434828 [debug] [MainThread]: On master: COMMIT
[0m18:04:58.436460 [debug] [MainThread]: Using postgres connection "master"
[0m18:04:58.437916 [debug] [MainThread]: On master: COMMIT
[0m18:04:58.439757 [debug] [MainThread]: SQL status: COMMIT in 0.000 seconds
[0m18:04:58.441346 [debug] [MainThread]: On master: Close
[0m18:04:58.443569 [debug] [MainThread]: Connection 'master' was properly closed.
[0m18:04:58.445269 [debug] [MainThread]: Connection 'model.homework.stg_iris' was properly closed.
[0m18:04:58.446914 [debug] [MainThread]: Connection 'model.homework.iris_processed' was properly closed.
[0m18:04:58.448447 [info ] [MainThread]: 
[0m18:04:58.450153 [info ] [MainThread]: Finished running 1 table model, 1 view model in 0 hours 0 minutes and 1.18 seconds (1.18s).
[0m18:04:58.452872 [debug] [MainThread]: Command end result
[0m18:04:58.550185 [debug] [MainThread]: Wrote artifact WritableManifest to /opt/airflow/dags/dbt/homework/target/manifest.json
[0m18:04:58.559280 [debug] [MainThread]: Wrote artifact SemanticManifest to /opt/airflow/dags/dbt/homework/target/semantic_manifest.json
[0m18:04:58.581784 [debug] [MainThread]: Wrote artifact RunExecutionResult to /opt/airflow/dags/dbt/homework/target/run_results.json
[0m18:04:58.583831 [info ] [MainThread]: 
[0m18:04:58.586290 [info ] [MainThread]: [31mCompleted with 1 error, 0 partial successes, and 0 warnings:[0m
[0m18:04:58.588384 [info ] [MainThread]: 
[0m18:04:58.590747 [error] [MainThread]:   Database Error in model iris_processed (models/mart/iris_processed.sql)
  function log(integer, double precision) does not exist
  LINE 294:         else log(10, sepal_length + 0)
                         ^
  HINT:  No function matches the given name and argument types. You might need to add explicit type casts.
  compiled code at target/run/homework/models/mart/iris_processed.sql
[0m18:04:58.593078 [info ] [MainThread]: 
[0m18:04:58.595297 [info ] [MainThread]: Done. PASS=1 WARN=0 ERROR=1 SKIP=0 TOTAL=2
[0m18:04:58.598632 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": false, "command_wall_clock_time": 4.8713703, "process_in_blocks": "0", "process_kernel_time": 0.42772, "process_mem_max_rss": "115484", "process_out_blocks": "0", "process_user_time": 6.137288}
[0m18:04:58.600909 [debug] [MainThread]: Command `dbt run` failed at 18:04:58.600724 after 4.87 seconds
[0m18:04:58.602662 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f2ab670ca90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f2ab58927f0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f2ab405c850>]}
[0m18:04:58.604667 [debug] [MainThread]: Flushing usage events
[0m18:04:59.182471 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m18:10:04.497758 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f86d6c83a90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f86d5da4460>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f86d5da4400>]}


============================== 18:10:04.513423 | 48fb53f9-e49e-4b2a-8176-a5928bd9f99b ==============================
[0m18:10:04.513423 [info ] [MainThread]: Running with dbt=1.9.4
[0m18:10:04.516278 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': '/opt/airflow/dags/dbt', 'debug': 'False', 'warn_error': 'None', 'log_path': '/opt/airflow/dags/dbt/homework/logs', 'version_check': 'True', 'fail_fast': 'False', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'empty': 'False', 'log_format': 'default', 'invocation_command': 'dbt --profile homework run --project-dir=/opt/airflow/dags/dbt/homework --vars {"is_test": false, "data_date": "2025-04-23"}', 'introspect': 'True', 'static_parser': 'True', 'target_path': 'None', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'send_anonymous_usage_stats': 'True'}
[0m18:10:04.968287 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '48fb53f9-e49e-4b2a-8176-a5928bd9f99b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f86d45777f0>]}
[0m18:10:05.099164 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '48fb53f9-e49e-4b2a-8176-a5928bd9f99b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f86d5fc45e0>]}
[0m18:10:05.102760 [info ] [MainThread]: Registered adapter: postgres=1.9.0
[0m18:10:05.381090 [debug] [MainThread]: checksum: f5df654a850f4b74beb13fbe0c7d8863b5b1a20bd535c3ac287d70e390b64d41, vars: {'data_date': '2025-04-23', 'is_test': False}, profile: homework, target: , version: 1.9.4
[0m18:10:06.946570 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m18:10:06.948540 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m18:10:06.965814 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 1 unused configuration paths:
- seeds.homework.iris_dataset
[0m18:10:07.051998 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '48fb53f9-e49e-4b2a-8176-a5928bd9f99b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f86d40cf130>]}
[0m18:10:07.357296 [debug] [MainThread]: Wrote artifact WritableManifest to /opt/airflow/dags/dbt/homework/target/manifest.json
[0m18:10:07.377757 [debug] [MainThread]: Wrote artifact SemanticManifest to /opt/airflow/dags/dbt/homework/target/semantic_manifest.json
[0m18:10:07.424480 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '48fb53f9-e49e-4b2a-8176-a5928bd9f99b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f86d44264f0>]}
[0m18:10:07.426665 [info ] [MainThread]: Found 2 models, 1 source, 587 macros
[0m18:10:07.428507 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '48fb53f9-e49e-4b2a-8176-a5928bd9f99b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f86d5e324c0>]}
[0m18:10:07.432663 [info ] [MainThread]: 
[0m18:10:07.434744 [info ] [MainThread]: Concurrency: 4 threads (target='dev')
[0m18:10:07.436979 [info ] [MainThread]: 
[0m18:10:07.439767 [debug] [MainThread]: Acquiring new postgres connection 'master'
[0m18:10:07.450599 [debug] [ThreadPool]: Acquiring new postgres connection 'list_analytics'
[0m18:10:07.536923 [debug] [ThreadPool]: Using postgres connection "list_analytics"
[0m18:10:07.539353 [debug] [ThreadPool]: On list_analytics: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "homework", "target_name": "dev", "connection_name": "list_analytics"} */

    select distinct nspname from pg_namespace
  
[0m18:10:07.541131 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m18:10:07.556940 [debug] [ThreadPool]: SQL status: SELECT 6 in 0.016 seconds
[0m18:10:07.561620 [debug] [ThreadPool]: On list_analytics: Close
[0m18:10:07.566607 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_analytics, now list_analytics_analytics)
[0m18:10:07.587540 [debug] [ThreadPool]: Using postgres connection "list_analytics_analytics"
[0m18:10:07.589684 [debug] [ThreadPool]: On list_analytics_analytics: BEGIN
[0m18:10:07.591619 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m18:10:07.603429 [debug] [ThreadPool]: SQL status: BEGIN in 0.012 seconds
[0m18:10:07.605462 [debug] [ThreadPool]: Using postgres connection "list_analytics_analytics"
[0m18:10:07.607325 [debug] [ThreadPool]: On list_analytics_analytics: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "homework", "target_name": "dev", "connection_name": "list_analytics_analytics"} */
select
      'analytics' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'analytics'
    union all
    select
      'analytics' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'analytics'
    union all
    select
      'analytics' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'analytics'
  
[0m18:10:07.613443 [debug] [ThreadPool]: SQL status: SELECT 2 in 0.005 seconds
[0m18:10:07.617802 [debug] [ThreadPool]: On list_analytics_analytics: ROLLBACK
[0m18:10:07.620090 [debug] [ThreadPool]: On list_analytics_analytics: Close
[0m18:10:07.632090 [debug] [MainThread]: Using postgres connection "master"
[0m18:10:07.633848 [debug] [MainThread]: On master: BEGIN
[0m18:10:07.635503 [debug] [MainThread]: Opening a new connection, currently in state init
[0m18:10:07.649850 [debug] [MainThread]: SQL status: BEGIN in 0.014 seconds
[0m18:10:07.651738 [debug] [MainThread]: Using postgres connection "master"
[0m18:10:07.653767 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "homework", "target_name": "dev", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select distinct
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v', 'm')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
[0m18:10:07.663578 [debug] [MainThread]: SQL status: SELECT 1 in 0.008 seconds
[0m18:10:07.667880 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '48fb53f9-e49e-4b2a-8176-a5928bd9f99b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f86d3659940>]}
[0m18:10:07.669701 [debug] [MainThread]: On master: ROLLBACK
[0m18:10:07.671648 [debug] [MainThread]: Using postgres connection "master"
[0m18:10:07.673188 [debug] [MainThread]: On master: BEGIN
[0m18:10:07.676011 [debug] [MainThread]: SQL status: BEGIN in 0.000 seconds
[0m18:10:07.677782 [debug] [MainThread]: On master: COMMIT
[0m18:10:07.686447 [debug] [MainThread]: Using postgres connection "master"
[0m18:10:07.688723 [debug] [MainThread]: On master: COMMIT
[0m18:10:07.691056 [debug] [MainThread]: SQL status: COMMIT in 0.000 seconds
[0m18:10:07.692835 [debug] [MainThread]: On master: Close
[0m18:10:07.700736 [debug] [Thread-1  ]: Began running node model.homework.stg_iris
[0m18:10:07.702934 [info ] [Thread-1  ]: 1 of 2 START sql view model analytics.stg_iris ................................. [RUN]
[0m18:10:07.704832 [debug] [Thread-1  ]: Re-using an available connection from the pool (formerly list_analytics_analytics, now model.homework.stg_iris)
[0m18:10:07.706518 [debug] [Thread-1  ]: Began compiling node model.homework.stg_iris
[0m18:10:07.727488 [debug] [Thread-1  ]: Writing injected SQL for node "model.homework.stg_iris"
[0m18:10:07.738074 [debug] [Thread-1  ]: Began executing node model.homework.stg_iris
[0m18:10:07.833964 [debug] [Thread-1  ]: Writing runtime sql for node "model.homework.stg_iris"
[0m18:10:07.846174 [debug] [Thread-1  ]: Using postgres connection "model.homework.stg_iris"
[0m18:10:07.848462 [debug] [Thread-1  ]: On model.homework.stg_iris: BEGIN
[0m18:10:07.850281 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
[0m18:10:07.862035 [debug] [Thread-1  ]: SQL status: BEGIN in 0.012 seconds
[0m18:10:07.864260 [debug] [Thread-1  ]: Using postgres connection "model.homework.stg_iris"
[0m18:10:07.866302 [debug] [Thread-1  ]: On model.homework.stg_iris: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "homework", "target_name": "dev", "node_id": "model.homework.stg_iris"} */

  create view "analytics"."analytics"."stg_iris__dbt_tmp"
    
    
  as (
    with source as (
    select * from "analytics"."analytics"."iris_dataset"
)

select
    sepal_length,
    sepal_width,
    petal_length,
    petal_width,
    species
from source
  );
[0m18:10:07.870556 [debug] [Thread-1  ]: SQL status: CREATE VIEW in 0.002 seconds
[0m18:10:07.891177 [debug] [Thread-1  ]: Using postgres connection "model.homework.stg_iris"
[0m18:10:07.893108 [debug] [Thread-1  ]: On model.homework.stg_iris: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "homework", "target_name": "dev", "node_id": "model.homework.stg_iris"} */
alter table "analytics"."analytics"."stg_iris" rename to "stg_iris__dbt_backup"
[0m18:10:07.895554 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.001 seconds
[0m18:10:07.905570 [debug] [Thread-1  ]: Using postgres connection "model.homework.stg_iris"
[0m18:10:07.907602 [debug] [Thread-1  ]: On model.homework.stg_iris: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "homework", "target_name": "dev", "node_id": "model.homework.stg_iris"} */
alter table "analytics"."analytics"."stg_iris__dbt_tmp" rename to "stg_iris"
[0m18:10:07.910470 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.001 seconds
[0m18:10:07.952987 [debug] [Thread-1  ]: On model.homework.stg_iris: COMMIT
[0m18:10:07.954890 [debug] [Thread-1  ]: Using postgres connection "model.homework.stg_iris"
[0m18:10:07.956717 [debug] [Thread-1  ]: On model.homework.stg_iris: COMMIT
[0m18:10:07.962972 [debug] [Thread-1  ]: SQL status: COMMIT in 0.004 seconds
[0m18:10:07.981789 [debug] [Thread-1  ]: Applying DROP to: "analytics"."analytics"."stg_iris__dbt_backup"
[0m18:10:07.994170 [debug] [Thread-1  ]: Using postgres connection "model.homework.stg_iris"
[0m18:10:07.996311 [debug] [Thread-1  ]: On model.homework.stg_iris: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "homework", "target_name": "dev", "node_id": "model.homework.stg_iris"} */
drop view if exists "analytics"."analytics"."stg_iris__dbt_backup" cascade
[0m18:10:08.002506 [debug] [Thread-1  ]: SQL status: DROP VIEW in 0.004 seconds
[0m18:10:08.008435 [debug] [Thread-1  ]: On model.homework.stg_iris: Close
[0m18:10:08.014894 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '48fb53f9-e49e-4b2a-8176-a5928bd9f99b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f86d358e070>]}
[0m18:10:08.017196 [info ] [Thread-1  ]: 1 of 2 OK created sql view model analytics.stg_iris ............................ [[32mCREATE VIEW[0m in 0.31s]
[0m18:10:08.019564 [debug] [Thread-1  ]: Finished running node model.homework.stg_iris
[0m18:10:08.022190 [debug] [Thread-3  ]: Began running node model.homework.iris_processed
[0m18:10:08.024174 [info ] [Thread-3  ]: 2 of 2 START sql table model analytics.iris_processed .......................... [RUN]
[0m18:10:08.026412 [debug] [Thread-3  ]: Acquiring new postgres connection 'model.homework.iris_processed'
[0m18:10:08.028222 [debug] [Thread-3  ]: Began compiling node model.homework.iris_processed
[0m18:10:08.095498 [debug] [Thread-3  ]: Using postgres connection "model.homework.iris_processed"
[0m18:10:08.097440 [debug] [Thread-3  ]: On model.homework.iris_processed: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "homework", "target_name": "dev", "node_id": "model.homework.iris_processed"} */

        select percentile_cont(0.5) within group (order by sepal_length ) from "analytics"."analytics"."stg_iris"
    
[0m18:10:08.099471 [debug] [Thread-3  ]: Opening a new connection, currently in state init
[0m18:10:08.112360 [debug] [Thread-3  ]: SQL status: SELECT 1 in 0.013 seconds
[0m18:10:08.116507 [debug] [Thread-3  ]: Using postgres connection "model.homework.iris_processed"
[0m18:10:08.118266 [debug] [Thread-3  ]: On model.homework.iris_processed: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "homework", "target_name": "dev", "node_id": "model.homework.iris_processed"} */

        select percentile_cont(0.5 - 0.5/2) within group (order by sepal_length ) from "analytics"."analytics"."stg_iris"
    
[0m18:10:08.120980 [debug] [Thread-3  ]: SQL status: SELECT 1 in 0.001 seconds
[0m18:10:08.124904 [debug] [Thread-3  ]: Using postgres connection "model.homework.iris_processed"
[0m18:10:08.126691 [debug] [Thread-3  ]: On model.homework.iris_processed: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "homework", "target_name": "dev", "node_id": "model.homework.iris_processed"} */

        select percentile_cont(0.5 + 0.5/2) within group (order by sepal_length ) from "analytics"."analytics"."stg_iris"
    
[0m18:10:08.129319 [debug] [Thread-3  ]: SQL status: SELECT 1 in 0.001 seconds
[0m18:10:08.148124 [debug] [Thread-3  ]: Using postgres connection "model.homework.iris_processed"
[0m18:10:08.149996 [debug] [Thread-3  ]: On model.homework.iris_processed: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "homework", "target_name": "dev", "node_id": "model.homework.iris_processed"} */

        select percentile_cont(0.5) within group (order by sepal_width ) from "analytics"."analytics"."stg_iris"
    
[0m18:10:08.152481 [debug] [Thread-3  ]: SQL status: SELECT 1 in 0.001 seconds
[0m18:10:08.156346 [debug] [Thread-3  ]: Using postgres connection "model.homework.iris_processed"
[0m18:10:08.158271 [debug] [Thread-3  ]: On model.homework.iris_processed: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "homework", "target_name": "dev", "node_id": "model.homework.iris_processed"} */

        select percentile_cont(0.5 - 0.5/2) within group (order by sepal_width ) from "analytics"."analytics"."stg_iris"
    
[0m18:10:08.161181 [debug] [Thread-3  ]: SQL status: SELECT 1 in 0.001 seconds
[0m18:10:08.165715 [debug] [Thread-3  ]: Using postgres connection "model.homework.iris_processed"
[0m18:10:08.167711 [debug] [Thread-3  ]: On model.homework.iris_processed: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "homework", "target_name": "dev", "node_id": "model.homework.iris_processed"} */

        select percentile_cont(0.5 + 0.5/2) within group (order by sepal_width ) from "analytics"."analytics"."stg_iris"
    
[0m18:10:08.170378 [debug] [Thread-3  ]: SQL status: SELECT 1 in 0.001 seconds
[0m18:10:08.176070 [debug] [Thread-3  ]: Using postgres connection "model.homework.iris_processed"
[0m18:10:08.177765 [debug] [Thread-3  ]: On model.homework.iris_processed: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "homework", "target_name": "dev", "node_id": "model.homework.iris_processed"} */

        select percentile_cont(0.5) within group (order by petal_length ) from "analytics"."analytics"."stg_iris"
    
[0m18:10:08.180033 [debug] [Thread-3  ]: SQL status: SELECT 1 in 0.001 seconds
[0m18:10:08.183905 [debug] [Thread-3  ]: Using postgres connection "model.homework.iris_processed"
[0m18:10:08.185541 [debug] [Thread-3  ]: On model.homework.iris_processed: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "homework", "target_name": "dev", "node_id": "model.homework.iris_processed"} */

        select percentile_cont(0.5 - 0.5/2) within group (order by petal_length ) from "analytics"."analytics"."stg_iris"
    
[0m18:10:08.187963 [debug] [Thread-3  ]: SQL status: SELECT 1 in 0.001 seconds
[0m18:10:08.191737 [debug] [Thread-3  ]: Using postgres connection "model.homework.iris_processed"
[0m18:10:08.193376 [debug] [Thread-3  ]: On model.homework.iris_processed: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "homework", "target_name": "dev", "node_id": "model.homework.iris_processed"} */

        select percentile_cont(0.5 + 0.5/2) within group (order by petal_length ) from "analytics"."analytics"."stg_iris"
    
[0m18:10:08.195698 [debug] [Thread-3  ]: SQL status: SELECT 1 in 0.000 seconds
[0m18:10:08.201231 [debug] [Thread-3  ]: Using postgres connection "model.homework.iris_processed"
[0m18:10:08.202872 [debug] [Thread-3  ]: On model.homework.iris_processed: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "homework", "target_name": "dev", "node_id": "model.homework.iris_processed"} */

        select percentile_cont(0.5) within group (order by petal_width ) from "analytics"."analytics"."stg_iris"
    
[0m18:10:08.205498 [debug] [Thread-3  ]: SQL status: SELECT 1 in 0.001 seconds
[0m18:10:08.209284 [debug] [Thread-3  ]: Using postgres connection "model.homework.iris_processed"
[0m18:10:08.211124 [debug] [Thread-3  ]: On model.homework.iris_processed: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "homework", "target_name": "dev", "node_id": "model.homework.iris_processed"} */

        select percentile_cont(0.5 - 0.5/2) within group (order by petal_width ) from "analytics"."analytics"."stg_iris"
    
[0m18:10:08.213545 [debug] [Thread-3  ]: SQL status: SELECT 1 in 0.001 seconds
[0m18:10:08.218205 [debug] [Thread-3  ]: Using postgres connection "model.homework.iris_processed"
[0m18:10:08.220350 [debug] [Thread-3  ]: On model.homework.iris_processed: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "homework", "target_name": "dev", "node_id": "model.homework.iris_processed"} */

        select percentile_cont(0.5 + 0.5/2) within group (order by petal_width ) from "analytics"."analytics"."stg_iris"
    
[0m18:10:08.222719 [debug] [Thread-3  ]: SQL status: SELECT 1 in 0.000 seconds
[0m18:10:08.247531 [debug] [Thread-3  ]: Using postgres connection "model.homework.iris_processed"
[0m18:10:08.249340 [debug] [Thread-3  ]: On model.homework.iris_processed: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "homework", "target_name": "dev", "node_id": "model.homework.iris_processed"} */

            select percentile_cont(0.5) within group (order by sepal_length ) from "analytics"."analytics"."stg_iris"
        
[0m18:10:08.251841 [debug] [Thread-3  ]: SQL status: SELECT 1 in 0.001 seconds
[0m18:10:08.256732 [debug] [Thread-3  ]: Using postgres connection "model.homework.iris_processed"
[0m18:10:08.258538 [debug] [Thread-3  ]: On model.homework.iris_processed: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "homework", "target_name": "dev", "node_id": "model.homework.iris_processed"} */

            select percentile_cont(0.5) within group (order by sepal_width ) from "analytics"."analytics"."stg_iris"
        
[0m18:10:08.260904 [debug] [Thread-3  ]: SQL status: SELECT 1 in 0.000 seconds
[0m18:10:08.265804 [debug] [Thread-3  ]: Using postgres connection "model.homework.iris_processed"
[0m18:10:08.267849 [debug] [Thread-3  ]: On model.homework.iris_processed: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "homework", "target_name": "dev", "node_id": "model.homework.iris_processed"} */

            select percentile_cont(0.5) within group (order by petal_length ) from "analytics"."analytics"."stg_iris"
        
[0m18:10:08.270210 [debug] [Thread-3  ]: SQL status: SELECT 1 in 0.001 seconds
[0m18:10:08.275147 [debug] [Thread-3  ]: Using postgres connection "model.homework.iris_processed"
[0m18:10:08.277154 [debug] [Thread-3  ]: On model.homework.iris_processed: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "homework", "target_name": "dev", "node_id": "model.homework.iris_processed"} */

            select percentile_cont(0.5) within group (order by petal_width ) from "analytics"."analytics"."stg_iris"
        
[0m18:10:08.279594 [debug] [Thread-3  ]: SQL status: SELECT 1 in 0.001 seconds
[0m18:10:08.361553 [debug] [Thread-3  ]: Using postgres connection "model.homework.iris_processed"
[0m18:10:08.363424 [debug] [Thread-3  ]: On model.homework.iris_processed: BEGIN
[0m18:10:08.366212 [debug] [Thread-3  ]: SQL status: BEGIN in 0.000 seconds
[0m18:10:08.368780 [debug] [Thread-3  ]: Using postgres connection "model.homework.iris_processed"
[0m18:10:08.371662 [debug] [Thread-3  ]: On model.homework.iris_processed: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "homework", "target_name": "dev", "node_id": "model.homework.iris_processed"} */
select
                species as value

            from "analytics"."analytics"."stg_iris"

            
            where species is not null  and true
            

            group by species
            order by species

            

        
[0m18:10:08.376232 [debug] [Thread-3  ]: SQL status: SELECT 3 in 0.001 seconds
[0m18:10:08.390137 [debug] [Thread-3  ]: Writing injected SQL for node "model.homework.iris_processed"
[0m18:10:08.406035 [debug] [Thread-3  ]: Began executing node model.homework.iris_processed
[0m18:10:08.459229 [debug] [Thread-3  ]: Writing runtime sql for node "model.homework.iris_processed"
[0m18:10:08.470723 [debug] [Thread-3  ]: Using postgres connection "model.homework.iris_processed"
[0m18:10:08.474666 [debug] [Thread-3  ]: On model.homework.iris_processed: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "homework", "target_name": "dev", "node_id": "model.homework.iris_processed"} */

  
    

  create  table "analytics"."analytics"."iris_processed__dbt_tmp"
  
  
    as
  
  (
    

with import_iris as (
    select *
    from "analytics"."analytics"."stg_iris"
)
select
    sepal_length,
    sepal_width,
    petal_length,
    petal_width,
    -- K Bins Discretization
    
        

    
        NTILE(5) over (order by sepal_length)
    

 as sepal_length_quantile_bin,
        

    
        
        floor(
        (
            sepal_length - (min(sepal_length) over ())
        )
        /
        (
            ((max(sepal_length) over ()) - (min(sepal_length) over ())) / 4::float
        )
        ) + 1
    

 as sepal_length_uniform_bin,
    
        

    
        NTILE(5) over (order by sepal_width)
    

 as sepal_width_quantile_bin,
        

    
        
        floor(
        (
            sepal_width - (min(sepal_width) over ())
        )
        /
        (
            ((max(sepal_width) over ()) - (min(sepal_width) over ())) / 4::float
        )
        ) + 1
    

 as sepal_width_uniform_bin,
    
        

    
        NTILE(5) over (order by petal_length)
    

 as petal_length_quantile_bin,
        

    
        
        floor(
        (
            petal_length - (min(petal_length) over ())
        )
        /
        (
            ((max(petal_length) over ()) - (min(petal_length) over ())) / 4::float
        )
        ) + 1
    

 as petal_length_uniform_bin,
    
        

    
        NTILE(5) over (order by petal_width)
    

 as petal_width_quantile_bin,
        

    
        
        floor(
        (
            petal_width - (min(petal_width) over ())
        )
        /
        (
            ((max(petal_width) over ()) - (min(petal_width) over ())) / 4::float
        )
        ) + 1
    

 as petal_width_uniform_bin,
    
-- Scaling
    
        

    

    
    
    

    
    
    

    (
        sepal_length - 5.8
    )
    /
    (
        6.4 - 5.1
    )

 as sepal_length_robust_scaled,
        

    (sepal_length) / (max(abs(sepal_length)) over ())::FLOAT

 as sepal_length_max_absolute_scaled,
        

    
    (
        ((sepal_length) - (min(sepal_length) over ()))
        /
        ((max(sepal_length) over ()) - (min(sepal_length) over ()))::FLOAT
    )
    *
    (1.0 - 0.0)
    +
    0.0

 as sepal_length_max_min_max_scaled,
    
        

    

    
    
    

    
    
    

    (
        sepal_width - 3.0
    )
    /
    (
        3.3 - 2.8
    )

 as sepal_width_robust_scaled,
        

    (sepal_width) / (max(abs(sepal_width)) over ())::FLOAT

 as sepal_width_max_absolute_scaled,
        

    
    (
        ((sepal_width) - (min(sepal_width) over ()))
        /
        ((max(sepal_width) over ()) - (min(sepal_width) over ()))::FLOAT
    )
    *
    (1.0 - 0.0)
    +
    0.0

 as sepal_width_max_min_max_scaled,
    
        

    

    
    
    

    
    
    

    (
        petal_length - 4.35
    )
    /
    (
        5.1 - 1.6
    )

 as petal_length_robust_scaled,
        

    (petal_length) / (max(abs(petal_length)) over ())::FLOAT

 as petal_length_max_absolute_scaled,
        

    
    (
        ((petal_length) - (min(petal_length) over ()))
        /
        ((max(petal_length) over ()) - (min(petal_length) over ()))::FLOAT
    )
    *
    (1.0 - 0.0)
    +
    0.0

 as petal_length_max_min_max_scaled,
    
        

    

    
    
    

    
    
    

    (
        petal_width - 1.3
    )
    /
    (
        1.8 - 0.3
    )

 as petal_width_robust_scaled,
        

    (petal_width) / (max(abs(petal_width)) over ())::FLOAT

 as petal_width_max_absolute_scaled,
        

    
    (
        ((petal_width) - (min(petal_width) over ()))
        /
        ((max(petal_width) over ()) - (min(petal_width) over ()))::FLOAT
    )
    *
    (1.0 - 0.0)
    +
    0.0

 as petal_width_max_min_max_scaled,
    

    -- Log Transformation
    
        

    case
        when sepal_length is null or sepal_length + 0 <= 0 then null
        else log(10, sepal_length + 0)
    end

 as sepal_length_logged,
    
        

    case
        when sepal_width is null or sepal_width + 0 <= 0 then null
        else log(10, sepal_width + 0)
    end

 as sepal_width_logged,
    
        

    case
        when petal_length is null or petal_length + 0 <= 0 then null
        else log(10, petal_length + 0)
    end

 as petal_length_logged,
    
        

    case
        when petal_width is null or petal_width + 0 <= 0 then null
        else log(10, petal_width + 0)
    end

 as petal_width_logged,
    

    -- Binarization
    
        

    

    
        

        
    

    case
        when sepal_length >=
            
                5.8
            
            then 1
        else 0
    end

 as sepal_length_binarized,
    
        

    

    
        

        
    

    case
        when sepal_width >=
            
                3.0
            
            then 1
        else 0
    end

 as sepal_width_binarized,
    
        

    

    
        

        
    

    case
        when petal_length >=
            
                4.35
            
            then 1
        else 0
    end

 as petal_length_binarized,
    
        

    

    
        

        
    

    case
        when petal_width >=
            
                1.3
            
            then 1
        else 0
    end

 as petal_width_binarized,
    

    -- Standardization
    
        

    
    (
        (sepal_length - avg(sepal_length) over ())
        /
        (stddev(sepal_length) over ())::FLOAT
    )
    *
    1
    +
    0

 as sepal_length_standardized,
    
        

    
    (
        (sepal_width - avg(sepal_width) over ())
        /
        (stddev(sepal_width) over ())::FLOAT
    )
    *
    1
    +
    0

 as sepal_width_standardized,
    
        

    
    (
        (petal_length - avg(petal_length) over ())
        /
        (stddev(petal_length) over ())::FLOAT
    )
    *
    1
    +
    0

 as petal_length_standardized,
    
        

    
    (
        (petal_width - avg(petal_width) over ())
        /
        (stddev(petal_width) over ())::FLOAT
    )
    *
    1
    +
    0

 as petal_width_standardized,
    
-- Interactions
    
        
            
            
            

    
        (sepal_length * sepal_width)
    

 as sepal_length_x_sepal_width_interaction,
            

    
        (sepal_length + sepal_width)
    

 as sepal_length_plus_sepal_width_interaction,
        
            
            
            

    
        (sepal_length * petal_length)
    

 as sepal_length_x_petal_length_interaction,
            

    
        (sepal_length + petal_length)
    

 as sepal_length_plus_petal_length_interaction,
        
            
            
            

    
        (sepal_length * petal_width)
    

 as sepal_length_x_petal_width_interaction,
            

    
        (sepal_length + petal_width)
    

 as sepal_length_plus_petal_width_interaction,
        
    
        
            
            
            

    
        (sepal_width * petal_length)
    

 as sepal_width_x_petal_length_interaction,
            

    
        (sepal_width + petal_length)
    

 as sepal_width_plus_petal_length_interaction,
        
            
            
            

    
        (sepal_width * petal_width)
    

 as sepal_width_x_petal_width_interaction,
            

    
        (sepal_width + petal_width)
    

 as sepal_width_plus_petal_width_interaction,
        
    
        
            
            
            

    
        (petal_length * petal_width)
    

 as petal_length_x_petal_width_interaction,
            

    
        (petal_length + petal_width)
    

 as petal_length_plus_petal_width_interaction,
        
    
        
    
species,    
    -- Label Encoding
    

    dense_rank() over (order by species) - 1

 as species_label_encoded,
    -- One Hot Encoding
    

    

    
        
    

    

    

        case
            when species = 'setosa' then 1
            else 0
        end as is_species__setosa,

    

        case
            when species = 'versicolor' then 1
            else 0
        end as is_species__versicolor,

    

        case
            when species = 'virginica' then 1
            else 0
        end as is_species__virginica,

    

    case
        when species is null then 1
        else 0
    end as is_species__


from "analytics"."analytics"."stg_iris"
  );
  
[0m18:10:08.480976 [debug] [Thread-3  ]: Postgres adapter: Postgres error: function log(integer, double precision) does not exist
LINE 294:         else log(10, sepal_length + 0)
                       ^
HINT:  No function matches the given name and argument types. You might need to add explicit type casts.

[0m18:10:08.483344 [debug] [Thread-3  ]: On model.homework.iris_processed: ROLLBACK
[0m18:10:08.486241 [debug] [Thread-3  ]: On model.homework.iris_processed: Close
[0m18:10:08.492229 [debug] [Thread-3  ]: Database Error in model iris_processed (models/mart/iris_processed.sql)
  function log(integer, double precision) does not exist
  LINE 294:         else log(10, sepal_length + 0)
                         ^
  HINT:  No function matches the given name and argument types. You might need to add explicit type casts.
  compiled code at target/run/homework/models/mart/iris_processed.sql
[0m18:10:08.494246 [debug] [Thread-3  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '48fb53f9-e49e-4b2a-8176-a5928bd9f99b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f86d3528250>]}
[0m18:10:08.496522 [error] [Thread-3  ]: 2 of 2 ERROR creating sql table model analytics.iris_processed ................. [[31mERROR[0m in 0.47s]
[0m18:10:08.498943 [debug] [Thread-3  ]: Finished running node model.homework.iris_processed
[0m18:10:08.501154 [debug] [Thread-7  ]: Marking all children of 'model.homework.iris_processed' to be skipped because of status 'error'.  Reason: Database Error in model iris_processed (models/mart/iris_processed.sql)
  function log(integer, double precision) does not exist
  LINE 294:         else log(10, sepal_length + 0)
                         ^
  HINT:  No function matches the given name and argument types. You might need to add explicit type casts.
  compiled code at target/run/homework/models/mart/iris_processed.sql.
[0m18:10:08.505373 [debug] [MainThread]: Using postgres connection "master"
[0m18:10:08.506944 [debug] [MainThread]: On master: BEGIN
[0m18:10:08.508387 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m18:10:08.519919 [debug] [MainThread]: SQL status: BEGIN in 0.011 seconds
[0m18:10:08.522101 [debug] [MainThread]: On master: COMMIT
[0m18:10:08.524362 [debug] [MainThread]: Using postgres connection "master"
[0m18:10:08.526535 [debug] [MainThread]: On master: COMMIT
[0m18:10:08.528319 [debug] [MainThread]: SQL status: COMMIT in 0.000 seconds
[0m18:10:08.530161 [debug] [MainThread]: On master: Close
[0m18:10:08.532538 [debug] [MainThread]: Connection 'master' was properly closed.
[0m18:10:08.534581 [debug] [MainThread]: Connection 'model.homework.stg_iris' was properly closed.
[0m18:10:08.536371 [debug] [MainThread]: Connection 'model.homework.iris_processed' was properly closed.
[0m18:10:08.538216 [info ] [MainThread]: 
[0m18:10:08.539852 [info ] [MainThread]: Finished running 1 table model, 1 view model in 0 hours 0 minutes and 1.10 seconds (1.10s).
[0m18:10:08.542719 [debug] [MainThread]: Command end result
[0m18:10:08.644874 [debug] [MainThread]: Wrote artifact WritableManifest to /opt/airflow/dags/dbt/homework/target/manifest.json
[0m18:10:08.655859 [debug] [MainThread]: Wrote artifact SemanticManifest to /opt/airflow/dags/dbt/homework/target/semantic_manifest.json
[0m18:10:08.674996 [debug] [MainThread]: Wrote artifact RunExecutionResult to /opt/airflow/dags/dbt/homework/target/run_results.json
[0m18:10:08.676694 [info ] [MainThread]: 
[0m18:10:08.678507 [info ] [MainThread]: [31mCompleted with 1 error, 0 partial successes, and 0 warnings:[0m
[0m18:10:08.680383 [info ] [MainThread]: 
[0m18:10:08.682194 [error] [MainThread]:   Database Error in model iris_processed (models/mart/iris_processed.sql)
  function log(integer, double precision) does not exist
  LINE 294:         else log(10, sepal_length + 0)
                         ^
  HINT:  No function matches the given name and argument types. You might need to add explicit type casts.
  compiled code at target/run/homework/models/mart/iris_processed.sql
[0m18:10:08.684097 [info ] [MainThread]: 
[0m18:10:08.686088 [info ] [MainThread]: Done. PASS=1 WARN=0 ERROR=1 SKIP=0 TOTAL=2
[0m18:10:08.691166 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": false, "command_wall_clock_time": 4.342252, "process_in_blocks": "24", "process_kernel_time": 0.339113, "process_mem_max_rss": "114492", "process_out_blocks": "0", "process_user_time": 5.994324}
[0m18:10:08.694064 [debug] [MainThread]: Command `dbt run` failed at 18:10:08.693872 after 4.35 seconds
[0m18:10:08.695889 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f86d6c83a90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f86d456c4c0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f86d456cf10>]}
[0m18:10:08.697835 [debug] [MainThread]: Flushing usage events
[0m18:10:09.336771 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m18:17:16.741373 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f5af1d709a0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f5af0e913a0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f5af0e91340>]}


============================== 18:17:16.754467 | 90ce430e-36ea-4267-9a7c-7c06f48cfc2f ==============================
[0m18:17:16.754467 [info ] [MainThread]: Running with dbt=1.9.4
[0m18:17:16.756988 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'fail_fast': 'False', 'debug': 'False', 'log_path': '/opt/airflow/dags/dbt/homework/logs', 'version_check': 'True', 'profiles_dir': '/opt/airflow/dags/dbt', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'empty': 'False', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'introspect': 'True', 'static_parser': 'True', 'invocation_command': 'dbt --profile homework run --project-dir=/opt/airflow/dags/dbt/homework --vars {"is_test": false, "data_date": "2025-04-23"}', 'target_path': 'None', 'log_format': 'default', 'send_anonymous_usage_stats': 'True'}
[0m18:17:17.224823 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '90ce430e-36ea-4267-9a7c-7c06f48cfc2f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f5aef7066d0>]}
[0m18:17:17.353942 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '90ce430e-36ea-4267-9a7c-7c06f48cfc2f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f5af1ed1100>]}
[0m18:17:17.356869 [info ] [MainThread]: Registered adapter: postgres=1.9.0
[0m18:17:17.641942 [debug] [MainThread]: checksum: f5df654a850f4b74beb13fbe0c7d8863b5b1a20bd535c3ac287d70e390b64d41, vars: {'data_date': '2025-04-23', 'is_test': False}, profile: homework, target: , version: 1.9.4
[0m18:17:19.519784 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 1 files changed.
[0m18:17:19.523347 [debug] [MainThread]: Partial parsing: updated file: dbt_ml_inline_preprocessing://macros/log_transform.sql
[0m18:17:20.942164 [warn ] [MainThread]: [[33mWARNING[0m]: Found patch for macro "log_transform" which was not found
[0m18:17:21.091650 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 1 unused configuration paths:
- seeds.homework.iris_dataset
[0m18:17:21.128459 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '90ce430e-36ea-4267-9a7c-7c06f48cfc2f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f5aeee23130>]}
[0m18:17:21.374978 [debug] [MainThread]: Wrote artifact WritableManifest to /opt/airflow/dags/dbt/homework/target/manifest.json
[0m18:17:21.393005 [debug] [MainThread]: Wrote artifact SemanticManifest to /opt/airflow/dags/dbt/homework/target/semantic_manifest.json
[0m18:17:21.427010 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '90ce430e-36ea-4267-9a7c-7c06f48cfc2f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f5aeee6d430>]}
[0m18:17:21.429326 [info ] [MainThread]: Found 2 models, 1 source, 586 macros
[0m18:17:21.430989 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '90ce430e-36ea-4267-9a7c-7c06f48cfc2f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f5aeee42ca0>]}
[0m18:17:21.434877 [info ] [MainThread]: 
[0m18:17:21.437341 [info ] [MainThread]: Concurrency: 4 threads (target='dev')
[0m18:17:21.439343 [info ] [MainThread]: 
[0m18:17:21.441728 [debug] [MainThread]: Acquiring new postgres connection 'master'
[0m18:17:21.453142 [debug] [ThreadPool]: Acquiring new postgres connection 'list_analytics'
[0m18:17:21.523352 [debug] [ThreadPool]: Using postgres connection "list_analytics"
[0m18:17:21.525391 [debug] [ThreadPool]: On list_analytics: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "homework", "target_name": "dev", "connection_name": "list_analytics"} */

    select distinct nspname from pg_namespace
  
[0m18:17:21.527061 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m18:17:21.541762 [debug] [ThreadPool]: SQL status: SELECT 6 in 0.015 seconds
[0m18:17:21.545421 [debug] [ThreadPool]: On list_analytics: Close
[0m18:17:21.549329 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_analytics, now list_analytics_analytics)
[0m18:17:21.563960 [debug] [ThreadPool]: Using postgres connection "list_analytics_analytics"
[0m18:17:21.565779 [debug] [ThreadPool]: On list_analytics_analytics: BEGIN
[0m18:17:21.567377 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m18:17:21.579212 [debug] [ThreadPool]: SQL status: BEGIN in 0.012 seconds
[0m18:17:21.581043 [debug] [ThreadPool]: Using postgres connection "list_analytics_analytics"
[0m18:17:21.583034 [debug] [ThreadPool]: On list_analytics_analytics: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "homework", "target_name": "dev", "connection_name": "list_analytics_analytics"} */
select
      'analytics' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'analytics'
    union all
    select
      'analytics' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'analytics'
    union all
    select
      'analytics' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'analytics'
  
[0m18:17:21.589501 [debug] [ThreadPool]: SQL status: SELECT 2 in 0.004 seconds
[0m18:17:21.596562 [debug] [ThreadPool]: On list_analytics_analytics: ROLLBACK
[0m18:17:21.599470 [debug] [ThreadPool]: On list_analytics_analytics: Close
[0m18:17:21.613920 [debug] [MainThread]: Using postgres connection "master"
[0m18:17:21.615822 [debug] [MainThread]: On master: BEGIN
[0m18:17:21.617435 [debug] [MainThread]: Opening a new connection, currently in state init
[0m18:17:21.629261 [debug] [MainThread]: SQL status: BEGIN in 0.012 seconds
[0m18:17:21.630976 [debug] [MainThread]: Using postgres connection "master"
[0m18:17:21.632988 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "homework", "target_name": "dev", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select distinct
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v', 'm')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
[0m18:17:21.643882 [debug] [MainThread]: SQL status: SELECT 1 in 0.009 seconds
[0m18:17:21.647831 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '90ce430e-36ea-4267-9a7c-7c06f48cfc2f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f5aee257490>]}
[0m18:17:21.649427 [debug] [MainThread]: On master: ROLLBACK
[0m18:17:21.651489 [debug] [MainThread]: Using postgres connection "master"
[0m18:17:21.653441 [debug] [MainThread]: On master: BEGIN
[0m18:17:21.656567 [debug] [MainThread]: SQL status: BEGIN in 0.001 seconds
[0m18:17:21.658448 [debug] [MainThread]: On master: COMMIT
[0m18:17:21.660295 [debug] [MainThread]: Using postgres connection "master"
[0m18:17:21.661951 [debug] [MainThread]: On master: COMMIT
[0m18:17:21.664087 [debug] [MainThread]: SQL status: COMMIT in 0.000 seconds
[0m18:17:21.665853 [debug] [MainThread]: On master: Close
[0m18:17:21.674663 [debug] [Thread-1  ]: Began running node model.homework.stg_iris
[0m18:17:21.676609 [info ] [Thread-1  ]: 1 of 2 START sql view model analytics.stg_iris ................................. [RUN]
[0m18:17:21.678571 [debug] [Thread-1  ]: Re-using an available connection from the pool (formerly list_analytics_analytics, now model.homework.stg_iris)
[0m18:17:21.680253 [debug] [Thread-1  ]: Began compiling node model.homework.stg_iris
[0m18:17:21.700293 [debug] [Thread-1  ]: Writing injected SQL for node "model.homework.stg_iris"
[0m18:17:21.710683 [debug] [Thread-1  ]: Began executing node model.homework.stg_iris
[0m18:17:21.792366 [debug] [Thread-1  ]: Writing runtime sql for node "model.homework.stg_iris"
[0m18:17:21.804488 [debug] [Thread-1  ]: Using postgres connection "model.homework.stg_iris"
[0m18:17:21.806777 [debug] [Thread-1  ]: On model.homework.stg_iris: BEGIN
[0m18:17:21.808856 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
[0m18:17:21.822464 [debug] [Thread-1  ]: SQL status: BEGIN in 0.014 seconds
[0m18:17:21.825847 [debug] [Thread-1  ]: Using postgres connection "model.homework.stg_iris"
[0m18:17:21.828270 [debug] [Thread-1  ]: On model.homework.stg_iris: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "homework", "target_name": "dev", "node_id": "model.homework.stg_iris"} */

  create view "analytics"."analytics"."stg_iris__dbt_tmp"
    
    
  as (
    with source as (
    select * from "analytics"."analytics"."iris_dataset"
)

select
    sepal_length,
    sepal_width,
    petal_length,
    petal_width,
    species
from source
  );
[0m18:17:21.852104 [debug] [Thread-1  ]: SQL status: CREATE VIEW in 0.002 seconds
[0m18:17:21.873926 [debug] [Thread-1  ]: Using postgres connection "model.homework.stg_iris"
[0m18:17:21.876056 [debug] [Thread-1  ]: On model.homework.stg_iris: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "homework", "target_name": "dev", "node_id": "model.homework.stg_iris"} */
alter table "analytics"."analytics"."stg_iris" rename to "stg_iris__dbt_backup"
[0m18:17:21.878703 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.001 seconds
[0m18:17:21.888591 [debug] [Thread-1  ]: Using postgres connection "model.homework.stg_iris"
[0m18:17:21.890646 [debug] [Thread-1  ]: On model.homework.stg_iris: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "homework", "target_name": "dev", "node_id": "model.homework.stg_iris"} */
alter table "analytics"."analytics"."stg_iris__dbt_tmp" rename to "stg_iris"
[0m18:17:21.893049 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.001 seconds
[0m18:17:21.933330 [debug] [Thread-1  ]: On model.homework.stg_iris: COMMIT
[0m18:17:21.935223 [debug] [Thread-1  ]: Using postgres connection "model.homework.stg_iris"
[0m18:17:21.937440 [debug] [Thread-1  ]: On model.homework.stg_iris: COMMIT
[0m18:17:21.943975 [debug] [Thread-1  ]: SQL status: COMMIT in 0.004 seconds
[0m18:17:21.967084 [debug] [Thread-1  ]: Applying DROP to: "analytics"."analytics"."stg_iris__dbt_backup"
[0m18:17:21.981943 [debug] [Thread-1  ]: Using postgres connection "model.homework.stg_iris"
[0m18:17:21.984198 [debug] [Thread-1  ]: On model.homework.stg_iris: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "homework", "target_name": "dev", "node_id": "model.homework.stg_iris"} */
drop view if exists "analytics"."analytics"."stg_iris__dbt_backup" cascade
[0m18:17:21.990819 [debug] [Thread-1  ]: SQL status: DROP VIEW in 0.004 seconds
[0m18:17:21.998647 [debug] [Thread-1  ]: On model.homework.stg_iris: Close
[0m18:17:22.005817 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '90ce430e-36ea-4267-9a7c-7c06f48cfc2f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f5aee2b6220>]}
[0m18:17:22.008423 [info ] [Thread-1  ]: 1 of 2 OK created sql view model analytics.stg_iris ............................ [[32mCREATE VIEW[0m in 0.32s]
[0m18:17:22.010980 [debug] [Thread-1  ]: Finished running node model.homework.stg_iris
[0m18:17:22.014056 [debug] [Thread-3  ]: Began running node model.homework.iris_processed
[0m18:17:22.016858 [info ] [Thread-3  ]: 2 of 2 START sql table model analytics.iris_processed .......................... [RUN]
[0m18:17:22.019818 [debug] [Thread-3  ]: Acquiring new postgres connection 'model.homework.iris_processed'
[0m18:17:22.023157 [debug] [Thread-3  ]: Began compiling node model.homework.iris_processed
[0m18:17:22.079261 [debug] [Thread-3  ]: Using postgres connection "model.homework.iris_processed"
[0m18:17:22.081731 [debug] [Thread-3  ]: On model.homework.iris_processed: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "homework", "target_name": "dev", "node_id": "model.homework.iris_processed"} */

        select percentile_cont(0.5) within group (order by sepal_length ) from "analytics"."analytics"."stg_iris"
    
[0m18:17:22.084033 [debug] [Thread-3  ]: Opening a new connection, currently in state init
[0m18:17:22.102403 [debug] [Thread-3  ]: SQL status: SELECT 1 in 0.018 seconds
[0m18:17:22.110378 [debug] [Thread-3  ]: Using postgres connection "model.homework.iris_processed"
[0m18:17:22.114064 [debug] [Thread-3  ]: On model.homework.iris_processed: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "homework", "target_name": "dev", "node_id": "model.homework.iris_processed"} */

        select percentile_cont(0.5 - 0.5/2) within group (order by sepal_length ) from "analytics"."analytics"."stg_iris"
    
[0m18:17:22.118269 [debug] [Thread-3  ]: SQL status: SELECT 1 in 0.001 seconds
[0m18:17:22.125461 [debug] [Thread-3  ]: Using postgres connection "model.homework.iris_processed"
[0m18:17:22.129164 [debug] [Thread-3  ]: On model.homework.iris_processed: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "homework", "target_name": "dev", "node_id": "model.homework.iris_processed"} */

        select percentile_cont(0.5 + 0.5/2) within group (order by sepal_length ) from "analytics"."analytics"."stg_iris"
    
[0m18:17:22.133160 [debug] [Thread-3  ]: SQL status: SELECT 1 in 0.001 seconds
[0m18:17:22.142058 [debug] [Thread-3  ]: Using postgres connection "model.homework.iris_processed"
[0m18:17:22.144444 [debug] [Thread-3  ]: On model.homework.iris_processed: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "homework", "target_name": "dev", "node_id": "model.homework.iris_processed"} */

        select percentile_cont(0.5) within group (order by sepal_width ) from "analytics"."analytics"."stg_iris"
    
[0m18:17:22.147699 [debug] [Thread-3  ]: SQL status: SELECT 1 in 0.001 seconds
[0m18:17:22.154988 [debug] [Thread-3  ]: Using postgres connection "model.homework.iris_processed"
[0m18:17:22.158029 [debug] [Thread-3  ]: On model.homework.iris_processed: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "homework", "target_name": "dev", "node_id": "model.homework.iris_processed"} */

        select percentile_cont(0.5 - 0.5/2) within group (order by sepal_width ) from "analytics"."analytics"."stg_iris"
    
[0m18:17:22.161948 [debug] [Thread-3  ]: SQL status: SELECT 1 in 0.001 seconds
[0m18:17:22.167350 [debug] [Thread-3  ]: Using postgres connection "model.homework.iris_processed"
[0m18:17:22.169876 [debug] [Thread-3  ]: On model.homework.iris_processed: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "homework", "target_name": "dev", "node_id": "model.homework.iris_processed"} */

        select percentile_cont(0.5 + 0.5/2) within group (order by sepal_width ) from "analytics"."analytics"."stg_iris"
    
[0m18:17:22.173317 [debug] [Thread-3  ]: SQL status: SELECT 1 in 0.001 seconds
[0m18:17:22.181386 [debug] [Thread-3  ]: Using postgres connection "model.homework.iris_processed"
[0m18:17:22.183968 [debug] [Thread-3  ]: On model.homework.iris_processed: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "homework", "target_name": "dev", "node_id": "model.homework.iris_processed"} */

        select percentile_cont(0.5) within group (order by petal_length ) from "analytics"."analytics"."stg_iris"
    
[0m18:17:22.187275 [debug] [Thread-3  ]: SQL status: SELECT 1 in 0.001 seconds
[0m18:17:22.194796 [debug] [Thread-3  ]: Using postgres connection "model.homework.iris_processed"
[0m18:17:22.197265 [debug] [Thread-3  ]: On model.homework.iris_processed: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "homework", "target_name": "dev", "node_id": "model.homework.iris_processed"} */

        select percentile_cont(0.5 - 0.5/2) within group (order by petal_length ) from "analytics"."analytics"."stg_iris"
    
[0m18:17:22.200187 [debug] [Thread-3  ]: SQL status: SELECT 1 in 0.001 seconds
[0m18:17:22.208719 [debug] [Thread-3  ]: Using postgres connection "model.homework.iris_processed"
[0m18:17:22.211880 [debug] [Thread-3  ]: On model.homework.iris_processed: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "homework", "target_name": "dev", "node_id": "model.homework.iris_processed"} */

        select percentile_cont(0.5 + 0.5/2) within group (order by petal_length ) from "analytics"."analytics"."stg_iris"
    
[0m18:17:22.214801 [debug] [Thread-3  ]: SQL status: SELECT 1 in 0.001 seconds
[0m18:17:22.224830 [debug] [Thread-3  ]: Using postgres connection "model.homework.iris_processed"
[0m18:17:22.227499 [debug] [Thread-3  ]: On model.homework.iris_processed: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "homework", "target_name": "dev", "node_id": "model.homework.iris_processed"} */

        select percentile_cont(0.5) within group (order by petal_width ) from "analytics"."analytics"."stg_iris"
    
[0m18:17:22.230517 [debug] [Thread-3  ]: SQL status: SELECT 1 in 0.001 seconds
[0m18:17:22.236442 [debug] [Thread-3  ]: Using postgres connection "model.homework.iris_processed"
[0m18:17:22.239586 [debug] [Thread-3  ]: On model.homework.iris_processed: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "homework", "target_name": "dev", "node_id": "model.homework.iris_processed"} */

        select percentile_cont(0.5 - 0.5/2) within group (order by petal_width ) from "analytics"."analytics"."stg_iris"
    
[0m18:17:22.243155 [debug] [Thread-3  ]: SQL status: SELECT 1 in 0.001 seconds
[0m18:17:22.250362 [debug] [Thread-3  ]: Using postgres connection "model.homework.iris_processed"
[0m18:17:22.276690 [debug] [Thread-3  ]: On model.homework.iris_processed: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "homework", "target_name": "dev", "node_id": "model.homework.iris_processed"} */

        select percentile_cont(0.5 + 0.5/2) within group (order by petal_width ) from "analytics"."analytics"."stg_iris"
    
[0m18:17:22.281071 [debug] [Thread-3  ]: SQL status: SELECT 1 in 0.001 seconds
[0m18:17:22.296612 [debug] [Thread-3  ]: On model.homework.iris_processed: Close
[0m18:17:22.310811 [debug] [Thread-3  ]: Compilation Error in model iris_processed (models/mart/iris_processed.sql)
  'dict object' has no attribute 'log_transform'. This can happen when calling a macro that does not exist. Check for typos and/or install package dependencies with "dbt deps".
[0m18:17:22.316210 [debug] [Thread-3  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '90ce430e-36ea-4267-9a7c-7c06f48cfc2f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f5aee2b65b0>]}
[0m18:17:22.320383 [error] [Thread-3  ]: 2 of 2 ERROR creating sql table model analytics.iris_processed ................. [[31mERROR[0m in 0.30s]
[0m18:17:22.327996 [debug] [Thread-3  ]: Finished running node model.homework.iris_processed
[0m18:17:22.332115 [debug] [Thread-7  ]: Marking all children of 'model.homework.iris_processed' to be skipped because of status 'error'.  Reason: Compilation Error in model iris_processed (models/mart/iris_processed.sql)
  'dict object' has no attribute 'log_transform'. This can happen when calling a macro that does not exist. Check for typos and/or install package dependencies with "dbt deps"..
[0m18:17:22.337382 [debug] [MainThread]: Using postgres connection "master"
[0m18:17:22.340145 [debug] [MainThread]: On master: BEGIN
[0m18:17:22.342825 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m18:17:22.364404 [debug] [MainThread]: SQL status: BEGIN in 0.021 seconds
[0m18:17:22.368669 [debug] [MainThread]: On master: COMMIT
[0m18:17:22.372266 [debug] [MainThread]: Using postgres connection "master"
[0m18:17:22.374661 [debug] [MainThread]: On master: COMMIT
[0m18:17:22.377280 [debug] [MainThread]: SQL status: COMMIT in 0.000 seconds
[0m18:17:22.379905 [debug] [MainThread]: On master: Close
[0m18:17:22.382700 [debug] [MainThread]: Connection 'master' was properly closed.
[0m18:17:22.385571 [debug] [MainThread]: Connection 'model.homework.stg_iris' was properly closed.
[0m18:17:22.389433 [debug] [MainThread]: Connection 'model.homework.iris_processed' was properly closed.
[0m18:17:22.391471 [info ] [MainThread]: 
[0m18:17:22.393453 [info ] [MainThread]: Finished running 1 table model, 1 view model in 0 hours 0 minutes and 0.95 seconds (0.95s).
[0m18:17:22.396626 [debug] [MainThread]: Command end result
[0m18:17:22.629054 [debug] [MainThread]: Wrote artifact WritableManifest to /opt/airflow/dags/dbt/homework/target/manifest.json
[0m18:17:22.636346 [debug] [MainThread]: Wrote artifact SemanticManifest to /opt/airflow/dags/dbt/homework/target/semantic_manifest.json
[0m18:17:22.657773 [debug] [MainThread]: Wrote artifact RunExecutionResult to /opt/airflow/dags/dbt/homework/target/run_results.json
[0m18:17:22.659435 [info ] [MainThread]: 
[0m18:17:22.661224 [info ] [MainThread]: [31mCompleted with 1 error, 0 partial successes, and 0 warnings:[0m
[0m18:17:22.662808 [info ] [MainThread]: 
[0m18:17:22.664394 [error] [MainThread]:   Compilation Error in model iris_processed (models/mart/iris_processed.sql)
  'dict object' has no attribute 'log_transform'. This can happen when calling a macro that does not exist. Check for typos and/or install package dependencies with "dbt deps".
[0m18:17:22.666034 [info ] [MainThread]: 
[0m18:17:22.667581 [info ] [MainThread]: Done. PASS=1 WARN=0 ERROR=1 SKIP=0 TOTAL=2
[0m18:17:22.670330 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": false, "command_wall_clock_time": 6.0913568, "process_in_blocks": "136", "process_kernel_time": 0.426588, "process_mem_max_rss": "121728", "process_out_blocks": "0", "process_user_time": 7.589303}
[0m18:17:22.672814 [debug] [MainThread]: Command `dbt run` failed at 18:17:22.672564 after 6.09 seconds
[0m18:17:22.674771 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f5af1d709a0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f5af2b602e0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f5af2a6a820>]}
[0m18:17:22.676709 [debug] [MainThread]: Flushing usage events
[0m18:17:23.283363 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m18:21:29.078937 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f1f385c0a30>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f1f376e1400>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f1f376e13a0>]}


============================== 18:21:29.090301 | 425e3fa5-ebaa-4d0c-8dfa-39a16be1a4ef ==============================
[0m18:21:29.090301 [info ] [MainThread]: Running with dbt=1.9.4
[0m18:21:29.093401 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': '/opt/airflow/dags/dbt', 'debug': 'False', 'version_check': 'True', 'log_path': '/opt/airflow/dags/dbt/homework/logs', 'fail_fast': 'False', 'warn_error': 'None', 'use_colors': 'True', 'use_experimental_parser': 'False', 'empty': 'False', 'quiet': 'False', 'no_print': 'None', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'invocation_command': 'dbt --profile homework run --project-dir=/opt/airflow/dags/dbt/homework --vars {"is_test": false, "data_date": "2025-04-23"}', 'log_format': 'default', 'static_parser': 'True', 'target_path': 'None', 'introspect': 'True', 'send_anonymous_usage_stats': 'True'}
[0m18:21:29.562022 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '425e3fa5-ebaa-4d0c-8dfa-39a16be1a4ef', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f1f35eabf70>]}
[0m18:21:29.698438 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '425e3fa5-ebaa-4d0c-8dfa-39a16be1a4ef', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f1f376a6f40>]}
[0m18:21:29.701162 [info ] [MainThread]: Registered adapter: postgres=1.9.0
[0m18:21:29.978208 [debug] [MainThread]: checksum: f5df654a850f4b74beb13fbe0c7d8863b5b1a20bd535c3ac287d70e390b64d41, vars: {'data_date': '2025-04-23', 'is_test': False}, profile: homework, target: , version: 1.9.4
[0m18:21:31.685094 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 1 files changed.
[0m18:21:31.687508 [debug] [MainThread]: Partial parsing: updated file: dbt_ml_inline_preprocessing://macros/log_transform.sql
[0m18:21:31.970942 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 1 unused configuration paths:
- seeds.homework.iris_dataset
[0m18:21:32.003056 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '425e3fa5-ebaa-4d0c-8dfa-39a16be1a4ef', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f1f359b60d0>]}
[0m18:21:32.254956 [debug] [MainThread]: Wrote artifact WritableManifest to /opt/airflow/dags/dbt/homework/target/manifest.json
[0m18:21:32.275860 [debug] [MainThread]: Wrote artifact SemanticManifest to /opt/airflow/dags/dbt/homework/target/semantic_manifest.json
[0m18:21:32.311188 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '425e3fa5-ebaa-4d0c-8dfa-39a16be1a4ef', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f1f359d5970>]}
[0m18:21:32.313561 [info ] [MainThread]: Found 2 models, 1 source, 587 macros
[0m18:21:32.315417 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '425e3fa5-ebaa-4d0c-8dfa-39a16be1a4ef', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f1f359d5ee0>]}
[0m18:21:32.319590 [info ] [MainThread]: 
[0m18:21:32.321612 [info ] [MainThread]: Concurrency: 4 threads (target='dev')
[0m18:21:32.323432 [info ] [MainThread]: 
[0m18:21:32.325352 [debug] [MainThread]: Acquiring new postgres connection 'master'
[0m18:21:32.336222 [debug] [ThreadPool]: Acquiring new postgres connection 'list_analytics'
[0m18:21:32.413986 [debug] [ThreadPool]: Using postgres connection "list_analytics"
[0m18:21:32.415733 [debug] [ThreadPool]: On list_analytics: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "homework", "target_name": "dev", "connection_name": "list_analytics"} */

    select distinct nspname from pg_namespace
  
[0m18:21:32.417426 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m18:21:32.431532 [debug] [ThreadPool]: SQL status: SELECT 6 in 0.014 seconds
[0m18:21:32.434920 [debug] [ThreadPool]: On list_analytics: Close
[0m18:21:32.438668 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_analytics, now list_analytics_analytics)
[0m18:21:32.456237 [debug] [ThreadPool]: Using postgres connection "list_analytics_analytics"
[0m18:21:32.458180 [debug] [ThreadPool]: On list_analytics_analytics: BEGIN
[0m18:21:32.459926 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m18:21:32.471490 [debug] [ThreadPool]: SQL status: BEGIN in 0.011 seconds
[0m18:21:32.473364 [debug] [ThreadPool]: Using postgres connection "list_analytics_analytics"
[0m18:21:32.475188 [debug] [ThreadPool]: On list_analytics_analytics: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "homework", "target_name": "dev", "connection_name": "list_analytics_analytics"} */
select
      'analytics' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'analytics'
    union all
    select
      'analytics' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'analytics'
    union all
    select
      'analytics' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'analytics'
  
[0m18:21:32.481171 [debug] [ThreadPool]: SQL status: SELECT 2 in 0.004 seconds
[0m18:21:32.484465 [debug] [ThreadPool]: On list_analytics_analytics: ROLLBACK
[0m18:21:32.486572 [debug] [ThreadPool]: On list_analytics_analytics: Close
[0m18:21:32.499270 [debug] [MainThread]: Using postgres connection "master"
[0m18:21:32.501088 [debug] [MainThread]: On master: BEGIN
[0m18:21:32.502796 [debug] [MainThread]: Opening a new connection, currently in state init
[0m18:21:32.514735 [debug] [MainThread]: SQL status: BEGIN in 0.012 seconds
[0m18:21:32.516581 [debug] [MainThread]: Using postgres connection "master"
[0m18:21:32.518598 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "homework", "target_name": "dev", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select distinct
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v', 'm')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
[0m18:21:32.529602 [debug] [MainThread]: SQL status: SELECT 1 in 0.009 seconds
[0m18:21:32.533199 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '425e3fa5-ebaa-4d0c-8dfa-39a16be1a4ef', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f1f34f01e20>]}
[0m18:21:32.535091 [debug] [MainThread]: On master: ROLLBACK
[0m18:21:32.536947 [debug] [MainThread]: Using postgres connection "master"
[0m18:21:32.538570 [debug] [MainThread]: On master: BEGIN
[0m18:21:32.540821 [debug] [MainThread]: SQL status: BEGIN in 0.000 seconds
[0m18:21:32.542617 [debug] [MainThread]: On master: COMMIT
[0m18:21:32.544682 [debug] [MainThread]: Using postgres connection "master"
[0m18:21:32.546807 [debug] [MainThread]: On master: COMMIT
[0m18:21:32.548636 [debug] [MainThread]: SQL status: COMMIT in 0.000 seconds
[0m18:21:32.550282 [debug] [MainThread]: On master: Close
[0m18:21:32.558394 [debug] [Thread-1  ]: Began running node model.homework.stg_iris
[0m18:21:32.561432 [info ] [Thread-1  ]: 1 of 2 START sql view model analytics.stg_iris ................................. [RUN]
[0m18:21:32.563912 [debug] [Thread-1  ]: Re-using an available connection from the pool (formerly list_analytics_analytics, now model.homework.stg_iris)
[0m18:21:32.566030 [debug] [Thread-1  ]: Began compiling node model.homework.stg_iris
[0m18:21:32.585481 [debug] [Thread-1  ]: Writing injected SQL for node "model.homework.stg_iris"
[0m18:21:32.596803 [debug] [Thread-1  ]: Began executing node model.homework.stg_iris
[0m18:21:32.680413 [debug] [Thread-1  ]: Writing runtime sql for node "model.homework.stg_iris"
[0m18:21:32.693297 [debug] [Thread-1  ]: Using postgres connection "model.homework.stg_iris"
[0m18:21:32.696147 [debug] [Thread-1  ]: On model.homework.stg_iris: BEGIN
[0m18:21:32.698234 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
[0m18:21:32.710562 [debug] [Thread-1  ]: SQL status: BEGIN in 0.012 seconds
[0m18:21:32.713363 [debug] [Thread-1  ]: Using postgres connection "model.homework.stg_iris"
[0m18:21:32.715016 [debug] [Thread-1  ]: On model.homework.stg_iris: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "homework", "target_name": "dev", "node_id": "model.homework.stg_iris"} */

  create view "analytics"."analytics"."stg_iris__dbt_tmp"
    
    
  as (
    with source as (
    select * from "analytics"."analytics"."iris_dataset"
)

select
    sepal_length,
    sepal_width,
    petal_length,
    petal_width,
    species
from source
  );
[0m18:21:32.718963 [debug] [Thread-1  ]: SQL status: CREATE VIEW in 0.002 seconds
[0m18:21:32.735101 [debug] [Thread-1  ]: Using postgres connection "model.homework.stg_iris"
[0m18:21:32.737281 [debug] [Thread-1  ]: On model.homework.stg_iris: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "homework", "target_name": "dev", "node_id": "model.homework.stg_iris"} */
alter table "analytics"."analytics"."stg_iris" rename to "stg_iris__dbt_backup"
[0m18:21:32.741605 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.001 seconds
[0m18:21:32.763781 [debug] [Thread-1  ]: Using postgres connection "model.homework.stg_iris"
[0m18:21:32.767789 [debug] [Thread-1  ]: On model.homework.stg_iris: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "homework", "target_name": "dev", "node_id": "model.homework.stg_iris"} */
alter table "analytics"."analytics"."stg_iris__dbt_tmp" rename to "stg_iris"
[0m18:21:32.770722 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.001 seconds
[0m18:21:32.817754 [debug] [Thread-1  ]: On model.homework.stg_iris: COMMIT
[0m18:21:32.819925 [debug] [Thread-1  ]: Using postgres connection "model.homework.stg_iris"
[0m18:21:32.821924 [debug] [Thread-1  ]: On model.homework.stg_iris: COMMIT
[0m18:21:32.828345 [debug] [Thread-1  ]: SQL status: COMMIT in 0.004 seconds
[0m18:21:32.846407 [debug] [Thread-1  ]: Applying DROP to: "analytics"."analytics"."stg_iris__dbt_backup"
[0m18:21:32.858791 [debug] [Thread-1  ]: Using postgres connection "model.homework.stg_iris"
[0m18:21:32.860534 [debug] [Thread-1  ]: On model.homework.stg_iris: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "homework", "target_name": "dev", "node_id": "model.homework.stg_iris"} */
drop view if exists "analytics"."analytics"."stg_iris__dbt_backup" cascade
[0m18:21:32.866967 [debug] [Thread-1  ]: SQL status: DROP VIEW in 0.004 seconds
[0m18:21:32.874919 [debug] [Thread-1  ]: On model.homework.stg_iris: Close
[0m18:21:32.881022 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '425e3fa5-ebaa-4d0c-8dfa-39a16be1a4ef', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f1f34e7f220>]}
[0m18:21:32.883528 [info ] [Thread-1  ]: 1 of 2 OK created sql view model analytics.stg_iris ............................ [[32mCREATE VIEW[0m in 0.31s]
[0m18:21:32.885779 [debug] [Thread-1  ]: Finished running node model.homework.stg_iris
[0m18:21:32.889192 [debug] [Thread-3  ]: Began running node model.homework.iris_processed
[0m18:21:32.892031 [info ] [Thread-3  ]: 2 of 2 START sql table model analytics.iris_processed .......................... [RUN]
[0m18:21:32.894704 [debug] [Thread-3  ]: Acquiring new postgres connection 'model.homework.iris_processed'
[0m18:21:32.896901 [debug] [Thread-3  ]: Began compiling node model.homework.iris_processed
[0m18:21:33.011274 [debug] [Thread-3  ]: Using postgres connection "model.homework.iris_processed"
[0m18:21:33.014540 [debug] [Thread-3  ]: On model.homework.iris_processed: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "homework", "target_name": "dev", "node_id": "model.homework.iris_processed"} */

        select percentile_cont(0.5) within group (order by sepal_length ) from "analytics"."analytics"."stg_iris"
    
[0m18:21:33.016987 [debug] [Thread-3  ]: Opening a new connection, currently in state init
[0m18:21:33.037907 [debug] [Thread-3  ]: SQL status: SELECT 1 in 0.021 seconds
[0m18:21:33.045691 [debug] [Thread-3  ]: Using postgres connection "model.homework.iris_processed"
[0m18:21:33.048270 [debug] [Thread-3  ]: On model.homework.iris_processed: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "homework", "target_name": "dev", "node_id": "model.homework.iris_processed"} */

        select percentile_cont(0.5 - 0.5/2) within group (order by sepal_length ) from "analytics"."analytics"."stg_iris"
    
[0m18:21:33.050872 [debug] [Thread-3  ]: SQL status: SELECT 1 in 0.001 seconds
[0m18:21:33.054803 [debug] [Thread-3  ]: Using postgres connection "model.homework.iris_processed"
[0m18:21:33.056472 [debug] [Thread-3  ]: On model.homework.iris_processed: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "homework", "target_name": "dev", "node_id": "model.homework.iris_processed"} */

        select percentile_cont(0.5 + 0.5/2) within group (order by sepal_length ) from "analytics"."analytics"."stg_iris"
    
[0m18:21:33.058622 [debug] [Thread-3  ]: SQL status: SELECT 1 in 0.001 seconds
[0m18:21:33.075922 [debug] [Thread-3  ]: Using postgres connection "model.homework.iris_processed"
[0m18:21:33.078105 [debug] [Thread-3  ]: On model.homework.iris_processed: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "homework", "target_name": "dev", "node_id": "model.homework.iris_processed"} */

        select percentile_cont(0.5) within group (order by sepal_width ) from "analytics"."analytics"."stg_iris"
    
[0m18:21:33.080956 [debug] [Thread-3  ]: SQL status: SELECT 1 in 0.001 seconds
[0m18:21:33.085103 [debug] [Thread-3  ]: Using postgres connection "model.homework.iris_processed"
[0m18:21:33.086919 [debug] [Thread-3  ]: On model.homework.iris_processed: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "homework", "target_name": "dev", "node_id": "model.homework.iris_processed"} */

        select percentile_cont(0.5 - 0.5/2) within group (order by sepal_width ) from "analytics"."analytics"."stg_iris"
    
[0m18:21:33.089237 [debug] [Thread-3  ]: SQL status: SELECT 1 in 0.001 seconds
[0m18:21:33.093456 [debug] [Thread-3  ]: Using postgres connection "model.homework.iris_processed"
[0m18:21:33.095818 [debug] [Thread-3  ]: On model.homework.iris_processed: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "homework", "target_name": "dev", "node_id": "model.homework.iris_processed"} */

        select percentile_cont(0.5 + 0.5/2) within group (order by sepal_width ) from "analytics"."analytics"."stg_iris"
    
[0m18:21:33.098142 [debug] [Thread-3  ]: SQL status: SELECT 1 in 0.001 seconds
[0m18:21:33.103662 [debug] [Thread-3  ]: Using postgres connection "model.homework.iris_processed"
[0m18:21:33.105287 [debug] [Thread-3  ]: On model.homework.iris_processed: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "homework", "target_name": "dev", "node_id": "model.homework.iris_processed"} */

        select percentile_cont(0.5) within group (order by petal_length ) from "analytics"."analytics"."stg_iris"
    
[0m18:21:33.108190 [debug] [Thread-3  ]: SQL status: SELECT 1 in 0.001 seconds
[0m18:21:33.115041 [debug] [Thread-3  ]: Using postgres connection "model.homework.iris_processed"
[0m18:21:33.117942 [debug] [Thread-3  ]: On model.homework.iris_processed: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "homework", "target_name": "dev", "node_id": "model.homework.iris_processed"} */

        select percentile_cont(0.5 - 0.5/2) within group (order by petal_length ) from "analytics"."analytics"."stg_iris"
    
[0m18:21:33.121110 [debug] [Thread-3  ]: SQL status: SELECT 1 in 0.001 seconds
[0m18:21:33.126884 [debug] [Thread-3  ]: Using postgres connection "model.homework.iris_processed"
[0m18:21:33.129735 [debug] [Thread-3  ]: On model.homework.iris_processed: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "homework", "target_name": "dev", "node_id": "model.homework.iris_processed"} */

        select percentile_cont(0.5 + 0.5/2) within group (order by petal_length ) from "analytics"."analytics"."stg_iris"
    
[0m18:21:33.132749 [debug] [Thread-3  ]: SQL status: SELECT 1 in 0.001 seconds
[0m18:21:33.140741 [debug] [Thread-3  ]: Using postgres connection "model.homework.iris_processed"
[0m18:21:33.142869 [debug] [Thread-3  ]: On model.homework.iris_processed: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "homework", "target_name": "dev", "node_id": "model.homework.iris_processed"} */

        select percentile_cont(0.5) within group (order by petal_width ) from "analytics"."analytics"."stg_iris"
    
[0m18:21:33.146416 [debug] [Thread-3  ]: SQL status: SELECT 1 in 0.001 seconds
[0m18:21:33.150978 [debug] [Thread-3  ]: Using postgres connection "model.homework.iris_processed"
[0m18:21:33.153034 [debug] [Thread-3  ]: On model.homework.iris_processed: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "homework", "target_name": "dev", "node_id": "model.homework.iris_processed"} */

        select percentile_cont(0.5 - 0.5/2) within group (order by petal_width ) from "analytics"."analytics"."stg_iris"
    
[0m18:21:33.155605 [debug] [Thread-3  ]: SQL status: SELECT 1 in 0.001 seconds
[0m18:21:33.160521 [debug] [Thread-3  ]: Using postgres connection "model.homework.iris_processed"
[0m18:21:33.164977 [debug] [Thread-3  ]: On model.homework.iris_processed: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "homework", "target_name": "dev", "node_id": "model.homework.iris_processed"} */

        select percentile_cont(0.5 + 0.5/2) within group (order by petal_width ) from "analytics"."analytics"."stg_iris"
    
[0m18:21:33.168676 [debug] [Thread-3  ]: SQL status: SELECT 1 in 0.001 seconds
[0m18:21:33.206532 [debug] [Thread-3  ]: Using postgres connection "model.homework.iris_processed"
[0m18:21:33.208558 [debug] [Thread-3  ]: On model.homework.iris_processed: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "homework", "target_name": "dev", "node_id": "model.homework.iris_processed"} */

            select percentile_cont(0.5) within group (order by sepal_length ) from "analytics"."analytics"."stg_iris"
        
[0m18:21:33.210838 [debug] [Thread-3  ]: SQL status: SELECT 1 in 0.000 seconds
[0m18:21:33.219701 [debug] [Thread-3  ]: Using postgres connection "model.homework.iris_processed"
[0m18:21:33.222426 [debug] [Thread-3  ]: On model.homework.iris_processed: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "homework", "target_name": "dev", "node_id": "model.homework.iris_processed"} */

            select percentile_cont(0.5) within group (order by sepal_width ) from "analytics"."analytics"."stg_iris"
        
[0m18:21:33.225622 [debug] [Thread-3  ]: SQL status: SELECT 1 in 0.001 seconds
[0m18:21:33.233025 [debug] [Thread-3  ]: Using postgres connection "model.homework.iris_processed"
[0m18:21:33.235272 [debug] [Thread-3  ]: On model.homework.iris_processed: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "homework", "target_name": "dev", "node_id": "model.homework.iris_processed"} */

            select percentile_cont(0.5) within group (order by petal_length ) from "analytics"."analytics"."stg_iris"
        
[0m18:21:33.238617 [debug] [Thread-3  ]: SQL status: SELECT 1 in 0.001 seconds
[0m18:21:33.246202 [debug] [Thread-3  ]: Using postgres connection "model.homework.iris_processed"
[0m18:21:33.249574 [debug] [Thread-3  ]: On model.homework.iris_processed: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "homework", "target_name": "dev", "node_id": "model.homework.iris_processed"} */

            select percentile_cont(0.5) within group (order by petal_width ) from "analytics"."analytics"."stg_iris"
        
[0m18:21:33.252813 [debug] [Thread-3  ]: SQL status: SELECT 1 in 0.001 seconds
[0m18:21:33.391056 [debug] [Thread-3  ]: Using postgres connection "model.homework.iris_processed"
[0m18:21:33.393310 [debug] [Thread-3  ]: On model.homework.iris_processed: BEGIN
[0m18:21:33.396994 [debug] [Thread-3  ]: SQL status: BEGIN in 0.001 seconds
[0m18:21:33.399576 [debug] [Thread-3  ]: Using postgres connection "model.homework.iris_processed"
[0m18:21:33.401724 [debug] [Thread-3  ]: On model.homework.iris_processed: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "homework", "target_name": "dev", "node_id": "model.homework.iris_processed"} */
select
                species as value

            from "analytics"."analytics"."stg_iris"

            
            where species is not null  and true
            

            group by species
            order by species

            

        
[0m18:21:33.405051 [debug] [Thread-3  ]: SQL status: SELECT 3 in 0.001 seconds
[0m18:21:33.421017 [debug] [Thread-3  ]: Writing injected SQL for node "model.homework.iris_processed"
[0m18:21:33.433027 [debug] [Thread-3  ]: Began executing node model.homework.iris_processed
[0m18:21:33.491938 [debug] [Thread-3  ]: Writing runtime sql for node "model.homework.iris_processed"
[0m18:21:33.503247 [debug] [Thread-3  ]: Using postgres connection "model.homework.iris_processed"
[0m18:21:33.506384 [debug] [Thread-3  ]: On model.homework.iris_processed: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "homework", "target_name": "dev", "node_id": "model.homework.iris_processed"} */

  
    

  create  table "analytics"."analytics"."iris_processed__dbt_tmp"
  
  
    as
  
  (
    

with import_iris as (
    select *
    from "analytics"."analytics"."stg_iris"
)
select
    sepal_length,
    sepal_width,
    petal_length,
    petal_width,
    -- K Bins Discretization
    
        

    
        NTILE(5) over (order by sepal_length)
    

 as sepal_length_quantile_bin,
        

    
        
        floor(
        (
            sepal_length - (min(sepal_length) over ())
        )
        /
        (
            ((max(sepal_length) over ()) - (min(sepal_length) over ())) / 4::float
        )
        ) + 1
    

 as sepal_length_uniform_bin,
    
        

    
        NTILE(5) over (order by sepal_width)
    

 as sepal_width_quantile_bin,
        

    
        
        floor(
        (
            sepal_width - (min(sepal_width) over ())
        )
        /
        (
            ((max(sepal_width) over ()) - (min(sepal_width) over ())) / 4::float
        )
        ) + 1
    

 as sepal_width_uniform_bin,
    
        

    
        NTILE(5) over (order by petal_length)
    

 as petal_length_quantile_bin,
        

    
        
        floor(
        (
            petal_length - (min(petal_length) over ())
        )
        /
        (
            ((max(petal_length) over ()) - (min(petal_length) over ())) / 4::float
        )
        ) + 1
    

 as petal_length_uniform_bin,
    
        

    
        NTILE(5) over (order by petal_width)
    

 as petal_width_quantile_bin,
        

    
        
        floor(
        (
            petal_width - (min(petal_width) over ())
        )
        /
        (
            ((max(petal_width) over ()) - (min(petal_width) over ())) / 4::float
        )
        ) + 1
    

 as petal_width_uniform_bin,
    
-- Scaling
    
        

    

    
    
    

    
    
    

    (
        sepal_length - 5.8
    )
    /
    (
        6.4 - 5.1
    )

 as sepal_length_robust_scaled,
        

    (sepal_length) / (max(abs(sepal_length)) over ())::FLOAT

 as sepal_length_max_absolute_scaled,
        

    
    (
        ((sepal_length) - (min(sepal_length) over ()))
        /
        ((max(sepal_length) over ()) - (min(sepal_length) over ()))::FLOAT
    )
    *
    (1.0 - 0.0)
    +
    0.0

 as sepal_length_max_min_max_scaled,
    
        

    

    
    
    

    
    
    

    (
        sepal_width - 3.0
    )
    /
    (
        3.3 - 2.8
    )

 as sepal_width_robust_scaled,
        

    (sepal_width) / (max(abs(sepal_width)) over ())::FLOAT

 as sepal_width_max_absolute_scaled,
        

    
    (
        ((sepal_width) - (min(sepal_width) over ()))
        /
        ((max(sepal_width) over ()) - (min(sepal_width) over ()))::FLOAT
    )
    *
    (1.0 - 0.0)
    +
    0.0

 as sepal_width_max_min_max_scaled,
    
        

    

    
    
    

    
    
    

    (
        petal_length - 4.35
    )
    /
    (
        5.1 - 1.6
    )

 as petal_length_robust_scaled,
        

    (petal_length) / (max(abs(petal_length)) over ())::FLOAT

 as petal_length_max_absolute_scaled,
        

    
    (
        ((petal_length) - (min(petal_length) over ()))
        /
        ((max(petal_length) over ()) - (min(petal_length) over ()))::FLOAT
    )
    *
    (1.0 - 0.0)
    +
    0.0

 as petal_length_max_min_max_scaled,
    
        

    

    
    
    

    
    
    

    (
        petal_width - 1.3
    )
    /
    (
        1.8 - 0.3
    )

 as petal_width_robust_scaled,
        

    (petal_width) / (max(abs(petal_width)) over ())::FLOAT

 as petal_width_max_absolute_scaled,
        

    
    (
        ((petal_width) - (min(petal_width) over ()))
        /
        ((max(petal_width) over ()) - (min(petal_width) over ()))::FLOAT
    )
    *
    (1.0 - 0.0)
    +
    0.0

 as petal_width_max_min_max_scaled,
    

    -- Log Transformation
    
        
    case
        when sepal_length is null or sepal_length + 0 <= 0 then null
        else log((sepal_length + 0 )::numeric) / log(10::numeric)
    end
    
 as sepal_length_logged,
    
        
    case
        when sepal_width is null or sepal_width + 0 <= 0 then null
        else log((sepal_width + 0 )::numeric) / log(10::numeric)
    end
    
 as sepal_width_logged,
    
        
    case
        when petal_length is null or petal_length + 0 <= 0 then null
        else log((petal_length + 0 )::numeric) / log(10::numeric)
    end
    
 as petal_length_logged,
    
        
    case
        when petal_width is null or petal_width + 0 <= 0 then null
        else log((petal_width + 0 )::numeric) / log(10::numeric)
    end
    
 as petal_width_logged,
    

    -- Binarization
    
        

    

    
        

        
    

    case
        when sepal_length >=
            
                5.8
            
            then 1
        else 0
    end

 as sepal_length_binarized,
    
        

    

    
        

        
    

    case
        when sepal_width >=
            
                3.0
            
            then 1
        else 0
    end

 as sepal_width_binarized,
    
        

    

    
        

        
    

    case
        when petal_length >=
            
                4.35
            
            then 1
        else 0
    end

 as petal_length_binarized,
    
        

    

    
        

        
    

    case
        when petal_width >=
            
                1.3
            
            then 1
        else 0
    end

 as petal_width_binarized,
    

    -- Standardization
    
        

    
    (
        (sepal_length - avg(sepal_length) over ())
        /
        (stddev(sepal_length) over ())::FLOAT
    )
    *
    1
    +
    0

 as sepal_length_standardized,
    
        

    
    (
        (sepal_width - avg(sepal_width) over ())
        /
        (stddev(sepal_width) over ())::FLOAT
    )
    *
    1
    +
    0

 as sepal_width_standardized,
    
        

    
    (
        (petal_length - avg(petal_length) over ())
        /
        (stddev(petal_length) over ())::FLOAT
    )
    *
    1
    +
    0

 as petal_length_standardized,
    
        

    
    (
        (petal_width - avg(petal_width) over ())
        /
        (stddev(petal_width) over ())::FLOAT
    )
    *
    1
    +
    0

 as petal_width_standardized,
    
-- Interactions
    
        
            
            
            

    
        (sepal_length * sepal_width)
    

 as sepal_length_x_sepal_width_interaction,
            

    
        (sepal_length + sepal_width)
    

 as sepal_length_plus_sepal_width_interaction,
        
            
            
            

    
        (sepal_length * petal_length)
    

 as sepal_length_x_petal_length_interaction,
            

    
        (sepal_length + petal_length)
    

 as sepal_length_plus_petal_length_interaction,
        
            
            
            

    
        (sepal_length * petal_width)
    

 as sepal_length_x_petal_width_interaction,
            

    
        (sepal_length + petal_width)
    

 as sepal_length_plus_petal_width_interaction,
        
    
        
            
            
            

    
        (sepal_width * petal_length)
    

 as sepal_width_x_petal_length_interaction,
            

    
        (sepal_width + petal_length)
    

 as sepal_width_plus_petal_length_interaction,
        
            
            
            

    
        (sepal_width * petal_width)
    

 as sepal_width_x_petal_width_interaction,
            

    
        (sepal_width + petal_width)
    

 as sepal_width_plus_petal_width_interaction,
        
    
        
            
            
            

    
        (petal_length * petal_width)
    

 as petal_length_x_petal_width_interaction,
            

    
        (petal_length + petal_width)
    

 as petal_length_plus_petal_width_interaction,
        
    
        
    
species,    
    -- Label Encoding
    

    dense_rank() over (order by species) - 1

 as species_label_encoded,
    -- One Hot Encoding
    

    

    
        
    

    

    

        case
            when species = 'setosa' then 1
            else 0
        end as is_species__setosa,

    

        case
            when species = 'versicolor' then 1
            else 0
        end as is_species__versicolor,

    

        case
            when species = 'virginica' then 1
            else 0
        end as is_species__virginica,

    

    case
        when species is null then 1
        else 0
    end as is_species__


from "analytics"."analytics"."stg_iris"
  );
  
[0m18:21:33.541007 [debug] [Thread-3  ]: SQL status: SELECT 150 in 0.031 seconds
[0m18:21:33.577846 [debug] [Thread-3  ]: Using postgres connection "model.homework.iris_processed"
[0m18:21:33.580780 [debug] [Thread-3  ]: On model.homework.iris_processed: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "homework", "target_name": "dev", "node_id": "model.homework.iris_processed"} */
alter table "analytics"."analytics"."iris_processed__dbt_tmp" rename to "iris_processed"
[0m18:21:33.584657 [debug] [Thread-3  ]: SQL status: ALTER TABLE in 0.001 seconds
[0m18:21:33.590311 [debug] [Thread-3  ]: On model.homework.iris_processed: COMMIT
[0m18:21:33.592108 [debug] [Thread-3  ]: Using postgres connection "model.homework.iris_processed"
[0m18:21:33.593788 [debug] [Thread-3  ]: On model.homework.iris_processed: COMMIT
[0m18:21:33.665304 [debug] [Thread-3  ]: SQL status: COMMIT in 0.069 seconds
[0m18:21:33.680827 [debug] [Thread-3  ]: Applying DROP to: "analytics"."analytics"."iris_processed__dbt_backup"
[0m18:21:33.695565 [debug] [Thread-3  ]: Using postgres connection "model.homework.iris_processed"
[0m18:21:33.700642 [debug] [Thread-3  ]: On model.homework.iris_processed: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "homework", "target_name": "dev", "node_id": "model.homework.iris_processed"} */
drop table if exists "analytics"."analytics"."iris_processed__dbt_backup" cascade
[0m18:21:33.705895 [debug] [Thread-3  ]: SQL status: DROP TABLE in 0.001 seconds
[0m18:21:33.714072 [debug] [Thread-3  ]: On model.homework.iris_processed: Close
[0m18:21:33.719148 [debug] [Thread-3  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '425e3fa5-ebaa-4d0c-8dfa-39a16be1a4ef', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f1f344d7a90>]}
[0m18:21:33.724014 [info ] [Thread-3  ]: 2 of 2 OK created sql table model analytics.iris_processed ..................... [[32mSELECT 150[0m in 0.82s]
[0m18:21:33.729605 [debug] [Thread-3  ]: Finished running node model.homework.iris_processed
[0m18:21:33.738044 [debug] [MainThread]: Using postgres connection "master"
[0m18:21:33.741758 [debug] [MainThread]: On master: BEGIN
[0m18:21:33.745706 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m18:21:33.769410 [debug] [MainThread]: SQL status: BEGIN in 0.024 seconds
[0m18:21:33.773219 [debug] [MainThread]: On master: COMMIT
[0m18:21:33.776877 [debug] [MainThread]: Using postgres connection "master"
[0m18:21:33.780678 [debug] [MainThread]: On master: COMMIT
[0m18:21:33.785078 [debug] [MainThread]: SQL status: COMMIT in 0.001 seconds
[0m18:21:33.788511 [debug] [MainThread]: On master: Close
[0m18:21:33.792310 [debug] [MainThread]: Connection 'master' was properly closed.
[0m18:21:33.796262 [debug] [MainThread]: Connection 'model.homework.stg_iris' was properly closed.
[0m18:21:33.800549 [debug] [MainThread]: Connection 'model.homework.iris_processed' was properly closed.
[0m18:21:33.804241 [info ] [MainThread]: 
[0m18:21:33.808024 [info ] [MainThread]: Finished running 1 table model, 1 view model in 0 hours 0 minutes and 1.48 seconds (1.48s).
[0m18:21:33.814615 [debug] [MainThread]: Command end result
[0m18:21:34.016866 [debug] [MainThread]: Wrote artifact WritableManifest to /opt/airflow/dags/dbt/homework/target/manifest.json
[0m18:21:34.035805 [debug] [MainThread]: Wrote artifact SemanticManifest to /opt/airflow/dags/dbt/homework/target/semantic_manifest.json
[0m18:21:34.104689 [debug] [MainThread]: Wrote artifact RunExecutionResult to /opt/airflow/dags/dbt/homework/target/run_results.json
[0m18:21:34.108409 [info ] [MainThread]: 
[0m18:21:34.112763 [info ] [MainThread]: [32mCompleted successfully[0m
[0m18:21:34.116906 [info ] [MainThread]: 
[0m18:21:34.120922 [info ] [MainThread]: Done. PASS=2 WARN=0 ERROR=0 SKIP=0 TOTAL=2
[0m18:21:34.126382 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": true, "command_wall_clock_time": 5.215573, "process_in_blocks": "0", "process_kernel_time": 0.381927, "process_mem_max_rss": "116008", "process_out_blocks": "0", "process_user_time": 6.482718}
[0m18:21:34.131304 [debug] [MainThread]: Command `dbt run` succeeded at 18:21:34.130812 after 5.22 seconds
[0m18:21:34.135297 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f1f385c0a30>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f1f35eabf70>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f1f359e8850>]}
[0m18:21:34.139450 [debug] [MainThread]: Flushing usage events
[0m18:21:34.783463 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m18:21:40.316731 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fe72f749a60>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fe72e86a550>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fe72e86a4f0>]}


============================== 18:21:40.335072 | dc4e2e1f-45da-4f66-8c4c-988812d08062 ==============================
[0m18:21:40.335072 [info ] [MainThread]: Running with dbt=1.9.4
[0m18:21:40.338932 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'debug': 'False', 'version_check': 'True', 'log_path': '/opt/airflow/dags/dbt/homework/logs', 'profiles_dir': '/opt/airflow/dags/dbt', 'fail_fast': 'True', 'use_colors': 'True', 'use_experimental_parser': 'False', 'empty': 'None', 'quiet': 'False', 'no_print': 'None', 'log_format': 'default', 'static_parser': 'True', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'invocation_command': 'dbt --profile homework test --project-dir=/opt/airflow/dags/dbt/homework --vars {"is_test": false, "data_date": "2025-04-23"} --fail-fast', 'target_path': 'None', 'introspect': 'True', 'send_anonymous_usage_stats': 'True'}
[0m18:21:40.962276 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'dc4e2e1f-45da-4f66-8c4c-988812d08062', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fe731140370>]}
[0m18:21:41.103006 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': 'dc4e2e1f-45da-4f66-8c4c-988812d08062', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fe72d0a09d0>]}
[0m18:21:41.105953 [info ] [MainThread]: Registered adapter: postgres=1.9.0
[0m18:21:41.373053 [debug] [MainThread]: checksum: f5df654a850f4b74beb13fbe0c7d8863b5b1a20bd535c3ac287d70e390b64d41, vars: {'data_date': '2025-04-23', 'is_test': False}, profile: homework, target: , version: 1.9.4
[0m18:21:42.985848 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m18:21:42.988373 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m18:21:43.005691 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 1 unused configuration paths:
- seeds.homework.iris_dataset
[0m18:21:43.097178 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'dc4e2e1f-45da-4f66-8c4c-988812d08062', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fe72cb96130>]}
[0m18:21:43.466581 [debug] [MainThread]: Wrote artifact WritableManifest to /opt/airflow/dags/dbt/homework/target/manifest.json
[0m18:21:43.488119 [debug] [MainThread]: Wrote artifact SemanticManifest to /opt/airflow/dags/dbt/homework/target/semantic_manifest.json
[0m18:21:43.544118 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'dc4e2e1f-45da-4f66-8c4c-988812d08062', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fe72cb9d940>]}
[0m18:21:43.545981 [info ] [MainThread]: Found 2 models, 1 source, 587 macros
[0m18:21:43.547695 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'dc4e2e1f-45da-4f66-8c4c-988812d08062', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fe72e8a1550>]}
[0m18:21:43.550657 [warn ] [MainThread]: Nothing to do. Try checking your model configs and model specification args
[0m18:21:43.555702 [debug] [MainThread]: Command end result
[0m18:21:43.660528 [debug] [MainThread]: Wrote artifact WritableManifest to /opt/airflow/dags/dbt/homework/target/manifest.json
[0m18:21:43.669677 [debug] [MainThread]: Wrote artifact SemanticManifest to /opt/airflow/dags/dbt/homework/target/semantic_manifest.json
[0m18:21:43.681968 [debug] [MainThread]: Wrote artifact RunExecutionResult to /opt/airflow/dags/dbt/homework/target/run_results.json
[0m18:21:43.684431 [debug] [MainThread]: Resource report: {"command_name": "test", "command_success": true, "command_wall_clock_time": 3.539744, "process_in_blocks": "16", "process_kernel_time": 0.325077, "process_mem_max_rss": "104668", "process_out_blocks": "0", "process_user_time": 5.302825}
[0m18:21:43.686141 [debug] [MainThread]: Command `dbt test` succeeded at 18:21:43.685966 after 3.54 seconds
[0m18:21:43.688374 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fe72f749a60>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fe72f5c6430>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fe72d00ca00>]}
[0m18:21:43.690541 [debug] [MainThread]: Flushing usage events
[0m18:21:44.233989 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m18:29:47.529806 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f9b8fd74610>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f9b8ee8ed90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f9b8ee8ed30>]}


============================== 18:29:47.543940 | 612698b3-a32d-475b-9ce3-62c8f6bc695b ==============================
[0m18:29:47.543940 [info ] [MainThread]: Running with dbt=1.9.4
[0m18:29:47.546962 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'debug': 'False', 'fail_fast': 'False', 'log_path': '/opt/airflow/dags/dbt/homework/logs', 'version_check': 'True', 'profiles_dir': '/opt/airflow/dags/dbt', 'use_colors': 'True', 'use_experimental_parser': 'False', 'empty': 'None', 'quiet': 'False', 'no_print': 'None', 'log_format': 'default', 'introspect': 'True', 'static_parser': 'True', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'target_path': 'None', 'invocation_command': 'dbt deps --profiles-dir /opt/airflow/dags/dbt --project-dir /opt/airflow/dags/dbt/homework', 'send_anonymous_usage_stats': 'True'}
[0m18:29:48.002984 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '612698b3-a32d-475b-9ce3-62c8f6bc695b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f9b8ee0a670>]}
[0m18:29:48.302619 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f862d4906d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f862d22cfa0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f862c5d9340>]}


============================== 18:29:48.315166 | d66baaad-c049-42d6-86dd-1d0b69d58334 ==============================
[0m18:29:48.315166 [info ] [MainThread]: Running with dbt=1.9.4
[0m18:29:48.317494 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'fail_fast': 'False', 'version_check': 'True', 'log_path': '/opt/airflow/dags/dbt/homework/logs', 'profiles_dir': '/opt/airflow/dags/dbt', 'debug': 'False', 'use_colors': 'True', 'use_experimental_parser': 'False', 'empty': 'None', 'quiet': 'False', 'no_print': 'None', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'invocation_command': 'dbt deps --profiles-dir /opt/airflow/dags/dbt --project-dir /opt/airflow/dags/dbt/homework', 'static_parser': 'True', 'introspect': 'True', 'target_path': 'None', 'log_format': 'default', 'send_anonymous_usage_stats': 'True'}
[0m18:29:48.519617 [debug] [MainThread]: Set downloads directory='/tmp/dbt-downloads-q1kmz7vv'
[0m18:29:48.521552 [debug] [MainThread]: Making package index registry request: GET https://hub.getdbt.com/api/v1/index.json
[0m18:29:48.627268 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'd66baaad-c049-42d6-86dd-1d0b69d58334', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f862c5234f0>]}
[0m18:29:48.681508 [debug] [MainThread]: Set downloads directory='/tmp/dbt-downloads-7guwiyc_'
[0m18:29:48.683564 [debug] [MainThread]: Making package index registry request: GET https://hub.getdbt.com/api/v1/index.json
[0m18:29:48.765531 [debug] [MainThread]: Response from registry index: GET https://hub.getdbt.com/api/v1/index.json 200
[0m18:29:48.774841 [debug] [MainThread]: Making package registry request: GET https://hub.getdbt.com/api/v1/Matts52/dbt_ml_inline_preprocessing.json
[0m18:29:48.858002 [debug] [MainThread]: Response from registry index: GET https://hub.getdbt.com/api/v1/index.json 200
[0m18:29:48.862246 [debug] [MainThread]: Making package registry request: GET https://hub.getdbt.com/api/v1/Matts52/dbt_ml_inline_preprocessing.json
[0m18:29:49.178991 [debug] [MainThread]: Response from registry: GET https://hub.getdbt.com/api/v1/Matts52/dbt_ml_inline_preprocessing.json 200
[0m18:29:49.179273 [debug] [MainThread]: Response from registry: GET https://hub.getdbt.com/api/v1/Matts52/dbt_ml_inline_preprocessing.json 200
[0m18:29:49.186410 [debug] [MainThread]: Making package registry request: GET https://hub.getdbt.com/api/v1/dbt-labs/dbt_utils.json
[0m18:29:49.187216 [debug] [MainThread]: Making package registry request: GET https://hub.getdbt.com/api/v1/dbt-labs/dbt_utils.json
[0m18:29:49.359191 [debug] [MainThread]: Response from registry: GET https://hub.getdbt.com/api/v1/dbt-labs/dbt_utils.json 200
[0m18:29:49.359187 [debug] [MainThread]: Response from registry: GET https://hub.getdbt.com/api/v1/dbt-labs/dbt_utils.json 200
[0m18:29:49.403683 [info ] [MainThread]: Installing Matts52/dbt_ml_inline_preprocessing
[0m18:29:49.411669 [info ] [MainThread]: Installing Matts52/dbt_ml_inline_preprocessing
[0m18:29:50.899843 [info ] [MainThread]: Installed from version 0.2.4
[0m18:29:50.900261 [error] [MainThread]: Encountered an error:
[Errno 2] No such file or directory: 'dbt_packages/dbt-ml-inline-preprocessing-0.2.4/integration_tests/profiles.yml'
[0m18:29:50.902164 [info ] [MainThread]: Up to date!
[0m18:29:50.904122 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'package', 'label': 'd66baaad-c049-42d6-86dd-1d0b69d58334', 'property_': 'install', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f862c5053d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f862c49a3a0>]}
[0m18:29:50.906211 [info ] [MainThread]: Installing dbt-labs/dbt_utils
[0m18:29:50.905785 [error] [MainThread]: Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/dbt/cli/requires.py", line 153, in wrapper
    result, success = func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.9/site-packages/dbt/cli/requires.py", line 103, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.9/site-packages/dbt/cli/requires.py", line 218, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.9/site-packages/dbt/cli/requires.py", line 264, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.9/site-packages/dbt/cli/main.py", line 455, in deps
    results = task.run()
  File "/home/airflow/.local/lib/python3.9/site-packages/dbt/task/deps.py", line 254, in run
    package.install(self.project, renderer)
  File "/home/airflow/.local/lib/python3.9/site-packages/dbt/deps/registry.py", line 63, in install
    self._install(project, renderer)
  File "/home/airflow/.local/lib/python3.9/site-packages/dbt/deps/base.py", line 121, in _install
    connection_exception_retry(download_untar_fn, 5)
  File "/home/airflow/.local/lib/python3.9/site-packages/dbt_common/utils/connection.py", line 21, in connection_exception_retry
    return fn()
  File "/home/airflow/.local/lib/python3.9/site-packages/dbt/deps/base.py", line 133, in download_and_untar
    system.untar_package(tar_path, deps_path, package_name)
  File "/home/airflow/.local/lib/python3.9/site-packages/dbt_common/clients/system.py", line 641, in untar_package
    safe_extract(tarball, dest_dir)
  File "/home/airflow/.local/lib/python3.9/site-packages/dbt_common/clients/system.py", line 634, in safe_extract
    tarball.extractall(path, members=members)
  File "/usr/local/lib/python3.9/tarfile.py", line 2045, in extractall
    self.extract(tarinfo, path, set_attrs=not tarinfo.isdir(),
  File "/usr/local/lib/python3.9/tarfile.py", line 2086, in extract
    self._extract_member(tarinfo, os.path.join(path, tarinfo.name),
  File "/usr/local/lib/python3.9/tarfile.py", line 2159, in _extract_member
    self.makefile(tarinfo, targetpath)
  File "/usr/local/lib/python3.9/tarfile.py", line 2200, in makefile
    with bltn_open(targetpath, "wb") as target:
FileNotFoundError: [Errno 2] No such file or directory: 'dbt_packages/dbt-ml-inline-preprocessing-0.2.4/integration_tests/profiles.yml'

[0m18:29:50.910557 [debug] [MainThread]: Resource report: {"command_name": "deps", "command_success": false, "command_wall_clock_time": 3.5103903, "process_in_blocks": "72", "process_kernel_time": 0.466591, "process_mem_max_rss": "95352", "process_out_blocks": "6880", "process_user_time": 4.477296}
[0m18:29:50.914283 [debug] [MainThread]: Command `dbt deps` failed at 18:29:50.913695 after 3.51 seconds
[0m18:29:50.917571 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f9b8fd74610>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f9b8fafba00>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f9b8ecd77c0>]}
[0m18:29:50.919606 [debug] [MainThread]: Flushing usage events
[0m18:29:51.527196 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m18:29:56.590426 [info ] [MainThread]: Installed from version 1.3.0
[0m18:29:56.592162 [info ] [MainThread]: Up to date!
[0m18:29:56.594555 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'package', 'label': 'd66baaad-c049-42d6-86dd-1d0b69d58334', 'property_': 'install', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f862c5053d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f862e9c0190>]}
[0m18:29:56.597970 [debug] [MainThread]: Resource report: {"command_name": "deps", "command_success": true, "command_wall_clock_time": 8.449141, "process_in_blocks": "0", "process_kernel_time": 0.500081, "process_mem_max_rss": "95140", "process_out_blocks": "7048", "process_user_time": 4.810783}
[0m18:29:56.600665 [debug] [MainThread]: Command `dbt deps` succeeded at 18:29:56.600396 after 8.45 seconds
[0m18:29:56.602584 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f862d4906d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f862c5234f0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f862d2c3d00>]}
[0m18:29:56.604509 [debug] [MainThread]: Flushing usage events
[0m18:29:57.116847 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m18:38:20.090152 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0116103610>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f011521dd60>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f011521dd00>]}


============================== 18:38:20.101328 | 22d36b09-aee5-49d6-b392-08e3afbfa130 ==============================
[0m18:38:20.101328 [info ] [MainThread]: Running with dbt=1.9.4
[0m18:38:20.103987 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': '/opt/airflow/dags/dbt', 'fail_fast': 'False', 'warn_error': 'None', 'log_path': '/opt/airflow/dags/dbt/homework/logs', 'version_check': 'True', 'debug': 'False', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'empty': 'None', 'log_format': 'default', 'static_parser': 'True', 'invocation_command': 'dbt deps --profiles-dir /opt/airflow/dags/dbt --project-dir /opt/airflow/dags/dbt/homework', 'introspect': 'True', 'target_path': 'None', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'send_anonymous_usage_stats': 'True'}
[0m18:38:20.376774 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '22d36b09-aee5-49d6-b392-08e3afbfa130', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0115289190>]}
[0m18:38:20.465992 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb9bb6af610>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb9ba7c9e20>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb9ba7c9dc0>]}


============================== 18:38:20.478201 | 851464e6-09f0-4713-97ec-d8ee2cd084d3 ==============================
[0m18:38:20.478201 [info ] [MainThread]: Running with dbt=1.9.4
[0m18:38:20.480546 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': '/opt/airflow/dags/dbt', 'debug': 'False', 'warn_error': 'None', 'log_path': '/opt/airflow/dags/dbt/homework/logs', 'fail_fast': 'False', 'version_check': 'True', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'empty': 'None', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'invocation_command': 'dbt deps --profiles-dir /opt/airflow/dags/dbt --project-dir /opt/airflow/dags/dbt/homework', 'static_parser': 'True', 'introspect': 'True', 'target_path': 'None', 'log_format': 'default', 'send_anonymous_usage_stats': 'True'}
[0m18:38:20.803494 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '851464e6-09f0-4713-97ec-d8ee2cd084d3', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb9ba790ac0>]}
[0m18:38:20.852461 [error] [MainThread]: Encountered an error:
[Errno 2] No such file or directory: 'test_star_uppercase.sql'
[0m18:38:20.856934 [error] [MainThread]: Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/dbt/cli/requires.py", line 153, in wrapper
    result, success = func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.9/site-packages/dbt/cli/requires.py", line 103, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.9/site-packages/dbt/cli/requires.py", line 218, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.9/site-packages/dbt/cli/requires.py", line 264, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.9/site-packages/dbt/cli/main.py", line 455, in deps
    results = task.run()
  File "/home/airflow/.local/lib/python3.9/site-packages/dbt/task/deps.py", line 227, in run
    system.rmtree(self.project.packages_install_path)
  File "/home/airflow/.local/lib/python3.9/site-packages/dbt_common/clients/system.py", line 715, in rmtree
    return shutil.rmtree(path, onerror=chmod_and_retry)
  File "/usr/local/lib/python3.9/shutil.py", line 734, in rmtree
    _rmtree_safe_fd(fd, path, onerror)
  File "/usr/local/lib/python3.9/shutil.py", line 667, in _rmtree_safe_fd
    _rmtree_safe_fd(dirfd, fullname, onerror)
  File "/usr/local/lib/python3.9/shutil.py", line 667, in _rmtree_safe_fd
    _rmtree_safe_fd(dirfd, fullname, onerror)
  File "/usr/local/lib/python3.9/shutil.py", line 667, in _rmtree_safe_fd
    _rmtree_safe_fd(dirfd, fullname, onerror)
  [Previous line repeated 1 more time]
  File "/usr/local/lib/python3.9/shutil.py", line 690, in _rmtree_safe_fd
    onerror(os.unlink, fullname, sys.exc_info())
  File "/usr/local/lib/python3.9/shutil.py", line 688, in _rmtree_safe_fd
    os.unlink(entry.name, dir_fd=topfd)
FileNotFoundError: [Errno 2] No such file or directory: 'test_star_uppercase.sql'

[0m18:38:20.861285 [debug] [MainThread]: Resource report: {"command_name": "deps", "command_success": false, "command_wall_clock_time": 0.532058, "process_in_blocks": "40", "process_kernel_time": 0.280055, "process_mem_max_rss": "92092", "process_out_blocks": "5744", "process_user_time": 4.030793}
[0m18:38:20.863922 [debug] [MainThread]: Command `dbt deps` failed at 18:38:20.863679 after 0.54 seconds
[0m18:38:20.865807 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb9bb6af610>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb9ba6b2fd0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb9ba6b2e50>]}
[0m18:38:20.867869 [debug] [MainThread]: Flushing usage events
[0m18:38:21.161212 [debug] [MainThread]: Set downloads directory='/tmp/dbt-downloads-5tgkgij_'
[0m18:38:21.165120 [debug] [MainThread]: Making package index registry request: GET https://hub.getdbt.com/api/v1/index.json
[0m18:38:21.396148 [debug] [MainThread]: Response from registry index: GET https://hub.getdbt.com/api/v1/index.json 200
[0m18:38:21.398750 [debug] [MainThread]: Making package registry request: GET https://hub.getdbt.com/api/v1/Matts52/dbt_ml_inline_preprocessing.json
[0m18:38:21.509015 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m18:38:21.741858 [debug] [MainThread]: Response from registry: GET https://hub.getdbt.com/api/v1/Matts52/dbt_ml_inline_preprocessing.json 200
[0m18:38:21.746416 [debug] [MainThread]: Making package registry request: GET https://hub.getdbt.com/api/v1/dbt-labs/dbt_utils.json
[0m18:38:21.873208 [debug] [MainThread]: Response from registry: GET https://hub.getdbt.com/api/v1/dbt-labs/dbt_utils.json 200
[0m18:38:21.889207 [info ] [MainThread]: Installing Matts52/dbt_ml_inline_preprocessing
[0m18:38:23.996088 [info ] [MainThread]: Installed from version 0.2.4
[0m18:38:23.998074 [info ] [MainThread]: Up to date!
[0m18:38:24.000244 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'package', 'label': '22d36b09-aee5-49d6-b392-08e3afbfa130', 'property_': 'install', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0115f51a90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f01150660d0>]}
[0m18:38:24.002375 [info ] [MainThread]: Installing dbt-labs/dbt_utils
[0m18:38:29.029504 [info ] [MainThread]: Installed from version 1.3.0
[0m18:38:29.031581 [info ] [MainThread]: Up to date!
[0m18:38:29.033583 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'package', 'label': '22d36b09-aee5-49d6-b392-08e3afbfa130', 'property_': 'install', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0115f51a90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f011510d100>]}
[0m18:38:29.036851 [debug] [MainThread]: Resource report: {"command_name": "deps", "command_success": true, "command_wall_clock_time": 9.082977, "process_in_blocks": "4304", "process_kernel_time": 0.568385, "process_mem_max_rss": "95056", "process_out_blocks": "7048", "process_user_time": 4.686685}
[0m18:38:29.039145 [debug] [MainThread]: Command `dbt deps` succeeded at 18:38:29.038936 after 9.09 seconds
[0m18:38:29.041070 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0116103610>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0115f0b280>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f01152894f0>]}
[0m18:38:29.043074 [debug] [MainThread]: Flushing usage events
[0m18:38:29.572332 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m18:40:17.268918 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f1ebc250af0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f1ebb3714f0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f1ebb371490>]}


============================== 18:40:17.281362 | 3947af21-946a-4afc-aaac-36fc3c43366a ==============================
[0m18:40:17.281362 [info ] [MainThread]: Running with dbt=1.9.4
[0m18:40:17.283859 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'debug': 'False', 'version_check': 'True', 'log_path': '/opt/airflow/dags/dbt/homework/logs', 'profiles_dir': '/opt/airflow/dags/dbt', 'fail_fast': 'False', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'empty': 'False', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'invocation_command': 'dbt --profile homework run --project-dir=/opt/airflow/dags/dbt/homework --vars {"is_test": false, "data_date": "2025-04-22"}', 'static_parser': 'True', 'introspect': 'True', 'target_path': 'None', 'log_format': 'default', 'send_anonymous_usage_stats': 'True'}
[0m18:40:17.774611 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '3947af21-946a-4afc-aaac-36fc3c43366a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f1eb9b97790>]}
[0m18:40:17.929516 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '3947af21-946a-4afc-aaac-36fc3c43366a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f1ebba08550>]}
[0m18:40:17.932253 [info ] [MainThread]: Registered adapter: postgres=1.9.0
[0m18:40:18.242174 [debug] [MainThread]: checksum: b4b46bb6a239f66694dfdd44ef1792882cb61f2fd7b1ea66b3c7a170d2bb602d, vars: {'data_date': '2025-04-22', 'is_test': False}, profile: homework, target: , version: 1.9.4
[0m18:40:18.696261 [info ] [MainThread]: Unable to do partial parsing because config vars, config profile, or config target have changed
[0m18:40:18.700342 [debug] [MainThread]: previous checksum: b4b46bb6a239f66694dfdd44ef1792882cb61f2fd7b1ea66b3c7a170d2bb602d, current checksum: f5df654a850f4b74beb13fbe0c7d8863b5b1a20bd535c3ac287d70e390b64d41
[0m18:40:18.704817 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'partial_parser', 'label': '3947af21-946a-4afc-aaac-36fc3c43366a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f1ebba8ed60>]}
[0m18:40:25.496096 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 1 unused configuration paths:
- seeds.homework.iris_dataset
[0m18:40:25.525587 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '3947af21-946a-4afc-aaac-36fc3c43366a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f1eb9811130>]}
[0m18:40:25.767722 [debug] [MainThread]: Wrote artifact WritableManifest to /opt/airflow/dags/dbt/homework/target/manifest.json
[0m18:40:25.787577 [debug] [MainThread]: Wrote artifact SemanticManifest to /opt/airflow/dags/dbt/homework/target/semantic_manifest.json
[0m18:40:25.822364 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '3947af21-946a-4afc-aaac-36fc3c43366a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f1eb84b05b0>]}
[0m18:40:25.824383 [info ] [MainThread]: Found 2 models, 1 source, 587 macros
[0m18:40:25.826208 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '3947af21-946a-4afc-aaac-36fc3c43366a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f1ebda15460>]}
[0m18:40:25.829663 [info ] [MainThread]: 
[0m18:40:25.831551 [info ] [MainThread]: Concurrency: 4 threads (target='dev')
[0m18:40:25.834200 [info ] [MainThread]: 
[0m18:40:25.836326 [debug] [MainThread]: Acquiring new postgres connection 'master'
[0m18:40:25.847023 [debug] [ThreadPool]: Acquiring new postgres connection 'list_analytics'
[0m18:40:25.914225 [debug] [ThreadPool]: Using postgres connection "list_analytics"
[0m18:40:25.917077 [debug] [ThreadPool]: On list_analytics: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "homework", "target_name": "dev", "connection_name": "list_analytics"} */

    select distinct nspname from pg_namespace
  
[0m18:40:25.918717 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m18:40:25.933908 [debug] [ThreadPool]: SQL status: SELECT 6 in 0.015 seconds
[0m18:40:25.937315 [debug] [ThreadPool]: On list_analytics: Close
[0m18:40:25.940908 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_analytics, now list_analytics_analytics)
[0m18:40:25.955471 [debug] [ThreadPool]: Using postgres connection "list_analytics_analytics"
[0m18:40:25.957348 [debug] [ThreadPool]: On list_analytics_analytics: BEGIN
[0m18:40:25.959086 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m18:40:25.971290 [debug] [ThreadPool]: SQL status: BEGIN in 0.012 seconds
[0m18:40:25.973192 [debug] [ThreadPool]: Using postgres connection "list_analytics_analytics"
[0m18:40:25.975117 [debug] [ThreadPool]: On list_analytics_analytics: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "homework", "target_name": "dev", "connection_name": "list_analytics_analytics"} */
select
      'analytics' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'analytics'
    union all
    select
      'analytics' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'analytics'
    union all
    select
      'analytics' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'analytics'
  
[0m18:40:25.982088 [debug] [ThreadPool]: SQL status: SELECT 1 in 0.005 seconds
[0m18:40:25.985811 [debug] [ThreadPool]: On list_analytics_analytics: ROLLBACK
[0m18:40:25.987833 [debug] [ThreadPool]: On list_analytics_analytics: Close
[0m18:40:25.999688 [debug] [MainThread]: Using postgres connection "master"
[0m18:40:26.001425 [debug] [MainThread]: On master: BEGIN
[0m18:40:26.003045 [debug] [MainThread]: Opening a new connection, currently in state init
[0m18:40:26.014078 [debug] [MainThread]: SQL status: BEGIN in 0.011 seconds
[0m18:40:26.016328 [debug] [MainThread]: Using postgres connection "master"
[0m18:40:26.018449 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "homework", "target_name": "dev", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select distinct
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v', 'm')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
[0m18:40:26.024393 [debug] [MainThread]: SQL status: SELECT 0 in 0.004 seconds
[0m18:40:26.027630 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '3947af21-946a-4afc-aaac-36fc3c43366a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f1eb80f60d0>]}
[0m18:40:26.029535 [debug] [MainThread]: On master: ROLLBACK
[0m18:40:26.031450 [debug] [MainThread]: Using postgres connection "master"
[0m18:40:26.033658 [debug] [MainThread]: On master: BEGIN
[0m18:40:26.035847 [debug] [MainThread]: SQL status: BEGIN in 0.001 seconds
[0m18:40:26.037652 [debug] [MainThread]: On master: COMMIT
[0m18:40:26.039341 [debug] [MainThread]: Using postgres connection "master"
[0m18:40:26.040902 [debug] [MainThread]: On master: COMMIT
[0m18:40:26.042677 [debug] [MainThread]: SQL status: COMMIT in 0.000 seconds
[0m18:40:26.044431 [debug] [MainThread]: On master: Close
[0m18:40:26.055745 [debug] [Thread-1  ]: Began running node model.homework.stg_iris
[0m18:40:26.058049 [info ] [Thread-1  ]: 1 of 2 START sql view model analytics.stg_iris ................................. [RUN]
[0m18:40:26.060188 [debug] [Thread-1  ]: Re-using an available connection from the pool (formerly list_analytics_analytics, now model.homework.stg_iris)
[0m18:40:26.062085 [debug] [Thread-1  ]: Began compiling node model.homework.stg_iris
[0m18:40:26.086123 [debug] [Thread-1  ]: Writing injected SQL for node "model.homework.stg_iris"
[0m18:40:26.096951 [debug] [Thread-1  ]: Began executing node model.homework.stg_iris
[0m18:40:26.234681 [debug] [Thread-1  ]: Writing runtime sql for node "model.homework.stg_iris"
[0m18:40:26.257932 [debug] [Thread-1  ]: Using postgres connection "model.homework.stg_iris"
[0m18:40:26.260141 [debug] [Thread-1  ]: On model.homework.stg_iris: BEGIN
[0m18:40:26.262083 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
[0m18:40:26.279370 [debug] [Thread-1  ]: SQL status: BEGIN in 0.017 seconds
[0m18:40:26.283931 [debug] [Thread-1  ]: Using postgres connection "model.homework.stg_iris"
[0m18:40:26.287189 [debug] [Thread-1  ]: On model.homework.stg_iris: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "homework", "target_name": "dev", "node_id": "model.homework.stg_iris"} */

  create view "analytics"."analytics"."stg_iris__dbt_tmp"
    
    
  as (
    with source as (
    select * from "analytics"."analytics"."iris_dataset"
)

select
    sepal_length,
    sepal_width,
    petal_length,
    petal_width,
    species
from source
  );
[0m18:40:26.296439 [debug] [Thread-1  ]: SQL status: CREATE VIEW in 0.006 seconds
[0m18:40:26.327090 [debug] [Thread-1  ]: Using postgres connection "model.homework.stg_iris"
[0m18:40:26.330744 [debug] [Thread-1  ]: On model.homework.stg_iris: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "homework", "target_name": "dev", "node_id": "model.homework.stg_iris"} */
alter table "analytics"."analytics"."stg_iris__dbt_tmp" rename to "stg_iris"
[0m18:40:26.335890 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.001 seconds
[0m18:40:26.405828 [debug] [Thread-1  ]: On model.homework.stg_iris: COMMIT
[0m18:40:26.408819 [debug] [Thread-1  ]: Using postgres connection "model.homework.stg_iris"
[0m18:40:26.411589 [debug] [Thread-1  ]: On model.homework.stg_iris: COMMIT
[0m18:40:26.418629 [debug] [Thread-1  ]: SQL status: COMMIT in 0.004 seconds
[0m18:40:26.456249 [debug] [Thread-1  ]: Applying DROP to: "analytics"."analytics"."stg_iris__dbt_backup"
[0m18:40:26.492358 [debug] [Thread-1  ]: Using postgres connection "model.homework.stg_iris"
[0m18:40:26.494831 [debug] [Thread-1  ]: On model.homework.stg_iris: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "homework", "target_name": "dev", "node_id": "model.homework.stg_iris"} */
drop view if exists "analytics"."analytics"."stg_iris__dbt_backup" cascade
[0m18:40:26.503682 [debug] [Thread-1  ]: SQL status: DROP VIEW in 0.001 seconds
[0m18:40:26.513950 [debug] [Thread-1  ]: On model.homework.stg_iris: Close
[0m18:40:26.521209 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '3947af21-946a-4afc-aaac-36fc3c43366a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f1ebdc54a60>]}
[0m18:40:26.523615 [info ] [Thread-1  ]: 1 of 2 OK created sql view model analytics.stg_iris ............................ [[32mCREATE VIEW[0m in 0.46s]
[0m18:40:26.526216 [debug] [Thread-1  ]: Finished running node model.homework.stg_iris
[0m18:40:26.529310 [debug] [Thread-3  ]: Began running node model.homework.iris_processed
[0m18:40:26.531777 [info ] [Thread-3  ]: 2 of 2 START sql table model analytics.iris_processed .......................... [RUN]
[0m18:40:26.535182 [debug] [Thread-3  ]: Acquiring new postgres connection 'model.homework.iris_processed'
[0m18:40:26.537830 [debug] [Thread-3  ]: Began compiling node model.homework.iris_processed
[0m18:40:26.584152 [debug] [Thread-3  ]: Using postgres connection "model.homework.iris_processed"
[0m18:40:26.586588 [debug] [Thread-3  ]: On model.homework.iris_processed: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "homework", "target_name": "dev", "node_id": "model.homework.iris_processed"} */

        select percentile_cont(0.5) within group (order by sepal_length ) from "analytics"."analytics"."stg_iris"
    
[0m18:40:26.588654 [debug] [Thread-3  ]: Opening a new connection, currently in state init
[0m18:40:26.603625 [debug] [Thread-3  ]: SQL status: SELECT 1 in 0.015 seconds
[0m18:40:26.609053 [debug] [Thread-3  ]: Using postgres connection "model.homework.iris_processed"
[0m18:40:26.611608 [debug] [Thread-3  ]: On model.homework.iris_processed: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "homework", "target_name": "dev", "node_id": "model.homework.iris_processed"} */

        select percentile_cont(0.5 - 0.5/2) within group (order by sepal_length ) from "analytics"."analytics"."stg_iris"
    
[0m18:40:26.615277 [debug] [Thread-3  ]: SQL status: SELECT 1 in 0.001 seconds
[0m18:40:26.622843 [debug] [Thread-3  ]: Using postgres connection "model.homework.iris_processed"
[0m18:40:26.624767 [debug] [Thread-3  ]: On model.homework.iris_processed: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "homework", "target_name": "dev", "node_id": "model.homework.iris_processed"} */

        select percentile_cont(0.5 + 0.5/2) within group (order by sepal_length ) from "analytics"."analytics"."stg_iris"
    
[0m18:40:26.627221 [debug] [Thread-3  ]: SQL status: SELECT 1 in 0.001 seconds
[0m18:40:26.633236 [debug] [Thread-3  ]: Using postgres connection "model.homework.iris_processed"
[0m18:40:26.635524 [debug] [Thread-3  ]: On model.homework.iris_processed: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "homework", "target_name": "dev", "node_id": "model.homework.iris_processed"} */

        select percentile_cont(0.5) within group (order by sepal_width ) from "analytics"."analytics"."stg_iris"
    
[0m18:40:26.638403 [debug] [Thread-3  ]: SQL status: SELECT 1 in 0.001 seconds
[0m18:40:26.643058 [debug] [Thread-3  ]: Using postgres connection "model.homework.iris_processed"
[0m18:40:26.644824 [debug] [Thread-3  ]: On model.homework.iris_processed: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "homework", "target_name": "dev", "node_id": "model.homework.iris_processed"} */

        select percentile_cont(0.5 - 0.5/2) within group (order by sepal_width ) from "analytics"."analytics"."stg_iris"
    
[0m18:40:26.647081 [debug] [Thread-3  ]: SQL status: SELECT 1 in 0.001 seconds
[0m18:40:26.652254 [debug] [Thread-3  ]: Using postgres connection "model.homework.iris_processed"
[0m18:40:26.655227 [debug] [Thread-3  ]: On model.homework.iris_processed: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "homework", "target_name": "dev", "node_id": "model.homework.iris_processed"} */

        select percentile_cont(0.5 + 0.5/2) within group (order by sepal_width ) from "analytics"."analytics"."stg_iris"
    
[0m18:40:26.658082 [debug] [Thread-3  ]: SQL status: SELECT 1 in 0.001 seconds
[0m18:40:26.663845 [debug] [Thread-3  ]: Using postgres connection "model.homework.iris_processed"
[0m18:40:26.665548 [debug] [Thread-3  ]: On model.homework.iris_processed: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "homework", "target_name": "dev", "node_id": "model.homework.iris_processed"} */

        select percentile_cont(0.5) within group (order by petal_length ) from "analytics"."analytics"."stg_iris"
    
[0m18:40:26.668930 [debug] [Thread-3  ]: SQL status: SELECT 1 in 0.001 seconds
[0m18:40:26.673083 [debug] [Thread-3  ]: Using postgres connection "model.homework.iris_processed"
[0m18:40:26.674696 [debug] [Thread-3  ]: On model.homework.iris_processed: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "homework", "target_name": "dev", "node_id": "model.homework.iris_processed"} */

        select percentile_cont(0.5 - 0.5/2) within group (order by petal_length ) from "analytics"."analytics"."stg_iris"
    
[0m18:40:26.676727 [debug] [Thread-3  ]: SQL status: SELECT 1 in 0.000 seconds
[0m18:40:26.680860 [debug] [Thread-3  ]: Using postgres connection "model.homework.iris_processed"
[0m18:40:26.683817 [debug] [Thread-3  ]: On model.homework.iris_processed: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "homework", "target_name": "dev", "node_id": "model.homework.iris_processed"} */

        select percentile_cont(0.5 + 0.5/2) within group (order by petal_length ) from "analytics"."analytics"."stg_iris"
    
[0m18:40:26.686221 [debug] [Thread-3  ]: SQL status: SELECT 1 in 0.001 seconds
[0m18:40:26.692080 [debug] [Thread-3  ]: Using postgres connection "model.homework.iris_processed"
[0m18:40:26.693816 [debug] [Thread-3  ]: On model.homework.iris_processed: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "homework", "target_name": "dev", "node_id": "model.homework.iris_processed"} */

        select percentile_cont(0.5) within group (order by petal_width ) from "analytics"."analytics"."stg_iris"
    
[0m18:40:26.696021 [debug] [Thread-3  ]: SQL status: SELECT 1 in 0.001 seconds
[0m18:40:26.700922 [debug] [Thread-3  ]: Using postgres connection "model.homework.iris_processed"
[0m18:40:26.702725 [debug] [Thread-3  ]: On model.homework.iris_processed: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "homework", "target_name": "dev", "node_id": "model.homework.iris_processed"} */

        select percentile_cont(0.5 - 0.5/2) within group (order by petal_width ) from "analytics"."analytics"."stg_iris"
    
[0m18:40:26.705074 [debug] [Thread-3  ]: SQL status: SELECT 1 in 0.001 seconds
[0m18:40:26.708913 [debug] [Thread-3  ]: Using postgres connection "model.homework.iris_processed"
[0m18:40:26.710588 [debug] [Thread-3  ]: On model.homework.iris_processed: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "homework", "target_name": "dev", "node_id": "model.homework.iris_processed"} */

        select percentile_cont(0.5 + 0.5/2) within group (order by petal_width ) from "analytics"."analytics"."stg_iris"
    
[0m18:40:26.712748 [debug] [Thread-3  ]: SQL status: SELECT 1 in 0.000 seconds
[0m18:40:26.723235 [debug] [Thread-3  ]: Using postgres connection "model.homework.iris_processed"
[0m18:40:26.725176 [debug] [Thread-3  ]: On model.homework.iris_processed: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "homework", "target_name": "dev", "node_id": "model.homework.iris_processed"} */

            select percentile_cont(0.5) within group (order by sepal_length ) from "analytics"."analytics"."stg_iris"
        
[0m18:40:26.727644 [debug] [Thread-3  ]: SQL status: SELECT 1 in 0.001 seconds
[0m18:40:26.733901 [debug] [Thread-3  ]: Using postgres connection "model.homework.iris_processed"
[0m18:40:26.735782 [debug] [Thread-3  ]: On model.homework.iris_processed: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "homework", "target_name": "dev", "node_id": "model.homework.iris_processed"} */

            select percentile_cont(0.5) within group (order by sepal_width ) from "analytics"."analytics"."stg_iris"
        
[0m18:40:26.738017 [debug] [Thread-3  ]: SQL status: SELECT 1 in 0.001 seconds
[0m18:40:26.745286 [debug] [Thread-3  ]: Using postgres connection "model.homework.iris_processed"
[0m18:40:26.747709 [debug] [Thread-3  ]: On model.homework.iris_processed: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "homework", "target_name": "dev", "node_id": "model.homework.iris_processed"} */

            select percentile_cont(0.5) within group (order by petal_length ) from "analytics"."analytics"."stg_iris"
        
[0m18:40:26.750758 [debug] [Thread-3  ]: SQL status: SELECT 1 in 0.001 seconds
[0m18:40:26.756044 [debug] [Thread-3  ]: Using postgres connection "model.homework.iris_processed"
[0m18:40:26.758219 [debug] [Thread-3  ]: On model.homework.iris_processed: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "homework", "target_name": "dev", "node_id": "model.homework.iris_processed"} */

            select percentile_cont(0.5) within group (order by petal_width ) from "analytics"."analytics"."stg_iris"
        
[0m18:40:26.760862 [debug] [Thread-3  ]: SQL status: SELECT 1 in 0.001 seconds
[0m18:40:26.785868 [debug] [Thread-3  ]: Using postgres connection "model.homework.iris_processed"
[0m18:40:26.787786 [debug] [Thread-3  ]: On model.homework.iris_processed: BEGIN
[0m18:40:26.790092 [debug] [Thread-3  ]: SQL status: BEGIN in 0.000 seconds
[0m18:40:26.791797 [debug] [Thread-3  ]: Using postgres connection "model.homework.iris_processed"
[0m18:40:26.793654 [debug] [Thread-3  ]: On model.homework.iris_processed: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "homework", "target_name": "dev", "node_id": "model.homework.iris_processed"} */
select
                species as value

            from "analytics"."analytics"."stg_iris"

            
            where species is not null  and true
            

            group by species
            order by species

            

        
[0m18:40:26.796320 [debug] [Thread-3  ]: SQL status: SELECT 3 in 0.001 seconds
[0m18:40:26.807827 [debug] [Thread-3  ]: Writing injected SQL for node "model.homework.iris_processed"
[0m18:40:26.819601 [debug] [Thread-3  ]: Began executing node model.homework.iris_processed
[0m18:40:26.876800 [debug] [Thread-3  ]: Writing runtime sql for node "model.homework.iris_processed"
[0m18:40:26.890878 [debug] [Thread-3  ]: Using postgres connection "model.homework.iris_processed"
[0m18:40:26.894020 [debug] [Thread-3  ]: On model.homework.iris_processed: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "homework", "target_name": "dev", "node_id": "model.homework.iris_processed"} */

  
    

  create  table "analytics"."analytics"."iris_processed__dbt_tmp"
  
  
    as
  
  (
    

with import_iris as (
    select *
    from "analytics"."analytics"."stg_iris"
)
select
    sepal_length,
    sepal_width,
    petal_length,
    petal_width,
    -- K Bins Discretization
    
        

    
        NTILE(5) over (order by sepal_length)
    

 as sepal_length_quantile_bin,
        

    
        
        floor(
        (
            sepal_length - (min(sepal_length) over ())
        )
        /
        (
            ((max(sepal_length) over ()) - (min(sepal_length) over ())) / 4::float
        )
        ) + 1
    

 as sepal_length_uniform_bin,
    
        

    
        NTILE(5) over (order by sepal_width)
    

 as sepal_width_quantile_bin,
        

    
        
        floor(
        (
            sepal_width - (min(sepal_width) over ())
        )
        /
        (
            ((max(sepal_width) over ()) - (min(sepal_width) over ())) / 4::float
        )
        ) + 1
    

 as sepal_width_uniform_bin,
    
        

    
        NTILE(5) over (order by petal_length)
    

 as petal_length_quantile_bin,
        

    
        
        floor(
        (
            petal_length - (min(petal_length) over ())
        )
        /
        (
            ((max(petal_length) over ()) - (min(petal_length) over ())) / 4::float
        )
        ) + 1
    

 as petal_length_uniform_bin,
    
        

    
        NTILE(5) over (order by petal_width)
    

 as petal_width_quantile_bin,
        

    
        
        floor(
        (
            petal_width - (min(petal_width) over ())
        )
        /
        (
            ((max(petal_width) over ()) - (min(petal_width) over ())) / 4::float
        )
        ) + 1
    

 as petal_width_uniform_bin,
    
-- Scaling
    
        

    

    
    
    

    
    
    

    (
        sepal_length - 5.8
    )
    /
    (
        6.4 - 5.1
    )

 as sepal_length_robust_scaled,
        

    (sepal_length) / (max(abs(sepal_length)) over ())::FLOAT

 as sepal_length_max_absolute_scaled,
        

    
    (
        ((sepal_length) - (min(sepal_length) over ()))
        /
        ((max(sepal_length) over ()) - (min(sepal_length) over ()))::FLOAT
    )
    *
    (1.0 - 0.0)
    +
    0.0

 as sepal_length_max_min_max_scaled,
    
        

    

    
    
    

    
    
    

    (
        sepal_width - 3.0
    )
    /
    (
        3.3 - 2.8
    )

 as sepal_width_robust_scaled,
        

    (sepal_width) / (max(abs(sepal_width)) over ())::FLOAT

 as sepal_width_max_absolute_scaled,
        

    
    (
        ((sepal_width) - (min(sepal_width) over ()))
        /
        ((max(sepal_width) over ()) - (min(sepal_width) over ()))::FLOAT
    )
    *
    (1.0 - 0.0)
    +
    0.0

 as sepal_width_max_min_max_scaled,
    
        

    

    
    
    

    
    
    

    (
        petal_length - 4.35
    )
    /
    (
        5.1 - 1.6
    )

 as petal_length_robust_scaled,
        

    (petal_length) / (max(abs(petal_length)) over ())::FLOAT

 as petal_length_max_absolute_scaled,
        

    
    (
        ((petal_length) - (min(petal_length) over ()))
        /
        ((max(petal_length) over ()) - (min(petal_length) over ()))::FLOAT
    )
    *
    (1.0 - 0.0)
    +
    0.0

 as petal_length_max_min_max_scaled,
    
        

    

    
    
    

    
    
    

    (
        petal_width - 1.3
    )
    /
    (
        1.8 - 0.3
    )

 as petal_width_robust_scaled,
        

    (petal_width) / (max(abs(petal_width)) over ())::FLOAT

 as petal_width_max_absolute_scaled,
        

    
    (
        ((petal_width) - (min(petal_width) over ()))
        /
        ((max(petal_width) over ()) - (min(petal_width) over ()))::FLOAT
    )
    *
    (1.0 - 0.0)
    +
    0.0

 as petal_width_max_min_max_scaled,
    

    -- Log Transformation
    
        

    case
        when sepal_length is null or sepal_length + 0 <= 0 then null
        else log(10, sepal_length + 0)
    end

 as sepal_length_logged,
    
        

    case
        when sepal_width is null or sepal_width + 0 <= 0 then null
        else log(10, sepal_width + 0)
    end

 as sepal_width_logged,
    
        

    case
        when petal_length is null or petal_length + 0 <= 0 then null
        else log(10, petal_length + 0)
    end

 as petal_length_logged,
    
        

    case
        when petal_width is null or petal_width + 0 <= 0 then null
        else log(10, petal_width + 0)
    end

 as petal_width_logged,
    

    -- Binarization
    
        

    

    
        

        
    

    case
        when sepal_length >=
            
                5.8
            
            then 1
        else 0
    end

 as sepal_length_binarized,
    
        

    

    
        

        
    

    case
        when sepal_width >=
            
                3.0
            
            then 1
        else 0
    end

 as sepal_width_binarized,
    
        

    

    
        

        
    

    case
        when petal_length >=
            
                4.35
            
            then 1
        else 0
    end

 as petal_length_binarized,
    
        

    

    
        

        
    

    case
        when petal_width >=
            
                1.3
            
            then 1
        else 0
    end

 as petal_width_binarized,
    

    -- Standardization
    
        

    
    (
        (sepal_length - avg(sepal_length) over ())
        /
        (stddev(sepal_length) over ())::FLOAT
    )
    *
    1
    +
    0

 as sepal_length_standardized,
    
        

    
    (
        (sepal_width - avg(sepal_width) over ())
        /
        (stddev(sepal_width) over ())::FLOAT
    )
    *
    1
    +
    0

 as sepal_width_standardized,
    
        

    
    (
        (petal_length - avg(petal_length) over ())
        /
        (stddev(petal_length) over ())::FLOAT
    )
    *
    1
    +
    0

 as petal_length_standardized,
    
        

    
    (
        (petal_width - avg(petal_width) over ())
        /
        (stddev(petal_width) over ())::FLOAT
    )
    *
    1
    +
    0

 as petal_width_standardized,
    
-- Interactions
    
        
            
            
            

    
        (sepal_length * sepal_width)
    

 as sepal_length_x_sepal_width_interaction,
            

    
        (sepal_length + sepal_width)
    

 as sepal_length_plus_sepal_width_interaction,
        
            
            
            

    
        (sepal_length * petal_length)
    

 as sepal_length_x_petal_length_interaction,
            

    
        (sepal_length + petal_length)
    

 as sepal_length_plus_petal_length_interaction,
        
            
            
            

    
        (sepal_length * petal_width)
    

 as sepal_length_x_petal_width_interaction,
            

    
        (sepal_length + petal_width)
    

 as sepal_length_plus_petal_width_interaction,
        
    
        
            
            
            

    
        (sepal_width * petal_length)
    

 as sepal_width_x_petal_length_interaction,
            

    
        (sepal_width + petal_length)
    

 as sepal_width_plus_petal_length_interaction,
        
            
            
            

    
        (sepal_width * petal_width)
    

 as sepal_width_x_petal_width_interaction,
            

    
        (sepal_width + petal_width)
    

 as sepal_width_plus_petal_width_interaction,
        
    
        
            
            
            

    
        (petal_length * petal_width)
    

 as petal_length_x_petal_width_interaction,
            

    
        (petal_length + petal_width)
    

 as petal_length_plus_petal_width_interaction,
        
    
        
    
species,    
    -- Label Encoding
    

    dense_rank() over (order by species) - 1

 as species_label_encoded,
    -- One Hot Encoding
    

    

    
        
    

    

    

        case
            when species = 'setosa' then 1
            else 0
        end as is_species__setosa,

    

        case
            when species = 'versicolor' then 1
            else 0
        end as is_species__versicolor,

    

        case
            when species = 'virginica' then 1
            else 0
        end as is_species__virginica,

    

    case
        when species is null then 1
        else 0
    end as is_species__


from "analytics"."analytics"."stg_iris"
  );
  
[0m18:40:26.900587 [debug] [Thread-3  ]: Postgres adapter: Postgres error: function log(integer, double precision) does not exist
LINE 294:         else log(10, sepal_length + 0)
                       ^
HINT:  No function matches the given name and argument types. You might need to add explicit type casts.

[0m18:40:26.904605 [debug] [Thread-3  ]: On model.homework.iris_processed: ROLLBACK
[0m18:40:26.906759 [debug] [Thread-3  ]: On model.homework.iris_processed: Close
[0m18:40:26.912191 [debug] [Thread-3  ]: Database Error in model iris_processed (models/mart/iris_processed.sql)
  function log(integer, double precision) does not exist
  LINE 294:         else log(10, sepal_length + 0)
                         ^
  HINT:  No function matches the given name and argument types. You might need to add explicit type casts.
  compiled code at target/run/homework/models/mart/iris_processed.sql
[0m18:40:26.914365 [debug] [Thread-3  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '3947af21-946a-4afc-aaac-36fc3c43366a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f1e986b9820>]}
[0m18:40:26.917507 [error] [Thread-3  ]: 2 of 2 ERROR creating sql table model analytics.iris_processed ................. [[31mERROR[0m in 0.38s]
[0m18:40:26.919886 [debug] [Thread-3  ]: Finished running node model.homework.iris_processed
[0m18:40:26.922024 [debug] [Thread-7  ]: Marking all children of 'model.homework.iris_processed' to be skipped because of status 'error'.  Reason: Database Error in model iris_processed (models/mart/iris_processed.sql)
  function log(integer, double precision) does not exist
  LINE 294:         else log(10, sepal_length + 0)
                         ^
  HINT:  No function matches the given name and argument types. You might need to add explicit type casts.
  compiled code at target/run/homework/models/mart/iris_processed.sql.
[0m18:40:26.926122 [debug] [MainThread]: Using postgres connection "master"
[0m18:40:26.927938 [debug] [MainThread]: On master: BEGIN
[0m18:40:26.929577 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m18:40:26.942339 [debug] [MainThread]: SQL status: BEGIN in 0.013 seconds
[0m18:40:26.944025 [debug] [MainThread]: On master: COMMIT
[0m18:40:26.945591 [debug] [MainThread]: Using postgres connection "master"
[0m18:40:26.947090 [debug] [MainThread]: On master: COMMIT
[0m18:40:26.948933 [debug] [MainThread]: SQL status: COMMIT in 0.000 seconds
[0m18:40:26.951444 [debug] [MainThread]: On master: Close
[0m18:40:26.953360 [debug] [MainThread]: Connection 'master' was properly closed.
[0m18:40:26.954912 [debug] [MainThread]: Connection 'model.homework.stg_iris' was properly closed.
[0m18:40:26.957093 [debug] [MainThread]: Connection 'model.homework.iris_processed' was properly closed.
[0m18:40:26.959165 [info ] [MainThread]: 
[0m18:40:26.960839 [info ] [MainThread]: Finished running 1 table model, 1 view model in 0 hours 0 minutes and 1.12 seconds (1.12s).
[0m18:40:26.963403 [debug] [MainThread]: Command end result
[0m18:40:27.077464 [debug] [MainThread]: Wrote artifact WritableManifest to /opt/airflow/dags/dbt/homework/target/manifest.json
[0m18:40:27.086070 [debug] [MainThread]: Wrote artifact SemanticManifest to /opt/airflow/dags/dbt/homework/target/semantic_manifest.json
[0m18:40:27.107715 [debug] [MainThread]: Wrote artifact RunExecutionResult to /opt/airflow/dags/dbt/homework/target/run_results.json
[0m18:40:27.109605 [info ] [MainThread]: 
[0m18:40:27.111473 [info ] [MainThread]: [31mCompleted with 1 error, 0 partial successes, and 0 warnings:[0m
[0m18:40:27.113124 [info ] [MainThread]: 
[0m18:40:27.114842 [error] [MainThread]:   Database Error in model iris_processed (models/mart/iris_processed.sql)
  function log(integer, double precision) does not exist
  LINE 294:         else log(10, sepal_length + 0)
                         ^
  HINT:  No function matches the given name and argument types. You might need to add explicit type casts.
  compiled code at target/run/homework/models/mart/iris_processed.sql
[0m18:40:27.117593 [info ] [MainThread]: 
[0m18:40:27.120415 [info ] [MainThread]: Done. PASS=1 WARN=0 ERROR=1 SKIP=0 TOTAL=2
[0m18:40:27.125544 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": false, "command_wall_clock_time": 10.044399, "process_in_blocks": "7376", "process_kernel_time": 0.469957, "process_mem_max_rss": "119648", "process_out_blocks": "0", "process_user_time": 11.168983}
[0m18:40:27.129209 [debug] [MainThread]: Command `dbt run` failed at 18:40:27.128857 after 10.05 seconds
[0m18:40:27.131583 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f1ebc250af0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f1eb84b01c0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f1ebc0940a0>]}
[0m18:40:27.134592 [debug] [MainThread]: Flushing usage events
[0m18:40:27.707376 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m18:40:52.420564 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f955b099ac0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f955a1ba4c0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f955a1ba460>]}


============================== 18:40:52.434638 | 7f6d6ec9-492d-4759-90d7-8745ad8debf6 ==============================
[0m18:40:52.434638 [info ] [MainThread]: Running with dbt=1.9.4
[0m18:40:52.437285 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'version_check': 'True', 'debug': 'False', 'log_path': '/opt/airflow/dags/dbt/homework/logs', 'fail_fast': 'False', 'profiles_dir': '/opt/airflow/dags/dbt', 'use_colors': 'True', 'use_experimental_parser': 'False', 'empty': 'False', 'quiet': 'False', 'no_print': 'None', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'invocation_command': 'dbt --profile homework run --project-dir=/opt/airflow/dags/dbt/homework --vars {"is_test": false, "data_date": "2025-04-23"}', 'static_parser': 'True', 'introspect': 'True', 'target_path': 'None', 'log_format': 'default', 'send_anonymous_usage_stats': 'True'}
[0m18:40:52.898385 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '7f6d6ec9-492d-4759-90d7-8745ad8debf6', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f95589ef460>]}
[0m18:40:53.051380 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '7f6d6ec9-492d-4759-90d7-8745ad8debf6', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f955a251130>]}
[0m18:40:53.054413 [info ] [MainThread]: Registered adapter: postgres=1.9.0
[0m18:40:53.415485 [debug] [MainThread]: checksum: f5df654a850f4b74beb13fbe0c7d8863b5b1a20bd535c3ac287d70e390b64d41, vars: {'data_date': '2025-04-23', 'is_test': False}, profile: homework, target: , version: 1.9.4
[0m18:40:53.943042 [info ] [MainThread]: Unable to do partial parsing because config vars, config profile, or config target have changed
[0m18:40:53.945000 [debug] [MainThread]: previous checksum: f5df654a850f4b74beb13fbe0c7d8863b5b1a20bd535c3ac287d70e390b64d41, current checksum: b4b46bb6a239f66694dfdd44ef1792882cb61f2fd7b1ea66b3c7a170d2bb602d
[0m18:40:53.946628 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'partial_parser', 'label': '7f6d6ec9-492d-4759-90d7-8745ad8debf6', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f955a8d7d30>]}
[0m18:40:59.862932 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 1 unused configuration paths:
- seeds.homework.iris_dataset
[0m18:40:59.895505 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '7f6d6ec9-492d-4759-90d7-8745ad8debf6', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f9558652130>]}
[0m18:41:00.186984 [debug] [MainThread]: Wrote artifact WritableManifest to /opt/airflow/dags/dbt/homework/target/manifest.json
[0m18:41:00.215150 [debug] [MainThread]: Wrote artifact SemanticManifest to /opt/airflow/dags/dbt/homework/target/semantic_manifest.json
[0m18:41:00.251838 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '7f6d6ec9-492d-4759-90d7-8745ad8debf6', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f9557320e20>]}
[0m18:41:00.253721 [info ] [MainThread]: Found 2 models, 1 source, 587 macros
[0m18:41:00.255330 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '7f6d6ec9-492d-4759-90d7-8745ad8debf6', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f9557266ac0>]}
[0m18:41:00.258629 [info ] [MainThread]: 
[0m18:41:00.260376 [info ] [MainThread]: Concurrency: 4 threads (target='dev')
[0m18:41:00.261868 [info ] [MainThread]: 
[0m18:41:00.263719 [debug] [MainThread]: Acquiring new postgres connection 'master'
[0m18:41:00.272901 [debug] [ThreadPool]: Acquiring new postgres connection 'list_analytics'
[0m18:41:00.329074 [debug] [ThreadPool]: Using postgres connection "list_analytics"
[0m18:41:00.331282 [debug] [ThreadPool]: On list_analytics: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "homework", "target_name": "dev", "connection_name": "list_analytics"} */

    select distinct nspname from pg_namespace
  
[0m18:41:00.333264 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m18:41:00.349544 [debug] [ThreadPool]: SQL status: SELECT 6 in 0.016 seconds
[0m18:41:00.353936 [debug] [ThreadPool]: On list_analytics: Close
[0m18:41:00.357887 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_analytics, now list_analytics_analytics)
[0m18:41:00.374309 [debug] [ThreadPool]: Using postgres connection "list_analytics_analytics"
[0m18:41:00.376498 [debug] [ThreadPool]: On list_analytics_analytics: BEGIN
[0m18:41:00.378484 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m18:41:00.391671 [debug] [ThreadPool]: SQL status: BEGIN in 0.013 seconds
[0m18:41:00.393704 [debug] [ThreadPool]: Using postgres connection "list_analytics_analytics"
[0m18:41:00.395697 [debug] [ThreadPool]: On list_analytics_analytics: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "homework", "target_name": "dev", "connection_name": "list_analytics_analytics"} */
select
      'analytics' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'analytics'
    union all
    select
      'analytics' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'analytics'
    union all
    select
      'analytics' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'analytics'
  
[0m18:41:00.401670 [debug] [ThreadPool]: SQL status: SELECT 2 in 0.004 seconds
[0m18:41:00.405589 [debug] [ThreadPool]: On list_analytics_analytics: ROLLBACK
[0m18:41:00.408063 [debug] [ThreadPool]: On list_analytics_analytics: Close
[0m18:41:00.420508 [debug] [MainThread]: Using postgres connection "master"
[0m18:41:00.422274 [debug] [MainThread]: On master: BEGIN
[0m18:41:00.424062 [debug] [MainThread]: Opening a new connection, currently in state init
[0m18:41:00.435856 [debug] [MainThread]: SQL status: BEGIN in 0.012 seconds
[0m18:41:00.437993 [debug] [MainThread]: Using postgres connection "master"
[0m18:41:00.440165 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "homework", "target_name": "dev", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select distinct
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v', 'm')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
[0m18:41:00.451981 [debug] [MainThread]: SQL status: SELECT 1 in 0.010 seconds
[0m18:41:00.456327 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '7f6d6ec9-492d-4759-90d7-8745ad8debf6', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f955733b1c0>]}
[0m18:41:00.458309 [debug] [MainThread]: On master: ROLLBACK
[0m18:41:00.460156 [debug] [MainThread]: Using postgres connection "master"
[0m18:41:00.461943 [debug] [MainThread]: On master: BEGIN
[0m18:41:00.464687 [debug] [MainThread]: SQL status: BEGIN in 0.001 seconds
[0m18:41:00.466585 [debug] [MainThread]: On master: COMMIT
[0m18:41:00.468602 [debug] [MainThread]: Using postgres connection "master"
[0m18:41:00.470470 [debug] [MainThread]: On master: COMMIT
[0m18:41:00.472794 [debug] [MainThread]: SQL status: COMMIT in 0.000 seconds
[0m18:41:00.474636 [debug] [MainThread]: On master: Close
[0m18:41:00.485202 [debug] [Thread-1  ]: Began running node model.homework.stg_iris
[0m18:41:00.488287 [info ] [Thread-1  ]: 1 of 2 START sql view model analytics.stg_iris ................................. [RUN]
[0m18:41:00.490917 [debug] [Thread-1  ]: Re-using an available connection from the pool (formerly list_analytics_analytics, now model.homework.stg_iris)
[0m18:41:00.492829 [debug] [Thread-1  ]: Began compiling node model.homework.stg_iris
[0m18:41:00.517130 [debug] [Thread-1  ]: Writing injected SQL for node "model.homework.stg_iris"
[0m18:41:00.531919 [debug] [Thread-1  ]: Began executing node model.homework.stg_iris
[0m18:41:00.632973 [debug] [Thread-1  ]: Writing runtime sql for node "model.homework.stg_iris"
[0m18:41:00.644713 [debug] [Thread-1  ]: Using postgres connection "model.homework.stg_iris"
[0m18:41:00.646782 [debug] [Thread-1  ]: On model.homework.stg_iris: BEGIN
[0m18:41:00.649172 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
[0m18:41:00.662290 [debug] [Thread-1  ]: SQL status: BEGIN in 0.013 seconds
[0m18:41:00.664496 [debug] [Thread-1  ]: Using postgres connection "model.homework.stg_iris"
[0m18:41:00.666578 [debug] [Thread-1  ]: On model.homework.stg_iris: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "homework", "target_name": "dev", "node_id": "model.homework.stg_iris"} */

  create view "analytics"."analytics"."stg_iris__dbt_tmp"
    
    
  as (
    with source as (
    select * from "analytics"."analytics"."iris_dataset"
)

select
    sepal_length,
    sepal_width,
    petal_length,
    petal_width,
    species
from source
  );
[0m18:41:00.671373 [debug] [Thread-1  ]: SQL status: CREATE VIEW in 0.002 seconds
[0m18:41:00.687097 [debug] [Thread-1  ]: Using postgres connection "model.homework.stg_iris"
[0m18:41:00.689474 [debug] [Thread-1  ]: On model.homework.stg_iris: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "homework", "target_name": "dev", "node_id": "model.homework.stg_iris"} */
alter table "analytics"."analytics"."stg_iris" rename to "stg_iris__dbt_backup"
[0m18:41:00.692113 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.001 seconds
[0m18:41:00.701490 [debug] [Thread-1  ]: Using postgres connection "model.homework.stg_iris"
[0m18:41:00.703353 [debug] [Thread-1  ]: On model.homework.stg_iris: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "homework", "target_name": "dev", "node_id": "model.homework.stg_iris"} */
alter table "analytics"."analytics"."stg_iris__dbt_tmp" rename to "stg_iris"
[0m18:41:00.705888 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.001 seconds
[0m18:41:00.749307 [debug] [Thread-1  ]: On model.homework.stg_iris: COMMIT
[0m18:41:00.751244 [debug] [Thread-1  ]: Using postgres connection "model.homework.stg_iris"
[0m18:41:00.753206 [debug] [Thread-1  ]: On model.homework.stg_iris: COMMIT
[0m18:41:00.758908 [debug] [Thread-1  ]: SQL status: COMMIT in 0.004 seconds
[0m18:41:00.779271 [debug] [Thread-1  ]: Applying DROP to: "analytics"."analytics"."stg_iris__dbt_backup"
[0m18:41:00.792936 [debug] [Thread-1  ]: Using postgres connection "model.homework.stg_iris"
[0m18:41:00.795048 [debug] [Thread-1  ]: On model.homework.stg_iris: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "homework", "target_name": "dev", "node_id": "model.homework.stg_iris"} */
drop view if exists "analytics"."analytics"."stg_iris__dbt_backup" cascade
[0m18:41:00.801092 [debug] [Thread-1  ]: SQL status: DROP VIEW in 0.004 seconds
[0m18:41:00.807416 [debug] [Thread-1  ]: On model.homework.stg_iris: Close
[0m18:41:00.812172 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '7f6d6ec9-492d-4759-90d7-8745ad8debf6', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f955ca9d6a0>]}
[0m18:41:00.814525 [info ] [Thread-1  ]: 1 of 2 OK created sql view model analytics.stg_iris ............................ [[32mCREATE VIEW[0m in 0.32s]
[0m18:41:00.816922 [debug] [Thread-1  ]: Finished running node model.homework.stg_iris
[0m18:41:00.820412 [debug] [Thread-3  ]: Began running node model.homework.iris_processed
[0m18:41:00.823086 [info ] [Thread-3  ]: 2 of 2 START sql table model analytics.iris_processed .......................... [RUN]
[0m18:41:00.825598 [debug] [Thread-3  ]: Acquiring new postgres connection 'model.homework.iris_processed'
[0m18:41:00.827452 [debug] [Thread-3  ]: Began compiling node model.homework.iris_processed
[0m18:41:00.867165 [debug] [Thread-3  ]: Using postgres connection "model.homework.iris_processed"
[0m18:41:00.870948 [debug] [Thread-3  ]: On model.homework.iris_processed: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "homework", "target_name": "dev", "node_id": "model.homework.iris_processed"} */

        select percentile_cont(0.5) within group (order by sepal_length ) from "analytics"."analytics"."stg_iris"
    
[0m18:41:00.875650 [debug] [Thread-3  ]: Opening a new connection, currently in state init
[0m18:41:00.895127 [debug] [Thread-3  ]: SQL status: SELECT 1 in 0.020 seconds
[0m18:41:00.904411 [debug] [Thread-3  ]: Using postgres connection "model.homework.iris_processed"
[0m18:41:00.908240 [debug] [Thread-3  ]: On model.homework.iris_processed: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "homework", "target_name": "dev", "node_id": "model.homework.iris_processed"} */

        select percentile_cont(0.5 - 0.5/2) within group (order by sepal_length ) from "analytics"."analytics"."stg_iris"
    
[0m18:41:00.913179 [debug] [Thread-3  ]: SQL status: SELECT 1 in 0.001 seconds
[0m18:41:00.921775 [debug] [Thread-3  ]: Using postgres connection "model.homework.iris_processed"
[0m18:41:00.926918 [debug] [Thread-3  ]: On model.homework.iris_processed: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "homework", "target_name": "dev", "node_id": "model.homework.iris_processed"} */

        select percentile_cont(0.5 + 0.5/2) within group (order by sepal_length ) from "analytics"."analytics"."stg_iris"
    
[0m18:41:00.932653 [debug] [Thread-3  ]: SQL status: SELECT 1 in 0.001 seconds
[0m18:41:00.952904 [debug] [Thread-3  ]: Using postgres connection "model.homework.iris_processed"
[0m18:41:00.956478 [debug] [Thread-3  ]: On model.homework.iris_processed: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "homework", "target_name": "dev", "node_id": "model.homework.iris_processed"} */

        select percentile_cont(0.5) within group (order by sepal_width ) from "analytics"."analytics"."stg_iris"
    
[0m18:41:00.960932 [debug] [Thread-3  ]: SQL status: SELECT 1 in 0.001 seconds
[0m18:41:00.973836 [debug] [Thread-3  ]: Using postgres connection "model.homework.iris_processed"
[0m18:41:00.978193 [debug] [Thread-3  ]: On model.homework.iris_processed: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "homework", "target_name": "dev", "node_id": "model.homework.iris_processed"} */

        select percentile_cont(0.5 - 0.5/2) within group (order by sepal_width ) from "analytics"."analytics"."stg_iris"
    
[0m18:41:00.982828 [debug] [Thread-3  ]: SQL status: SELECT 1 in 0.001 seconds
[0m18:41:00.991143 [debug] [Thread-3  ]: Using postgres connection "model.homework.iris_processed"
[0m18:41:01.001984 [debug] [Thread-3  ]: On model.homework.iris_processed: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "homework", "target_name": "dev", "node_id": "model.homework.iris_processed"} */

        select percentile_cont(0.5 + 0.5/2) within group (order by sepal_width ) from "analytics"."analytics"."stg_iris"
    
[0m18:41:01.006742 [debug] [Thread-3  ]: SQL status: SELECT 1 in 0.001 seconds
[0m18:41:01.021313 [debug] [Thread-3  ]: Using postgres connection "model.homework.iris_processed"
[0m18:41:01.025030 [debug] [Thread-3  ]: On model.homework.iris_processed: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "homework", "target_name": "dev", "node_id": "model.homework.iris_processed"} */

        select percentile_cont(0.5) within group (order by petal_length ) from "analytics"."analytics"."stg_iris"
    
[0m18:41:01.032882 [debug] [Thread-3  ]: SQL status: SELECT 1 in 0.002 seconds
[0m18:41:01.040584 [debug] [Thread-3  ]: Using postgres connection "model.homework.iris_processed"
[0m18:41:01.043319 [debug] [Thread-3  ]: On model.homework.iris_processed: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "homework", "target_name": "dev", "node_id": "model.homework.iris_processed"} */

        select percentile_cont(0.5 - 0.5/2) within group (order by petal_length ) from "analytics"."analytics"."stg_iris"
    
[0m18:41:01.047563 [debug] [Thread-3  ]: SQL status: SELECT 1 in 0.001 seconds
[0m18:41:01.053871 [debug] [Thread-3  ]: Using postgres connection "model.homework.iris_processed"
[0m18:41:01.057080 [debug] [Thread-3  ]: On model.homework.iris_processed: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "homework", "target_name": "dev", "node_id": "model.homework.iris_processed"} */

        select percentile_cont(0.5 + 0.5/2) within group (order by petal_length ) from "analytics"."analytics"."stg_iris"
    
[0m18:41:01.060850 [debug] [Thread-3  ]: SQL status: SELECT 1 in 0.001 seconds
[0m18:41:01.073815 [debug] [Thread-3  ]: Using postgres connection "model.homework.iris_processed"
[0m18:41:01.077731 [debug] [Thread-3  ]: On model.homework.iris_processed: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "homework", "target_name": "dev", "node_id": "model.homework.iris_processed"} */

        select percentile_cont(0.5) within group (order by petal_width ) from "analytics"."analytics"."stg_iris"
    
[0m18:41:01.081107 [debug] [Thread-3  ]: SQL status: SELECT 1 in 0.001 seconds
[0m18:41:01.085972 [debug] [Thread-3  ]: Using postgres connection "model.homework.iris_processed"
[0m18:41:01.088030 [debug] [Thread-3  ]: On model.homework.iris_processed: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "homework", "target_name": "dev", "node_id": "model.homework.iris_processed"} */

        select percentile_cont(0.5 - 0.5/2) within group (order by petal_width ) from "analytics"."analytics"."stg_iris"
    
[0m18:41:01.090373 [debug] [Thread-3  ]: SQL status: SELECT 1 in 0.001 seconds
[0m18:41:01.094346 [debug] [Thread-3  ]: Using postgres connection "model.homework.iris_processed"
[0m18:41:01.096473 [debug] [Thread-3  ]: On model.homework.iris_processed: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "homework", "target_name": "dev", "node_id": "model.homework.iris_processed"} */

        select percentile_cont(0.5 + 0.5/2) within group (order by petal_width ) from "analytics"."analytics"."stg_iris"
    
[0m18:41:01.098799 [debug] [Thread-3  ]: SQL status: SELECT 1 in 0.001 seconds
[0m18:41:01.108138 [debug] [Thread-3  ]: Using postgres connection "model.homework.iris_processed"
[0m18:41:01.110051 [debug] [Thread-3  ]: On model.homework.iris_processed: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "homework", "target_name": "dev", "node_id": "model.homework.iris_processed"} */

            select percentile_cont(0.5) within group (order by sepal_length ) from "analytics"."analytics"."stg_iris"
        
[0m18:41:01.112658 [debug] [Thread-3  ]: SQL status: SELECT 1 in 0.001 seconds
[0m18:41:01.118267 [debug] [Thread-3  ]: Using postgres connection "model.homework.iris_processed"
[0m18:41:01.120296 [debug] [Thread-3  ]: On model.homework.iris_processed: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "homework", "target_name": "dev", "node_id": "model.homework.iris_processed"} */

            select percentile_cont(0.5) within group (order by sepal_width ) from "analytics"."analytics"."stg_iris"
        
[0m18:41:01.122696 [debug] [Thread-3  ]: SQL status: SELECT 1 in 0.001 seconds
[0m18:41:01.127280 [debug] [Thread-3  ]: Using postgres connection "model.homework.iris_processed"
[0m18:41:01.129275 [debug] [Thread-3  ]: On model.homework.iris_processed: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "homework", "target_name": "dev", "node_id": "model.homework.iris_processed"} */

            select percentile_cont(0.5) within group (order by petal_length ) from "analytics"."analytics"."stg_iris"
        
[0m18:41:01.131793 [debug] [Thread-3  ]: SQL status: SELECT 1 in 0.001 seconds
[0m18:41:01.137113 [debug] [Thread-3  ]: Using postgres connection "model.homework.iris_processed"
[0m18:41:01.138917 [debug] [Thread-3  ]: On model.homework.iris_processed: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "homework", "target_name": "dev", "node_id": "model.homework.iris_processed"} */

            select percentile_cont(0.5) within group (order by petal_width ) from "analytics"."analytics"."stg_iris"
        
[0m18:41:01.141039 [debug] [Thread-3  ]: SQL status: SELECT 1 in 0.001 seconds
[0m18:41:01.164484 [debug] [Thread-3  ]: Using postgres connection "model.homework.iris_processed"
[0m18:41:01.166328 [debug] [Thread-3  ]: On model.homework.iris_processed: BEGIN
[0m18:41:01.168496 [debug] [Thread-3  ]: SQL status: BEGIN in 0.000 seconds
[0m18:41:01.170434 [debug] [Thread-3  ]: Using postgres connection "model.homework.iris_processed"
[0m18:41:01.172744 [debug] [Thread-3  ]: On model.homework.iris_processed: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "homework", "target_name": "dev", "node_id": "model.homework.iris_processed"} */
select
                species as value

            from "analytics"."analytics"."stg_iris"

            
            where species is not null  and true
            

            group by species
            order by species

            

        
[0m18:41:01.175970 [debug] [Thread-3  ]: SQL status: SELECT 3 in 0.001 seconds
[0m18:41:01.188404 [debug] [Thread-3  ]: Writing injected SQL for node "model.homework.iris_processed"
[0m18:41:01.198769 [debug] [Thread-3  ]: Began executing node model.homework.iris_processed
[0m18:41:01.261730 [debug] [Thread-3  ]: Writing runtime sql for node "model.homework.iris_processed"
[0m18:41:01.272821 [debug] [Thread-3  ]: Using postgres connection "model.homework.iris_processed"
[0m18:41:01.275777 [debug] [Thread-3  ]: On model.homework.iris_processed: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "homework", "target_name": "dev", "node_id": "model.homework.iris_processed"} */

  
    

  create  table "analytics"."analytics"."iris_processed__dbt_tmp"
  
  
    as
  
  (
    

with import_iris as (
    select *
    from "analytics"."analytics"."stg_iris"
)
select
    sepal_length,
    sepal_width,
    petal_length,
    petal_width,
    -- K Bins Discretization
    
        

    
        NTILE(5) over (order by sepal_length)
    

 as sepal_length_quantile_bin,
        

    
        
        floor(
        (
            sepal_length - (min(sepal_length) over ())
        )
        /
        (
            ((max(sepal_length) over ()) - (min(sepal_length) over ())) / 4::float
        )
        ) + 1
    

 as sepal_length_uniform_bin,
    
        

    
        NTILE(5) over (order by sepal_width)
    

 as sepal_width_quantile_bin,
        

    
        
        floor(
        (
            sepal_width - (min(sepal_width) over ())
        )
        /
        (
            ((max(sepal_width) over ()) - (min(sepal_width) over ())) / 4::float
        )
        ) + 1
    

 as sepal_width_uniform_bin,
    
        

    
        NTILE(5) over (order by petal_length)
    

 as petal_length_quantile_bin,
        

    
        
        floor(
        (
            petal_length - (min(petal_length) over ())
        )
        /
        (
            ((max(petal_length) over ()) - (min(petal_length) over ())) / 4::float
        )
        ) + 1
    

 as petal_length_uniform_bin,
    
        

    
        NTILE(5) over (order by petal_width)
    

 as petal_width_quantile_bin,
        

    
        
        floor(
        (
            petal_width - (min(petal_width) over ())
        )
        /
        (
            ((max(petal_width) over ()) - (min(petal_width) over ())) / 4::float
        )
        ) + 1
    

 as petal_width_uniform_bin,
    
-- Scaling
    
        

    

    
    
    

    
    
    

    (
        sepal_length - 5.8
    )
    /
    (
        6.4 - 5.1
    )

 as sepal_length_robust_scaled,
        

    (sepal_length) / (max(abs(sepal_length)) over ())::FLOAT

 as sepal_length_max_absolute_scaled,
        

    
    (
        ((sepal_length) - (min(sepal_length) over ()))
        /
        ((max(sepal_length) over ()) - (min(sepal_length) over ()))::FLOAT
    )
    *
    (1.0 - 0.0)
    +
    0.0

 as sepal_length_max_min_max_scaled,
    
        

    

    
    
    

    
    
    

    (
        sepal_width - 3.0
    )
    /
    (
        3.3 - 2.8
    )

 as sepal_width_robust_scaled,
        

    (sepal_width) / (max(abs(sepal_width)) over ())::FLOAT

 as sepal_width_max_absolute_scaled,
        

    
    (
        ((sepal_width) - (min(sepal_width) over ()))
        /
        ((max(sepal_width) over ()) - (min(sepal_width) over ()))::FLOAT
    )
    *
    (1.0 - 0.0)
    +
    0.0

 as sepal_width_max_min_max_scaled,
    
        

    

    
    
    

    
    
    

    (
        petal_length - 4.35
    )
    /
    (
        5.1 - 1.6
    )

 as petal_length_robust_scaled,
        

    (petal_length) / (max(abs(petal_length)) over ())::FLOAT

 as petal_length_max_absolute_scaled,
        

    
    (
        ((petal_length) - (min(petal_length) over ()))
        /
        ((max(petal_length) over ()) - (min(petal_length) over ()))::FLOAT
    )
    *
    (1.0 - 0.0)
    +
    0.0

 as petal_length_max_min_max_scaled,
    
        

    

    
    
    

    
    
    

    (
        petal_width - 1.3
    )
    /
    (
        1.8 - 0.3
    )

 as petal_width_robust_scaled,
        

    (petal_width) / (max(abs(petal_width)) over ())::FLOAT

 as petal_width_max_absolute_scaled,
        

    
    (
        ((petal_width) - (min(petal_width) over ()))
        /
        ((max(petal_width) over ()) - (min(petal_width) over ()))::FLOAT
    )
    *
    (1.0 - 0.0)
    +
    0.0

 as petal_width_max_min_max_scaled,
    

    -- Log Transformation
    
        

    case
        when sepal_length is null or sepal_length + 0 <= 0 then null
        else log(10, sepal_length + 0)
    end

 as sepal_length_logged,
    
        

    case
        when sepal_width is null or sepal_width + 0 <= 0 then null
        else log(10, sepal_width + 0)
    end

 as sepal_width_logged,
    
        

    case
        when petal_length is null or petal_length + 0 <= 0 then null
        else log(10, petal_length + 0)
    end

 as petal_length_logged,
    
        

    case
        when petal_width is null or petal_width + 0 <= 0 then null
        else log(10, petal_width + 0)
    end

 as petal_width_logged,
    

    -- Binarization
    
        

    

    
        

        
    

    case
        when sepal_length >=
            
                5.8
            
            then 1
        else 0
    end

 as sepal_length_binarized,
    
        

    

    
        

        
    

    case
        when sepal_width >=
            
                3.0
            
            then 1
        else 0
    end

 as sepal_width_binarized,
    
        

    

    
        

        
    

    case
        when petal_length >=
            
                4.35
            
            then 1
        else 0
    end

 as petal_length_binarized,
    
        

    

    
        

        
    

    case
        when petal_width >=
            
                1.3
            
            then 1
        else 0
    end

 as petal_width_binarized,
    

    -- Standardization
    
        

    
    (
        (sepal_length - avg(sepal_length) over ())
        /
        (stddev(sepal_length) over ())::FLOAT
    )
    *
    1
    +
    0

 as sepal_length_standardized,
    
        

    
    (
        (sepal_width - avg(sepal_width) over ())
        /
        (stddev(sepal_width) over ())::FLOAT
    )
    *
    1
    +
    0

 as sepal_width_standardized,
    
        

    
    (
        (petal_length - avg(petal_length) over ())
        /
        (stddev(petal_length) over ())::FLOAT
    )
    *
    1
    +
    0

 as petal_length_standardized,
    
        

    
    (
        (petal_width - avg(petal_width) over ())
        /
        (stddev(petal_width) over ())::FLOAT
    )
    *
    1
    +
    0

 as petal_width_standardized,
    
-- Interactions
    
        
            
            
            

    
        (sepal_length * sepal_width)
    

 as sepal_length_x_sepal_width_interaction,
            

    
        (sepal_length + sepal_width)
    

 as sepal_length_plus_sepal_width_interaction,
        
            
            
            

    
        (sepal_length * petal_length)
    

 as sepal_length_x_petal_length_interaction,
            

    
        (sepal_length + petal_length)
    

 as sepal_length_plus_petal_length_interaction,
        
            
            
            

    
        (sepal_length * petal_width)
    

 as sepal_length_x_petal_width_interaction,
            

    
        (sepal_length + petal_width)
    

 as sepal_length_plus_petal_width_interaction,
        
    
        
            
            
            

    
        (sepal_width * petal_length)
    

 as sepal_width_x_petal_length_interaction,
            

    
        (sepal_width + petal_length)
    

 as sepal_width_plus_petal_length_interaction,
        
            
            
            

    
        (sepal_width * petal_width)
    

 as sepal_width_x_petal_width_interaction,
            

    
        (sepal_width + petal_width)
    

 as sepal_width_plus_petal_width_interaction,
        
    
        
            
            
            

    
        (petal_length * petal_width)
    

 as petal_length_x_petal_width_interaction,
            

    
        (petal_length + petal_width)
    

 as petal_length_plus_petal_width_interaction,
        
    
        
    
species,    
    -- Label Encoding
    

    dense_rank() over (order by species) - 1

 as species_label_encoded,
    -- One Hot Encoding
    

    

    
        
    

    

    

        case
            when species = 'setosa' then 1
            else 0
        end as is_species__setosa,

    

        case
            when species = 'versicolor' then 1
            else 0
        end as is_species__versicolor,

    

        case
            when species = 'virginica' then 1
            else 0
        end as is_species__virginica,

    

    case
        when species is null then 1
        else 0
    end as is_species__


from "analytics"."analytics"."stg_iris"
  );
  
[0m18:41:01.280871 [debug] [Thread-3  ]: Postgres adapter: Postgres error: function log(integer, double precision) does not exist
LINE 294:         else log(10, sepal_length + 0)
                       ^
HINT:  No function matches the given name and argument types. You might need to add explicit type casts.

[0m18:41:01.282921 [debug] [Thread-3  ]: On model.homework.iris_processed: ROLLBACK
[0m18:41:01.285073 [debug] [Thread-3  ]: On model.homework.iris_processed: Close
[0m18:41:01.290185 [debug] [Thread-3  ]: Database Error in model iris_processed (models/mart/iris_processed.sql)
  function log(integer, double precision) does not exist
  LINE 294:         else log(10, sepal_length + 0)
                         ^
  HINT:  No function matches the given name and argument types. You might need to add explicit type casts.
  compiled code at target/run/homework/models/mart/iris_processed.sql
[0m18:41:01.292386 [debug] [Thread-3  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '7f6d6ec9-492d-4759-90d7-8745ad8debf6', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f9556622bb0>]}
[0m18:41:01.294519 [error] [Thread-3  ]: 2 of 2 ERROR creating sql table model analytics.iris_processed ................. [[31mERROR[0m in 0.47s]
[0m18:41:01.296689 [debug] [Thread-3  ]: Finished running node model.homework.iris_processed
[0m18:41:01.298971 [debug] [Thread-7  ]: Marking all children of 'model.homework.iris_processed' to be skipped because of status 'error'.  Reason: Database Error in model iris_processed (models/mart/iris_processed.sql)
  function log(integer, double precision) does not exist
  LINE 294:         else log(10, sepal_length + 0)
                         ^
  HINT:  No function matches the given name and argument types. You might need to add explicit type casts.
  compiled code at target/run/homework/models/mart/iris_processed.sql.
[0m18:41:01.303170 [debug] [MainThread]: Using postgres connection "master"
[0m18:41:01.305152 [debug] [MainThread]: On master: BEGIN
[0m18:41:01.306559 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m18:41:01.319833 [debug] [MainThread]: SQL status: BEGIN in 0.013 seconds
[0m18:41:01.321834 [debug] [MainThread]: On master: COMMIT
[0m18:41:01.323714 [debug] [MainThread]: Using postgres connection "master"
[0m18:41:01.325188 [debug] [MainThread]: On master: COMMIT
[0m18:41:01.327069 [debug] [MainThread]: SQL status: COMMIT in 0.000 seconds
[0m18:41:01.329045 [debug] [MainThread]: On master: Close
[0m18:41:01.331170 [debug] [MainThread]: Connection 'master' was properly closed.
[0m18:41:01.332916 [debug] [MainThread]: Connection 'model.homework.stg_iris' was properly closed.
[0m18:41:01.334225 [debug] [MainThread]: Connection 'model.homework.iris_processed' was properly closed.
[0m18:41:01.335751 [info ] [MainThread]: 
[0m18:41:01.337333 [info ] [MainThread]: Finished running 1 table model, 1 view model in 0 hours 0 minutes and 1.07 seconds (1.07s).
[0m18:41:01.339780 [debug] [MainThread]: Command end result
[0m18:41:01.433929 [debug] [MainThread]: Wrote artifact WritableManifest to /opt/airflow/dags/dbt/homework/target/manifest.json
[0m18:41:01.443488 [debug] [MainThread]: Wrote artifact SemanticManifest to /opt/airflow/dags/dbt/homework/target/semantic_manifest.json
[0m18:41:01.461941 [debug] [MainThread]: Wrote artifact RunExecutionResult to /opt/airflow/dags/dbt/homework/target/run_results.json
[0m18:41:01.464426 [info ] [MainThread]: 
[0m18:41:01.466608 [info ] [MainThread]: [31mCompleted with 1 error, 0 partial successes, and 0 warnings:[0m
[0m18:41:01.468501 [info ] [MainThread]: 
[0m18:41:01.470232 [error] [MainThread]:   Database Error in model iris_processed (models/mart/iris_processed.sql)
  function log(integer, double precision) does not exist
  LINE 294:         else log(10, sepal_length + 0)
                         ^
  HINT:  No function matches the given name and argument types. You might need to add explicit type casts.
  compiled code at target/run/homework/models/mart/iris_processed.sql
[0m18:41:01.471910 [info ] [MainThread]: 
[0m18:41:01.473622 [info ] [MainThread]: Done. PASS=1 WARN=0 ERROR=1 SKIP=0 TOTAL=2
[0m18:41:01.476439 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": false, "command_wall_clock_time": 9.20303, "process_in_blocks": "480", "process_kernel_time": 0.469691, "process_mem_max_rss": "120548", "process_out_blocks": "0", "process_user_time": 10.662994}
[0m18:41:01.478790 [debug] [MainThread]: Command `dbt run` failed at 18:41:01.478564 after 9.21 seconds
[0m18:41:01.481023 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f955b099ac0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f955a251130>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f955aec6160>]}
[0m18:41:01.483206 [debug] [MainThread]: Flushing usage events
[0m18:41:02.016482 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m18:43:00.096354 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff32dc99b20>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff32cdba430>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff32cdba3d0>]}


============================== 18:43:00.108241 | a5eb8854-caa0-4ce6-9feb-3411388bc4a4 ==============================
[0m18:43:00.108241 [info ] [MainThread]: Running with dbt=1.9.4
[0m18:43:00.111442 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': '/opt/airflow/dags/dbt', 'fail_fast': 'False', 'version_check': 'True', 'log_path': '/opt/airflow/dags/dbt/homework/logs', 'debug': 'False', 'warn_error': 'None', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'empty': 'False', 'log_format': 'default', 'static_parser': 'True', 'introspect': 'True', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'target_path': 'None', 'invocation_command': 'dbt --profile homework run --project-dir=/opt/airflow/dags/dbt/homework --vars {"is_test": false, "data_date": "2025-04-22"}', 'send_anonymous_usage_stats': 'True'}
[0m18:43:00.564465 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'a5eb8854-caa0-4ce6-9feb-3411388bc4a4', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff32cdfa760>]}
[0m18:43:00.700586 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': 'a5eb8854-caa0-4ce6-9feb-3411388bc4a4', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff32b542e80>]}
[0m18:43:00.703230 [info ] [MainThread]: Registered adapter: postgres=1.9.0
[0m18:43:01.096830 [debug] [MainThread]: checksum: b4b46bb6a239f66694dfdd44ef1792882cb61f2fd7b1ea66b3c7a170d2bb602d, vars: {'data_date': '2025-04-22', 'is_test': False}, profile: homework, target: , version: 1.9.4
[0m18:43:01.369161 [info ] [MainThread]: Unable to do partial parsing because config vars, config profile, or config target have changed
[0m18:43:01.370901 [debug] [MainThread]: previous checksum: b4b46bb6a239f66694dfdd44ef1792882cb61f2fd7b1ea66b3c7a170d2bb602d, current checksum: f5df654a850f4b74beb13fbe0c7d8863b5b1a20bd535c3ac287d70e390b64d41
[0m18:43:01.372507 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'partial_parser', 'label': 'a5eb8854-caa0-4ce6-9feb-3411388bc4a4', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff32d4d7610>]}
[0m18:43:07.264290 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 1 unused configuration paths:
- seeds.homework.iris_dataset
[0m18:43:07.300447 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'a5eb8854-caa0-4ce6-9feb-3411388bc4a4', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff32b25d130>]}
[0m18:43:07.536312 [debug] [MainThread]: Wrote artifact WritableManifest to /opt/airflow/dags/dbt/homework/target/manifest.json
[0m18:43:07.556108 [debug] [MainThread]: Wrote artifact SemanticManifest to /opt/airflow/dags/dbt/homework/target/semantic_manifest.json
[0m18:43:07.588073 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'a5eb8854-caa0-4ce6-9feb-3411388bc4a4', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff32b248940>]}
[0m18:43:07.590059 [info ] [MainThread]: Found 2 models, 1 source, 587 macros
[0m18:43:07.591493 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'a5eb8854-caa0-4ce6-9feb-3411388bc4a4', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff32b2482e0>]}
[0m18:43:07.594754 [info ] [MainThread]: 
[0m18:43:07.596275 [info ] [MainThread]: Concurrency: 4 threads (target='dev')
[0m18:43:07.597832 [info ] [MainThread]: 
[0m18:43:07.599528 [debug] [MainThread]: Acquiring new postgres connection 'master'
[0m18:43:07.610085 [debug] [ThreadPool]: Acquiring new postgres connection 'list_analytics'
[0m18:43:07.666401 [debug] [ThreadPool]: Using postgres connection "list_analytics"
[0m18:43:07.668934 [debug] [ThreadPool]: On list_analytics: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "homework", "target_name": "dev", "connection_name": "list_analytics"} */

    select distinct nspname from pg_namespace
  
[0m18:43:07.670733 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m18:43:07.685657 [debug] [ThreadPool]: SQL status: SELECT 6 in 0.015 seconds
[0m18:43:07.689207 [debug] [ThreadPool]: On list_analytics: Close
[0m18:43:07.692645 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_analytics, now list_analytics_analytics)
[0m18:43:07.708902 [debug] [ThreadPool]: Using postgres connection "list_analytics_analytics"
[0m18:43:07.710614 [debug] [ThreadPool]: On list_analytics_analytics: BEGIN
[0m18:43:07.712099 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m18:43:07.724657 [debug] [ThreadPool]: SQL status: BEGIN in 0.012 seconds
[0m18:43:07.726461 [debug] [ThreadPool]: Using postgres connection "list_analytics_analytics"
[0m18:43:07.728374 [debug] [ThreadPool]: On list_analytics_analytics: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "homework", "target_name": "dev", "connection_name": "list_analytics_analytics"} */
select
      'analytics' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'analytics'
    union all
    select
      'analytics' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'analytics'
    union all
    select
      'analytics' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'analytics'
  
[0m18:43:07.733430 [debug] [ThreadPool]: SQL status: SELECT 2 in 0.003 seconds
[0m18:43:07.737097 [debug] [ThreadPool]: On list_analytics_analytics: ROLLBACK
[0m18:43:07.739348 [debug] [ThreadPool]: On list_analytics_analytics: Close
[0m18:43:07.752108 [debug] [MainThread]: Using postgres connection "master"
[0m18:43:07.753964 [debug] [MainThread]: On master: BEGIN
[0m18:43:07.755563 [debug] [MainThread]: Opening a new connection, currently in state init
[0m18:43:07.766813 [debug] [MainThread]: SQL status: BEGIN in 0.011 seconds
[0m18:43:07.768881 [debug] [MainThread]: Using postgres connection "master"
[0m18:43:07.770909 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "homework", "target_name": "dev", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select distinct
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v', 'm')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
[0m18:43:07.781521 [debug] [MainThread]: SQL status: SELECT 1 in 0.008 seconds
[0m18:43:07.785589 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'a5eb8854-caa0-4ce6-9feb-3411388bc4a4', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff32933c130>]}
[0m18:43:07.787565 [debug] [MainThread]: On master: ROLLBACK
[0m18:43:07.789807 [debug] [MainThread]: Using postgres connection "master"
[0m18:43:07.792025 [debug] [MainThread]: On master: BEGIN
[0m18:43:07.794731 [debug] [MainThread]: SQL status: BEGIN in 0.001 seconds
[0m18:43:07.798830 [debug] [MainThread]: On master: COMMIT
[0m18:43:07.801548 [debug] [MainThread]: Using postgres connection "master"
[0m18:43:07.803984 [debug] [MainThread]: On master: COMMIT
[0m18:43:07.806587 [debug] [MainThread]: SQL status: COMMIT in 0.000 seconds
[0m18:43:07.808923 [debug] [MainThread]: On master: Close
[0m18:43:07.819105 [debug] [Thread-1  ]: Began running node model.homework.stg_iris
[0m18:43:07.821478 [info ] [Thread-1  ]: 1 of 2 START sql view model analytics.stg_iris ................................. [RUN]
[0m18:43:07.823969 [debug] [Thread-1  ]: Re-using an available connection from the pool (formerly list_analytics_analytics, now model.homework.stg_iris)
[0m18:43:07.826101 [debug] [Thread-1  ]: Began compiling node model.homework.stg_iris
[0m18:43:07.847287 [debug] [Thread-1  ]: Writing injected SQL for node "model.homework.stg_iris"
[0m18:43:07.857295 [debug] [Thread-1  ]: Began executing node model.homework.stg_iris
[0m18:43:07.944078 [debug] [Thread-1  ]: Writing runtime sql for node "model.homework.stg_iris"
[0m18:43:07.951464 [debug] [Thread-1  ]: Using postgres connection "model.homework.stg_iris"
[0m18:43:07.953981 [debug] [Thread-1  ]: On model.homework.stg_iris: BEGIN
[0m18:43:07.955699 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
[0m18:43:07.967294 [debug] [Thread-1  ]: SQL status: BEGIN in 0.011 seconds
[0m18:43:07.969756 [debug] [Thread-1  ]: Using postgres connection "model.homework.stg_iris"
[0m18:43:07.971653 [debug] [Thread-1  ]: On model.homework.stg_iris: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "homework", "target_name": "dev", "node_id": "model.homework.stg_iris"} */

  create view "analytics"."analytics"."stg_iris__dbt_tmp"
    
    
  as (
    with source as (
    select * from "analytics"."analytics"."iris_dataset"
)

select
    sepal_length,
    sepal_width,
    petal_length,
    petal_width,
    species
from source
  );
[0m18:43:07.975672 [debug] [Thread-1  ]: SQL status: CREATE VIEW in 0.002 seconds
[0m18:43:07.991567 [debug] [Thread-1  ]: Using postgres connection "model.homework.stg_iris"
[0m18:43:07.993228 [debug] [Thread-1  ]: On model.homework.stg_iris: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "homework", "target_name": "dev", "node_id": "model.homework.stg_iris"} */
alter table "analytics"."analytics"."stg_iris" rename to "stg_iris__dbt_backup"
[0m18:43:07.995475 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.001 seconds
[0m18:43:08.004634 [debug] [Thread-1  ]: Using postgres connection "model.homework.stg_iris"
[0m18:43:08.006830 [debug] [Thread-1  ]: On model.homework.stg_iris: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "homework", "target_name": "dev", "node_id": "model.homework.stg_iris"} */
alter table "analytics"."analytics"."stg_iris__dbt_tmp" rename to "stg_iris"
[0m18:43:08.009018 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.001 seconds
[0m18:43:08.046650 [debug] [Thread-1  ]: On model.homework.stg_iris: COMMIT
[0m18:43:08.048333 [debug] [Thread-1  ]: Using postgres connection "model.homework.stg_iris"
[0m18:43:08.050189 [debug] [Thread-1  ]: On model.homework.stg_iris: COMMIT
[0m18:43:08.055802 [debug] [Thread-1  ]: SQL status: COMMIT in 0.004 seconds
[0m18:43:08.077210 [debug] [Thread-1  ]: Applying DROP to: "analytics"."analytics"."stg_iris__dbt_backup"
[0m18:43:08.098425 [debug] [Thread-1  ]: Using postgres connection "model.homework.stg_iris"
[0m18:43:08.100829 [debug] [Thread-1  ]: On model.homework.stg_iris: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "homework", "target_name": "dev", "node_id": "model.homework.stg_iris"} */
drop view if exists "analytics"."analytics"."stg_iris__dbt_backup" cascade
[0m18:43:08.112648 [debug] [Thread-1  ]: SQL status: DROP VIEW in 0.004 seconds
[0m18:43:08.122147 [debug] [Thread-1  ]: On model.homework.stg_iris: Close
[0m18:43:08.128845 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'a5eb8854-caa0-4ce6-9feb-3411388bc4a4', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff32f69d9a0>]}
[0m18:43:08.131297 [info ] [Thread-1  ]: 1 of 2 OK created sql view model analytics.stg_iris ............................ [[32mCREATE VIEW[0m in 0.30s]
[0m18:43:08.133604 [debug] [Thread-1  ]: Finished running node model.homework.stg_iris
[0m18:43:08.137240 [debug] [Thread-3  ]: Began running node model.homework.iris_processed
[0m18:43:08.139623 [info ] [Thread-3  ]: 2 of 2 START sql table model analytics.iris_processed .......................... [RUN]
[0m18:43:08.141901 [debug] [Thread-3  ]: Acquiring new postgres connection 'model.homework.iris_processed'
[0m18:43:08.143656 [debug] [Thread-3  ]: Began compiling node model.homework.iris_processed
[0m18:43:08.194701 [debug] [Thread-3  ]: Using postgres connection "model.homework.iris_processed"
[0m18:43:08.196460 [debug] [Thread-3  ]: On model.homework.iris_processed: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "homework", "target_name": "dev", "node_id": "model.homework.iris_processed"} */

        select percentile_cont(0.5) within group (order by sepal_length ) from "analytics"."analytics"."stg_iris"
    
[0m18:43:08.198094 [debug] [Thread-3  ]: Opening a new connection, currently in state init
[0m18:43:08.212134 [debug] [Thread-3  ]: SQL status: SELECT 1 in 0.014 seconds
[0m18:43:08.216520 [debug] [Thread-3  ]: Using postgres connection "model.homework.iris_processed"
[0m18:43:08.218775 [debug] [Thread-3  ]: On model.homework.iris_processed: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "homework", "target_name": "dev", "node_id": "model.homework.iris_processed"} */

        select percentile_cont(0.5 - 0.5/2) within group (order by sepal_length ) from "analytics"."analytics"."stg_iris"
    
[0m18:43:08.221226 [debug] [Thread-3  ]: SQL status: SELECT 1 in 0.001 seconds
[0m18:43:08.224986 [debug] [Thread-3  ]: Using postgres connection "model.homework.iris_processed"
[0m18:43:08.226733 [debug] [Thread-3  ]: On model.homework.iris_processed: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "homework", "target_name": "dev", "node_id": "model.homework.iris_processed"} */

        select percentile_cont(0.5 + 0.5/2) within group (order by sepal_length ) from "analytics"."analytics"."stg_iris"
    
[0m18:43:08.229094 [debug] [Thread-3  ]: SQL status: SELECT 1 in 0.001 seconds
[0m18:43:08.235811 [debug] [Thread-3  ]: Using postgres connection "model.homework.iris_processed"
[0m18:43:08.237803 [debug] [Thread-3  ]: On model.homework.iris_processed: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "homework", "target_name": "dev", "node_id": "model.homework.iris_processed"} */

        select percentile_cont(0.5) within group (order by sepal_width ) from "analytics"."analytics"."stg_iris"
    
[0m18:43:08.240044 [debug] [Thread-3  ]: SQL status: SELECT 1 in 0.001 seconds
[0m18:43:08.243720 [debug] [Thread-3  ]: Using postgres connection "model.homework.iris_processed"
[0m18:43:08.245395 [debug] [Thread-3  ]: On model.homework.iris_processed: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "homework", "target_name": "dev", "node_id": "model.homework.iris_processed"} */

        select percentile_cont(0.5 - 0.5/2) within group (order by sepal_width ) from "analytics"."analytics"."stg_iris"
    
[0m18:43:08.247595 [debug] [Thread-3  ]: SQL status: SELECT 1 in 0.000 seconds
[0m18:43:08.251953 [debug] [Thread-3  ]: Using postgres connection "model.homework.iris_processed"
[0m18:43:08.254042 [debug] [Thread-3  ]: On model.homework.iris_processed: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "homework", "target_name": "dev", "node_id": "model.homework.iris_processed"} */

        select percentile_cont(0.5 + 0.5/2) within group (order by sepal_width ) from "analytics"."analytics"."stg_iris"
    
[0m18:43:08.256195 [debug] [Thread-3  ]: SQL status: SELECT 1 in 0.001 seconds
[0m18:43:08.261847 [debug] [Thread-3  ]: Using postgres connection "model.homework.iris_processed"
[0m18:43:08.263584 [debug] [Thread-3  ]: On model.homework.iris_processed: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "homework", "target_name": "dev", "node_id": "model.homework.iris_processed"} */

        select percentile_cont(0.5) within group (order by petal_length ) from "analytics"."analytics"."stg_iris"
    
[0m18:43:08.265812 [debug] [Thread-3  ]: SQL status: SELECT 1 in 0.001 seconds
[0m18:43:08.270601 [debug] [Thread-3  ]: Using postgres connection "model.homework.iris_processed"
[0m18:43:08.272347 [debug] [Thread-3  ]: On model.homework.iris_processed: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "homework", "target_name": "dev", "node_id": "model.homework.iris_processed"} */

        select percentile_cont(0.5 - 0.5/2) within group (order by petal_length ) from "analytics"."analytics"."stg_iris"
    
[0m18:43:08.274542 [debug] [Thread-3  ]: SQL status: SELECT 1 in 0.001 seconds
[0m18:43:08.278715 [debug] [Thread-3  ]: Using postgres connection "model.homework.iris_processed"
[0m18:43:08.280482 [debug] [Thread-3  ]: On model.homework.iris_processed: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "homework", "target_name": "dev", "node_id": "model.homework.iris_processed"} */

        select percentile_cont(0.5 + 0.5/2) within group (order by petal_length ) from "analytics"."analytics"."stg_iris"
    
[0m18:43:08.282664 [debug] [Thread-3  ]: SQL status: SELECT 1 in 0.000 seconds
[0m18:43:08.291755 [debug] [Thread-3  ]: Using postgres connection "model.homework.iris_processed"
[0m18:43:08.293718 [debug] [Thread-3  ]: On model.homework.iris_processed: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "homework", "target_name": "dev", "node_id": "model.homework.iris_processed"} */

        select percentile_cont(0.5) within group (order by petal_width ) from "analytics"."analytics"."stg_iris"
    
[0m18:43:08.296089 [debug] [Thread-3  ]: SQL status: SELECT 1 in 0.001 seconds
[0m18:43:08.300160 [debug] [Thread-3  ]: Using postgres connection "model.homework.iris_processed"
[0m18:43:08.305208 [debug] [Thread-3  ]: On model.homework.iris_processed: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "homework", "target_name": "dev", "node_id": "model.homework.iris_processed"} */

        select percentile_cont(0.5 - 0.5/2) within group (order by petal_width ) from "analytics"."analytics"."stg_iris"
    
[0m18:43:08.307953 [debug] [Thread-3  ]: SQL status: SELECT 1 in 0.001 seconds
[0m18:43:08.312384 [debug] [Thread-3  ]: Using postgres connection "model.homework.iris_processed"
[0m18:43:08.314301 [debug] [Thread-3  ]: On model.homework.iris_processed: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "homework", "target_name": "dev", "node_id": "model.homework.iris_processed"} */

        select percentile_cont(0.5 + 0.5/2) within group (order by petal_width ) from "analytics"."analytics"."stg_iris"
    
[0m18:43:08.316762 [debug] [Thread-3  ]: SQL status: SELECT 1 in 0.001 seconds
[0m18:43:08.325361 [debug] [Thread-3  ]: Using postgres connection "model.homework.iris_processed"
[0m18:43:08.327254 [debug] [Thread-3  ]: On model.homework.iris_processed: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "homework", "target_name": "dev", "node_id": "model.homework.iris_processed"} */

            select percentile_cont(0.5) within group (order by sepal_length ) from "analytics"."analytics"."stg_iris"
        
[0m18:43:08.329759 [debug] [Thread-3  ]: SQL status: SELECT 1 in 0.001 seconds
[0m18:43:08.334349 [debug] [Thread-3  ]: Using postgres connection "model.homework.iris_processed"
[0m18:43:08.336950 [debug] [Thread-3  ]: On model.homework.iris_processed: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "homework", "target_name": "dev", "node_id": "model.homework.iris_processed"} */

            select percentile_cont(0.5) within group (order by sepal_width ) from "analytics"."analytics"."stg_iris"
        
[0m18:43:08.339941 [debug] [Thread-3  ]: SQL status: SELECT 1 in 0.001 seconds
[0m18:43:08.347255 [debug] [Thread-3  ]: Using postgres connection "model.homework.iris_processed"
[0m18:43:08.349382 [debug] [Thread-3  ]: On model.homework.iris_processed: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "homework", "target_name": "dev", "node_id": "model.homework.iris_processed"} */

            select percentile_cont(0.5) within group (order by petal_length ) from "analytics"."analytics"."stg_iris"
        
[0m18:43:08.352551 [debug] [Thread-3  ]: SQL status: SELECT 1 in 0.001 seconds
[0m18:43:08.359757 [debug] [Thread-3  ]: Using postgres connection "model.homework.iris_processed"
[0m18:43:08.361839 [debug] [Thread-3  ]: On model.homework.iris_processed: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "homework", "target_name": "dev", "node_id": "model.homework.iris_processed"} */

            select percentile_cont(0.5) within group (order by petal_width ) from "analytics"."analytics"."stg_iris"
        
[0m18:43:08.364558 [debug] [Thread-3  ]: SQL status: SELECT 1 in 0.001 seconds
[0m18:43:08.393787 [debug] [Thread-3  ]: Using postgres connection "model.homework.iris_processed"
[0m18:43:08.395767 [debug] [Thread-3  ]: On model.homework.iris_processed: BEGIN
[0m18:43:08.397861 [debug] [Thread-3  ]: SQL status: BEGIN in 0.000 seconds
[0m18:43:08.399698 [debug] [Thread-3  ]: Using postgres connection "model.homework.iris_processed"
[0m18:43:08.401726 [debug] [Thread-3  ]: On model.homework.iris_processed: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "homework", "target_name": "dev", "node_id": "model.homework.iris_processed"} */
select
                species as value

            from "analytics"."analytics"."stg_iris"

            
            where species is not null  and true
            

            group by species
            order by species

            

        
[0m18:43:08.405080 [debug] [Thread-3  ]: SQL status: SELECT 3 in 0.001 seconds
[0m18:43:08.416193 [debug] [Thread-3  ]: Writing injected SQL for node "model.homework.iris_processed"
[0m18:43:08.427836 [debug] [Thread-3  ]: Began executing node model.homework.iris_processed
[0m18:43:08.487299 [debug] [Thread-3  ]: Writing runtime sql for node "model.homework.iris_processed"
[0m18:43:08.497732 [debug] [Thread-3  ]: Using postgres connection "model.homework.iris_processed"
[0m18:43:08.500623 [debug] [Thread-3  ]: On model.homework.iris_processed: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "homework", "target_name": "dev", "node_id": "model.homework.iris_processed"} */

  
    

  create  table "analytics"."analytics"."iris_processed__dbt_tmp"
  
  
    as
  
  (
    

with import_iris as (
    select *
    from "analytics"."analytics"."stg_iris"
)
select
    sepal_length,
    sepal_width,
    petal_length,
    petal_width,
    -- K Bins Discretization
    
        

    
        NTILE(5) over (order by sepal_length)
    

 as sepal_length_quantile_bin,
        

    
        
        floor(
        (
            sepal_length - (min(sepal_length) over ())
        )
        /
        (
            ((max(sepal_length) over ()) - (min(sepal_length) over ())) / 4::float
        )
        ) + 1
    

 as sepal_length_uniform_bin,
    
        

    
        NTILE(5) over (order by sepal_width)
    

 as sepal_width_quantile_bin,
        

    
        
        floor(
        (
            sepal_width - (min(sepal_width) over ())
        )
        /
        (
            ((max(sepal_width) over ()) - (min(sepal_width) over ())) / 4::float
        )
        ) + 1
    

 as sepal_width_uniform_bin,
    
        

    
        NTILE(5) over (order by petal_length)
    

 as petal_length_quantile_bin,
        

    
        
        floor(
        (
            petal_length - (min(petal_length) over ())
        )
        /
        (
            ((max(petal_length) over ()) - (min(petal_length) over ())) / 4::float
        )
        ) + 1
    

 as petal_length_uniform_bin,
    
        

    
        NTILE(5) over (order by petal_width)
    

 as petal_width_quantile_bin,
        

    
        
        floor(
        (
            petal_width - (min(petal_width) over ())
        )
        /
        (
            ((max(petal_width) over ()) - (min(petal_width) over ())) / 4::float
        )
        ) + 1
    

 as petal_width_uniform_bin,
    
-- Scaling
    
        

    

    
    
    

    
    
    

    (
        sepal_length - 5.8
    )
    /
    (
        6.4 - 5.1
    )

 as sepal_length_robust_scaled,
        

    (sepal_length) / (max(abs(sepal_length)) over ())::FLOAT

 as sepal_length_max_absolute_scaled,
        

    
    (
        ((sepal_length) - (min(sepal_length) over ()))
        /
        ((max(sepal_length) over ()) - (min(sepal_length) over ()))::FLOAT
    )
    *
    (1.0 - 0.0)
    +
    0.0

 as sepal_length_max_min_max_scaled,
    
        

    

    
    
    

    
    
    

    (
        sepal_width - 3.0
    )
    /
    (
        3.3 - 2.8
    )

 as sepal_width_robust_scaled,
        

    (sepal_width) / (max(abs(sepal_width)) over ())::FLOAT

 as sepal_width_max_absolute_scaled,
        

    
    (
        ((sepal_width) - (min(sepal_width) over ()))
        /
        ((max(sepal_width) over ()) - (min(sepal_width) over ()))::FLOAT
    )
    *
    (1.0 - 0.0)
    +
    0.0

 as sepal_width_max_min_max_scaled,
    
        

    

    
    
    

    
    
    

    (
        petal_length - 4.35
    )
    /
    (
        5.1 - 1.6
    )

 as petal_length_robust_scaled,
        

    (petal_length) / (max(abs(petal_length)) over ())::FLOAT

 as petal_length_max_absolute_scaled,
        

    
    (
        ((petal_length) - (min(petal_length) over ()))
        /
        ((max(petal_length) over ()) - (min(petal_length) over ()))::FLOAT
    )
    *
    (1.0 - 0.0)
    +
    0.0

 as petal_length_max_min_max_scaled,
    
        

    

    
    
    

    
    
    

    (
        petal_width - 1.3
    )
    /
    (
        1.8 - 0.3
    )

 as petal_width_robust_scaled,
        

    (petal_width) / (max(abs(petal_width)) over ())::FLOAT

 as petal_width_max_absolute_scaled,
        

    
    (
        ((petal_width) - (min(petal_width) over ()))
        /
        ((max(petal_width) over ()) - (min(petal_width) over ()))::FLOAT
    )
    *
    (1.0 - 0.0)
    +
    0.0

 as petal_width_max_min_max_scaled,
    

    -- Log Transformation
    
        
    case
        when sepal_length is null or sepal_length + 0 <= 0 then null
        else log((sepal_length + 0 )::numeric) / log(10::numeric)
    end
    
 as sepal_length_logged,
    
        
    case
        when sepal_width is null or sepal_width + 0 <= 0 then null
        else log((sepal_width + 0 )::numeric) / log(10::numeric)
    end
    
 as sepal_width_logged,
    
        
    case
        when petal_length is null or petal_length + 0 <= 0 then null
        else log((petal_length + 0 )::numeric) / log(10::numeric)
    end
    
 as petal_length_logged,
    
        
    case
        when petal_width is null or petal_width + 0 <= 0 then null
        else log((petal_width + 0 )::numeric) / log(10::numeric)
    end
    
 as petal_width_logged,
    

    -- Binarization
    
        

    

    
        

        
    

    case
        when sepal_length >=
            
                5.8
            
            then 1
        else 0
    end

 as sepal_length_binarized,
    
        

    

    
        

        
    

    case
        when sepal_width >=
            
                3.0
            
            then 1
        else 0
    end

 as sepal_width_binarized,
    
        

    

    
        

        
    

    case
        when petal_length >=
            
                4.35
            
            then 1
        else 0
    end

 as petal_length_binarized,
    
        

    

    
        

        
    

    case
        when petal_width >=
            
                1.3
            
            then 1
        else 0
    end

 as petal_width_binarized,
    

    -- Standardization
    
        

    
    (
        (sepal_length - avg(sepal_length) over ())
        /
        (stddev(sepal_length) over ())::FLOAT
    )
    *
    1
    +
    0

 as sepal_length_standardized,
    
        

    
    (
        (sepal_width - avg(sepal_width) over ())
        /
        (stddev(sepal_width) over ())::FLOAT
    )
    *
    1
    +
    0

 as sepal_width_standardized,
    
        

    
    (
        (petal_length - avg(petal_length) over ())
        /
        (stddev(petal_length) over ())::FLOAT
    )
    *
    1
    +
    0

 as petal_length_standardized,
    
        

    
    (
        (petal_width - avg(petal_width) over ())
        /
        (stddev(petal_width) over ())::FLOAT
    )
    *
    1
    +
    0

 as petal_width_standardized,
    
-- Interactions
    
        
            
            
            

    
        (sepal_length * sepal_width)
    

 as sepal_length_x_sepal_width_interaction,
            

    
        (sepal_length + sepal_width)
    

 as sepal_length_plus_sepal_width_interaction,
        
            
            
            

    
        (sepal_length * petal_length)
    

 as sepal_length_x_petal_length_interaction,
            

    
        (sepal_length + petal_length)
    

 as sepal_length_plus_petal_length_interaction,
        
            
            
            

    
        (sepal_length * petal_width)
    

 as sepal_length_x_petal_width_interaction,
            

    
        (sepal_length + petal_width)
    

 as sepal_length_plus_petal_width_interaction,
        
    
        
            
            
            

    
        (sepal_width * petal_length)
    

 as sepal_width_x_petal_length_interaction,
            

    
        (sepal_width + petal_length)
    

 as sepal_width_plus_petal_length_interaction,
        
            
            
            

    
        (sepal_width * petal_width)
    

 as sepal_width_x_petal_width_interaction,
            

    
        (sepal_width + petal_width)
    

 as sepal_width_plus_petal_width_interaction,
        
    
        
            
            
            

    
        (petal_length * petal_width)
    

 as petal_length_x_petal_width_interaction,
            

    
        (petal_length + petal_width)
    

 as petal_length_plus_petal_width_interaction,
        
    
        
    
species,    
    -- Label Encoding
    

    dense_rank() over (order by species) - 1

 as species_label_encoded,
    -- One Hot Encoding
    

    

    
        
    

    

    

        case
            when species = 'setosa' then 1
            else 0
        end as is_species__setosa,

    

        case
            when species = 'versicolor' then 1
            else 0
        end as is_species__versicolor,

    

        case
            when species = 'virginica' then 1
            else 0
        end as is_species__virginica,

    

    case
        when species is null then 1
        else 0
    end as is_species__


from "analytics"."analytics"."stg_iris"
  );
  
[0m18:43:08.541300 [debug] [Thread-3  ]: SQL status: SELECT 150 in 0.036 seconds
[0m18:43:08.561710 [debug] [Thread-3  ]: Using postgres connection "model.homework.iris_processed"
[0m18:43:08.563815 [debug] [Thread-3  ]: On model.homework.iris_processed: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "homework", "target_name": "dev", "node_id": "model.homework.iris_processed"} */
alter table "analytics"."analytics"."iris_processed__dbt_tmp" rename to "iris_processed"
[0m18:43:08.566551 [debug] [Thread-3  ]: SQL status: ALTER TABLE in 0.001 seconds
[0m18:43:08.571786 [debug] [Thread-3  ]: On model.homework.iris_processed: COMMIT
[0m18:43:08.573819 [debug] [Thread-3  ]: Using postgres connection "model.homework.iris_processed"
[0m18:43:08.575694 [debug] [Thread-3  ]: On model.homework.iris_processed: COMMIT
[0m18:43:08.581503 [debug] [Thread-3  ]: SQL status: COMMIT in 0.004 seconds
[0m18:43:08.590815 [debug] [Thread-3  ]: Applying DROP to: "analytics"."analytics"."iris_processed__dbt_backup"
[0m18:43:08.598341 [debug] [Thread-3  ]: Using postgres connection "model.homework.iris_processed"
[0m18:43:08.600369 [debug] [Thread-3  ]: On model.homework.iris_processed: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "homework", "target_name": "dev", "node_id": "model.homework.iris_processed"} */
drop table if exists "analytics"."analytics"."iris_processed__dbt_backup" cascade
[0m18:43:08.602842 [debug] [Thread-3  ]: SQL status: DROP TABLE in 0.001 seconds
[0m18:43:08.606837 [debug] [Thread-3  ]: On model.homework.iris_processed: Close
[0m18:43:08.609199 [debug] [Thread-3  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'a5eb8854-caa0-4ce6-9feb-3411388bc4a4', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff3281aefd0>]}
[0m18:43:08.611723 [info ] [Thread-3  ]: 2 of 2 OK created sql table model analytics.iris_processed ..................... [[32mSELECT 150[0m in 0.47s]
[0m18:43:08.613995 [debug] [Thread-3  ]: Finished running node model.homework.iris_processed
[0m18:43:08.617773 [debug] [MainThread]: Using postgres connection "master"
[0m18:43:08.620056 [debug] [MainThread]: On master: BEGIN
[0m18:43:08.621942 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m18:43:08.633448 [debug] [MainThread]: SQL status: BEGIN in 0.011 seconds
[0m18:43:08.635442 [debug] [MainThread]: On master: COMMIT
[0m18:43:08.637524 [debug] [MainThread]: Using postgres connection "master"
[0m18:43:08.639128 [debug] [MainThread]: On master: COMMIT
[0m18:43:08.640994 [debug] [MainThread]: SQL status: COMMIT in 0.000 seconds
[0m18:43:08.642669 [debug] [MainThread]: On master: Close
[0m18:43:08.644456 [debug] [MainThread]: Connection 'master' was properly closed.
[0m18:43:08.645904 [debug] [MainThread]: Connection 'model.homework.stg_iris' was properly closed.
[0m18:43:08.647427 [debug] [MainThread]: Connection 'model.homework.iris_processed' was properly closed.
[0m18:43:08.648997 [info ] [MainThread]: 
[0m18:43:08.650500 [info ] [MainThread]: Finished running 1 table model, 1 view model in 0 hours 0 minutes and 1.05 seconds (1.05s).
[0m18:43:08.653501 [debug] [MainThread]: Command end result
[0m18:43:08.752665 [debug] [MainThread]: Wrote artifact WritableManifest to /opt/airflow/dags/dbt/homework/target/manifest.json
[0m18:43:08.762474 [debug] [MainThread]: Wrote artifact SemanticManifest to /opt/airflow/dags/dbt/homework/target/semantic_manifest.json
[0m18:43:08.784571 [debug] [MainThread]: Wrote artifact RunExecutionResult to /opt/airflow/dags/dbt/homework/target/run_results.json
[0m18:43:08.787019 [info ] [MainThread]: 
[0m18:43:08.789041 [info ] [MainThread]: [32mCompleted successfully[0m
[0m18:43:08.790467 [info ] [MainThread]: 
[0m18:43:08.792045 [info ] [MainThread]: Done. PASS=2 WARN=0 ERROR=0 SKIP=0 TOTAL=2
[0m18:43:08.794724 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": true, "command_wall_clock_time": 8.86935, "process_in_blocks": "0", "process_kernel_time": 0.452668, "process_mem_max_rss": "120452", "process_out_blocks": "0", "process_user_time": 10.079412}
[0m18:43:08.796840 [debug] [MainThread]: Command `dbt run` succeeded at 18:43:08.796631 after 8.87 seconds
[0m18:43:08.799078 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff32dc99b20>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff329db0f40>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff32b542e80>]}
[0m18:43:08.800895 [debug] [MainThread]: Flushing usage events
[0m18:43:09.384834 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m18:43:15.390482 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f55a1813af0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f55a0934520>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f55a09344c0>]}


============================== 18:43:15.405930 | 0a58fbc7-3a34-483b-8b04-864e625b2736 ==============================
[0m18:43:15.405930 [info ] [MainThread]: Running with dbt=1.9.4
[0m18:43:15.409655 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'fail_fast': 'True', 'profiles_dir': '/opt/airflow/dags/dbt', 'log_path': '/opt/airflow/dags/dbt/homework/logs', 'version_check': 'True', 'debug': 'False', 'use_colors': 'True', 'use_experimental_parser': 'False', 'empty': 'None', 'quiet': 'False', 'no_print': 'None', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'static_parser': 'True', 'introspect': 'True', 'invocation_command': 'dbt --profile homework test --project-dir=/opt/airflow/dags/dbt/homework --vars {"is_test": false, "data_date": "2025-04-22"} --fail-fast', 'target_path': 'None', 'log_format': 'default', 'send_anonymous_usage_stats': 'True'}
[0m18:43:15.974412 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '0a58fbc7-3a34-483b-8b04-864e625b2736', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f55a31fac70>]}
[0m18:43:16.136691 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '0a58fbc7-3a34-483b-8b04-864e625b2736', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f559f075520>]}
[0m18:43:16.139900 [info ] [MainThread]: Registered adapter: postgres=1.9.0
[0m18:43:16.415629 [debug] [MainThread]: checksum: b4b46bb6a239f66694dfdd44ef1792882cb61f2fd7b1ea66b3c7a170d2bb602d, vars: {'data_date': '2025-04-22', 'is_test': False}, profile: homework, target: , version: 1.9.4
[0m18:43:18.004240 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m18:43:18.006274 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m18:43:18.024287 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 1 unused configuration paths:
- seeds.homework.iris_dataset
[0m18:43:18.113813 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '0a58fbc7-3a34-483b-8b04-864e625b2736', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f559ec63130>]}
[0m18:43:18.510291 [debug] [MainThread]: Wrote artifact WritableManifest to /opt/airflow/dags/dbt/homework/target/manifest.json
[0m18:43:18.530172 [debug] [MainThread]: Wrote artifact SemanticManifest to /opt/airflow/dags/dbt/homework/target/semantic_manifest.json
[0m18:43:18.578497 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '0a58fbc7-3a34-483b-8b04-864e625b2736', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f559eb41580>]}
[0m18:43:18.580971 [info ] [MainThread]: Found 2 models, 1 source, 587 macros
[0m18:43:18.582938 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '0a58fbc7-3a34-483b-8b04-864e625b2736', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f559eba8a30>]}
[0m18:43:18.586484 [warn ] [MainThread]: Nothing to do. Try checking your model configs and model specification args
[0m18:43:18.591176 [debug] [MainThread]: Command end result
[0m18:43:18.689356 [debug] [MainThread]: Wrote artifact WritableManifest to /opt/airflow/dags/dbt/homework/target/manifest.json
[0m18:43:18.698369 [debug] [MainThread]: Wrote artifact SemanticManifest to /opt/airflow/dags/dbt/homework/target/semantic_manifest.json
[0m18:43:18.710222 [debug] [MainThread]: Wrote artifact RunExecutionResult to /opt/airflow/dags/dbt/homework/target/run_results.json
[0m18:43:18.713629 [debug] [MainThread]: Resource report: {"command_name": "test", "command_success": true, "command_wall_clock_time": 3.5475154, "process_in_blocks": "0", "process_kernel_time": 0.359903, "process_mem_max_rss": "104872", "process_out_blocks": "0", "process_user_time": 5.478527}
[0m18:43:18.715793 [debug] [MainThread]: Command `dbt test` succeeded at 18:43:18.715615 after 3.55 seconds
[0m18:43:18.717798 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f55a1813af0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f55a16dd6d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f559f106130>]}
[0m18:43:18.719688 [debug] [MainThread]: Flushing usage events
[0m18:43:19.271912 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m09:41:42.128904 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f7231464910>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f7230583dc0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f7230583e20>]}


============================== 09:41:42.145102 | 5ccd7ec2-c688-4715-b325-b1aefd185dbe ==============================
[0m09:41:42.145102 [info ] [MainThread]: Running with dbt=1.9.4
[0m09:41:42.134236 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f24345c2970>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f24336e1d30>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f24336e1d90>]}
[0m09:41:42.148344 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': '/opt/airflow/dags/dbt', 'version_check': 'True', 'warn_error': 'None', 'log_path': '/opt/airflow/dags/dbt/homework/logs', 'fail_fast': 'False', 'debug': 'False', 'use_colors': 'True', 'use_experimental_parser': 'False', 'empty': 'None', 'quiet': 'False', 'no_print': 'None', 'log_format': 'default', 'invocation_command': 'dbt deps --profiles-dir /opt/airflow/dags/dbt --project-dir /opt/airflow/dags/dbt/homework', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'static_parser': 'True', 'target_path': 'None', 'introspect': 'True', 'send_anonymous_usage_stats': 'True'}


============================== 09:41:42.150134 | ebea02bd-62bc-4a3b-a852-f719b331583c ==============================
[0m09:41:42.150134 [info ] [MainThread]: Running with dbt=1.9.4
[0m09:41:42.154576 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': '/opt/airflow/dags/dbt', 'debug': 'False', 'fail_fast': 'False', 'log_path': '/opt/airflow/dags/dbt/homework/logs', 'version_check': 'True', 'warn_error': 'None', 'use_colors': 'True', 'use_experimental_parser': 'False', 'empty': 'None', 'quiet': 'False', 'no_print': 'None', 'log_format': 'default', 'introspect': 'True', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'static_parser': 'True', 'target_path': 'None', 'invocation_command': 'dbt deps --profiles-dir /opt/airflow/dags/dbt --project-dir /opt/airflow/dags/dbt/homework', 'send_anonymous_usage_stats': 'True'}
[0m09:41:42.564142 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'ebea02bd-62bc-4a3b-a852-f719b331583c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f24336a7df0>]}
[0m09:41:42.580624 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '5ccd7ec2-c688-4715-b325-b1aefd185dbe', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f7230507a00>]}
[0m09:41:42.669915 [error] [MainThread]: Encountered an error:
[Errno 2] No such file or directory: '.gitattributes'
[0m09:41:42.678509 [error] [MainThread]: Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/dbt/cli/requires.py", line 153, in wrapper
    result, success = func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.9/site-packages/dbt/cli/requires.py", line 103, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.9/site-packages/dbt/cli/requires.py", line 218, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.9/site-packages/dbt/cli/requires.py", line 264, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.9/site-packages/dbt/cli/main.py", line 455, in deps
    results = task.run()
  File "/home/airflow/.local/lib/python3.9/site-packages/dbt/task/deps.py", line 227, in run
    system.rmtree(self.project.packages_install_path)
  File "/home/airflow/.local/lib/python3.9/site-packages/dbt_common/clients/system.py", line 715, in rmtree
    return shutil.rmtree(path, onerror=chmod_and_retry)
  File "/usr/local/lib/python3.9/shutil.py", line 734, in rmtree
    _rmtree_safe_fd(fd, path, onerror)
  File "/usr/local/lib/python3.9/shutil.py", line 667, in _rmtree_safe_fd
    _rmtree_safe_fd(dirfd, fullname, onerror)
  File "/usr/local/lib/python3.9/shutil.py", line 690, in _rmtree_safe_fd
    onerror(os.unlink, fullname, sys.exc_info())
  File "/usr/local/lib/python3.9/shutil.py", line 688, in _rmtree_safe_fd
    os.unlink(entry.name, dir_fd=topfd)
FileNotFoundError: [Errno 2] No such file or directory: '.gitattributes'

[0m09:41:42.683566 [debug] [MainThread]: Resource report: {"command_name": "deps", "command_success": false, "command_wall_clock_time": 0.7414393, "process_in_blocks": "43688", "process_kernel_time": 0.651785, "process_mem_max_rss": "92060", "process_out_blocks": "0", "process_user_time": 5.996428}
[0m09:41:42.686581 [debug] [MainThread]: Command `dbt deps` failed at 09:41:42.686096 after 0.74 seconds
[0m09:41:42.688761 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f24345c2970>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f243355e340>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f243355e220>]}
[0m09:41:42.693097 [debug] [MainThread]: Flushing usage events
[0m09:41:43.257064 [debug] [MainThread]: Set downloads directory='/tmp/dbt-downloads-_7sxf625'
[0m09:41:43.258946 [debug] [MainThread]: Making package index registry request: GET https://hub.getdbt.com/api/v1/index.json
[0m09:41:43.454973 [debug] [MainThread]: Response from registry index: GET https://hub.getdbt.com/api/v1/index.json 200
[0m09:41:43.457549 [debug] [MainThread]: Making package registry request: GET https://hub.getdbt.com/api/v1/Matts52/dbt_ml_inline_preprocessing.json
[0m09:41:43.791742 [debug] [MainThread]: Response from registry: GET https://hub.getdbt.com/api/v1/Matts52/dbt_ml_inline_preprocessing.json 200
[0m09:41:43.795044 [debug] [MainThread]: Making package registry request: GET https://hub.getdbt.com/api/v1/dbt-labs/dbt_utils.json
[0m09:41:43.903880 [debug] [MainThread]: Response from registry: GET https://hub.getdbt.com/api/v1/dbt-labs/dbt_utils.json 200
[0m09:41:43.910324 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m09:41:43.922593 [info ] [MainThread]: Installing Matts52/dbt_ml_inline_preprocessing
[0m09:41:58.543938 [info ] [MainThread]: Installed from version 0.2.4
[0m09:41:58.547853 [info ] [MainThread]: Up to date!
[0m09:41:58.552456 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'package', 'label': '5ccd7ec2-c688-4715-b325-b1aefd185dbe', 'property_': 'install', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f7230472fa0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f72313605e0>]}
[0m09:41:58.556223 [info ] [MainThread]: Installing dbt-labs/dbt_utils
[0m09:42:09.120479 [info ] [MainThread]: Installed from version 1.3.0
[0m09:42:09.123811 [info ] [MainThread]: Up to date!
[0m09:42:09.128052 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'package', 'label': '5ccd7ec2-c688-4715-b325-b1aefd185dbe', 'property_': 'install', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f7230472fa0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f7230419d60>]}
[0m09:42:09.138414 [debug] [MainThread]: Resource report: {"command_name": "deps", "command_success": true, "command_wall_clock_time": 27.199041, "process_in_blocks": "36344", "process_kernel_time": 1.038221, "process_mem_max_rss": "95076", "process_out_blocks": "1304", "process_user_time": 6.524508}
[0m09:42:09.146285 [debug] [MainThread]: Command `dbt deps` succeeded at 09:42:09.145437 after 27.21 seconds
[0m09:42:09.151454 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f7231464910>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f72313605e0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f72312c7df0>]}
[0m09:42:09.154348 [debug] [MainThread]: Flushing usage events
[0m09:42:10.436725 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m09:43:30.809777 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f9ee4759b20>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f9ee387a430>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f9ee387a3d0>]}


============================== 09:43:30.829546 | 264beaf0-e929-4541-97c4-1aaaa726bb9c ==============================
[0m09:43:30.829546 [info ] [MainThread]: Running with dbt=1.9.4
[0m09:43:30.832439 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'fail_fast': 'False', 'debug': 'False', 'log_path': '/opt/airflow/dags/dbt/homework/logs', 'version_check': 'True', 'profiles_dir': '/opt/airflow/dags/dbt', 'use_colors': 'True', 'use_experimental_parser': 'False', 'empty': 'False', 'quiet': 'False', 'no_print': 'None', 'log_format': 'default', 'invocation_command': 'dbt --profile homework run --project-dir=/opt/airflow/dags/dbt/homework --vars {"is_test": false, "data_date": "2025-04-23"}', 'static_parser': 'True', 'introspect': 'True', 'target_path': 'None', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'send_anonymous_usage_stats': 'True'}
[0m09:43:31.478189 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '264beaf0-e929-4541-97c4-1aaaa726bb9c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f9ee38ba760>]}
[0m09:43:31.676272 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '264beaf0-e929-4541-97c4-1aaaa726bb9c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f9ee2002e80>]}
[0m09:43:31.680588 [info ] [MainThread]: Registered adapter: postgres=1.9.0
[0m09:43:32.187028 [debug] [MainThread]: checksum: f5df654a850f4b74beb13fbe0c7d8863b5b1a20bd535c3ac287d70e390b64d41, vars: {'data_date': '2025-04-23', 'is_test': False}, profile: homework, target: , version: 1.9.4
[0m09:43:32.785396 [info ] [MainThread]: Unable to do partial parsing because config vars, config profile, or config target have changed
[0m09:43:32.789334 [debug] [MainThread]: previous checksum: f5df654a850f4b74beb13fbe0c7d8863b5b1a20bd535c3ac287d70e390b64d41, current checksum: b4b46bb6a239f66694dfdd44ef1792882cb61f2fd7b1ea66b3c7a170d2bb602d
[0m09:43:32.794490 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'partial_parser', 'label': '264beaf0-e929-4541-97c4-1aaaa726bb9c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f9ee3f97610>]}
[0m09:43:45.643352 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 1 unused configuration paths:
- seeds.homework.iris_dataset
[0m09:43:45.771315 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '264beaf0-e929-4541-97c4-1aaaa726bb9c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f9ee1d26130>]}
[0m09:43:46.478366 [debug] [MainThread]: Wrote artifact WritableManifest to /opt/airflow/dags/dbt/homework/target/manifest.json
[0m09:43:46.533023 [debug] [MainThread]: Wrote artifact SemanticManifest to /opt/airflow/dags/dbt/homework/target/semantic_manifest.json
[0m09:43:46.633487 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '264beaf0-e929-4541-97c4-1aaaa726bb9c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f9ee1cfd7c0>]}
[0m09:43:46.638540 [info ] [MainThread]: Found 2 models, 1 source, 587 macros
[0m09:43:46.646461 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '264beaf0-e929-4541-97c4-1aaaa726bb9c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f9ee1cfdca0>]}
[0m09:43:46.657383 [info ] [MainThread]: 
[0m09:43:46.663283 [info ] [MainThread]: Concurrency: 4 threads (target='dev')
[0m09:43:46.667635 [info ] [MainThread]: 
[0m09:43:46.673076 [debug] [MainThread]: Acquiring new postgres connection 'master'
[0m09:43:46.700015 [debug] [ThreadPool]: Acquiring new postgres connection 'list_analytics'
[0m09:43:46.946321 [debug] [ThreadPool]: Using postgres connection "list_analytics"
[0m09:43:46.964106 [debug] [ThreadPool]: On list_analytics: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "homework", "target_name": "dev", "connection_name": "list_analytics"} */

    select distinct nspname from pg_namespace
  
[0m09:43:46.974516 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m09:43:49.685781 [debug] [ThreadPool]: SQL status: SELECT 6 in 2.711 seconds
[0m09:43:49.703683 [debug] [ThreadPool]: On list_analytics: Close
[0m09:43:49.717903 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_analytics, now list_analytics_analytics)
[0m09:43:49.779523 [debug] [ThreadPool]: Using postgres connection "list_analytics_analytics"
[0m09:43:49.782928 [debug] [ThreadPool]: On list_analytics_analytics: BEGIN
[0m09:43:49.786034 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m09:43:49.827547 [debug] [ThreadPool]: SQL status: BEGIN in 0.042 seconds
[0m09:43:49.834538 [debug] [ThreadPool]: Using postgres connection "list_analytics_analytics"
[0m09:43:49.837527 [debug] [ThreadPool]: On list_analytics_analytics: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "homework", "target_name": "dev", "connection_name": "list_analytics_analytics"} */
select
      'analytics' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'analytics'
    union all
    select
      'analytics' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'analytics'
    union all
    select
      'analytics' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'analytics'
  
[0m09:43:49.910773 [debug] [ThreadPool]: SQL status: SELECT 3 in 0.070 seconds
[0m09:43:49.916000 [debug] [ThreadPool]: On list_analytics_analytics: ROLLBACK
[0m09:43:49.919410 [debug] [ThreadPool]: On list_analytics_analytics: Close
[0m09:43:49.947244 [debug] [MainThread]: Using postgres connection "master"
[0m09:43:49.950355 [debug] [MainThread]: On master: BEGIN
[0m09:43:49.953652 [debug] [MainThread]: Opening a new connection, currently in state init
[0m09:43:49.977388 [debug] [MainThread]: SQL status: BEGIN in 0.024 seconds
[0m09:43:49.990186 [debug] [MainThread]: Using postgres connection "master"
[0m09:43:49.994114 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "homework", "target_name": "dev", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select distinct
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v', 'm')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
[0m09:43:50.061695 [debug] [MainThread]: SQL status: SELECT 1 in 0.060 seconds
[0m09:43:50.069535 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '264beaf0-e929-4541-97c4-1aaaa726bb9c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f9ee1b4e3a0>]}
[0m09:43:50.074185 [debug] [MainThread]: On master: ROLLBACK
[0m09:43:50.079498 [debug] [MainThread]: Using postgres connection "master"
[0m09:43:50.084455 [debug] [MainThread]: On master: BEGIN
[0m09:43:50.089380 [debug] [MainThread]: SQL status: BEGIN in 0.001 seconds
[0m09:43:50.093663 [debug] [MainThread]: On master: COMMIT
[0m09:43:50.098246 [debug] [MainThread]: Using postgres connection "master"
[0m09:43:50.101858 [debug] [MainThread]: On master: COMMIT
[0m09:43:50.110312 [debug] [MainThread]: SQL status: COMMIT in 0.000 seconds
[0m09:43:50.113386 [debug] [MainThread]: On master: Close
[0m09:43:50.140352 [debug] [Thread-1  ]: Began running node model.homework.stg_iris
[0m09:43:50.149429 [info ] [Thread-1  ]: 1 of 2 START sql view model analytics.stg_iris ................................. [RUN]
[0m09:43:50.153975 [debug] [Thread-1  ]: Re-using an available connection from the pool (formerly list_analytics_analytics, now model.homework.stg_iris)
[0m09:43:50.158556 [debug] [Thread-1  ]: Began compiling node model.homework.stg_iris
[0m09:43:50.235227 [debug] [Thread-1  ]: Writing injected SQL for node "model.homework.stg_iris"
[0m09:43:50.259603 [debug] [Thread-1  ]: Began executing node model.homework.stg_iris
[0m09:43:50.540393 [debug] [Thread-1  ]: Writing runtime sql for node "model.homework.stg_iris"
[0m09:43:50.560188 [debug] [Thread-1  ]: Using postgres connection "model.homework.stg_iris"
[0m09:43:50.563204 [debug] [Thread-1  ]: On model.homework.stg_iris: BEGIN
[0m09:43:50.566746 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
[0m09:43:50.591432 [debug] [Thread-1  ]: SQL status: BEGIN in 0.025 seconds
[0m09:43:50.594772 [debug] [Thread-1  ]: Using postgres connection "model.homework.stg_iris"
[0m09:43:50.602323 [debug] [Thread-1  ]: On model.homework.stg_iris: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "homework", "target_name": "dev", "node_id": "model.homework.stg_iris"} */

  create view "analytics"."analytics"."stg_iris__dbt_tmp"
    
    
  as (
    with source as (
    select * from "analytics"."analytics"."iris_dataset"
)

select
    sepal_length,
    sepal_width,
    petal_length,
    petal_width,
    species
from source
  );
[0m09:43:50.664857 [debug] [Thread-1  ]: SQL status: CREATE VIEW in 0.059 seconds
[0m09:43:50.696502 [debug] [Thread-1  ]: Using postgres connection "model.homework.stg_iris"
[0m09:43:50.706622 [debug] [Thread-1  ]: On model.homework.stg_iris: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "homework", "target_name": "dev", "node_id": "model.homework.stg_iris"} */
alter table "analytics"."analytics"."stg_iris" rename to "stg_iris__dbt_backup"
[0m09:43:50.713302 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.003 seconds
[0m09:43:50.734214 [debug] [Thread-1  ]: Using postgres connection "model.homework.stg_iris"
[0m09:43:50.737271 [debug] [Thread-1  ]: On model.homework.stg_iris: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "homework", "target_name": "dev", "node_id": "model.homework.stg_iris"} */
alter table "analytics"."analytics"."stg_iris__dbt_tmp" rename to "stg_iris"
[0m09:43:50.745307 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.002 seconds
[0m09:43:50.834070 [debug] [Thread-1  ]: On model.homework.stg_iris: COMMIT
[0m09:43:50.837295 [debug] [Thread-1  ]: Using postgres connection "model.homework.stg_iris"
[0m09:43:50.840464 [debug] [Thread-1  ]: On model.homework.stg_iris: COMMIT
[0m09:43:50.865852 [debug] [Thread-1  ]: SQL status: COMMIT in 0.020 seconds
[0m09:43:50.896357 [debug] [Thread-1  ]: Applying DROP to: "analytics"."analytics"."stg_iris__dbt_backup"
[0m09:43:50.928973 [debug] [Thread-1  ]: Using postgres connection "model.homework.stg_iris"
[0m09:43:50.933224 [debug] [Thread-1  ]: On model.homework.stg_iris: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "homework", "target_name": "dev", "node_id": "model.homework.stg_iris"} */
drop view if exists "analytics"."analytics"."stg_iris__dbt_backup" cascade
[0m09:43:50.957990 [debug] [Thread-1  ]: SQL status: DROP VIEW in 0.021 seconds
[0m09:43:50.967340 [debug] [Thread-1  ]: On model.homework.stg_iris: Close
[0m09:43:50.974908 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '264beaf0-e929-4541-97c4-1aaaa726bb9c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f9ee09975e0>]}
[0m09:43:50.980223 [info ] [Thread-1  ]: 1 of 2 OK created sql view model analytics.stg_iris ............................ [[32mCREATE VIEW[0m in 0.82s]
[0m09:43:50.986308 [debug] [Thread-1  ]: Finished running node model.homework.stg_iris
[0m09:43:50.991847 [debug] [Thread-3  ]: Began running node model.homework.iris_processed
[0m09:43:50.996366 [info ] [Thread-3  ]: 2 of 2 START sql table model analytics.iris_processed .......................... [RUN]
[0m09:43:51.000244 [debug] [Thread-3  ]: Acquiring new postgres connection 'model.homework.iris_processed'
[0m09:43:51.003539 [debug] [Thread-3  ]: Began compiling node model.homework.iris_processed
[0m09:43:51.161870 [debug] [Thread-3  ]: Using postgres connection "model.homework.iris_processed"
[0m09:43:51.168231 [debug] [Thread-3  ]: On model.homework.iris_processed: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "homework", "target_name": "dev", "node_id": "model.homework.iris_processed"} */

        select percentile_cont(0.5) within group (order by sepal_length ) from "analytics"."analytics"."stg_iris"
    
[0m09:43:51.170807 [debug] [Thread-3  ]: Opening a new connection, currently in state init
[0m09:43:51.200833 [debug] [Thread-3  ]: SQL status: SELECT 1 in 0.030 seconds
[0m09:43:51.205911 [debug] [Thread-3  ]: Using postgres connection "model.homework.iris_processed"
[0m09:43:51.208487 [debug] [Thread-3  ]: On model.homework.iris_processed: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "homework", "target_name": "dev", "node_id": "model.homework.iris_processed"} */

        select percentile_cont(0.5 - 0.5/2) within group (order by sepal_length ) from "analytics"."analytics"."stg_iris"
    
[0m09:43:51.219716 [debug] [Thread-3  ]: SQL status: SELECT 1 in 0.009 seconds
[0m09:43:51.227148 [debug] [Thread-3  ]: Using postgres connection "model.homework.iris_processed"
[0m09:43:51.230648 [debug] [Thread-3  ]: On model.homework.iris_processed: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "homework", "target_name": "dev", "node_id": "model.homework.iris_processed"} */

        select percentile_cont(0.5 + 0.5/2) within group (order by sepal_length ) from "analytics"."analytics"."stg_iris"
    
[0m09:43:51.236411 [debug] [Thread-3  ]: SQL status: SELECT 1 in 0.001 seconds
[0m09:43:51.247036 [debug] [Thread-3  ]: Using postgres connection "model.homework.iris_processed"
[0m09:43:51.250488 [debug] [Thread-3  ]: On model.homework.iris_processed: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "homework", "target_name": "dev", "node_id": "model.homework.iris_processed"} */

        select percentile_cont(0.5) within group (order by sepal_width ) from "analytics"."analytics"."stg_iris"
    
[0m09:43:51.257056 [debug] [Thread-3  ]: SQL status: SELECT 1 in 0.001 seconds
[0m09:43:51.261529 [debug] [Thread-3  ]: Using postgres connection "model.homework.iris_processed"
[0m09:43:51.264042 [debug] [Thread-3  ]: On model.homework.iris_processed: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "homework", "target_name": "dev", "node_id": "model.homework.iris_processed"} */

        select percentile_cont(0.5 - 0.5/2) within group (order by sepal_width ) from "analytics"."analytics"."stg_iris"
    
[0m09:43:51.267230 [debug] [Thread-3  ]: SQL status: SELECT 1 in 0.001 seconds
[0m09:43:51.273600 [debug] [Thread-3  ]: Using postgres connection "model.homework.iris_processed"
[0m09:43:51.277210 [debug] [Thread-3  ]: On model.homework.iris_processed: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "homework", "target_name": "dev", "node_id": "model.homework.iris_processed"} */

        select percentile_cont(0.5 + 0.5/2) within group (order by sepal_width ) from "analytics"."analytics"."stg_iris"
    
[0m09:43:51.281211 [debug] [Thread-3  ]: SQL status: SELECT 1 in 0.001 seconds
[0m09:43:51.295601 [debug] [Thread-3  ]: Using postgres connection "model.homework.iris_processed"
[0m09:43:51.301192 [debug] [Thread-3  ]: On model.homework.iris_processed: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "homework", "target_name": "dev", "node_id": "model.homework.iris_processed"} */

        select percentile_cont(0.5) within group (order by petal_length ) from "analytics"."analytics"."stg_iris"
    
[0m09:43:51.329004 [debug] [Thread-3  ]: SQL status: SELECT 1 in 0.021 seconds
[0m09:43:51.342607 [debug] [Thread-3  ]: Using postgres connection "model.homework.iris_processed"
[0m09:43:51.346565 [debug] [Thread-3  ]: On model.homework.iris_processed: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "homework", "target_name": "dev", "node_id": "model.homework.iris_processed"} */

        select percentile_cont(0.5 - 0.5/2) within group (order by petal_length ) from "analytics"."analytics"."stg_iris"
    
[0m09:43:51.355981 [debug] [Thread-3  ]: SQL status: SELECT 1 in 0.003 seconds
[0m09:43:51.365160 [debug] [Thread-3  ]: Using postgres connection "model.homework.iris_processed"
[0m09:43:51.375096 [debug] [Thread-3  ]: On model.homework.iris_processed: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "homework", "target_name": "dev", "node_id": "model.homework.iris_processed"} */

        select percentile_cont(0.5 + 0.5/2) within group (order by petal_length ) from "analytics"."analytics"."stg_iris"
    
[0m09:43:51.381777 [debug] [Thread-3  ]: SQL status: SELECT 1 in 0.001 seconds
[0m09:43:51.402571 [debug] [Thread-3  ]: Using postgres connection "model.homework.iris_processed"
[0m09:43:51.406373 [debug] [Thread-3  ]: On model.homework.iris_processed: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "homework", "target_name": "dev", "node_id": "model.homework.iris_processed"} */

        select percentile_cont(0.5) within group (order by petal_width ) from "analytics"."analytics"."stg_iris"
    
[0m09:43:51.411469 [debug] [Thread-3  ]: SQL status: SELECT 1 in 0.001 seconds
[0m09:43:51.424333 [debug] [Thread-3  ]: Using postgres connection "model.homework.iris_processed"
[0m09:43:51.430060 [debug] [Thread-3  ]: On model.homework.iris_processed: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "homework", "target_name": "dev", "node_id": "model.homework.iris_processed"} */

        select percentile_cont(0.5 - 0.5/2) within group (order by petal_width ) from "analytics"."analytics"."stg_iris"
    
[0m09:43:51.442140 [debug] [Thread-3  ]: SQL status: SELECT 1 in 0.001 seconds
[0m09:43:51.451528 [debug] [Thread-3  ]: Using postgres connection "model.homework.iris_processed"
[0m09:43:51.460740 [debug] [Thread-3  ]: On model.homework.iris_processed: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "homework", "target_name": "dev", "node_id": "model.homework.iris_processed"} */

        select percentile_cont(0.5 + 0.5/2) within group (order by petal_width ) from "analytics"."analytics"."stg_iris"
    
[0m09:43:51.467441 [debug] [Thread-3  ]: SQL status: SELECT 1 in 0.001 seconds
[0m09:43:51.491573 [debug] [Thread-3  ]: Using postgres connection "model.homework.iris_processed"
[0m09:43:51.496140 [debug] [Thread-3  ]: On model.homework.iris_processed: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "homework", "target_name": "dev", "node_id": "model.homework.iris_processed"} */

            select percentile_cont(0.5) within group (order by sepal_length ) from "analytics"."analytics"."stg_iris"
        
[0m09:43:51.500874 [debug] [Thread-3  ]: SQL status: SELECT 1 in 0.001 seconds
[0m09:43:51.518145 [debug] [Thread-3  ]: Using postgres connection "model.homework.iris_processed"
[0m09:43:51.522365 [debug] [Thread-3  ]: On model.homework.iris_processed: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "homework", "target_name": "dev", "node_id": "model.homework.iris_processed"} */

            select percentile_cont(0.5) within group (order by sepal_width ) from "analytics"."analytics"."stg_iris"
        
[0m09:43:51.531852 [debug] [Thread-3  ]: SQL status: SELECT 1 in 0.001 seconds
[0m09:43:51.544834 [debug] [Thread-3  ]: Using postgres connection "model.homework.iris_processed"
[0m09:43:51.551289 [debug] [Thread-3  ]: On model.homework.iris_processed: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "homework", "target_name": "dev", "node_id": "model.homework.iris_processed"} */

            select percentile_cont(0.5) within group (order by petal_length ) from "analytics"."analytics"."stg_iris"
        
[0m09:43:51.556576 [debug] [Thread-3  ]: SQL status: SELECT 1 in 0.001 seconds
[0m09:43:51.568560 [debug] [Thread-3  ]: Using postgres connection "model.homework.iris_processed"
[0m09:43:51.575564 [debug] [Thread-3  ]: On model.homework.iris_processed: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "homework", "target_name": "dev", "node_id": "model.homework.iris_processed"} */

            select percentile_cont(0.5) within group (order by petal_width ) from "analytics"."analytics"."stg_iris"
        
[0m09:43:51.582334 [debug] [Thread-3  ]: SQL status: SELECT 1 in 0.001 seconds
[0m09:43:51.650621 [debug] [Thread-3  ]: Using postgres connection "model.homework.iris_processed"
[0m09:43:51.653825 [debug] [Thread-3  ]: On model.homework.iris_processed: BEGIN
[0m09:43:51.658075 [debug] [Thread-3  ]: SQL status: BEGIN in 0.001 seconds
[0m09:43:51.666352 [debug] [Thread-3  ]: Using postgres connection "model.homework.iris_processed"
[0m09:43:51.670127 [debug] [Thread-3  ]: On model.homework.iris_processed: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "homework", "target_name": "dev", "node_id": "model.homework.iris_processed"} */
select
                species as value

            from "analytics"."analytics"."stg_iris"

            
            where species is not null  and true
            

            group by species
            order by species

            

        
[0m09:43:51.676227 [debug] [Thread-3  ]: SQL status: SELECT 3 in 0.002 seconds
[0m09:43:51.712786 [debug] [Thread-3  ]: Writing injected SQL for node "model.homework.iris_processed"
[0m09:43:51.776958 [debug] [Thread-3  ]: Began executing node model.homework.iris_processed
[0m09:43:51.926163 [debug] [Thread-3  ]: Writing runtime sql for node "model.homework.iris_processed"
[0m09:43:51.944667 [debug] [Thread-3  ]: Using postgres connection "model.homework.iris_processed"
[0m09:43:51.951303 [debug] [Thread-3  ]: On model.homework.iris_processed: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "homework", "target_name": "dev", "node_id": "model.homework.iris_processed"} */

  
    

  create  table "analytics"."analytics"."iris_processed__dbt_tmp"
  
  
    as
  
  (
    

with import_iris as (
    select *
    from "analytics"."analytics"."stg_iris"
)
select
    sepal_length,
    sepal_width,
    petal_length,
    petal_width,
    -- K Bins Discretization
    
        

    
        NTILE(5) over (order by sepal_length)
    

 as sepal_length_quantile_bin,
        

    
        
        floor(
        (
            sepal_length - (min(sepal_length) over ())
        )
        /
        (
            ((max(sepal_length) over ()) - (min(sepal_length) over ())) / 4::float
        )
        ) + 1
    

 as sepal_length_uniform_bin,
    
        

    
        NTILE(5) over (order by sepal_width)
    

 as sepal_width_quantile_bin,
        

    
        
        floor(
        (
            sepal_width - (min(sepal_width) over ())
        )
        /
        (
            ((max(sepal_width) over ()) - (min(sepal_width) over ())) / 4::float
        )
        ) + 1
    

 as sepal_width_uniform_bin,
    
        

    
        NTILE(5) over (order by petal_length)
    

 as petal_length_quantile_bin,
        

    
        
        floor(
        (
            petal_length - (min(petal_length) over ())
        )
        /
        (
            ((max(petal_length) over ()) - (min(petal_length) over ())) / 4::float
        )
        ) + 1
    

 as petal_length_uniform_bin,
    
        

    
        NTILE(5) over (order by petal_width)
    

 as petal_width_quantile_bin,
        

    
        
        floor(
        (
            petal_width - (min(petal_width) over ())
        )
        /
        (
            ((max(petal_width) over ()) - (min(petal_width) over ())) / 4::float
        )
        ) + 1
    

 as petal_width_uniform_bin,
    
-- Scaling
    
        

    

    
    
    

    
    
    

    (
        sepal_length - 5.8
    )
    /
    (
        6.4 - 5.1
    )

 as sepal_length_robust_scaled,
        

    (sepal_length) / (max(abs(sepal_length)) over ())::FLOAT

 as sepal_length_max_absolute_scaled,
        

    
    (
        ((sepal_length) - (min(sepal_length) over ()))
        /
        ((max(sepal_length) over ()) - (min(sepal_length) over ()))::FLOAT
    )
    *
    (1.0 - 0.0)
    +
    0.0

 as sepal_length_max_min_max_scaled,
    
        

    

    
    
    

    
    
    

    (
        sepal_width - 3.0
    )
    /
    (
        3.3 - 2.8
    )

 as sepal_width_robust_scaled,
        

    (sepal_width) / (max(abs(sepal_width)) over ())::FLOAT

 as sepal_width_max_absolute_scaled,
        

    
    (
        ((sepal_width) - (min(sepal_width) over ()))
        /
        ((max(sepal_width) over ()) - (min(sepal_width) over ()))::FLOAT
    )
    *
    (1.0 - 0.0)
    +
    0.0

 as sepal_width_max_min_max_scaled,
    
        

    

    
    
    

    
    
    

    (
        petal_length - 4.35
    )
    /
    (
        5.1 - 1.6
    )

 as petal_length_robust_scaled,
        

    (petal_length) / (max(abs(petal_length)) over ())::FLOAT

 as petal_length_max_absolute_scaled,
        

    
    (
        ((petal_length) - (min(petal_length) over ()))
        /
        ((max(petal_length) over ()) - (min(petal_length) over ()))::FLOAT
    )
    *
    (1.0 - 0.0)
    +
    0.0

 as petal_length_max_min_max_scaled,
    
        

    

    
    
    

    
    
    

    (
        petal_width - 1.3
    )
    /
    (
        1.8 - 0.3
    )

 as petal_width_robust_scaled,
        

    (petal_width) / (max(abs(petal_width)) over ())::FLOAT

 as petal_width_max_absolute_scaled,
        

    
    (
        ((petal_width) - (min(petal_width) over ()))
        /
        ((max(petal_width) over ()) - (min(petal_width) over ()))::FLOAT
    )
    *
    (1.0 - 0.0)
    +
    0.0

 as petal_width_max_min_max_scaled,
    

    -- Log Transformation
    
        

    case
        when sepal_length is null or sepal_length + 0 <= 0 then null
        else log(10, sepal_length + 0)
    end

 as sepal_length_logged,
    
        

    case
        when sepal_width is null or sepal_width + 0 <= 0 then null
        else log(10, sepal_width + 0)
    end

 as sepal_width_logged,
    
        

    case
        when petal_length is null or petal_length + 0 <= 0 then null
        else log(10, petal_length + 0)
    end

 as petal_length_logged,
    
        

    case
        when petal_width is null or petal_width + 0 <= 0 then null
        else log(10, petal_width + 0)
    end

 as petal_width_logged,
    

    -- Binarization
    
        

    

    
        

        
    

    case
        when sepal_length >=
            
                5.8
            
            then 1
        else 0
    end

 as sepal_length_binarized,
    
        

    

    
        

        
    

    case
        when sepal_width >=
            
                3.0
            
            then 1
        else 0
    end

 as sepal_width_binarized,
    
        

    

    
        

        
    

    case
        when petal_length >=
            
                4.35
            
            then 1
        else 0
    end

 as petal_length_binarized,
    
        

    

    
        

        
    

    case
        when petal_width >=
            
                1.3
            
            then 1
        else 0
    end

 as petal_width_binarized,
    

    -- Standardization
    
        

    
    (
        (sepal_length - avg(sepal_length) over ())
        /
        (stddev(sepal_length) over ())::FLOAT
    )
    *
    1
    +
    0

 as sepal_length_standardized,
    
        

    
    (
        (sepal_width - avg(sepal_width) over ())
        /
        (stddev(sepal_width) over ())::FLOAT
    )
    *
    1
    +
    0

 as sepal_width_standardized,
    
        

    
    (
        (petal_length - avg(petal_length) over ())
        /
        (stddev(petal_length) over ())::FLOAT
    )
    *
    1
    +
    0

 as petal_length_standardized,
    
        

    
    (
        (petal_width - avg(petal_width) over ())
        /
        (stddev(petal_width) over ())::FLOAT
    )
    *
    1
    +
    0

 as petal_width_standardized,
    
-- Interactions
    
        
            
            
            

    
        (sepal_length * sepal_width)
    

 as sepal_length_x_sepal_width_interaction,
            

    
        (sepal_length + sepal_width)
    

 as sepal_length_plus_sepal_width_interaction,
        
            
            
            

    
        (sepal_length * petal_length)
    

 as sepal_length_x_petal_length_interaction,
            

    
        (sepal_length + petal_length)
    

 as sepal_length_plus_petal_length_interaction,
        
            
            
            

    
        (sepal_length * petal_width)
    

 as sepal_length_x_petal_width_interaction,
            

    
        (sepal_length + petal_width)
    

 as sepal_length_plus_petal_width_interaction,
        
    
        
            
            
            

    
        (sepal_width * petal_length)
    

 as sepal_width_x_petal_length_interaction,
            

    
        (sepal_width + petal_length)
    

 as sepal_width_plus_petal_length_interaction,
        
            
            
            

    
        (sepal_width * petal_width)
    

 as sepal_width_x_petal_width_interaction,
            

    
        (sepal_width + petal_width)
    

 as sepal_width_plus_petal_width_interaction,
        
    
        
            
            
            

    
        (petal_length * petal_width)
    

 as petal_length_x_petal_width_interaction,
            

    
        (petal_length + petal_width)
    

 as petal_length_plus_petal_width_interaction,
        
    
        
    
species,    
    -- Label Encoding
    

    dense_rank() over (order by species) - 1

 as species_label_encoded,
    -- One Hot Encoding
    

    

    
        
    

    

    

        case
            when species = 'setosa' then 1
            else 0
        end as is_species__setosa,

    

        case
            when species = 'versicolor' then 1
            else 0
        end as is_species__versicolor,

    

        case
            when species = 'virginica' then 1
            else 0
        end as is_species__virginica,

    

    case
        when species is null then 1
        else 0
    end as is_species__


from "analytics"."analytics"."stg_iris"
  );
  
[0m09:43:52.191643 [debug] [Thread-3  ]: Postgres adapter: Postgres error: function log(integer, double precision) does not exist
LINE 294:         else log(10, sepal_length + 0)
                       ^
HINT:  No function matches the given name and argument types. You might need to add explicit type casts.

[0m09:43:52.198601 [debug] [Thread-3  ]: On model.homework.iris_processed: ROLLBACK
[0m09:43:52.203003 [debug] [Thread-3  ]: On model.homework.iris_processed: Close
[0m09:43:52.823399 [debug] [Thread-3  ]: Database Error in model iris_processed (models/mart/iris_processed.sql)
  function log(integer, double precision) does not exist
  LINE 294:         else log(10, sepal_length + 0)
                         ^
  HINT:  No function matches the given name and argument types. You might need to add explicit type casts.
  compiled code at target/run/homework/models/mart/iris_processed.sql
[0m09:43:52.828288 [debug] [Thread-3  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '264beaf0-e929-4541-97c4-1aaaa726bb9c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f9eb8c3c7f0>]}
[0m09:43:52.837575 [error] [Thread-3  ]: 2 of 2 ERROR creating sql table model analytics.iris_processed ................. [[31mERROR[0m in 1.83s]
[0m09:43:52.842343 [debug] [Thread-3  ]: Finished running node model.homework.iris_processed
[0m09:43:52.846211 [debug] [Thread-7  ]: Marking all children of 'model.homework.iris_processed' to be skipped because of status 'error'.  Reason: Database Error in model iris_processed (models/mart/iris_processed.sql)
  function log(integer, double precision) does not exist
  LINE 294:         else log(10, sepal_length + 0)
                         ^
  HINT:  No function matches the given name and argument types. You might need to add explicit type casts.
  compiled code at target/run/homework/models/mart/iris_processed.sql.
[0m09:43:52.853548 [debug] [MainThread]: Using postgres connection "master"
[0m09:43:52.856187 [debug] [MainThread]: On master: BEGIN
[0m09:43:52.859319 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m09:43:52.877117 [debug] [MainThread]: SQL status: BEGIN in 0.018 seconds
[0m09:43:52.880215 [debug] [MainThread]: On master: COMMIT
[0m09:43:52.882865 [debug] [MainThread]: Using postgres connection "master"
[0m09:43:52.885133 [debug] [MainThread]: On master: COMMIT
[0m09:43:52.887400 [debug] [MainThread]: SQL status: COMMIT in 0.000 seconds
[0m09:43:52.890283 [debug] [MainThread]: On master: Close
[0m09:43:52.892708 [debug] [MainThread]: Connection 'master' was properly closed.
[0m09:43:52.895897 [debug] [MainThread]: Connection 'model.homework.stg_iris' was properly closed.
[0m09:43:52.898281 [debug] [MainThread]: Connection 'model.homework.iris_processed' was properly closed.
[0m09:43:52.900657 [info ] [MainThread]: 
[0m09:43:52.903304 [info ] [MainThread]: Finished running 1 table model, 1 view model in 0 hours 0 minutes and 6.23 seconds (6.23s).
[0m09:43:52.907465 [debug] [MainThread]: Command end result
[0m09:43:53.083639 [debug] [MainThread]: Wrote artifact WritableManifest to /opt/airflow/dags/dbt/homework/target/manifest.json
[0m09:43:53.096184 [debug] [MainThread]: Wrote artifact SemanticManifest to /opt/airflow/dags/dbt/homework/target/semantic_manifest.json
[0m09:43:53.140511 [debug] [MainThread]: Wrote artifact RunExecutionResult to /opt/airflow/dags/dbt/homework/target/run_results.json
[0m09:43:53.143470 [info ] [MainThread]: 
[0m09:43:53.147104 [info ] [MainThread]: [31mCompleted with 1 error, 0 partial successes, and 0 warnings:[0m
[0m09:43:53.150670 [info ] [MainThread]: 
[0m09:43:53.159008 [error] [MainThread]:   Database Error in model iris_processed (models/mart/iris_processed.sql)
  function log(integer, double precision) does not exist
  LINE 294:         else log(10, sepal_length + 0)
                         ^
  HINT:  No function matches the given name and argument types. You might need to add explicit type casts.
  compiled code at target/run/homework/models/mart/iris_processed.sql
[0m09:43:53.161914 [info ] [MainThread]: 
[0m09:43:53.165037 [info ] [MainThread]: Done. PASS=1 WARN=0 ERROR=1 SKIP=0 TOTAL=2
[0m09:43:53.169494 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": false, "command_wall_clock_time": 22.564533, "process_in_blocks": "4136", "process_kernel_time": 0.81285, "process_mem_max_rss": "119456", "process_out_blocks": "0", "process_user_time": 20.524464}
[0m09:43:53.174763 [debug] [MainThread]: Command `dbt run` failed at 09:43:53.174235 after 22.57 seconds
[0m09:43:53.177590 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f9ee4759b20>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f9ee38ba760>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f9ee45c8a00>]}
[0m09:43:53.181630 [debug] [MainThread]: Flushing usage events
[0m09:43:53.798004 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m09:48:16.735666 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f074aa07ac0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0749b284c0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0749b28460>]}


============================== 09:48:16.751237 | 3b466ab4-7cc8-4b52-9d8a-f9a78bb28437 ==============================
[0m09:48:16.751237 [info ] [MainThread]: Running with dbt=1.9.4
[0m09:48:16.753883 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': '/opt/airflow/dags/dbt', 'debug': 'False', 'warn_error': 'None', 'log_path': '/opt/airflow/dags/dbt/homework/logs', 'fail_fast': 'False', 'version_check': 'True', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'empty': 'False', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'static_parser': 'True', 'invocation_command': 'dbt --profile homework run --project-dir=/opt/airflow/dags/dbt/homework --vars {"is_test": false, "data_date": "2025-04-23"}', 'log_format': 'default', 'target_path': 'None', 'introspect': 'True', 'send_anonymous_usage_stats': 'True'}
[0m09:48:17.358206 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '3b466ab4-7cc8-4b52-9d8a-f9a78bb28437', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f074835e460>]}
[0m09:48:17.510791 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '3b466ab4-7cc8-4b52-9d8a-f9a78bb28437', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0749bbf220>]}
[0m09:48:17.513586 [info ] [MainThread]: Registered adapter: postgres=1.9.0
[0m09:48:17.909129 [debug] [MainThread]: checksum: f5df654a850f4b74beb13fbe0c7d8863b5b1a20bd535c3ac287d70e390b64d41, vars: {'data_date': '2025-04-23', 'is_test': False}, profile: homework, target: , version: 1.9.4
[0m09:48:20.089055 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 1 files changed.
[0m09:48:20.091499 [debug] [MainThread]: Partial parsing: updated file: homework://models/staging/stg_iris.sql
[0m09:48:21.022178 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 1 unused configuration paths:
- seeds.homework.iris_dataset
[0m09:48:21.063975 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '3b466ab4-7cc8-4b52-9d8a-f9a78bb28437', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0746be0ee0>]}
[0m09:48:21.331034 [debug] [MainThread]: Wrote artifact WritableManifest to /opt/airflow/dags/dbt/homework/target/manifest.json
[0m09:48:21.353200 [debug] [MainThread]: Wrote artifact SemanticManifest to /opt/airflow/dags/dbt/homework/target/semantic_manifest.json
[0m09:48:21.399868 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '3b466ab4-7cc8-4b52-9d8a-f9a78bb28437', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0746c34340>]}
[0m09:48:21.402053 [info ] [MainThread]: Found 2 models, 1 source, 587 macros
[0m09:48:21.404998 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '3b466ab4-7cc8-4b52-9d8a-f9a78bb28437', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0749d48580>]}
[0m09:48:21.409457 [info ] [MainThread]: 
[0m09:48:21.411374 [info ] [MainThread]: Concurrency: 4 threads (target='dev')
[0m09:48:21.413130 [info ] [MainThread]: 
[0m09:48:21.415193 [debug] [MainThread]: Acquiring new postgres connection 'master'
[0m09:48:21.429204 [debug] [ThreadPool]: Acquiring new postgres connection 'list_analytics'
[0m09:48:21.539160 [debug] [ThreadPool]: Using postgres connection "list_analytics"
[0m09:48:21.541135 [debug] [ThreadPool]: On list_analytics: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "homework", "target_name": "dev", "connection_name": "list_analytics"} */

    select distinct nspname from pg_namespace
  
[0m09:48:21.542893 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m09:48:21.564217 [debug] [ThreadPool]: SQL status: SELECT 6 in 0.021 seconds
[0m09:48:21.568831 [debug] [ThreadPool]: On list_analytics: Close
[0m09:48:21.573821 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_analytics, now list_analytics_analytics)
[0m09:48:21.595200 [debug] [ThreadPool]: Using postgres connection "list_analytics_analytics"
[0m09:48:21.597129 [debug] [ThreadPool]: On list_analytics_analytics: BEGIN
[0m09:48:21.599261 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m09:48:21.612826 [debug] [ThreadPool]: SQL status: BEGIN in 0.013 seconds
[0m09:48:21.615691 [debug] [ThreadPool]: Using postgres connection "list_analytics_analytics"
[0m09:48:21.617938 [debug] [ThreadPool]: On list_analytics_analytics: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "homework", "target_name": "dev", "connection_name": "list_analytics_analytics"} */
select
      'analytics' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'analytics'
    union all
    select
      'analytics' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'analytics'
    union all
    select
      'analytics' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'analytics'
  
[0m09:48:21.629232 [debug] [ThreadPool]: SQL status: SELECT 3 in 0.009 seconds
[0m09:48:21.633649 [debug] [ThreadPool]: On list_analytics_analytics: ROLLBACK
[0m09:48:21.636535 [debug] [ThreadPool]: On list_analytics_analytics: Close
[0m09:48:21.655394 [debug] [MainThread]: Using postgres connection "master"
[0m09:48:21.657714 [debug] [MainThread]: On master: BEGIN
[0m09:48:21.659595 [debug] [MainThread]: Opening a new connection, currently in state init
[0m09:48:21.677540 [debug] [MainThread]: SQL status: BEGIN in 0.018 seconds
[0m09:48:21.680429 [debug] [MainThread]: Using postgres connection "master"
[0m09:48:21.683358 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "homework", "target_name": "dev", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select distinct
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v', 'm')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
[0m09:48:21.701059 [debug] [MainThread]: SQL status: SELECT 1 in 0.015 seconds
[0m09:48:21.706427 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '3b466ab4-7cc8-4b52-9d8a-f9a78bb28437', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0748020e20>]}
[0m09:48:21.708665 [debug] [MainThread]: On master: ROLLBACK
[0m09:48:21.711213 [debug] [MainThread]: Using postgres connection "master"
[0m09:48:21.714018 [debug] [MainThread]: On master: BEGIN
[0m09:48:21.717201 [debug] [MainThread]: SQL status: BEGIN in 0.001 seconds
[0m09:48:21.719912 [debug] [MainThread]: On master: COMMIT
[0m09:48:21.723129 [debug] [MainThread]: Using postgres connection "master"
[0m09:48:21.725936 [debug] [MainThread]: On master: COMMIT
[0m09:48:21.728636 [debug] [MainThread]: SQL status: COMMIT in 0.000 seconds
[0m09:48:21.731341 [debug] [MainThread]: On master: Close
[0m09:48:21.745690 [debug] [Thread-1  ]: Began running node model.homework.stg_iris
[0m09:48:21.748430 [info ] [Thread-1  ]: 1 of 2 START sql view model analytics.stg_iris ................................. [RUN]
[0m09:48:21.750832 [debug] [Thread-1  ]: Re-using an available connection from the pool (formerly list_analytics_analytics, now model.homework.stg_iris)
[0m09:48:21.753256 [debug] [Thread-1  ]: Began compiling node model.homework.stg_iris
[0m09:48:21.784434 [debug] [Thread-1  ]: Writing injected SQL for node "model.homework.stg_iris"
[0m09:48:21.797101 [debug] [Thread-1  ]: Began executing node model.homework.stg_iris
[0m09:48:21.915666 [debug] [Thread-1  ]: Writing runtime sql for node "model.homework.stg_iris"
[0m09:48:21.936720 [debug] [Thread-1  ]: Using postgres connection "model.homework.stg_iris"
[0m09:48:21.940471 [debug] [Thread-1  ]: On model.homework.stg_iris: BEGIN
[0m09:48:21.943682 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
[0m09:48:21.962118 [debug] [Thread-1  ]: SQL status: BEGIN in 0.018 seconds
[0m09:48:21.968310 [debug] [Thread-1  ]: Using postgres connection "model.homework.stg_iris"
[0m09:48:21.973977 [debug] [Thread-1  ]: On model.homework.stg_iris: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "homework", "target_name": "dev", "node_id": "model.homework.stg_iris"} */

  create view "analytics"."analytics"."stg_iris__dbt_tmp"
    
    
  as (
    with source as (
    select * from "analytics"."analytics"."iris_dataset"
)

select
    cast(sepal_length to numeric) as sepal_length,
    cast(sepal_width to numeric) as sepal_width,
    cast(petal_length to numeric) as petal_length,
    cast(petal_width to numeric) as petal_width,
    species
from source
  );
[0m09:48:21.978577 [debug] [Thread-1  ]: Postgres adapter: Postgres error: syntax error at or near "to"
LINE 12:     cast(sepal_length to numeric) as sepal_length,
                               ^

[0m09:48:21.982916 [debug] [Thread-1  ]: On model.homework.stg_iris: ROLLBACK
[0m09:48:21.992930 [debug] [Thread-1  ]: On model.homework.stg_iris: Close
[0m09:48:22.010120 [debug] [Thread-1  ]: Database Error in model stg_iris (models/staging/stg_iris.sql)
  syntax error at or near "to"
  LINE 12:     cast(sepal_length to numeric) as sepal_length,
                                 ^
  compiled code at target/run/homework/models/staging/stg_iris.sql
[0m09:48:22.018431 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '3b466ab4-7cc8-4b52-9d8a-f9a78bb28437', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f074d7104f0>]}
[0m09:48:22.026262 [error] [Thread-1  ]: 1 of 2 ERROR creating sql view model analytics.stg_iris ........................ [[31mERROR[0m in 0.26s]
[0m09:48:22.030245 [debug] [Thread-1  ]: Finished running node model.homework.stg_iris
[0m09:48:22.033668 [debug] [Thread-7  ]: Marking all children of 'model.homework.stg_iris' to be skipped because of status 'error'.  Reason: Database Error in model stg_iris (models/staging/stg_iris.sql)
  syntax error at or near "to"
  LINE 12:     cast(sepal_length to numeric) as sepal_length,
                                 ^
  compiled code at target/run/homework/models/staging/stg_iris.sql.
[0m09:48:22.038527 [debug] [Thread-3  ]: Began running node model.homework.iris_processed
[0m09:48:22.043210 [info ] [Thread-3  ]: 2 of 2 SKIP relation analytics.iris_processed .................................. [[33mSKIP[0m]
[0m09:48:22.046115 [debug] [Thread-3  ]: Finished running node model.homework.iris_processed
[0m09:48:22.051780 [debug] [MainThread]: Using postgres connection "master"
[0m09:48:22.055072 [debug] [MainThread]: On master: BEGIN
[0m09:48:22.059789 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m09:48:22.080591 [debug] [MainThread]: SQL status: BEGIN in 0.021 seconds
[0m09:48:22.083521 [debug] [MainThread]: On master: COMMIT
[0m09:48:22.086137 [debug] [MainThread]: Using postgres connection "master"
[0m09:48:22.090833 [debug] [MainThread]: On master: COMMIT
[0m09:48:22.094464 [debug] [MainThread]: SQL status: COMMIT in 0.000 seconds
[0m09:48:22.097608 [debug] [MainThread]: On master: Close
[0m09:48:22.100948 [debug] [MainThread]: Connection 'master' was properly closed.
[0m09:48:22.104010 [debug] [MainThread]: Connection 'model.homework.stg_iris' was properly closed.
[0m09:48:22.109447 [info ] [MainThread]: 
[0m09:48:22.113032 [info ] [MainThread]: Finished running 1 table model, 1 view model in 0 hours 0 minutes and 0.69 seconds (0.69s).
[0m09:48:22.117589 [debug] [MainThread]: Command end result
[0m09:48:22.269426 [debug] [MainThread]: Wrote artifact WritableManifest to /opt/airflow/dags/dbt/homework/target/manifest.json
[0m09:48:22.278700 [debug] [MainThread]: Wrote artifact SemanticManifest to /opt/airflow/dags/dbt/homework/target/semantic_manifest.json
[0m09:48:22.299361 [debug] [MainThread]: Wrote artifact RunExecutionResult to /opt/airflow/dags/dbt/homework/target/run_results.json
[0m09:48:22.301276 [info ] [MainThread]: 
[0m09:48:22.303429 [info ] [MainThread]: [31mCompleted with 1 error, 0 partial successes, and 0 warnings:[0m
[0m09:48:22.305897 [info ] [MainThread]: 
[0m09:48:22.308166 [error] [MainThread]:   Database Error in model stg_iris (models/staging/stg_iris.sql)
  syntax error at or near "to"
  LINE 12:     cast(sepal_length to numeric) as sepal_length,
                                 ^
  compiled code at target/run/homework/models/staging/stg_iris.sql
[0m09:48:22.309949 [info ] [MainThread]: 
[0m09:48:22.311778 [info ] [MainThread]: Done. PASS=0 WARN=0 ERROR=1 SKIP=1 TOTAL=2
[0m09:48:22.315058 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": false, "command_wall_clock_time": 5.7441645, "process_in_blocks": "0", "process_kernel_time": 0.868208, "process_mem_max_rss": "118920", "process_out_blocks": "0", "process_user_time": 7.933629}
[0m09:48:22.317294 [debug] [MainThread]: Command `dbt run` failed at 09:48:22.317062 after 5.75 seconds
[0m09:48:22.319231 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f074aa07ac0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f074a8347f0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f074a90ba00>]}
[0m09:48:22.321630 [debug] [MainThread]: Flushing usage events
[0m09:48:22.922051 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m09:49:57.446910 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f84e0d73ac0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f84dfe94490>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f84dfe94430>]}


============================== 09:49:57.459818 | 520b07dc-b70c-4088-85b0-de90f6721dfe ==============================
[0m09:49:57.459818 [info ] [MainThread]: Running with dbt=1.9.4
[0m09:49:57.462067 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'fail_fast': 'False', 'profiles_dir': '/opt/airflow/dags/dbt', 'log_path': '/opt/airflow/dags/dbt/homework/logs', 'version_check': 'True', 'debug': 'False', 'use_colors': 'True', 'use_experimental_parser': 'False', 'empty': 'False', 'quiet': 'False', 'no_print': 'None', 'log_format': 'default', 'introspect': 'True', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'static_parser': 'True', 'target_path': 'None', 'invocation_command': 'dbt --profile homework run --project-dir=/opt/airflow/dags/dbt/homework --vars {"is_test": false, "data_date": "2025-04-23"}', 'send_anonymous_usage_stats': 'True'}
[0m09:49:57.917546 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '520b07dc-b70c-4088-85b0-de90f6721dfe', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f84dff34f70>]}
[0m09:49:58.042681 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '520b07dc-b70c-4088-85b0-de90f6721dfe', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f84e052b520>]}
[0m09:49:58.044914 [info ] [MainThread]: Registered adapter: postgres=1.9.0
[0m09:49:58.322916 [debug] [MainThread]: checksum: f5df654a850f4b74beb13fbe0c7d8863b5b1a20bd535c3ac287d70e390b64d41, vars: {'data_date': '2025-04-23', 'is_test': False}, profile: homework, target: , version: 1.9.4
[0m09:50:00.537378 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 1 files changed.
[0m09:50:00.539691 [debug] [MainThread]: Partial parsing: updated file: homework://models/staging/stg_iris.sql
[0m09:50:01.361142 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 1 unused configuration paths:
- seeds.homework.iris_dataset
[0m09:50:01.396717 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '520b07dc-b70c-4088-85b0-de90f6721dfe', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f84dcf50ee0>]}
[0m09:50:01.663964 [debug] [MainThread]: Wrote artifact WritableManifest to /opt/airflow/dags/dbt/homework/target/manifest.json
[0m09:50:01.683292 [debug] [MainThread]: Wrote artifact SemanticManifest to /opt/airflow/dags/dbt/homework/target/semantic_manifest.json
[0m09:50:01.720299 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '520b07dc-b70c-4088-85b0-de90f6721dfe', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f84de636a00>]}
[0m09:50:01.722512 [info ] [MainThread]: Found 2 models, 1 source, 587 macros
[0m09:50:01.725109 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '520b07dc-b70c-4088-85b0-de90f6721dfe', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f84de636d30>]}
[0m09:50:01.729121 [info ] [MainThread]: 
[0m09:50:01.731464 [info ] [MainThread]: Concurrency: 4 threads (target='dev')
[0m09:50:01.733465 [info ] [MainThread]: 
[0m09:50:01.737224 [debug] [MainThread]: Acquiring new postgres connection 'master'
[0m09:50:01.748817 [debug] [ThreadPool]: Acquiring new postgres connection 'list_analytics'
[0m09:50:01.837867 [debug] [ThreadPool]: Using postgres connection "list_analytics"
[0m09:50:01.839921 [debug] [ThreadPool]: On list_analytics: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "homework", "target_name": "dev", "connection_name": "list_analytics"} */

    select distinct nspname from pg_namespace
  
[0m09:50:01.841670 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m09:50:01.856799 [debug] [ThreadPool]: SQL status: SELECT 6 in 0.015 seconds
[0m09:50:01.860237 [debug] [ThreadPool]: On list_analytics: Close
[0m09:50:01.863552 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_analytics, now list_analytics_analytics)
[0m09:50:01.878846 [debug] [ThreadPool]: Using postgres connection "list_analytics_analytics"
[0m09:50:01.880540 [debug] [ThreadPool]: On list_analytics_analytics: BEGIN
[0m09:50:01.882013 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m09:50:01.893512 [debug] [ThreadPool]: SQL status: BEGIN in 0.011 seconds
[0m09:50:01.895768 [debug] [ThreadPool]: Using postgres connection "list_analytics_analytics"
[0m09:50:01.897478 [debug] [ThreadPool]: On list_analytics_analytics: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "homework", "target_name": "dev", "connection_name": "list_analytics_analytics"} */
select
      'analytics' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'analytics'
    union all
    select
      'analytics' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'analytics'
    union all
    select
      'analytics' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'analytics'
  
[0m09:50:01.903686 [debug] [ThreadPool]: SQL status: SELECT 3 in 0.005 seconds
[0m09:50:01.907641 [debug] [ThreadPool]: On list_analytics_analytics: ROLLBACK
[0m09:50:01.910016 [debug] [ThreadPool]: On list_analytics_analytics: Close
[0m09:50:01.924886 [debug] [MainThread]: Using postgres connection "master"
[0m09:50:01.927061 [debug] [MainThread]: On master: BEGIN
[0m09:50:01.928784 [debug] [MainThread]: Opening a new connection, currently in state init
[0m09:50:01.941595 [debug] [MainThread]: SQL status: BEGIN in 0.013 seconds
[0m09:50:01.944330 [debug] [MainThread]: Using postgres connection "master"
[0m09:50:01.946865 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "homework", "target_name": "dev", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select distinct
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v', 'm')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
[0m09:50:01.959132 [debug] [MainThread]: SQL status: SELECT 1 in 0.010 seconds
[0m09:50:01.963338 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '520b07dc-b70c-4088-85b0-de90f6721dfe', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f84de337070>]}
[0m09:50:01.965591 [debug] [MainThread]: On master: ROLLBACK
[0m09:50:01.967773 [debug] [MainThread]: Using postgres connection "master"
[0m09:50:01.970395 [debug] [MainThread]: On master: BEGIN
[0m09:50:01.973809 [debug] [MainThread]: SQL status: BEGIN in 0.001 seconds
[0m09:50:01.977436 [debug] [MainThread]: On master: COMMIT
[0m09:50:01.979626 [debug] [MainThread]: Using postgres connection "master"
[0m09:50:01.981546 [debug] [MainThread]: On master: COMMIT
[0m09:50:01.983933 [debug] [MainThread]: SQL status: COMMIT in 0.000 seconds
[0m09:50:01.986479 [debug] [MainThread]: On master: Close
[0m09:50:01.996738 [debug] [Thread-1  ]: Began running node model.homework.stg_iris
[0m09:50:01.999017 [info ] [Thread-1  ]: 1 of 2 START sql view model analytics.stg_iris ................................. [RUN]
[0m09:50:02.001389 [debug] [Thread-1  ]: Re-using an available connection from the pool (formerly list_analytics_analytics, now model.homework.stg_iris)
[0m09:50:02.004449 [debug] [Thread-1  ]: Began compiling node model.homework.stg_iris
[0m09:50:02.026104 [debug] [Thread-1  ]: Writing injected SQL for node "model.homework.stg_iris"
[0m09:50:02.039254 [debug] [Thread-1  ]: Began executing node model.homework.stg_iris
[0m09:50:02.125901 [debug] [Thread-1  ]: Writing runtime sql for node "model.homework.stg_iris"
[0m09:50:02.140519 [debug] [Thread-1  ]: Using postgres connection "model.homework.stg_iris"
[0m09:50:02.142639 [debug] [Thread-1  ]: On model.homework.stg_iris: BEGIN
[0m09:50:02.144424 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
[0m09:50:02.157548 [debug] [Thread-1  ]: SQL status: BEGIN in 0.013 seconds
[0m09:50:02.159946 [debug] [Thread-1  ]: Using postgres connection "model.homework.stg_iris"
[0m09:50:02.162122 [debug] [Thread-1  ]: On model.homework.stg_iris: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "homework", "target_name": "dev", "node_id": "model.homework.stg_iris"} */

  create view "analytics"."analytics"."stg_iris__dbt_tmp"
    
    
  as (
    with source as (
    select * from "analytics"."analytics"."iris_dataset"
)

select
    cast(sepal_length as numeric) as sepal_length,
    cast(sepal_width as numeric) as sepal_width,
    cast(petal_length as numeric) as petal_length,
    cast(petal_width as numeric) as petal_width,
    species
from source
  );
[0m09:50:02.212787 [debug] [Thread-1  ]: SQL status: CREATE VIEW in 0.049 seconds
[0m09:50:02.229912 [debug] [Thread-1  ]: Using postgres connection "model.homework.stg_iris"
[0m09:50:02.232060 [debug] [Thread-1  ]: On model.homework.stg_iris: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "homework", "target_name": "dev", "node_id": "model.homework.stg_iris"} */
alter table "analytics"."analytics"."stg_iris" rename to "stg_iris__dbt_backup"
[0m09:50:02.235906 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.001 seconds
[0m09:50:02.244736 [debug] [Thread-1  ]: Using postgres connection "model.homework.stg_iris"
[0m09:50:02.246851 [debug] [Thread-1  ]: On model.homework.stg_iris: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "homework", "target_name": "dev", "node_id": "model.homework.stg_iris"} */
alter table "analytics"."analytics"."stg_iris__dbt_tmp" rename to "stg_iris"
[0m09:50:02.250059 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.001 seconds
[0m09:50:02.292393 [debug] [Thread-1  ]: On model.homework.stg_iris: COMMIT
[0m09:50:02.294538 [debug] [Thread-1  ]: Using postgres connection "model.homework.stg_iris"
[0m09:50:02.296671 [debug] [Thread-1  ]: On model.homework.stg_iris: COMMIT
[0m09:50:02.304610 [debug] [Thread-1  ]: SQL status: COMMIT in 0.006 seconds
[0m09:50:02.321638 [debug] [Thread-1  ]: Applying DROP to: "analytics"."analytics"."stg_iris__dbt_backup"
[0m09:50:02.332818 [debug] [Thread-1  ]: Using postgres connection "model.homework.stg_iris"
[0m09:50:02.335944 [debug] [Thread-1  ]: On model.homework.stg_iris: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "homework", "target_name": "dev", "node_id": "model.homework.stg_iris"} */
drop view if exists "analytics"."analytics"."stg_iris__dbt_backup" cascade
[0m09:50:02.348980 [debug] [Thread-1  ]: SQL status: DROP VIEW in 0.011 seconds
[0m09:50:02.356515 [debug] [Thread-1  ]: On model.homework.stg_iris: Close
[0m09:50:02.361683 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '520b07dc-b70c-4088-85b0-de90f6721dfe', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f84e27776a0>]}
[0m09:50:02.365022 [info ] [Thread-1  ]: 1 of 2 OK created sql view model analytics.stg_iris ............................ [[32mCREATE VIEW[0m in 0.36s]
[0m09:50:02.369560 [debug] [Thread-1  ]: Finished running node model.homework.stg_iris
[0m09:50:02.373682 [debug] [Thread-3  ]: Began running node model.homework.iris_processed
[0m09:50:02.376722 [info ] [Thread-3  ]: 2 of 2 START sql table model analytics.iris_processed .......................... [RUN]
[0m09:50:02.379891 [debug] [Thread-3  ]: Acquiring new postgres connection 'model.homework.iris_processed'
[0m09:50:02.382613 [debug] [Thread-3  ]: Began compiling node model.homework.iris_processed
[0m09:50:02.492850 [debug] [Thread-3  ]: Using postgres connection "model.homework.iris_processed"
[0m09:50:02.494563 [debug] [Thread-3  ]: On model.homework.iris_processed: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "homework", "target_name": "dev", "node_id": "model.homework.iris_processed"} */

        select percentile_cont(0.5) within group (order by sepal_length ) from "analytics"."analytics"."stg_iris"
    
[0m09:50:02.496249 [debug] [Thread-3  ]: Opening a new connection, currently in state init
[0m09:50:02.513914 [debug] [Thread-3  ]: SQL status: SELECT 1 in 0.018 seconds
[0m09:50:02.517570 [debug] [Thread-3  ]: Using postgres connection "model.homework.iris_processed"
[0m09:50:02.519684 [debug] [Thread-3  ]: On model.homework.iris_processed: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "homework", "target_name": "dev", "node_id": "model.homework.iris_processed"} */

        select percentile_cont(0.5 - 0.5/2) within group (order by sepal_length ) from "analytics"."analytics"."stg_iris"
    
[0m09:50:02.524027 [debug] [Thread-3  ]: SQL status: SELECT 1 in 0.002 seconds
[0m09:50:02.528058 [debug] [Thread-3  ]: Using postgres connection "model.homework.iris_processed"
[0m09:50:02.529718 [debug] [Thread-3  ]: On model.homework.iris_processed: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "homework", "target_name": "dev", "node_id": "model.homework.iris_processed"} */

        select percentile_cont(0.5 + 0.5/2) within group (order by sepal_length ) from "analytics"."analytics"."stg_iris"
    
[0m09:50:02.532023 [debug] [Thread-3  ]: SQL status: SELECT 1 in 0.001 seconds
[0m09:50:02.547295 [debug] [Thread-3  ]: Using postgres connection "model.homework.iris_processed"
[0m09:50:02.548971 [debug] [Thread-3  ]: On model.homework.iris_processed: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "homework", "target_name": "dev", "node_id": "model.homework.iris_processed"} */

        select percentile_cont(0.5) within group (order by sepal_width ) from "analytics"."analytics"."stg_iris"
    
[0m09:50:02.551349 [debug] [Thread-3  ]: SQL status: SELECT 1 in 0.001 seconds
[0m09:50:02.556208 [debug] [Thread-3  ]: Using postgres connection "model.homework.iris_processed"
[0m09:50:02.558122 [debug] [Thread-3  ]: On model.homework.iris_processed: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "homework", "target_name": "dev", "node_id": "model.homework.iris_processed"} */

        select percentile_cont(0.5 - 0.5/2) within group (order by sepal_width ) from "analytics"."analytics"."stg_iris"
    
[0m09:50:02.560687 [debug] [Thread-3  ]: SQL status: SELECT 1 in 0.001 seconds
[0m09:50:02.565239 [debug] [Thread-3  ]: Using postgres connection "model.homework.iris_processed"
[0m09:50:02.567061 [debug] [Thread-3  ]: On model.homework.iris_processed: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "homework", "target_name": "dev", "node_id": "model.homework.iris_processed"} */

        select percentile_cont(0.5 + 0.5/2) within group (order by sepal_width ) from "analytics"."analytics"."stg_iris"
    
[0m09:50:02.569881 [debug] [Thread-3  ]: SQL status: SELECT 1 in 0.001 seconds
[0m09:50:02.578187 [debug] [Thread-3  ]: Using postgres connection "model.homework.iris_processed"
[0m09:50:02.580167 [debug] [Thread-3  ]: On model.homework.iris_processed: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "homework", "target_name": "dev", "node_id": "model.homework.iris_processed"} */

        select percentile_cont(0.5) within group (order by petal_length ) from "analytics"."analytics"."stg_iris"
    
[0m09:50:02.583752 [debug] [Thread-3  ]: SQL status: SELECT 1 in 0.002 seconds
[0m09:50:02.588848 [debug] [Thread-3  ]: Using postgres connection "model.homework.iris_processed"
[0m09:50:02.590693 [debug] [Thread-3  ]: On model.homework.iris_processed: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "homework", "target_name": "dev", "node_id": "model.homework.iris_processed"} */

        select percentile_cont(0.5 - 0.5/2) within group (order by petal_length ) from "analytics"."analytics"."stg_iris"
    
[0m09:50:02.593503 [debug] [Thread-3  ]: SQL status: SELECT 1 in 0.001 seconds
[0m09:50:02.597540 [debug] [Thread-3  ]: Using postgres connection "model.homework.iris_processed"
[0m09:50:02.599427 [debug] [Thread-3  ]: On model.homework.iris_processed: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "homework", "target_name": "dev", "node_id": "model.homework.iris_processed"} */

        select percentile_cont(0.5 + 0.5/2) within group (order by petal_length ) from "analytics"."analytics"."stg_iris"
    
[0m09:50:02.602229 [debug] [Thread-3  ]: SQL status: SELECT 1 in 0.001 seconds
[0m09:50:02.609573 [debug] [Thread-3  ]: Using postgres connection "model.homework.iris_processed"
[0m09:50:02.611496 [debug] [Thread-3  ]: On model.homework.iris_processed: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "homework", "target_name": "dev", "node_id": "model.homework.iris_processed"} */

        select percentile_cont(0.5) within group (order by petal_width ) from "analytics"."analytics"."stg_iris"
    
[0m09:50:02.614006 [debug] [Thread-3  ]: SQL status: SELECT 1 in 0.001 seconds
[0m09:50:02.617795 [debug] [Thread-3  ]: Using postgres connection "model.homework.iris_processed"
[0m09:50:02.619792 [debug] [Thread-3  ]: On model.homework.iris_processed: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "homework", "target_name": "dev", "node_id": "model.homework.iris_processed"} */

        select percentile_cont(0.5 - 0.5/2) within group (order by petal_width ) from "analytics"."analytics"."stg_iris"
    
[0m09:50:02.622485 [debug] [Thread-3  ]: SQL status: SELECT 1 in 0.001 seconds
[0m09:50:02.626790 [debug] [Thread-3  ]: Using postgres connection "model.homework.iris_processed"
[0m09:50:02.628474 [debug] [Thread-3  ]: On model.homework.iris_processed: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "homework", "target_name": "dev", "node_id": "model.homework.iris_processed"} */

        select percentile_cont(0.5 + 0.5/2) within group (order by petal_width ) from "analytics"."analytics"."stg_iris"
    
[0m09:50:02.630808 [debug] [Thread-3  ]: SQL status: SELECT 1 in 0.001 seconds
[0m09:50:02.655845 [debug] [Thread-3  ]: Using postgres connection "model.homework.iris_processed"
[0m09:50:02.657716 [debug] [Thread-3  ]: On model.homework.iris_processed: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "homework", "target_name": "dev", "node_id": "model.homework.iris_processed"} */

            select percentile_cont(0.5) within group (order by sepal_length ) from "analytics"."analytics"."stg_iris"
        
[0m09:50:02.660061 [debug] [Thread-3  ]: SQL status: SELECT 1 in 0.001 seconds
[0m09:50:02.664912 [debug] [Thread-3  ]: Using postgres connection "model.homework.iris_processed"
[0m09:50:02.666849 [debug] [Thread-3  ]: On model.homework.iris_processed: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "homework", "target_name": "dev", "node_id": "model.homework.iris_processed"} */

            select percentile_cont(0.5) within group (order by sepal_width ) from "analytics"."analytics"."stg_iris"
        
[0m09:50:02.669718 [debug] [Thread-3  ]: SQL status: SELECT 1 in 0.001 seconds
[0m09:50:02.674721 [debug] [Thread-3  ]: Using postgres connection "model.homework.iris_processed"
[0m09:50:02.681081 [debug] [Thread-3  ]: On model.homework.iris_processed: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "homework", "target_name": "dev", "node_id": "model.homework.iris_processed"} */

            select percentile_cont(0.5) within group (order by petal_length ) from "analytics"."analytics"."stg_iris"
        
[0m09:50:02.683636 [debug] [Thread-3  ]: SQL status: SELECT 1 in 0.001 seconds
[0m09:50:02.689813 [debug] [Thread-3  ]: Using postgres connection "model.homework.iris_processed"
[0m09:50:02.691941 [debug] [Thread-3  ]: On model.homework.iris_processed: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "homework", "target_name": "dev", "node_id": "model.homework.iris_processed"} */

            select percentile_cont(0.5) within group (order by petal_width ) from "analytics"."analytics"."stg_iris"
        
[0m09:50:02.694395 [debug] [Thread-3  ]: SQL status: SELECT 1 in 0.001 seconds
[0m09:50:02.782355 [debug] [Thread-3  ]: Using postgres connection "model.homework.iris_processed"
[0m09:50:02.784234 [debug] [Thread-3  ]: On model.homework.iris_processed: BEGIN
[0m09:50:02.787776 [debug] [Thread-3  ]: SQL status: BEGIN in 0.000 seconds
[0m09:50:02.790365 [debug] [Thread-3  ]: Using postgres connection "model.homework.iris_processed"
[0m09:50:02.792630 [debug] [Thread-3  ]: On model.homework.iris_processed: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "homework", "target_name": "dev", "node_id": "model.homework.iris_processed"} */
select
                species as value

            from "analytics"."analytics"."stg_iris"

            
            where species is not null  and true
            

            group by species
            order by species

            

        
[0m09:50:02.797898 [debug] [Thread-3  ]: SQL status: SELECT 3 in 0.003 seconds
[0m09:50:02.813604 [debug] [Thread-3  ]: Writing injected SQL for node "model.homework.iris_processed"
[0m09:50:02.826364 [debug] [Thread-3  ]: Began executing node model.homework.iris_processed
[0m09:50:02.889336 [debug] [Thread-3  ]: Writing runtime sql for node "model.homework.iris_processed"
[0m09:50:02.901235 [debug] [Thread-3  ]: Using postgres connection "model.homework.iris_processed"
[0m09:50:02.905020 [debug] [Thread-3  ]: On model.homework.iris_processed: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "homework", "target_name": "dev", "node_id": "model.homework.iris_processed"} */

  
    

  create  table "analytics"."analytics"."iris_processed__dbt_tmp"
  
  
    as
  
  (
    

with import_iris as (
    select *
    from "analytics"."analytics"."stg_iris"
)
select
    sepal_length,
    sepal_width,
    petal_length,
    petal_width,
    -- K Bins Discretization
    
        

    
        NTILE(5) over (order by sepal_length)
    

 as sepal_length_quantile_bin,
        

    
        
        floor(
        (
            sepal_length - (min(sepal_length) over ())
        )
        /
        (
            ((max(sepal_length) over ()) - (min(sepal_length) over ())) / 4::float
        )
        ) + 1
    

 as sepal_length_uniform_bin,
    
        

    
        NTILE(5) over (order by sepal_width)
    

 as sepal_width_quantile_bin,
        

    
        
        floor(
        (
            sepal_width - (min(sepal_width) over ())
        )
        /
        (
            ((max(sepal_width) over ()) - (min(sepal_width) over ())) / 4::float
        )
        ) + 1
    

 as sepal_width_uniform_bin,
    
        

    
        NTILE(5) over (order by petal_length)
    

 as petal_length_quantile_bin,
        

    
        
        floor(
        (
            petal_length - (min(petal_length) over ())
        )
        /
        (
            ((max(petal_length) over ()) - (min(petal_length) over ())) / 4::float
        )
        ) + 1
    

 as petal_length_uniform_bin,
    
        

    
        NTILE(5) over (order by petal_width)
    

 as petal_width_quantile_bin,
        

    
        
        floor(
        (
            petal_width - (min(petal_width) over ())
        )
        /
        (
            ((max(petal_width) over ()) - (min(petal_width) over ())) / 4::float
        )
        ) + 1
    

 as petal_width_uniform_bin,
    
-- Scaling
    
        

    

    
    
    

    
    
    

    (
        sepal_length - 5.8
    )
    /
    (
        6.4 - 5.1
    )

 as sepal_length_robust_scaled,
        

    (sepal_length) / (max(abs(sepal_length)) over ())::FLOAT

 as sepal_length_max_absolute_scaled,
        

    
    (
        ((sepal_length) - (min(sepal_length) over ()))
        /
        ((max(sepal_length) over ()) - (min(sepal_length) over ()))::FLOAT
    )
    *
    (1.0 - 0.0)
    +
    0.0

 as sepal_length_max_min_max_scaled,
    
        

    

    
    
    

    
    
    

    (
        sepal_width - 3.0
    )
    /
    (
        3.3 - 2.8
    )

 as sepal_width_robust_scaled,
        

    (sepal_width) / (max(abs(sepal_width)) over ())::FLOAT

 as sepal_width_max_absolute_scaled,
        

    
    (
        ((sepal_width) - (min(sepal_width) over ()))
        /
        ((max(sepal_width) over ()) - (min(sepal_width) over ()))::FLOAT
    )
    *
    (1.0 - 0.0)
    +
    0.0

 as sepal_width_max_min_max_scaled,
    
        

    

    
    
    

    
    
    

    (
        petal_length - 4.35
    )
    /
    (
        5.1 - 1.6
    )

 as petal_length_robust_scaled,
        

    (petal_length) / (max(abs(petal_length)) over ())::FLOAT

 as petal_length_max_absolute_scaled,
        

    
    (
        ((petal_length) - (min(petal_length) over ()))
        /
        ((max(petal_length) over ()) - (min(petal_length) over ()))::FLOAT
    )
    *
    (1.0 - 0.0)
    +
    0.0

 as petal_length_max_min_max_scaled,
    
        

    

    
    
    

    
    
    

    (
        petal_width - 1.3
    )
    /
    (
        1.8 - 0.3
    )

 as petal_width_robust_scaled,
        

    (petal_width) / (max(abs(petal_width)) over ())::FLOAT

 as petal_width_max_absolute_scaled,
        

    
    (
        ((petal_width) - (min(petal_width) over ()))
        /
        ((max(petal_width) over ()) - (min(petal_width) over ()))::FLOAT
    )
    *
    (1.0 - 0.0)
    +
    0.0

 as petal_width_max_min_max_scaled,
    

    -- Log Transformation
    
        

    case
        when sepal_length is null or sepal_length + 0 <= 0 then null
        else log(10, sepal_length + 0)
    end

 as sepal_length_logged,
    
        

    case
        when sepal_width is null or sepal_width + 0 <= 0 then null
        else log(10, sepal_width + 0)
    end

 as sepal_width_logged,
    
        

    case
        when petal_length is null or petal_length + 0 <= 0 then null
        else log(10, petal_length + 0)
    end

 as petal_length_logged,
    
        

    case
        when petal_width is null or petal_width + 0 <= 0 then null
        else log(10, petal_width + 0)
    end

 as petal_width_logged,
    

    -- Binarization
    
        

    

    
        

        
    

    case
        when sepal_length >=
            
                5.8
            
            then 1
        else 0
    end

 as sepal_length_binarized,
    
        

    

    
        

        
    

    case
        when sepal_width >=
            
                3.0
            
            then 1
        else 0
    end

 as sepal_width_binarized,
    
        

    

    
        

        
    

    case
        when petal_length >=
            
                4.35
            
            then 1
        else 0
    end

 as petal_length_binarized,
    
        

    

    
        

        
    

    case
        when petal_width >=
            
                1.3
            
            then 1
        else 0
    end

 as petal_width_binarized,
    

    -- Standardization
    
        

    
    (
        (sepal_length - avg(sepal_length) over ())
        /
        (stddev(sepal_length) over ())::FLOAT
    )
    *
    1
    +
    0

 as sepal_length_standardized,
    
        

    
    (
        (sepal_width - avg(sepal_width) over ())
        /
        (stddev(sepal_width) over ())::FLOAT
    )
    *
    1
    +
    0

 as sepal_width_standardized,
    
        

    
    (
        (petal_length - avg(petal_length) over ())
        /
        (stddev(petal_length) over ())::FLOAT
    )
    *
    1
    +
    0

 as petal_length_standardized,
    
        

    
    (
        (petal_width - avg(petal_width) over ())
        /
        (stddev(petal_width) over ())::FLOAT
    )
    *
    1
    +
    0

 as petal_width_standardized,
    
-- Interactions
    
        
            
            
            

    
        (sepal_length * sepal_width)
    

 as sepal_length_x_sepal_width_interaction,
            

    
        (sepal_length + sepal_width)
    

 as sepal_length_plus_sepal_width_interaction,
        
            
            
            

    
        (sepal_length * petal_length)
    

 as sepal_length_x_petal_length_interaction,
            

    
        (sepal_length + petal_length)
    

 as sepal_length_plus_petal_length_interaction,
        
            
            
            

    
        (sepal_length * petal_width)
    

 as sepal_length_x_petal_width_interaction,
            

    
        (sepal_length + petal_width)
    

 as sepal_length_plus_petal_width_interaction,
        
    
        
            
            
            

    
        (sepal_width * petal_length)
    

 as sepal_width_x_petal_length_interaction,
            

    
        (sepal_width + petal_length)
    

 as sepal_width_plus_petal_length_interaction,
        
            
            
            

    
        (sepal_width * petal_width)
    

 as sepal_width_x_petal_width_interaction,
            

    
        (sepal_width + petal_width)
    

 as sepal_width_plus_petal_width_interaction,
        
    
        
            
            
            

    
        (petal_length * petal_width)
    

 as petal_length_x_petal_width_interaction,
            

    
        (petal_length + petal_width)
    

 as petal_length_plus_petal_width_interaction,
        
    
        
    
species,    
    -- Label Encoding
    

    dense_rank() over (order by species) - 1

 as species_label_encoded,
    -- One Hot Encoding
    

    

    
        
    

    

    

        case
            when species = 'setosa' then 1
            else 0
        end as is_species__setosa,

    

        case
            when species = 'versicolor' then 1
            else 0
        end as is_species__versicolor,

    

        case
            when species = 'virginica' then 1
            else 0
        end as is_species__virginica,

    

    case
        when species is null then 1
        else 0
    end as is_species__


from "analytics"."analytics"."stg_iris"
  );
  
[0m09:50:02.987206 [debug] [Thread-3  ]: SQL status: SELECT 150 in 0.078 seconds
[0m09:50:03.005709 [debug] [Thread-3  ]: Using postgres connection "model.homework.iris_processed"
[0m09:50:03.007466 [debug] [Thread-3  ]: On model.homework.iris_processed: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "homework", "target_name": "dev", "node_id": "model.homework.iris_processed"} */
alter table "analytics"."analytics"."iris_processed" rename to "iris_processed__dbt_backup"
[0m09:50:03.010532 [debug] [Thread-3  ]: SQL status: ALTER TABLE in 0.001 seconds
[0m09:50:03.020595 [debug] [Thread-3  ]: Using postgres connection "model.homework.iris_processed"
[0m09:50:03.022469 [debug] [Thread-3  ]: On model.homework.iris_processed: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "homework", "target_name": "dev", "node_id": "model.homework.iris_processed"} */
alter table "analytics"."analytics"."iris_processed__dbt_tmp" rename to "iris_processed"
[0m09:50:03.024881 [debug] [Thread-3  ]: SQL status: ALTER TABLE in 0.001 seconds
[0m09:50:03.029604 [debug] [Thread-3  ]: On model.homework.iris_processed: COMMIT
[0m09:50:03.031721 [debug] [Thread-3  ]: Using postgres connection "model.homework.iris_processed"
[0m09:50:03.033420 [debug] [Thread-3  ]: On model.homework.iris_processed: COMMIT
[0m09:50:03.038172 [debug] [Thread-3  ]: SQL status: COMMIT in 0.003 seconds
[0m09:50:03.045422 [debug] [Thread-3  ]: Applying DROP to: "analytics"."analytics"."iris_processed__dbt_backup"
[0m09:50:03.052613 [debug] [Thread-3  ]: Using postgres connection "model.homework.iris_processed"
[0m09:50:03.055791 [debug] [Thread-3  ]: On model.homework.iris_processed: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "homework", "target_name": "dev", "node_id": "model.homework.iris_processed"} */
drop table if exists "analytics"."analytics"."iris_processed__dbt_backup" cascade
[0m09:50:03.068989 [debug] [Thread-3  ]: SQL status: DROP TABLE in 0.011 seconds
[0m09:50:03.073260 [debug] [Thread-3  ]: On model.homework.iris_processed: Close
[0m09:50:03.075620 [debug] [Thread-3  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '520b07dc-b70c-4088-85b0-de90f6721dfe', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f84dc245d90>]}
[0m09:50:03.078047 [info ] [Thread-3  ]: 2 of 2 OK created sql table model analytics.iris_processed ..................... [[32mSELECT 150[0m in 0.70s]
[0m09:50:03.080407 [debug] [Thread-3  ]: Finished running node model.homework.iris_processed
[0m09:50:03.084169 [debug] [MainThread]: Using postgres connection "master"
[0m09:50:03.086087 [debug] [MainThread]: On master: BEGIN
[0m09:50:03.088327 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m09:50:03.099388 [debug] [MainThread]: SQL status: BEGIN in 0.011 seconds
[0m09:50:03.101521 [debug] [MainThread]: On master: COMMIT
[0m09:50:03.104070 [debug] [MainThread]: Using postgres connection "master"
[0m09:50:03.106303 [debug] [MainThread]: On master: COMMIT
[0m09:50:03.108347 [debug] [MainThread]: SQL status: COMMIT in 0.000 seconds
[0m09:50:03.109942 [debug] [MainThread]: On master: Close
[0m09:50:03.111948 [debug] [MainThread]: Connection 'master' was properly closed.
[0m09:50:03.113554 [debug] [MainThread]: Connection 'model.homework.stg_iris' was properly closed.
[0m09:50:03.115195 [debug] [MainThread]: Connection 'model.homework.iris_processed' was properly closed.
[0m09:50:03.117777 [info ] [MainThread]: 
[0m09:50:03.120101 [info ] [MainThread]: Finished running 1 table model, 1 view model in 0 hours 0 minutes and 1.38 seconds (1.38s).
[0m09:50:03.123945 [debug] [MainThread]: Command end result
[0m09:50:03.248892 [debug] [MainThread]: Wrote artifact WritableManifest to /opt/airflow/dags/dbt/homework/target/manifest.json
[0m09:50:03.282983 [debug] [MainThread]: Wrote artifact SemanticManifest to /opt/airflow/dags/dbt/homework/target/semantic_manifest.json
[0m09:50:03.388560 [debug] [MainThread]: Wrote artifact RunExecutionResult to /opt/airflow/dags/dbt/homework/target/run_results.json
[0m09:50:03.396739 [info ] [MainThread]: 
[0m09:50:03.404203 [info ] [MainThread]: [32mCompleted successfully[0m
[0m09:50:03.409053 [info ] [MainThread]: 
[0m09:50:03.413714 [info ] [MainThread]: Done. PASS=2 WARN=0 ERROR=0 SKIP=0 TOTAL=2
[0m09:50:03.418515 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": true, "command_wall_clock_time": 6.178824, "process_in_blocks": "0", "process_kernel_time": 0.576542, "process_mem_max_rss": "121004", "process_out_blocks": "0", "process_user_time": 7.369258}
[0m09:50:03.423706 [debug] [MainThread]: Command `dbt run` succeeded at 09:50:03.423209 after 6.18 seconds
[0m09:50:03.426397 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f84e0d73ac0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f84e052b520>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f84dd038850>]}
[0m09:50:03.429409 [debug] [MainThread]: Flushing usage events
[0m09:50:04.019147 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m09:50:09.538933 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff7f1682a90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff7f07a45e0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff7f07a4580>]}


============================== 09:50:09.555084 | d4c11cd4-5624-403b-9064-7780b6fd325e ==============================
[0m09:50:09.555084 [info ] [MainThread]: Running with dbt=1.9.4
[0m09:50:09.557897 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': '/opt/airflow/dags/dbt', 'fail_fast': 'True', 'version_check': 'True', 'log_path': '/opt/airflow/dags/dbt/homework/logs', 'debug': 'False', 'warn_error': 'None', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'empty': 'None', 'log_format': 'default', 'invocation_command': 'dbt --profile homework test --project-dir=/opt/airflow/dags/dbt/homework --vars {"is_test": false, "data_date": "2025-04-23"} --fail-fast', 'introspect': 'True', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'target_path': 'None', 'static_parser': 'True', 'send_anonymous_usage_stats': 'True'}
[0m09:50:10.047550 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'd4c11cd4-5624-403b-9064-7780b6fd325e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff7f3079b20>]}
[0m09:50:10.185477 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': 'd4c11cd4-5624-403b-9064-7780b6fd325e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff7f1435430>]}
[0m09:50:10.188043 [info ] [MainThread]: Registered adapter: postgres=1.9.0
[0m09:50:10.467240 [debug] [MainThread]: checksum: f5df654a850f4b74beb13fbe0c7d8863b5b1a20bd535c3ac287d70e390b64d41, vars: {'data_date': '2025-04-23', 'is_test': False}, profile: homework, target: , version: 1.9.4
[0m09:50:12.931012 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m09:50:12.933054 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m09:50:12.951373 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 1 unused configuration paths:
- seeds.homework.iris_dataset
[0m09:50:13.039970 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'd4c11cd4-5624-403b-9064-7780b6fd325e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff7eead2130>]}
[0m09:50:13.357354 [debug] [MainThread]: Wrote artifact WritableManifest to /opt/airflow/dags/dbt/homework/target/manifest.json
[0m09:50:13.376852 [debug] [MainThread]: Wrote artifact SemanticManifest to /opt/airflow/dags/dbt/homework/target/semantic_manifest.json
[0m09:50:13.461949 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'd4c11cd4-5624-403b-9064-7780b6fd325e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff7eea174c0>]}
[0m09:50:13.465151 [info ] [MainThread]: Found 2 models, 1 source, 587 macros
[0m09:50:13.467399 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'd4c11cd4-5624-403b-9064-7780b6fd325e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff7f0821a00>]}
[0m09:50:13.471090 [warn ] [MainThread]: Nothing to do. Try checking your model configs and model specification args
[0m09:50:13.476157 [debug] [MainThread]: Command end result
[0m09:50:13.644165 [debug] [MainThread]: Wrote artifact WritableManifest to /opt/airflow/dags/dbt/homework/target/manifest.json
[0m09:50:13.661119 [debug] [MainThread]: Wrote artifact SemanticManifest to /opt/airflow/dags/dbt/homework/target/semantic_manifest.json
[0m09:50:13.683635 [debug] [MainThread]: Wrote artifact RunExecutionResult to /opt/airflow/dags/dbt/homework/target/run_results.json
[0m09:50:13.687595 [debug] [MainThread]: Resource report: {"command_name": "test", "command_success": true, "command_wall_clock_time": 4.290678, "process_in_blocks": "592", "process_kernel_time": 0.409162, "process_mem_max_rss": "104568", "process_out_blocks": "0", "process_user_time": 5.269213}
[0m09:50:13.691022 [debug] [MainThread]: Command `dbt test` succeeded at 09:50:13.690699 after 4.29 seconds
[0m09:50:13.694138 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff7f1682a90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff7f14ce7f0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff7eea72fa0>]}
[0m09:50:13.697787 [debug] [MainThread]: Flushing usage events
[0m09:50:14.264593 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m10:36:42.277229 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fea87c9ca30>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fea86dbd400>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fea86dbd3a0>]}


============================== 10:36:42.289565 | a8773d4e-75f9-4cc5-bd5c-bd3232dcb5c1 ==============================
[0m10:36:42.289565 [info ] [MainThread]: Running with dbt=1.9.4
[0m10:36:42.291869 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': '/opt/airflow/dags/dbt', 'version_check': 'True', 'debug': 'False', 'log_path': '/opt/airflow/dags/dbt/homework/logs', 'fail_fast': 'False', 'warn_error': 'None', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'empty': 'False', 'log_format': 'default', 'static_parser': 'True', 'invocation_command': 'dbt --profile homework run --project-dir=/opt/airflow/dags/dbt/homework --vars {"is_test": false, "data_date": "2025-04-23"}', 'introspect': 'True', 'target_path': 'None', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'send_anonymous_usage_stats': 'True'}
[0m10:36:42.800768 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'a8773d4e-75f9-4cc5-bd5c-bd3232dcb5c1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fea85588f70>]}
[0m10:36:42.932845 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': 'a8773d4e-75f9-4cc5-bd5c-bd3232dcb5c1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fea86d81f40>]}
[0m10:36:42.935332 [info ] [MainThread]: Registered adapter: postgres=1.9.0
[0m10:36:43.240963 [debug] [MainThread]: checksum: f5df654a850f4b74beb13fbe0c7d8863b5b1a20bd535c3ac287d70e390b64d41, vars: {'data_date': '2025-04-23', 'is_test': False}, profile: homework, target: , version: 1.9.4
[0m10:36:45.426489 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m10:36:45.428190 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m10:36:45.444512 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 1 unused configuration paths:
- seeds.homework.iris_dataset
[0m10:36:45.529246 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'a8773d4e-75f9-4cc5-bd5c-bd3232dcb5c1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fea850e9130>]}
[0m10:36:45.853747 [debug] [MainThread]: Wrote artifact WritableManifest to /opt/airflow/dags/dbt/homework/target/manifest.json
[0m10:36:45.877654 [debug] [MainThread]: Wrote artifact SemanticManifest to /opt/airflow/dags/dbt/homework/target/semantic_manifest.json
[0m10:36:45.928566 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'a8773d4e-75f9-4cc5-bd5c-bd3232dcb5c1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fea85089ac0>]}
[0m10:36:45.931522 [info ] [MainThread]: Found 2 models, 1 source, 587 macros
[0m10:36:45.933820 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'a8773d4e-75f9-4cc5-bd5c-bd3232dcb5c1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fea86e239d0>]}
[0m10:36:45.937865 [info ] [MainThread]: 
[0m10:36:45.939857 [info ] [MainThread]: Concurrency: 4 threads (target='dev')
[0m10:36:45.941761 [info ] [MainThread]: 
[0m10:36:45.943985 [debug] [MainThread]: Acquiring new postgres connection 'master'
[0m10:36:45.955682 [debug] [ThreadPool]: Acquiring new postgres connection 'list_analytics'
[0m10:36:46.086649 [debug] [ThreadPool]: Using postgres connection "list_analytics"
[0m10:36:46.088518 [debug] [ThreadPool]: On list_analytics: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "homework", "target_name": "dev", "connection_name": "list_analytics"} */

    select distinct nspname from pg_namespace
  
[0m10:36:46.090181 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m10:36:46.119955 [debug] [ThreadPool]: SQL status: SELECT 6 in 0.030 seconds
[0m10:36:46.123426 [debug] [ThreadPool]: On list_analytics: Close
[0m10:36:46.127346 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_analytics, now list_analytics_analytics)
[0m10:36:46.144007 [debug] [ThreadPool]: Using postgres connection "list_analytics_analytics"
[0m10:36:46.145988 [debug] [ThreadPool]: On list_analytics_analytics: BEGIN
[0m10:36:46.148204 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m10:36:46.161840 [debug] [ThreadPool]: SQL status: BEGIN in 0.014 seconds
[0m10:36:46.165181 [debug] [ThreadPool]: Using postgres connection "list_analytics_analytics"
[0m10:36:46.167935 [debug] [ThreadPool]: On list_analytics_analytics: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "homework", "target_name": "dev", "connection_name": "list_analytics_analytics"} */
select
      'analytics' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'analytics'
    union all
    select
      'analytics' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'analytics'
    union all
    select
      'analytics' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'analytics'
  
[0m10:36:46.184006 [debug] [ThreadPool]: SQL status: SELECT 3 in 0.014 seconds
[0m10:36:46.188060 [debug] [ThreadPool]: On list_analytics_analytics: ROLLBACK
[0m10:36:46.190503 [debug] [ThreadPool]: On list_analytics_analytics: Close
[0m10:36:46.204834 [debug] [MainThread]: Using postgres connection "master"
[0m10:36:46.207315 [debug] [MainThread]: On master: BEGIN
[0m10:36:46.209249 [debug] [MainThread]: Opening a new connection, currently in state init
[0m10:36:46.223011 [debug] [MainThread]: SQL status: BEGIN in 0.014 seconds
[0m10:36:46.228451 [debug] [MainThread]: Using postgres connection "master"
[0m10:36:46.231729 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "homework", "target_name": "dev", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select distinct
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v', 'm')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
[0m10:36:46.261946 [debug] [MainThread]: SQL status: SELECT 1 in 0.025 seconds
[0m10:36:46.268306 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'a8773d4e-75f9-4cc5-bd5c-bd3232dcb5c1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fea8462b8e0>]}
[0m10:36:46.271044 [debug] [MainThread]: On master: ROLLBACK
[0m10:36:46.273968 [debug] [MainThread]: Using postgres connection "master"
[0m10:36:46.276396 [debug] [MainThread]: On master: BEGIN
[0m10:36:46.279257 [debug] [MainThread]: SQL status: BEGIN in 0.001 seconds
[0m10:36:46.283473 [debug] [MainThread]: On master: COMMIT
[0m10:36:46.286507 [debug] [MainThread]: Using postgres connection "master"
[0m10:36:46.288744 [debug] [MainThread]: On master: COMMIT
[0m10:36:46.291475 [debug] [MainThread]: SQL status: COMMIT in 0.000 seconds
[0m10:36:46.293898 [debug] [MainThread]: On master: Close
[0m10:36:46.306448 [debug] [Thread-1  ]: Began running node model.homework.stg_iris
[0m10:36:46.309806 [info ] [Thread-1  ]: 1 of 2 START sql view model analytics.stg_iris ................................. [RUN]
[0m10:36:46.312549 [debug] [Thread-1  ]: Re-using an available connection from the pool (formerly list_analytics_analytics, now model.homework.stg_iris)
[0m10:36:46.315420 [debug] [Thread-1  ]: Began compiling node model.homework.stg_iris
[0m10:36:46.339427 [debug] [Thread-1  ]: Writing injected SQL for node "model.homework.stg_iris"
[0m10:36:46.353362 [debug] [Thread-1  ]: Began executing node model.homework.stg_iris
[0m10:36:46.437101 [debug] [Thread-1  ]: Writing runtime sql for node "model.homework.stg_iris"
[0m10:36:46.451383 [debug] [Thread-1  ]: Using postgres connection "model.homework.stg_iris"
[0m10:36:46.453486 [debug] [Thread-1  ]: On model.homework.stg_iris: BEGIN
[0m10:36:46.455417 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
[0m10:36:46.469691 [debug] [Thread-1  ]: SQL status: BEGIN in 0.014 seconds
[0m10:36:46.472276 [debug] [Thread-1  ]: Using postgres connection "model.homework.stg_iris"
[0m10:36:46.474643 [debug] [Thread-1  ]: On model.homework.stg_iris: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "homework", "target_name": "dev", "node_id": "model.homework.stg_iris"} */

  create view "analytics"."analytics"."stg_iris__dbt_tmp"
    
    
  as (
    with source as (
    select * from "analytics"."analytics"."iris_dataset"
)

select
    cast(sepal_length as numeric) as sepal_length,
    cast(sepal_width as numeric) as sepal_width,
    cast(petal_length as numeric) as petal_length,
    cast(petal_width as numeric) as petal_width,
    species
from source
  );
[0m10:36:46.496120 [debug] [Thread-1  ]: SQL status: CREATE VIEW in 0.019 seconds
[0m10:36:46.515514 [debug] [Thread-1  ]: Using postgres connection "model.homework.stg_iris"
[0m10:36:46.518425 [debug] [Thread-1  ]: On model.homework.stg_iris: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "homework", "target_name": "dev", "node_id": "model.homework.stg_iris"} */
alter table "analytics"."analytics"."stg_iris" rename to "stg_iris__dbt_backup"
[0m10:36:46.521848 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.001 seconds
[0m10:36:46.531205 [debug] [Thread-1  ]: Using postgres connection "model.homework.stg_iris"
[0m10:36:46.534266 [debug] [Thread-1  ]: On model.homework.stg_iris: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "homework", "target_name": "dev", "node_id": "model.homework.stg_iris"} */
alter table "analytics"."analytics"."stg_iris__dbt_tmp" rename to "stg_iris"
[0m10:36:46.537367 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.001 seconds
[0m10:36:46.587257 [debug] [Thread-1  ]: On model.homework.stg_iris: COMMIT
[0m10:36:46.589695 [debug] [Thread-1  ]: Using postgres connection "model.homework.stg_iris"
[0m10:36:46.591803 [debug] [Thread-1  ]: On model.homework.stg_iris: COMMIT
[0m10:36:46.602092 [debug] [Thread-1  ]: SQL status: COMMIT in 0.008 seconds
[0m10:36:46.618484 [debug] [Thread-1  ]: Applying DROP to: "analytics"."analytics"."stg_iris__dbt_backup"
[0m10:36:46.629664 [debug] [Thread-1  ]: Using postgres connection "model.homework.stg_iris"
[0m10:36:46.632220 [debug] [Thread-1  ]: On model.homework.stg_iris: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "homework", "target_name": "dev", "node_id": "model.homework.stg_iris"} */
drop view if exists "analytics"."analytics"."stg_iris__dbt_backup" cascade
[0m10:36:46.641619 [debug] [Thread-1  ]: SQL status: DROP VIEW in 0.007 seconds
[0m10:36:46.648887 [debug] [Thread-1  ]: On model.homework.stg_iris: Close
[0m10:36:46.654421 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'a8773d4e-75f9-4cc5-bd5c-bd3232dcb5c1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fea845a7220>]}
[0m10:36:46.657189 [info ] [Thread-1  ]: 1 of 2 OK created sql view model analytics.stg_iris ............................ [[32mCREATE VIEW[0m in 0.34s]
[0m10:36:46.659649 [debug] [Thread-1  ]: Finished running node model.homework.stg_iris
[0m10:36:46.662614 [debug] [Thread-3  ]: Began running node model.homework.iris_processed
[0m10:36:46.665185 [info ] [Thread-3  ]: 2 of 2 START sql table model analytics.iris_processed .......................... [RUN]
[0m10:36:46.668035 [debug] [Thread-3  ]: Acquiring new postgres connection 'model.homework.iris_processed'
[0m10:36:46.673273 [debug] [Thread-3  ]: Began compiling node model.homework.iris_processed
[0m10:36:46.847079 [debug] [Thread-3  ]: Using postgres connection "model.homework.iris_processed"
[0m10:36:46.849631 [debug] [Thread-3  ]: On model.homework.iris_processed: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "homework", "target_name": "dev", "node_id": "model.homework.iris_processed"} */

        select percentile_cont(0.5) within group (order by sepal_length ) from "analytics"."analytics"."stg_iris"
    
[0m10:36:46.851538 [debug] [Thread-3  ]: Opening a new connection, currently in state init
[0m10:36:46.869163 [debug] [Thread-3  ]: SQL status: SELECT 1 in 0.018 seconds
[0m10:36:46.873255 [debug] [Thread-3  ]: Using postgres connection "model.homework.iris_processed"
[0m10:36:46.874956 [debug] [Thread-3  ]: On model.homework.iris_processed: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "homework", "target_name": "dev", "node_id": "model.homework.iris_processed"} */

        select percentile_cont(0.5 - 0.5/2) within group (order by sepal_length ) from "analytics"."analytics"."stg_iris"
    
[0m10:36:46.879027 [debug] [Thread-3  ]: SQL status: SELECT 1 in 0.002 seconds
[0m10:36:46.883817 [debug] [Thread-3  ]: Using postgres connection "model.homework.iris_processed"
[0m10:36:46.885630 [debug] [Thread-3  ]: On model.homework.iris_processed: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "homework", "target_name": "dev", "node_id": "model.homework.iris_processed"} */

        select percentile_cont(0.5 + 0.5/2) within group (order by sepal_length ) from "analytics"."analytics"."stg_iris"
    
[0m10:36:46.888078 [debug] [Thread-3  ]: SQL status: SELECT 1 in 0.001 seconds
[0m10:36:46.907857 [debug] [Thread-3  ]: Using postgres connection "model.homework.iris_processed"
[0m10:36:46.909683 [debug] [Thread-3  ]: On model.homework.iris_processed: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "homework", "target_name": "dev", "node_id": "model.homework.iris_processed"} */

        select percentile_cont(0.5) within group (order by sepal_width ) from "analytics"."analytics"."stg_iris"
    
[0m10:36:46.911997 [debug] [Thread-3  ]: SQL status: SELECT 1 in 0.001 seconds
[0m10:36:46.916438 [debug] [Thread-3  ]: Using postgres connection "model.homework.iris_processed"
[0m10:36:46.918177 [debug] [Thread-3  ]: On model.homework.iris_processed: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "homework", "target_name": "dev", "node_id": "model.homework.iris_processed"} */

        select percentile_cont(0.5 - 0.5/2) within group (order by sepal_width ) from "analytics"."analytics"."stg_iris"
    
[0m10:36:46.920502 [debug] [Thread-3  ]: SQL status: SELECT 1 in 0.001 seconds
[0m10:36:46.924379 [debug] [Thread-3  ]: Using postgres connection "model.homework.iris_processed"
[0m10:36:46.926022 [debug] [Thread-3  ]: On model.homework.iris_processed: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "homework", "target_name": "dev", "node_id": "model.homework.iris_processed"} */

        select percentile_cont(0.5 + 0.5/2) within group (order by sepal_width ) from "analytics"."analytics"."stg_iris"
    
[0m10:36:46.928197 [debug] [Thread-3  ]: SQL status: SELECT 1 in 0.001 seconds
[0m10:36:46.934386 [debug] [Thread-3  ]: Using postgres connection "model.homework.iris_processed"
[0m10:36:46.936117 [debug] [Thread-3  ]: On model.homework.iris_processed: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "homework", "target_name": "dev", "node_id": "model.homework.iris_processed"} */

        select percentile_cont(0.5) within group (order by petal_length ) from "analytics"."analytics"."stg_iris"
    
[0m10:36:46.938531 [debug] [Thread-3  ]: SQL status: SELECT 1 in 0.001 seconds
[0m10:36:46.942380 [debug] [Thread-3  ]: Using postgres connection "model.homework.iris_processed"
[0m10:36:46.944022 [debug] [Thread-3  ]: On model.homework.iris_processed: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "homework", "target_name": "dev", "node_id": "model.homework.iris_processed"} */

        select percentile_cont(0.5 - 0.5/2) within group (order by petal_length ) from "analytics"."analytics"."stg_iris"
    
[0m10:36:46.946649 [debug] [Thread-3  ]: SQL status: SELECT 1 in 0.001 seconds
[0m10:36:46.950989 [debug] [Thread-3  ]: Using postgres connection "model.homework.iris_processed"
[0m10:36:46.952799 [debug] [Thread-3  ]: On model.homework.iris_processed: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "homework", "target_name": "dev", "node_id": "model.homework.iris_processed"} */

        select percentile_cont(0.5 + 0.5/2) within group (order by petal_length ) from "analytics"."analytics"."stg_iris"
    
[0m10:36:46.955153 [debug] [Thread-3  ]: SQL status: SELECT 1 in 0.001 seconds
[0m10:36:46.961552 [debug] [Thread-3  ]: Using postgres connection "model.homework.iris_processed"
[0m10:36:46.963162 [debug] [Thread-3  ]: On model.homework.iris_processed: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "homework", "target_name": "dev", "node_id": "model.homework.iris_processed"} */

        select percentile_cont(0.5) within group (order by petal_width ) from "analytics"."analytics"."stg_iris"
    
[0m10:36:46.966108 [debug] [Thread-3  ]: SQL status: SELECT 1 in 0.001 seconds
[0m10:36:46.969999 [debug] [Thread-3  ]: Using postgres connection "model.homework.iris_processed"
[0m10:36:46.971683 [debug] [Thread-3  ]: On model.homework.iris_processed: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "homework", "target_name": "dev", "node_id": "model.homework.iris_processed"} */

        select percentile_cont(0.5 - 0.5/2) within group (order by petal_width ) from "analytics"."analytics"."stg_iris"
    
[0m10:36:46.974019 [debug] [Thread-3  ]: SQL status: SELECT 1 in 0.001 seconds
[0m10:36:46.977863 [debug] [Thread-3  ]: Using postgres connection "model.homework.iris_processed"
[0m10:36:46.979669 [debug] [Thread-3  ]: On model.homework.iris_processed: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "homework", "target_name": "dev", "node_id": "model.homework.iris_processed"} */

        select percentile_cont(0.5 + 0.5/2) within group (order by petal_width ) from "analytics"."analytics"."stg_iris"
    
[0m10:36:46.982836 [debug] [Thread-3  ]: SQL status: SELECT 1 in 0.001 seconds
[0m10:36:47.007530 [debug] [Thread-3  ]: Using postgres connection "model.homework.iris_processed"
[0m10:36:47.009417 [debug] [Thread-3  ]: On model.homework.iris_processed: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "homework", "target_name": "dev", "node_id": "model.homework.iris_processed"} */

            select percentile_cont(0.5) within group (order by sepal_length ) from "analytics"."analytics"."stg_iris"
        
[0m10:36:47.011916 [debug] [Thread-3  ]: SQL status: SELECT 1 in 0.001 seconds
[0m10:36:47.023635 [debug] [Thread-3  ]: Using postgres connection "model.homework.iris_processed"
[0m10:36:47.026249 [debug] [Thread-3  ]: On model.homework.iris_processed: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "homework", "target_name": "dev", "node_id": "model.homework.iris_processed"} */

            select percentile_cont(0.5) within group (order by sepal_width ) from "analytics"."analytics"."stg_iris"
        
[0m10:36:47.029381 [debug] [Thread-3  ]: SQL status: SELECT 1 in 0.001 seconds
[0m10:36:47.036201 [debug] [Thread-3  ]: Using postgres connection "model.homework.iris_processed"
[0m10:36:47.038742 [debug] [Thread-3  ]: On model.homework.iris_processed: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "homework", "target_name": "dev", "node_id": "model.homework.iris_processed"} */

            select percentile_cont(0.5) within group (order by petal_length ) from "analytics"."analytics"."stg_iris"
        
[0m10:36:47.041848 [debug] [Thread-3  ]: SQL status: SELECT 1 in 0.001 seconds
[0m10:36:47.048093 [debug] [Thread-3  ]: Using postgres connection "model.homework.iris_processed"
[0m10:36:47.051034 [debug] [Thread-3  ]: On model.homework.iris_processed: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "homework", "target_name": "dev", "node_id": "model.homework.iris_processed"} */

            select percentile_cont(0.5) within group (order by petal_width ) from "analytics"."analytics"."stg_iris"
        
[0m10:36:47.053997 [debug] [Thread-3  ]: SQL status: SELECT 1 in 0.001 seconds
[0m10:36:47.134895 [debug] [Thread-3  ]: Using postgres connection "model.homework.iris_processed"
[0m10:36:47.136897 [debug] [Thread-3  ]: On model.homework.iris_processed: BEGIN
[0m10:36:47.139178 [debug] [Thread-3  ]: SQL status: BEGIN in 0.000 seconds
[0m10:36:47.141228 [debug] [Thread-3  ]: Using postgres connection "model.homework.iris_processed"
[0m10:36:47.143416 [debug] [Thread-3  ]: On model.homework.iris_processed: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "homework", "target_name": "dev", "node_id": "model.homework.iris_processed"} */
select
                species as value

            from "analytics"."analytics"."stg_iris"

            
            where species is not null  and true
            

            group by species
            order by species

            

        
[0m10:36:47.148847 [debug] [Thread-3  ]: SQL status: SELECT 3 in 0.003 seconds
[0m10:36:47.161430 [debug] [Thread-3  ]: Writing injected SQL for node "model.homework.iris_processed"
[0m10:36:47.175796 [debug] [Thread-3  ]: Began executing node model.homework.iris_processed
[0m10:36:47.243037 [debug] [Thread-3  ]: Writing runtime sql for node "model.homework.iris_processed"
[0m10:36:47.257363 [debug] [Thread-3  ]: Using postgres connection "model.homework.iris_processed"
[0m10:36:47.260500 [debug] [Thread-3  ]: On model.homework.iris_processed: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "homework", "target_name": "dev", "node_id": "model.homework.iris_processed"} */

  
    

  create  table "analytics"."analytics"."iris_processed__dbt_tmp"
  
  
    as
  
  (
    

with import_iris as (
    select *
    from "analytics"."analytics"."stg_iris"
)
select
    sepal_length,
    sepal_width,
    petal_length,
    petal_width,
    -- K Bins Discretization
    
        

    
        NTILE(5) over (order by sepal_length)
    

 as sepal_length_quantile_bin,
        

    
        
        floor(
        (
            sepal_length - (min(sepal_length) over ())
        )
        /
        (
            ((max(sepal_length) over ()) - (min(sepal_length) over ())) / 4::float
        )
        ) + 1
    

 as sepal_length_uniform_bin,
    
        

    
        NTILE(5) over (order by sepal_width)
    

 as sepal_width_quantile_bin,
        

    
        
        floor(
        (
            sepal_width - (min(sepal_width) over ())
        )
        /
        (
            ((max(sepal_width) over ()) - (min(sepal_width) over ())) / 4::float
        )
        ) + 1
    

 as sepal_width_uniform_bin,
    
        

    
        NTILE(5) over (order by petal_length)
    

 as petal_length_quantile_bin,
        

    
        
        floor(
        (
            petal_length - (min(petal_length) over ())
        )
        /
        (
            ((max(petal_length) over ()) - (min(petal_length) over ())) / 4::float
        )
        ) + 1
    

 as petal_length_uniform_bin,
    
        

    
        NTILE(5) over (order by petal_width)
    

 as petal_width_quantile_bin,
        

    
        
        floor(
        (
            petal_width - (min(petal_width) over ())
        )
        /
        (
            ((max(petal_width) over ()) - (min(petal_width) over ())) / 4::float
        )
        ) + 1
    

 as petal_width_uniform_bin,
    
-- Scaling
    
        

    

    
    
    

    
    
    

    (
        sepal_length - 5.8
    )
    /
    (
        6.4 - 5.1
    )

 as sepal_length_robust_scaled,
        

    (sepal_length) / (max(abs(sepal_length)) over ())::FLOAT

 as sepal_length_max_absolute_scaled,
        

    
    (
        ((sepal_length) - (min(sepal_length) over ()))
        /
        ((max(sepal_length) over ()) - (min(sepal_length) over ()))::FLOAT
    )
    *
    (1.0 - 0.0)
    +
    0.0

 as sepal_length_max_min_max_scaled,
    
        

    

    
    
    

    
    
    

    (
        sepal_width - 3.0
    )
    /
    (
        3.3 - 2.8
    )

 as sepal_width_robust_scaled,
        

    (sepal_width) / (max(abs(sepal_width)) over ())::FLOAT

 as sepal_width_max_absolute_scaled,
        

    
    (
        ((sepal_width) - (min(sepal_width) over ()))
        /
        ((max(sepal_width) over ()) - (min(sepal_width) over ()))::FLOAT
    )
    *
    (1.0 - 0.0)
    +
    0.0

 as sepal_width_max_min_max_scaled,
    
        

    

    
    
    

    
    
    

    (
        petal_length - 4.35
    )
    /
    (
        5.1 - 1.6
    )

 as petal_length_robust_scaled,
        

    (petal_length) / (max(abs(petal_length)) over ())::FLOAT

 as petal_length_max_absolute_scaled,
        

    
    (
        ((petal_length) - (min(petal_length) over ()))
        /
        ((max(petal_length) over ()) - (min(petal_length) over ()))::FLOAT
    )
    *
    (1.0 - 0.0)
    +
    0.0

 as petal_length_max_min_max_scaled,
    
        

    

    
    
    

    
    
    

    (
        petal_width - 1.3
    )
    /
    (
        1.8 - 0.3
    )

 as petal_width_robust_scaled,
        

    (petal_width) / (max(abs(petal_width)) over ())::FLOAT

 as petal_width_max_absolute_scaled,
        

    
    (
        ((petal_width) - (min(petal_width) over ()))
        /
        ((max(petal_width) over ()) - (min(petal_width) over ()))::FLOAT
    )
    *
    (1.0 - 0.0)
    +
    0.0

 as petal_width_max_min_max_scaled,
    

    -- Log Transformation
    
        

    case
        when sepal_length is null or sepal_length + 0 <= 0 then null
        else log(10, sepal_length + 0)
    end

 as sepal_length_logged,
    
        

    case
        when sepal_width is null or sepal_width + 0 <= 0 then null
        else log(10, sepal_width + 0)
    end

 as sepal_width_logged,
    
        

    case
        when petal_length is null or petal_length + 0 <= 0 then null
        else log(10, petal_length + 0)
    end

 as petal_length_logged,
    
        

    case
        when petal_width is null or petal_width + 0 <= 0 then null
        else log(10, petal_width + 0)
    end

 as petal_width_logged,
    

    -- Binarization
    
        

    

    
        

        
    

    case
        when sepal_length >=
            
                5.8
            
            then 1
        else 0
    end

 as sepal_length_binarized,
    
        

    

    
        

        
    

    case
        when sepal_width >=
            
                3.0
            
            then 1
        else 0
    end

 as sepal_width_binarized,
    
        

    

    
        

        
    

    case
        when petal_length >=
            
                4.35
            
            then 1
        else 0
    end

 as petal_length_binarized,
    
        

    

    
        

        
    

    case
        when petal_width >=
            
                1.3
            
            then 1
        else 0
    end

 as petal_width_binarized,
    

    -- Standardization
    
        

    
    (
        (sepal_length - avg(sepal_length) over ())
        /
        (stddev(sepal_length) over ())::FLOAT
    )
    *
    1
    +
    0

 as sepal_length_standardized,
    
        

    
    (
        (sepal_width - avg(sepal_width) over ())
        /
        (stddev(sepal_width) over ())::FLOAT
    )
    *
    1
    +
    0

 as sepal_width_standardized,
    
        

    
    (
        (petal_length - avg(petal_length) over ())
        /
        (stddev(petal_length) over ())::FLOAT
    )
    *
    1
    +
    0

 as petal_length_standardized,
    
        

    
    (
        (petal_width - avg(petal_width) over ())
        /
        (stddev(petal_width) over ())::FLOAT
    )
    *
    1
    +
    0

 as petal_width_standardized,
    
-- Interactions
    
        
            
            
            

    
        (sepal_length * sepal_width)
    

 as sepal_length_x_sepal_width_interaction,
            

    
        (sepal_length + sepal_width)
    

 as sepal_length_plus_sepal_width_interaction,
        
            
            
            

    
        (sepal_length * petal_length)
    

 as sepal_length_x_petal_length_interaction,
            

    
        (sepal_length + petal_length)
    

 as sepal_length_plus_petal_length_interaction,
        
            
            
            

    
        (sepal_length * petal_width)
    

 as sepal_length_x_petal_width_interaction,
            

    
        (sepal_length + petal_width)
    

 as sepal_length_plus_petal_width_interaction,
        
    
        
            
            
            

    
        (sepal_width * petal_length)
    

 as sepal_width_x_petal_length_interaction,
            

    
        (sepal_width + petal_length)
    

 as sepal_width_plus_petal_length_interaction,
        
            
            
            

    
        (sepal_width * petal_width)
    

 as sepal_width_x_petal_width_interaction,
            

    
        (sepal_width + petal_width)
    

 as sepal_width_plus_petal_width_interaction,
        
    
        
            
            
            

    
        (petal_length * petal_width)
    

 as petal_length_x_petal_width_interaction,
            

    
        (petal_length + petal_width)
    

 as petal_length_plus_petal_width_interaction,
        
    
        
    
species,    
    -- Label Encoding
    

    dense_rank() over (order by species) - 1

 as species_label_encoded,
    -- One Hot Encoding
    

    

    
        
    

    

    

        case
            when species = 'setosa' then 1
            else 0
        end as is_species__setosa,

    

        case
            when species = 'versicolor' then 1
            else 0
        end as is_species__versicolor,

    

        case
            when species = 'virginica' then 1
            else 0
        end as is_species__virginica,

    

    case
        when species is null then 1
        else 0
    end as is_species__


from "analytics"."analytics"."stg_iris"
  );
  
[0m10:36:47.311483 [debug] [Thread-3  ]: SQL status: SELECT 150 in 0.048 seconds
[0m10:36:47.329860 [debug] [Thread-3  ]: Using postgres connection "model.homework.iris_processed"
[0m10:36:47.332146 [debug] [Thread-3  ]: On model.homework.iris_processed: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "homework", "target_name": "dev", "node_id": "model.homework.iris_processed"} */
alter table "analytics"."analytics"."iris_processed" rename to "iris_processed__dbt_backup"
[0m10:36:47.335292 [debug] [Thread-3  ]: SQL status: ALTER TABLE in 0.001 seconds
[0m10:36:47.345477 [debug] [Thread-3  ]: Using postgres connection "model.homework.iris_processed"
[0m10:36:47.347443 [debug] [Thread-3  ]: On model.homework.iris_processed: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "homework", "target_name": "dev", "node_id": "model.homework.iris_processed"} */
alter table "analytics"."analytics"."iris_processed__dbt_tmp" rename to "iris_processed"
[0m10:36:47.350297 [debug] [Thread-3  ]: SQL status: ALTER TABLE in 0.000 seconds
[0m10:36:47.355528 [debug] [Thread-3  ]: On model.homework.iris_processed: COMMIT
[0m10:36:47.358068 [debug] [Thread-3  ]: Using postgres connection "model.homework.iris_processed"
[0m10:36:47.360113 [debug] [Thread-3  ]: On model.homework.iris_processed: COMMIT
[0m10:36:47.366779 [debug] [Thread-3  ]: SQL status: COMMIT in 0.005 seconds
[0m10:36:47.374647 [debug] [Thread-3  ]: Applying DROP to: "analytics"."analytics"."iris_processed__dbt_backup"
[0m10:36:47.381014 [debug] [Thread-3  ]: Using postgres connection "model.homework.iris_processed"
[0m10:36:47.383723 [debug] [Thread-3  ]: On model.homework.iris_processed: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "homework", "target_name": "dev", "node_id": "model.homework.iris_processed"} */
drop table if exists "analytics"."analytics"."iris_processed__dbt_backup" cascade
[0m10:36:47.445997 [debug] [Thread-3  ]: SQL status: DROP TABLE in 0.060 seconds
[0m10:36:47.451017 [debug] [Thread-3  ]: On model.homework.iris_processed: Close
[0m10:36:47.453443 [debug] [Thread-3  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'a8773d4e-75f9-4cc5-bd5c-bd3232dcb5c1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fea87e69490>]}
[0m10:36:47.456025 [info ] [Thread-3  ]: 2 of 2 OK created sql table model analytics.iris_processed ..................... [[32mSELECT 150[0m in 0.79s]
[0m10:36:47.458254 [debug] [Thread-3  ]: Finished running node model.homework.iris_processed
[0m10:36:47.462379 [debug] [MainThread]: Using postgres connection "master"
[0m10:36:47.464328 [debug] [MainThread]: On master: BEGIN
[0m10:36:47.466499 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m10:36:47.477499 [debug] [MainThread]: SQL status: BEGIN in 0.011 seconds
[0m10:36:47.480227 [debug] [MainThread]: On master: COMMIT
[0m10:36:47.482588 [debug] [MainThread]: Using postgres connection "master"
[0m10:36:47.484710 [debug] [MainThread]: On master: COMMIT
[0m10:36:47.487124 [debug] [MainThread]: SQL status: COMMIT in 0.000 seconds
[0m10:36:47.489128 [debug] [MainThread]: On master: Close
[0m10:36:47.491071 [debug] [MainThread]: Connection 'master' was properly closed.
[0m10:36:47.492761 [debug] [MainThread]: Connection 'model.homework.stg_iris' was properly closed.
[0m10:36:47.494839 [debug] [MainThread]: Connection 'model.homework.iris_processed' was properly closed.
[0m10:36:47.496763 [info ] [MainThread]: 
[0m10:36:47.499265 [info ] [MainThread]: Finished running 1 table model, 1 view model in 0 hours 0 minutes and 1.55 seconds (1.55s).
[0m10:36:47.503354 [debug] [MainThread]: Command end result
[0m10:36:47.607797 [debug] [MainThread]: Wrote artifact WritableManifest to /opt/airflow/dags/dbt/homework/target/manifest.json
[0m10:36:47.618725 [debug] [MainThread]: Wrote artifact SemanticManifest to /opt/airflow/dags/dbt/homework/target/semantic_manifest.json
[0m10:36:47.642669 [debug] [MainThread]: Wrote artifact RunExecutionResult to /opt/airflow/dags/dbt/homework/target/run_results.json
[0m10:36:47.644729 [info ] [MainThread]: 
[0m10:36:47.646754 [info ] [MainThread]: [32mCompleted successfully[0m
[0m10:36:47.649047 [info ] [MainThread]: 
[0m10:36:47.651287 [info ] [MainThread]: Done. PASS=2 WARN=0 ERROR=0 SKIP=0 TOTAL=2
[0m10:36:47.654787 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": true, "command_wall_clock_time": 5.5952926, "process_in_blocks": "0", "process_kernel_time": 1.445474, "process_mem_max_rss": "114692", "process_out_blocks": "0", "process_user_time": 8.473472}
[0m10:36:47.657193 [debug] [MainThread]: Command `dbt run` succeeded at 10:36:47.656952 after 5.60 seconds
[0m10:36:47.659067 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fea87c9ca30>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fea855a2a90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fea855a2340>]}
[0m10:36:47.660936 [debug] [MainThread]: Flushing usage events
[0m10:36:48.492614 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m10:39:57.965919 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd49cf34b20>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd49c0554c0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd49c055460>]}


============================== 10:39:57.984292 | 65721cdc-6b4f-4793-b8fc-f8ec56f151a3 ==============================
[0m10:39:57.984292 [info ] [MainThread]: Running with dbt=1.9.4
[0m10:39:57.986754 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'version_check': 'True', 'debug': 'False', 'log_path': '/opt/airflow/dags/dbt/homework/logs', 'fail_fast': 'False', 'profiles_dir': '/opt/airflow/dags/dbt', 'use_colors': 'True', 'use_experimental_parser': 'False', 'empty': 'False', 'quiet': 'False', 'no_print': 'None', 'log_format': 'default', 'invocation_command': 'dbt --profile homework run --project-dir=/opt/airflow/dags/dbt/homework --vars {"is_test": false, "data_date": "2025-04-23"}', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'introspect': 'True', 'target_path': 'None', 'static_parser': 'True', 'send_anonymous_usage_stats': 'True'}
[0m10:39:58.498819 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '65721cdc-6b4f-4793-b8fc-f8ec56f151a3', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd49c0f5ee0>]}
[0m10:39:58.657168 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '65721cdc-6b4f-4793-b8fc-f8ec56f151a3', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd49c7231c0>]}
[0m10:39:58.659865 [info ] [MainThread]: Registered adapter: postgres=1.9.0
[0m10:39:58.958924 [debug] [MainThread]: checksum: f5df654a850f4b74beb13fbe0c7d8863b5b1a20bd535c3ac287d70e390b64d41, vars: {'data_date': '2025-04-23', 'is_test': False}, profile: homework, target: , version: 1.9.4
[0m10:40:00.569761 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m10:40:00.571545 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m10:40:00.586250 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 1 unused configuration paths:
- seeds.homework.iris_dataset
[0m10:40:00.667469 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '65721cdc-6b4f-4793-b8fc-f8ec56f151a3', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd49a380130>]}
[0m10:40:00.987774 [debug] [MainThread]: Wrote artifact WritableManifest to /opt/airflow/dags/dbt/homework/target/manifest.json
[0m10:40:01.006646 [debug] [MainThread]: Wrote artifact SemanticManifest to /opt/airflow/dags/dbt/homework/target/semantic_manifest.json
[0m10:40:01.056163 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '65721cdc-6b4f-4793-b8fc-f8ec56f151a3', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd49a320f70>]}
[0m10:40:01.059115 [info ] [MainThread]: Found 2 models, 1 source, 587 macros
[0m10:40:01.061421 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '65721cdc-6b4f-4793-b8fc-f8ec56f151a3', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd49c0d2a60>]}
[0m10:40:01.065649 [info ] [MainThread]: 
[0m10:40:01.067427 [info ] [MainThread]: Concurrency: 4 threads (target='dev')
[0m10:40:01.069467 [info ] [MainThread]: 
[0m10:40:01.071875 [debug] [MainThread]: Acquiring new postgres connection 'master'
[0m10:40:01.084840 [debug] [ThreadPool]: Acquiring new postgres connection 'list_analytics'
[0m10:40:01.216054 [debug] [ThreadPool]: Using postgres connection "list_analytics"
[0m10:40:01.217651 [debug] [ThreadPool]: On list_analytics: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "homework", "target_name": "dev", "connection_name": "list_analytics"} */

    select distinct nspname from pg_namespace
  
[0m10:40:01.219135 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m10:40:01.236612 [debug] [ThreadPool]: SQL status: SELECT 6 in 0.017 seconds
[0m10:40:01.240663 [debug] [ThreadPool]: On list_analytics: Close
[0m10:40:01.245168 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_analytics, now list_analytics_analytics)
[0m10:40:01.260845 [debug] [ThreadPool]: Using postgres connection "list_analytics_analytics"
[0m10:40:01.262903 [debug] [ThreadPool]: On list_analytics_analytics: BEGIN
[0m10:40:01.264715 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m10:40:01.284406 [debug] [ThreadPool]: SQL status: BEGIN in 0.020 seconds
[0m10:40:01.286628 [debug] [ThreadPool]: Using postgres connection "list_analytics_analytics"
[0m10:40:01.288873 [debug] [ThreadPool]: On list_analytics_analytics: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "homework", "target_name": "dev", "connection_name": "list_analytics_analytics"} */
select
      'analytics' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'analytics'
    union all
    select
      'analytics' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'analytics'
    union all
    select
      'analytics' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'analytics'
  
[0m10:40:01.308810 [debug] [ThreadPool]: SQL status: SELECT 3 in 0.017 seconds
[0m10:40:01.313089 [debug] [ThreadPool]: On list_analytics_analytics: ROLLBACK
[0m10:40:01.316214 [debug] [ThreadPool]: On list_analytics_analytics: Close
[0m10:40:01.331979 [debug] [MainThread]: Using postgres connection "master"
[0m10:40:01.335908 [debug] [MainThread]: On master: BEGIN
[0m10:40:01.339389 [debug] [MainThread]: Opening a new connection, currently in state init
[0m10:40:01.371608 [debug] [MainThread]: SQL status: BEGIN in 0.032 seconds
[0m10:40:01.374187 [debug] [MainThread]: Using postgres connection "master"
[0m10:40:01.377913 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "homework", "target_name": "dev", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select distinct
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v', 'm')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
[0m10:40:01.405336 [debug] [MainThread]: SQL status: SELECT 1 in 0.024 seconds
[0m10:40:01.411094 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '65721cdc-6b4f-4793-b8fc-f8ec56f151a3', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd4998c39d0>]}
[0m10:40:01.414026 [debug] [MainThread]: On master: ROLLBACK
[0m10:40:01.416640 [debug] [MainThread]: Using postgres connection "master"
[0m10:40:01.418676 [debug] [MainThread]: On master: BEGIN
[0m10:40:01.421315 [debug] [MainThread]: SQL status: BEGIN in 0.001 seconds
[0m10:40:01.424378 [debug] [MainThread]: On master: COMMIT
[0m10:40:01.427706 [debug] [MainThread]: Using postgres connection "master"
[0m10:40:01.431194 [debug] [MainThread]: On master: COMMIT
[0m10:40:01.434076 [debug] [MainThread]: SQL status: COMMIT in 0.000 seconds
[0m10:40:01.436289 [debug] [MainThread]: On master: Close
[0m10:40:01.448698 [debug] [Thread-1  ]: Began running node model.homework.stg_iris
[0m10:40:01.451578 [info ] [Thread-1  ]: 1 of 2 START sql view model analytics.stg_iris ................................. [RUN]
[0m10:40:01.454262 [debug] [Thread-1  ]: Re-using an available connection from the pool (formerly list_analytics_analytics, now model.homework.stg_iris)
[0m10:40:01.456739 [debug] [Thread-1  ]: Began compiling node model.homework.stg_iris
[0m10:40:01.485420 [debug] [Thread-1  ]: Writing injected SQL for node "model.homework.stg_iris"
[0m10:40:01.502350 [debug] [Thread-1  ]: Began executing node model.homework.stg_iris
[0m10:40:01.643236 [debug] [Thread-1  ]: Writing runtime sql for node "model.homework.stg_iris"
[0m10:40:01.656690 [debug] [Thread-1  ]: Using postgres connection "model.homework.stg_iris"
[0m10:40:01.659506 [debug] [Thread-1  ]: On model.homework.stg_iris: BEGIN
[0m10:40:01.661826 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
[0m10:40:01.676922 [debug] [Thread-1  ]: SQL status: BEGIN in 0.015 seconds
[0m10:40:01.681143 [debug] [Thread-1  ]: Using postgres connection "model.homework.stg_iris"
[0m10:40:01.684375 [debug] [Thread-1  ]: On model.homework.stg_iris: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "homework", "target_name": "dev", "node_id": "model.homework.stg_iris"} */

  create view "analytics"."analytics"."stg_iris__dbt_tmp"
    
    
  as (
    with source as (
    select * from "analytics"."analytics"."iris_dataset"
)

select
    cast(sepal_length as numeric) as sepal_length,
    cast(sepal_width as numeric) as sepal_width,
    cast(petal_length as numeric) as petal_length,
    cast(petal_width as numeric) as petal_width,
    species
from source
  );
[0m10:40:01.691141 [debug] [Thread-1  ]: SQL status: CREATE VIEW in 0.003 seconds
[0m10:40:01.727274 [debug] [Thread-1  ]: Using postgres connection "model.homework.stg_iris"
[0m10:40:01.731428 [debug] [Thread-1  ]: On model.homework.stg_iris: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "homework", "target_name": "dev", "node_id": "model.homework.stg_iris"} */
alter table "analytics"."analytics"."stg_iris" rename to "stg_iris__dbt_backup"
[0m10:40:01.735513 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.001 seconds
[0m10:40:01.754983 [debug] [Thread-1  ]: Using postgres connection "model.homework.stg_iris"
[0m10:40:01.758167 [debug] [Thread-1  ]: On model.homework.stg_iris: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "homework", "target_name": "dev", "node_id": "model.homework.stg_iris"} */
alter table "analytics"."analytics"."stg_iris__dbt_tmp" rename to "stg_iris"
[0m10:40:01.762374 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.001 seconds
[0m10:40:01.828778 [debug] [Thread-1  ]: On model.homework.stg_iris: COMMIT
[0m10:40:01.830753 [debug] [Thread-1  ]: Using postgres connection "model.homework.stg_iris"
[0m10:40:01.832621 [debug] [Thread-1  ]: On model.homework.stg_iris: COMMIT
[0m10:40:01.838346 [debug] [Thread-1  ]: SQL status: COMMIT in 0.004 seconds
[0m10:40:01.859757 [debug] [Thread-1  ]: Applying DROP to: "analytics"."analytics"."stg_iris__dbt_backup"
[0m10:40:01.879868 [debug] [Thread-1  ]: Using postgres connection "model.homework.stg_iris"
[0m10:40:01.882314 [debug] [Thread-1  ]: On model.homework.stg_iris: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "homework", "target_name": "dev", "node_id": "model.homework.stg_iris"} */
drop view if exists "analytics"."analytics"."stg_iris__dbt_backup" cascade
[0m10:40:01.888512 [debug] [Thread-1  ]: SQL status: DROP VIEW in 0.004 seconds
[0m10:40:01.897399 [debug] [Thread-1  ]: On model.homework.stg_iris: Close
[0m10:40:01.904976 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '65721cdc-6b4f-4793-b8fc-f8ec56f151a3', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd49983f070>]}
[0m10:40:01.907790 [info ] [Thread-1  ]: 1 of 2 OK created sql view model analytics.stg_iris ............................ [[32mCREATE VIEW[0m in 0.45s]
[0m10:40:01.911644 [debug] [Thread-1  ]: Finished running node model.homework.stg_iris
[0m10:40:01.916123 [debug] [Thread-3  ]: Began running node model.homework.iris_processed
[0m10:40:01.918805 [info ] [Thread-3  ]: 2 of 2 START sql table model analytics.iris_processed .......................... [RUN]
[0m10:40:01.921796 [debug] [Thread-3  ]: Acquiring new postgres connection 'model.homework.iris_processed'
[0m10:40:01.925055 [debug] [Thread-3  ]: Began compiling node model.homework.iris_processed
[0m10:40:02.021912 [debug] [Thread-3  ]: Using postgres connection "model.homework.iris_processed"
[0m10:40:02.024332 [debug] [Thread-3  ]: On model.homework.iris_processed: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "homework", "target_name": "dev", "node_id": "model.homework.iris_processed"} */

        select percentile_cont(0.5) within group (order by sepal_length ) from "analytics"."analytics"."stg_iris"
    
[0m10:40:02.026837 [debug] [Thread-3  ]: Opening a new connection, currently in state init
[0m10:40:02.042625 [debug] [Thread-3  ]: SQL status: SELECT 1 in 0.016 seconds
[0m10:40:02.046783 [debug] [Thread-3  ]: Using postgres connection "model.homework.iris_processed"
[0m10:40:02.048613 [debug] [Thread-3  ]: On model.homework.iris_processed: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "homework", "target_name": "dev", "node_id": "model.homework.iris_processed"} */

        select percentile_cont(0.5 - 0.5/2) within group (order by sepal_length ) from "analytics"."analytics"."stg_iris"
    
[0m10:40:02.051394 [debug] [Thread-3  ]: SQL status: SELECT 1 in 0.001 seconds
[0m10:40:02.055368 [debug] [Thread-3  ]: Using postgres connection "model.homework.iris_processed"
[0m10:40:02.057214 [debug] [Thread-3  ]: On model.homework.iris_processed: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "homework", "target_name": "dev", "node_id": "model.homework.iris_processed"} */

        select percentile_cont(0.5 + 0.5/2) within group (order by sepal_length ) from "analytics"."analytics"."stg_iris"
    
[0m10:40:02.060540 [debug] [Thread-3  ]: SQL status: SELECT 1 in 0.001 seconds
[0m10:40:02.082322 [debug] [Thread-3  ]: Using postgres connection "model.homework.iris_processed"
[0m10:40:02.084609 [debug] [Thread-3  ]: On model.homework.iris_processed: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "homework", "target_name": "dev", "node_id": "model.homework.iris_processed"} */

        select percentile_cont(0.5) within group (order by sepal_width ) from "analytics"."analytics"."stg_iris"
    
[0m10:40:02.087285 [debug] [Thread-3  ]: SQL status: SELECT 1 in 0.001 seconds
[0m10:40:02.092360 [debug] [Thread-3  ]: Using postgres connection "model.homework.iris_processed"
[0m10:40:02.094328 [debug] [Thread-3  ]: On model.homework.iris_processed: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "homework", "target_name": "dev", "node_id": "model.homework.iris_processed"} */

        select percentile_cont(0.5 - 0.5/2) within group (order by sepal_width ) from "analytics"."analytics"."stg_iris"
    
[0m10:40:02.096814 [debug] [Thread-3  ]: SQL status: SELECT 1 in 0.001 seconds
[0m10:40:02.101259 [debug] [Thread-3  ]: Using postgres connection "model.homework.iris_processed"
[0m10:40:02.103145 [debug] [Thread-3  ]: On model.homework.iris_processed: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "homework", "target_name": "dev", "node_id": "model.homework.iris_processed"} */

        select percentile_cont(0.5 + 0.5/2) within group (order by sepal_width ) from "analytics"."analytics"."stg_iris"
    
[0m10:40:02.105702 [debug] [Thread-3  ]: SQL status: SELECT 1 in 0.001 seconds
[0m10:40:02.112957 [debug] [Thread-3  ]: Using postgres connection "model.homework.iris_processed"
[0m10:40:02.114891 [debug] [Thread-3  ]: On model.homework.iris_processed: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "homework", "target_name": "dev", "node_id": "model.homework.iris_processed"} */

        select percentile_cont(0.5) within group (order by petal_length ) from "analytics"."analytics"."stg_iris"
    
[0m10:40:02.117312 [debug] [Thread-3  ]: SQL status: SELECT 1 in 0.001 seconds
[0m10:40:02.121383 [debug] [Thread-3  ]: Using postgres connection "model.homework.iris_processed"
[0m10:40:02.123117 [debug] [Thread-3  ]: On model.homework.iris_processed: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "homework", "target_name": "dev", "node_id": "model.homework.iris_processed"} */

        select percentile_cont(0.5 - 0.5/2) within group (order by petal_length ) from "analytics"."analytics"."stg_iris"
    
[0m10:40:02.126179 [debug] [Thread-3  ]: SQL status: SELECT 1 in 0.001 seconds
[0m10:40:02.130554 [debug] [Thread-3  ]: Using postgres connection "model.homework.iris_processed"
[0m10:40:02.132553 [debug] [Thread-3  ]: On model.homework.iris_processed: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "homework", "target_name": "dev", "node_id": "model.homework.iris_processed"} */

        select percentile_cont(0.5 + 0.5/2) within group (order by petal_length ) from "analytics"."analytics"."stg_iris"
    
[0m10:40:02.135262 [debug] [Thread-3  ]: SQL status: SELECT 1 in 0.001 seconds
[0m10:40:02.141796 [debug] [Thread-3  ]: Using postgres connection "model.homework.iris_processed"
[0m10:40:02.144070 [debug] [Thread-3  ]: On model.homework.iris_processed: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "homework", "target_name": "dev", "node_id": "model.homework.iris_processed"} */

        select percentile_cont(0.5) within group (order by petal_width ) from "analytics"."analytics"."stg_iris"
    
[0m10:40:02.146698 [debug] [Thread-3  ]: SQL status: SELECT 1 in 0.001 seconds
[0m10:40:02.151280 [debug] [Thread-3  ]: Using postgres connection "model.homework.iris_processed"
[0m10:40:02.153155 [debug] [Thread-3  ]: On model.homework.iris_processed: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "homework", "target_name": "dev", "node_id": "model.homework.iris_processed"} */

        select percentile_cont(0.5 - 0.5/2) within group (order by petal_width ) from "analytics"."analytics"."stg_iris"
    
[0m10:40:02.155756 [debug] [Thread-3  ]: SQL status: SELECT 1 in 0.001 seconds
[0m10:40:02.160497 [debug] [Thread-3  ]: Using postgres connection "model.homework.iris_processed"
[0m10:40:02.162463 [debug] [Thread-3  ]: On model.homework.iris_processed: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "homework", "target_name": "dev", "node_id": "model.homework.iris_processed"} */

        select percentile_cont(0.5 + 0.5/2) within group (order by petal_width ) from "analytics"."analytics"."stg_iris"
    
[0m10:40:02.165097 [debug] [Thread-3  ]: SQL status: SELECT 1 in 0.001 seconds
[0m10:40:02.194433 [debug] [Thread-3  ]: Using postgres connection "model.homework.iris_processed"
[0m10:40:02.196657 [debug] [Thread-3  ]: On model.homework.iris_processed: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "homework", "target_name": "dev", "node_id": "model.homework.iris_processed"} */

            select percentile_cont(0.5) within group (order by sepal_length ) from "analytics"."analytics"."stg_iris"
        
[0m10:40:02.199354 [debug] [Thread-3  ]: SQL status: SELECT 1 in 0.001 seconds
[0m10:40:02.204434 [debug] [Thread-3  ]: Using postgres connection "model.homework.iris_processed"
[0m10:40:02.206421 [debug] [Thread-3  ]: On model.homework.iris_processed: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "homework", "target_name": "dev", "node_id": "model.homework.iris_processed"} */

            select percentile_cont(0.5) within group (order by sepal_width ) from "analytics"."analytics"."stg_iris"
        
[0m10:40:02.209779 [debug] [Thread-3  ]: SQL status: SELECT 1 in 0.001 seconds
[0m10:40:02.215330 [debug] [Thread-3  ]: Using postgres connection "model.homework.iris_processed"
[0m10:40:02.217245 [debug] [Thread-3  ]: On model.homework.iris_processed: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "homework", "target_name": "dev", "node_id": "model.homework.iris_processed"} */

            select percentile_cont(0.5) within group (order by petal_length ) from "analytics"."analytics"."stg_iris"
        
[0m10:40:02.219848 [debug] [Thread-3  ]: SQL status: SELECT 1 in 0.001 seconds
[0m10:40:02.225015 [debug] [Thread-3  ]: Using postgres connection "model.homework.iris_processed"
[0m10:40:02.227503 [debug] [Thread-3  ]: On model.homework.iris_processed: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "homework", "target_name": "dev", "node_id": "model.homework.iris_processed"} */

            select percentile_cont(0.5) within group (order by petal_width ) from "analytics"."analytics"."stg_iris"
        
[0m10:40:02.230354 [debug] [Thread-3  ]: SQL status: SELECT 1 in 0.001 seconds
[0m10:40:02.327817 [debug] [Thread-3  ]: Using postgres connection "model.homework.iris_processed"
[0m10:40:02.330322 [debug] [Thread-3  ]: On model.homework.iris_processed: BEGIN
[0m10:40:02.333051 [debug] [Thread-3  ]: SQL status: BEGIN in 0.000 seconds
[0m10:40:02.335720 [debug] [Thread-3  ]: Using postgres connection "model.homework.iris_processed"
[0m10:40:02.338207 [debug] [Thread-3  ]: On model.homework.iris_processed: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "homework", "target_name": "dev", "node_id": "model.homework.iris_processed"} */
select
                species as value

            from "analytics"."analytics"."stg_iris"

            
            where species is not null  and true
            

            group by species
            order by species

            

        
[0m10:40:02.341809 [debug] [Thread-3  ]: SQL status: SELECT 3 in 0.001 seconds
[0m10:40:02.355887 [debug] [Thread-3  ]: Writing injected SQL for node "model.homework.iris_processed"
[0m10:40:02.370080 [debug] [Thread-3  ]: Began executing node model.homework.iris_processed
[0m10:40:02.437149 [debug] [Thread-3  ]: Writing runtime sql for node "model.homework.iris_processed"
[0m10:40:02.449800 [debug] [Thread-3  ]: Using postgres connection "model.homework.iris_processed"
[0m10:40:02.453084 [debug] [Thread-3  ]: On model.homework.iris_processed: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "homework", "target_name": "dev", "node_id": "model.homework.iris_processed"} */

  
    

  create  table "analytics"."analytics"."iris_processed__dbt_tmp"
  
  
    as
  
  (
    

with import_iris as (
    select *
    from "analytics"."analytics"."stg_iris"
)
select
    sepal_length,
    sepal_width,
    petal_length,
    petal_width,
    -- K Bins Discretization
    
        

    
        NTILE(5) over (order by sepal_length)
    

 as sepal_length_quantile_bin,
        

    
        
        floor(
        (
            sepal_length - (min(sepal_length) over ())
        )
        /
        (
            ((max(sepal_length) over ()) - (min(sepal_length) over ())) / 4::float
        )
        ) + 1
    

 as sepal_length_uniform_bin,
    
        

    
        NTILE(5) over (order by sepal_width)
    

 as sepal_width_quantile_bin,
        

    
        
        floor(
        (
            sepal_width - (min(sepal_width) over ())
        )
        /
        (
            ((max(sepal_width) over ()) - (min(sepal_width) over ())) / 4::float
        )
        ) + 1
    

 as sepal_width_uniform_bin,
    
        

    
        NTILE(5) over (order by petal_length)
    

 as petal_length_quantile_bin,
        

    
        
        floor(
        (
            petal_length - (min(petal_length) over ())
        )
        /
        (
            ((max(petal_length) over ()) - (min(petal_length) over ())) / 4::float
        )
        ) + 1
    

 as petal_length_uniform_bin,
    
        

    
        NTILE(5) over (order by petal_width)
    

 as petal_width_quantile_bin,
        

    
        
        floor(
        (
            petal_width - (min(petal_width) over ())
        )
        /
        (
            ((max(petal_width) over ()) - (min(petal_width) over ())) / 4::float
        )
        ) + 1
    

 as petal_width_uniform_bin,
    
-- Scaling
    
        

    

    
    
    

    
    
    

    (
        sepal_length - 5.8
    )
    /
    (
        6.4 - 5.1
    )

 as sepal_length_robust_scaled,
        

    (sepal_length) / (max(abs(sepal_length)) over ())::FLOAT

 as sepal_length_max_absolute_scaled,
        

    
    (
        ((sepal_length) - (min(sepal_length) over ()))
        /
        ((max(sepal_length) over ()) - (min(sepal_length) over ()))::FLOAT
    )
    *
    (1.0 - 0.0)
    +
    0.0

 as sepal_length_max_min_max_scaled,
    
        

    

    
    
    

    
    
    

    (
        sepal_width - 3.0
    )
    /
    (
        3.3 - 2.8
    )

 as sepal_width_robust_scaled,
        

    (sepal_width) / (max(abs(sepal_width)) over ())::FLOAT

 as sepal_width_max_absolute_scaled,
        

    
    (
        ((sepal_width) - (min(sepal_width) over ()))
        /
        ((max(sepal_width) over ()) - (min(sepal_width) over ()))::FLOAT
    )
    *
    (1.0 - 0.0)
    +
    0.0

 as sepal_width_max_min_max_scaled,
    
        

    

    
    
    

    
    
    

    (
        petal_length - 4.35
    )
    /
    (
        5.1 - 1.6
    )

 as petal_length_robust_scaled,
        

    (petal_length) / (max(abs(petal_length)) over ())::FLOAT

 as petal_length_max_absolute_scaled,
        

    
    (
        ((petal_length) - (min(petal_length) over ()))
        /
        ((max(petal_length) over ()) - (min(petal_length) over ()))::FLOAT
    )
    *
    (1.0 - 0.0)
    +
    0.0

 as petal_length_max_min_max_scaled,
    
        

    

    
    
    

    
    
    

    (
        petal_width - 1.3
    )
    /
    (
        1.8 - 0.3
    )

 as petal_width_robust_scaled,
        

    (petal_width) / (max(abs(petal_width)) over ())::FLOAT

 as petal_width_max_absolute_scaled,
        

    
    (
        ((petal_width) - (min(petal_width) over ()))
        /
        ((max(petal_width) over ()) - (min(petal_width) over ()))::FLOAT
    )
    *
    (1.0 - 0.0)
    +
    0.0

 as petal_width_max_min_max_scaled,
    

    -- Log Transformation
    
        

    case
        when sepal_length is null or sepal_length + 0 <= 0 then null
        else log(10, sepal_length + 0)
    end

 as sepal_length_logged,
    
        

    case
        when sepal_width is null or sepal_width + 0 <= 0 then null
        else log(10, sepal_width + 0)
    end

 as sepal_width_logged,
    
        

    case
        when petal_length is null or petal_length + 0 <= 0 then null
        else log(10, petal_length + 0)
    end

 as petal_length_logged,
    
        

    case
        when petal_width is null or petal_width + 0 <= 0 then null
        else log(10, petal_width + 0)
    end

 as petal_width_logged,
    

    -- Binarization
    
        

    

    
        

        
    

    case
        when sepal_length >=
            
                5.8
            
            then 1
        else 0
    end

 as sepal_length_binarized,
    
        

    

    
        

        
    

    case
        when sepal_width >=
            
                3.0
            
            then 1
        else 0
    end

 as sepal_width_binarized,
    
        

    

    
        

        
    

    case
        when petal_length >=
            
                4.35
            
            then 1
        else 0
    end

 as petal_length_binarized,
    
        

    

    
        

        
    

    case
        when petal_width >=
            
                1.3
            
            then 1
        else 0
    end

 as petal_width_binarized,
    

    -- Standardization
    
        

    
    (
        (sepal_length - avg(sepal_length) over ())
        /
        (stddev(sepal_length) over ())::FLOAT
    )
    *
    1
    +
    0

 as sepal_length_standardized,
    
        

    
    (
        (sepal_width - avg(sepal_width) over ())
        /
        (stddev(sepal_width) over ())::FLOAT
    )
    *
    1
    +
    0

 as sepal_width_standardized,
    
        

    
    (
        (petal_length - avg(petal_length) over ())
        /
        (stddev(petal_length) over ())::FLOAT
    )
    *
    1
    +
    0

 as petal_length_standardized,
    
        

    
    (
        (petal_width - avg(petal_width) over ())
        /
        (stddev(petal_width) over ())::FLOAT
    )
    *
    1
    +
    0

 as petal_width_standardized,
    
-- Interactions
    
        
            
            
            

    
        (sepal_length * sepal_width)
    

 as sepal_length_x_sepal_width_interaction,
            

    
        (sepal_length + sepal_width)
    

 as sepal_length_plus_sepal_width_interaction,
        
            
            
            

    
        (sepal_length * petal_length)
    

 as sepal_length_x_petal_length_interaction,
            

    
        (sepal_length + petal_length)
    

 as sepal_length_plus_petal_length_interaction,
        
            
            
            

    
        (sepal_length * petal_width)
    

 as sepal_length_x_petal_width_interaction,
            

    
        (sepal_length + petal_width)
    

 as sepal_length_plus_petal_width_interaction,
        
    
        
            
            
            

    
        (sepal_width * petal_length)
    

 as sepal_width_x_petal_length_interaction,
            

    
        (sepal_width + petal_length)
    

 as sepal_width_plus_petal_length_interaction,
        
            
            
            

    
        (sepal_width * petal_width)
    

 as sepal_width_x_petal_width_interaction,
            

    
        (sepal_width + petal_width)
    

 as sepal_width_plus_petal_width_interaction,
        
    
        
            
            
            

    
        (petal_length * petal_width)
    

 as petal_length_x_petal_width_interaction,
            

    
        (petal_length + petal_width)
    

 as petal_length_plus_petal_width_interaction,
        
    
        
    
species,    
    -- Label Encoding
    

    dense_rank() over (order by species) - 1

 as species_label_encoded,
    -- One Hot Encoding
    

    

    
        
    

    

    

        case
            when species = 'setosa' then 1
            else 0
        end as is_species__setosa,

    

        case
            when species = 'versicolor' then 1
            else 0
        end as is_species__versicolor,

    

        case
            when species = 'virginica' then 1
            else 0
        end as is_species__virginica,

    

    case
        when species is null then 1
        else 0
    end as is_species__


from "analytics"."analytics"."stg_iris"
  );
  
[0m10:40:02.496141 [debug] [Thread-3  ]: SQL status: SELECT 150 in 0.040 seconds
[0m10:40:02.519618 [debug] [Thread-3  ]: Using postgres connection "model.homework.iris_processed"
[0m10:40:02.522218 [debug] [Thread-3  ]: On model.homework.iris_processed: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "homework", "target_name": "dev", "node_id": "model.homework.iris_processed"} */
alter table "analytics"."analytics"."iris_processed" rename to "iris_processed__dbt_backup"
[0m10:40:02.524463 [debug] [Thread-3  ]: SQL status: ALTER TABLE in 0.001 seconds
[0m10:40:02.534485 [debug] [Thread-3  ]: Using postgres connection "model.homework.iris_processed"
[0m10:40:02.536334 [debug] [Thread-3  ]: On model.homework.iris_processed: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "homework", "target_name": "dev", "node_id": "model.homework.iris_processed"} */
alter table "analytics"."analytics"."iris_processed__dbt_tmp" rename to "iris_processed"
[0m10:40:02.538689 [debug] [Thread-3  ]: SQL status: ALTER TABLE in 0.001 seconds
[0m10:40:02.543838 [debug] [Thread-3  ]: On model.homework.iris_processed: COMMIT
[0m10:40:02.545792 [debug] [Thread-3  ]: Using postgres connection "model.homework.iris_processed"
[0m10:40:02.547603 [debug] [Thread-3  ]: On model.homework.iris_processed: COMMIT
[0m10:40:02.553668 [debug] [Thread-3  ]: SQL status: COMMIT in 0.004 seconds
[0m10:40:02.561676 [debug] [Thread-3  ]: Applying DROP to: "analytics"."analytics"."iris_processed__dbt_backup"
[0m10:40:02.568535 [debug] [Thread-3  ]: Using postgres connection "model.homework.iris_processed"
[0m10:40:02.570467 [debug] [Thread-3  ]: On model.homework.iris_processed: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "homework", "target_name": "dev", "node_id": "model.homework.iris_processed"} */
drop table if exists "analytics"."analytics"."iris_processed__dbt_backup" cascade
[0m10:40:02.578403 [debug] [Thread-3  ]: SQL status: DROP TABLE in 0.006 seconds
[0m10:40:02.582329 [debug] [Thread-3  ]: On model.homework.iris_processed: Close
[0m10:40:02.585036 [debug] [Thread-3  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '65721cdc-6b4f-4793-b8fc-f8ec56f151a3', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd498724d90>]}
[0m10:40:02.587423 [info ] [Thread-3  ]: 2 of 2 OK created sql table model analytics.iris_processed ..................... [[32mSELECT 150[0m in 0.66s]
[0m10:40:02.589716 [debug] [Thread-3  ]: Finished running node model.homework.iris_processed
[0m10:40:02.594451 [debug] [MainThread]: Using postgres connection "master"
[0m10:40:02.596224 [debug] [MainThread]: On master: BEGIN
[0m10:40:02.597964 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m10:40:02.609657 [debug] [MainThread]: SQL status: BEGIN in 0.012 seconds
[0m10:40:02.611865 [debug] [MainThread]: On master: COMMIT
[0m10:40:02.613541 [debug] [MainThread]: Using postgres connection "master"
[0m10:40:02.615156 [debug] [MainThread]: On master: COMMIT
[0m10:40:02.617006 [debug] [MainThread]: SQL status: COMMIT in 0.000 seconds
[0m10:40:02.619312 [debug] [MainThread]: On master: Close
[0m10:40:02.621694 [debug] [MainThread]: Connection 'master' was properly closed.
[0m10:40:02.623921 [debug] [MainThread]: Connection 'model.homework.stg_iris' was properly closed.
[0m10:40:02.627659 [debug] [MainThread]: Connection 'model.homework.iris_processed' was properly closed.
[0m10:40:02.630454 [info ] [MainThread]: 
[0m10:40:02.632469 [info ] [MainThread]: Finished running 1 table model, 1 view model in 0 hours 0 minutes and 1.56 seconds (1.56s).
[0m10:40:02.635461 [debug] [MainThread]: Command end result
[0m10:40:02.742269 [debug] [MainThread]: Wrote artifact WritableManifest to /opt/airflow/dags/dbt/homework/target/manifest.json
[0m10:40:02.750656 [debug] [MainThread]: Wrote artifact SemanticManifest to /opt/airflow/dags/dbt/homework/target/semantic_manifest.json
[0m10:40:02.768454 [debug] [MainThread]: Wrote artifact RunExecutionResult to /opt/airflow/dags/dbt/homework/target/run_results.json
[0m10:40:02.769954 [info ] [MainThread]: 
[0m10:40:02.771535 [info ] [MainThread]: [32mCompleted successfully[0m
[0m10:40:02.773278 [info ] [MainThread]: 
[0m10:40:02.774966 [info ] [MainThread]: Done. PASS=2 WARN=0 ERROR=0 SKIP=0 TOTAL=2
[0m10:40:02.780420 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": true, "command_wall_clock_time": 4.9908705, "process_in_blocks": "5008", "process_kernel_time": 1.731292, "process_mem_max_rss": "115212", "process_out_blocks": "0", "process_user_time": 6.3011}
[0m10:40:02.782823 [debug] [MainThread]: Command `dbt run` succeeded at 10:40:02.782564 after 4.99 seconds
[0m10:40:02.784641 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd49cf34b20>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd49c0f5ee0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd49a7d46a0>]}
[0m10:40:02.786557 [debug] [MainThread]: Flushing usage events
[0m10:40:03.352962 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m10:45:26.544662 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f16ae1e3af0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f16ad304520>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f16ad3044c0>]}


============================== 10:45:26.568478 | 2d347611-d155-4229-b5c7-1c4ee96c82f6 ==============================
[0m10:45:26.568478 [info ] [MainThread]: Running with dbt=1.9.4
[0m10:45:26.573246 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'fail_fast': 'True', 'version_check': 'True', 'log_path': '/opt/airflow/dags/dbt/homework/logs', 'debug': 'False', 'profiles_dir': '/opt/airflow/dags/dbt', 'use_colors': 'True', 'use_experimental_parser': 'False', 'empty': 'None', 'quiet': 'False', 'no_print': 'None', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'static_parser': 'True', 'invocation_command': 'dbt --profile homework test --project-dir=/opt/airflow/dags/dbt/homework --vars {"is_test": false, "data_date": "2025-04-23"} --fail-fast', 'log_format': 'default', 'target_path': 'None', 'introspect': 'True', 'send_anonymous_usage_stats': 'True'}
[0m10:45:27.165961 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '2d347611-d155-4229-b5c7-1c4ee96c82f6', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f16afbcac70>]}
[0m10:45:27.314787 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '2d347611-d155-4229-b5c7-1c4ee96c82f6', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f16aba46520>]}
[0m10:45:27.317153 [info ] [MainThread]: Registered adapter: postgres=1.9.0
[0m10:45:27.609137 [debug] [MainThread]: checksum: f5df654a850f4b74beb13fbe0c7d8863b5b1a20bd535c3ac287d70e390b64d41, vars: {'data_date': '2025-04-23', 'is_test': False}, profile: homework, target: , version: 1.9.4
[0m10:45:29.713897 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m10:45:29.715933 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m10:45:29.735264 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 1 unused configuration paths:
- seeds.homework.iris_dataset
[0m10:45:29.828041 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '2d347611-d155-4229-b5c7-1c4ee96c82f6', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f16ab633130>]}
[0m10:45:30.132594 [debug] [MainThread]: Wrote artifact WritableManifest to /opt/airflow/dags/dbt/homework/target/manifest.json
[0m10:45:30.153626 [debug] [MainThread]: Wrote artifact SemanticManifest to /opt/airflow/dags/dbt/homework/target/semantic_manifest.json
[0m10:45:30.233985 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '2d347611-d155-4229-b5c7-1c4ee96c82f6', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f16ab511580>]}
[0m10:45:30.235920 [info ] [MainThread]: Found 2 models, 1 source, 587 macros
[0m10:45:30.238078 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '2d347611-d155-4229-b5c7-1c4ee96c82f6', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f16ab578a30>]}
[0m10:45:30.242160 [warn ] [MainThread]: Nothing to do. Try checking your model configs and model specification args
[0m10:45:30.247011 [debug] [MainThread]: Command end result
[0m10:45:30.365846 [debug] [MainThread]: Wrote artifact WritableManifest to /opt/airflow/dags/dbt/homework/target/manifest.json
[0m10:45:30.376039 [debug] [MainThread]: Wrote artifact SemanticManifest to /opt/airflow/dags/dbt/homework/target/semantic_manifest.json
[0m10:45:30.391737 [debug] [MainThread]: Wrote artifact RunExecutionResult to /opt/airflow/dags/dbt/homework/target/run_results.json
[0m10:45:30.395234 [debug] [MainThread]: Resource report: {"command_name": "test", "command_success": true, "command_wall_clock_time": 4.0325656, "process_in_blocks": "2768", "process_kernel_time": 0.485546, "process_mem_max_rss": "104712", "process_out_blocks": "0", "process_user_time": 5.440098}
[0m10:45:30.397826 [debug] [MainThread]: Command `dbt test` succeeded at 10:45:30.397510 after 4.04 seconds
[0m10:45:30.400174 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f16ae1e3af0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f16ae0ad6d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f16abad6130>]}
[0m10:45:30.402475 [debug] [MainThread]: Flushing usage events
[0m10:45:30.996514 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m10:54:16.367421 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd41d7c2ac0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd41c8e34c0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd41c8e3460>]}


============================== 10:54:16.378559 | 984b0604-2cef-44c4-9d18-c371171922cb ==============================
[0m10:54:16.378559 [info ] [MainThread]: Running with dbt=1.9.4
[0m10:54:16.381407 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': '/opt/airflow/dags/dbt', 'version_check': 'True', 'debug': 'False', 'log_path': '/opt/airflow/dags/dbt/homework/logs', 'warn_error': 'None', 'fail_fast': 'False', 'use_colors': 'True', 'use_experimental_parser': 'False', 'empty': 'False', 'quiet': 'False', 'no_print': 'None', 'log_format': 'default', 'introspect': 'True', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'invocation_command': 'dbt --profile homework run --project-dir=/opt/airflow/dags/dbt/homework --vars {"is_test": false, "data_date": "2025-04-23"}', 'target_path': 'None', 'static_parser': 'True', 'send_anonymous_usage_stats': 'True'}
[0m10:54:16.917714 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '984b0604-2cef-44c4-9d18-c371171922cb', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd41b118460>]}
[0m10:54:17.058868 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '984b0604-2cef-44c4-9d18-c371171922cb', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd41c97a220>]}
[0m10:54:17.061519 [info ] [MainThread]: Registered adapter: postgres=1.9.0
[0m10:54:17.393745 [debug] [MainThread]: checksum: f5df654a850f4b74beb13fbe0c7d8863b5b1a20bd535c3ac287d70e390b64d41, vars: {'data_date': '2025-04-23', 'is_test': False}, profile: homework, target: , version: 1.9.4
[0m10:54:19.328040 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m10:54:19.330278 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m10:54:19.354350 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 1 unused configuration paths:
- seeds.homework.iris_dataset
[0m10:54:19.441995 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '984b0604-2cef-44c4-9d18-c371171922cb', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd41ac0f130>]}
[0m10:54:19.895020 [debug] [MainThread]: Wrote artifact WritableManifest to /opt/airflow/dags/dbt/homework/target/manifest.json
[0m10:54:19.918341 [debug] [MainThread]: Wrote artifact SemanticManifest to /opt/airflow/dags/dbt/homework/target/semantic_manifest.json
[0m10:54:19.963100 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '984b0604-2cef-44c4-9d18-c371171922cb', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd41abafdc0>]}
[0m10:54:19.966026 [info ] [MainThread]: Found 2 models, 1 source, 587 macros
[0m10:54:19.969164 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '984b0604-2cef-44c4-9d18-c371171922cb', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd41c948610>]}
[0m10:54:19.973208 [info ] [MainThread]: 
[0m10:54:19.974962 [info ] [MainThread]: Concurrency: 4 threads (target='dev')
[0m10:54:19.976776 [info ] [MainThread]: 
[0m10:54:19.978952 [debug] [MainThread]: Acquiring new postgres connection 'master'
[0m10:54:19.990763 [debug] [ThreadPool]: Acquiring new postgres connection 'list_analytics'
[0m10:54:20.062895 [debug] [ThreadPool]: Using postgres connection "list_analytics"
[0m10:54:20.064626 [debug] [ThreadPool]: On list_analytics: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "homework", "target_name": "dev", "connection_name": "list_analytics"} */

    select distinct nspname from pg_namespace
  
[0m10:54:20.066558 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m10:54:20.080250 [debug] [ThreadPool]: SQL status: SELECT 6 in 0.014 seconds
[0m10:54:20.083745 [debug] [ThreadPool]: On list_analytics: Close
[0m10:54:20.087843 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_analytics, now list_analytics_analytics)
[0m10:54:20.104693 [debug] [ThreadPool]: Using postgres connection "list_analytics_analytics"
[0m10:54:20.106436 [debug] [ThreadPool]: On list_analytics_analytics: BEGIN
[0m10:54:20.107966 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m10:54:20.119362 [debug] [ThreadPool]: SQL status: BEGIN in 0.011 seconds
[0m10:54:20.121343 [debug] [ThreadPool]: Using postgres connection "list_analytics_analytics"
[0m10:54:20.123367 [debug] [ThreadPool]: On list_analytics_analytics: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "homework", "target_name": "dev", "connection_name": "list_analytics_analytics"} */
select
      'analytics' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'analytics'
    union all
    select
      'analytics' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'analytics'
    union all
    select
      'analytics' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'analytics'
  
[0m10:54:20.129352 [debug] [ThreadPool]: SQL status: SELECT 3 in 0.004 seconds
[0m10:54:20.132512 [debug] [ThreadPool]: On list_analytics_analytics: ROLLBACK
[0m10:54:20.134952 [debug] [ThreadPool]: On list_analytics_analytics: Close
[0m10:54:20.149575 [debug] [MainThread]: Using postgres connection "master"
[0m10:54:20.152777 [debug] [MainThread]: On master: BEGIN
[0m10:54:20.155509 [debug] [MainThread]: Opening a new connection, currently in state init
[0m10:54:20.168471 [debug] [MainThread]: SQL status: BEGIN in 0.013 seconds
[0m10:54:20.171070 [debug] [MainThread]: Using postgres connection "master"
[0m10:54:20.173803 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "homework", "target_name": "dev", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select distinct
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v', 'm')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
[0m10:54:20.186374 [debug] [MainThread]: SQL status: SELECT 1 in 0.010 seconds
[0m10:54:20.190841 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '984b0604-2cef-44c4-9d18-c371171922cb', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd41afd5f40>]}
[0m10:54:20.192983 [debug] [MainThread]: On master: ROLLBACK
[0m10:54:20.195036 [debug] [MainThread]: Using postgres connection "master"
[0m10:54:20.196844 [debug] [MainThread]: On master: BEGIN
[0m10:54:20.199276 [debug] [MainThread]: SQL status: BEGIN in 0.001 seconds
[0m10:54:20.202459 [debug] [MainThread]: On master: COMMIT
[0m10:54:20.205434 [debug] [MainThread]: Using postgres connection "master"
[0m10:54:20.207758 [debug] [MainThread]: On master: COMMIT
[0m10:54:20.210502 [debug] [MainThread]: SQL status: COMMIT in 0.000 seconds
[0m10:54:20.212356 [debug] [MainThread]: On master: Close
[0m10:54:20.222836 [debug] [Thread-1  ]: Began running node model.homework.stg_iris
[0m10:54:20.225198 [info ] [Thread-1  ]: 1 of 2 START sql view model analytics.stg_iris ................................. [RUN]
[0m10:54:20.227390 [debug] [Thread-1  ]: Re-using an available connection from the pool (formerly list_analytics_analytics, now model.homework.stg_iris)
[0m10:54:20.229273 [debug] [Thread-1  ]: Began compiling node model.homework.stg_iris
[0m10:54:20.249486 [debug] [Thread-1  ]: Writing injected SQL for node "model.homework.stg_iris"
[0m10:54:20.264035 [debug] [Thread-1  ]: Began executing node model.homework.stg_iris
[0m10:54:20.351582 [debug] [Thread-1  ]: Writing runtime sql for node "model.homework.stg_iris"
[0m10:54:20.364788 [debug] [Thread-1  ]: Using postgres connection "model.homework.stg_iris"
[0m10:54:20.366957 [debug] [Thread-1  ]: On model.homework.stg_iris: BEGIN
[0m10:54:20.369516 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
[0m10:54:20.381538 [debug] [Thread-1  ]: SQL status: BEGIN in 0.012 seconds
[0m10:54:20.385377 [debug] [Thread-1  ]: Using postgres connection "model.homework.stg_iris"
[0m10:54:20.388446 [debug] [Thread-1  ]: On model.homework.stg_iris: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "homework", "target_name": "dev", "node_id": "model.homework.stg_iris"} */

  create view "analytics"."analytics"."stg_iris__dbt_tmp"
    
    
  as (
    with source as (
    select * from "analytics"."analytics"."iris_dataset"
)

select
    cast(sepal_length as numeric) as sepal_length,
    cast(sepal_width as numeric) as sepal_width,
    cast(petal_length as numeric) as petal_length,
    cast(petal_width as numeric) as petal_width,
    species
from source
  );
[0m10:54:20.414605 [debug] [Thread-1  ]: SQL status: CREATE VIEW in 0.024 seconds
[0m10:54:20.440544 [debug] [Thread-1  ]: Using postgres connection "model.homework.stg_iris"
[0m10:54:20.442852 [debug] [Thread-1  ]: On model.homework.stg_iris: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "homework", "target_name": "dev", "node_id": "model.homework.stg_iris"} */
alter table "analytics"."analytics"."stg_iris" rename to "stg_iris__dbt_backup"
[0m10:54:20.446799 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.001 seconds
[0m10:54:20.459717 [debug] [Thread-1  ]: Using postgres connection "model.homework.stg_iris"
[0m10:54:20.462153 [debug] [Thread-1  ]: On model.homework.stg_iris: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "homework", "target_name": "dev", "node_id": "model.homework.stg_iris"} */
alter table "analytics"."analytics"."stg_iris__dbt_tmp" rename to "stg_iris"
[0m10:54:20.465311 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.001 seconds
[0m10:54:20.518619 [debug] [Thread-1  ]: On model.homework.stg_iris: COMMIT
[0m10:54:20.520762 [debug] [Thread-1  ]: Using postgres connection "model.homework.stg_iris"
[0m10:54:20.522443 [debug] [Thread-1  ]: On model.homework.stg_iris: COMMIT
[0m10:54:20.527666 [debug] [Thread-1  ]: SQL status: COMMIT in 0.003 seconds
[0m10:54:20.542465 [debug] [Thread-1  ]: Applying DROP to: "analytics"."analytics"."stg_iris__dbt_backup"
[0m10:54:20.554647 [debug] [Thread-1  ]: Using postgres connection "model.homework.stg_iris"
[0m10:54:20.556567 [debug] [Thread-1  ]: On model.homework.stg_iris: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "homework", "target_name": "dev", "node_id": "model.homework.stg_iris"} */
drop view if exists "analytics"."analytics"."stg_iris__dbt_backup" cascade
[0m10:54:20.561857 [debug] [Thread-1  ]: SQL status: DROP VIEW in 0.003 seconds
[0m10:54:20.569051 [debug] [Thread-1  ]: On model.homework.stg_iris: Close
[0m10:54:20.574326 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '984b0604-2cef-44c4-9d18-c371171922cb', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd41a0cd070>]}
[0m10:54:20.576864 [info ] [Thread-1  ]: 1 of 2 OK created sql view model analytics.stg_iris ............................ [[32mCREATE VIEW[0m in 0.34s]
[0m10:54:20.579115 [debug] [Thread-1  ]: Finished running node model.homework.stg_iris
[0m10:54:20.581607 [debug] [Thread-3  ]: Began running node model.homework.iris_processed
[0m10:54:20.583864 [info ] [Thread-3  ]: 2 of 2 START sql table model analytics.iris_processed .......................... [RUN]
[0m10:54:20.586648 [debug] [Thread-3  ]: Acquiring new postgres connection 'model.homework.iris_processed'
[0m10:54:20.588478 [debug] [Thread-3  ]: Began compiling node model.homework.iris_processed
[0m10:54:20.657968 [debug] [Thread-3  ]: Using postgres connection "model.homework.iris_processed"
[0m10:54:20.659833 [debug] [Thread-3  ]: On model.homework.iris_processed: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "homework", "target_name": "dev", "node_id": "model.homework.iris_processed"} */

        select percentile_cont(0.5) within group (order by sepal_length ) from "analytics"."analytics"."stg_iris"
    
[0m10:54:20.661806 [debug] [Thread-3  ]: Opening a new connection, currently in state init
[0m10:54:20.675884 [debug] [Thread-3  ]: SQL status: SELECT 1 in 0.014 seconds
[0m10:54:20.680130 [debug] [Thread-3  ]: Using postgres connection "model.homework.iris_processed"
[0m10:54:20.682025 [debug] [Thread-3  ]: On model.homework.iris_processed: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "homework", "target_name": "dev", "node_id": "model.homework.iris_processed"} */

        select percentile_cont(0.5 - 0.5/2) within group (order by sepal_length ) from "analytics"."analytics"."stg_iris"
    
[0m10:54:20.685415 [debug] [Thread-3  ]: SQL status: SELECT 1 in 0.001 seconds
[0m10:54:20.689710 [debug] [Thread-3  ]: Using postgres connection "model.homework.iris_processed"
[0m10:54:20.691779 [debug] [Thread-3  ]: On model.homework.iris_processed: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "homework", "target_name": "dev", "node_id": "model.homework.iris_processed"} */

        select percentile_cont(0.5 + 0.5/2) within group (order by sepal_length ) from "analytics"."analytics"."stg_iris"
    
[0m10:54:20.694163 [debug] [Thread-3  ]: SQL status: SELECT 1 in 0.001 seconds
[0m10:54:20.710773 [debug] [Thread-3  ]: Using postgres connection "model.homework.iris_processed"
[0m10:54:20.712704 [debug] [Thread-3  ]: On model.homework.iris_processed: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "homework", "target_name": "dev", "node_id": "model.homework.iris_processed"} */

        select percentile_cont(0.5) within group (order by sepal_width ) from "analytics"."analytics"."stg_iris"
    
[0m10:54:20.715356 [debug] [Thread-3  ]: SQL status: SELECT 1 in 0.001 seconds
[0m10:54:20.719817 [debug] [Thread-3  ]: Using postgres connection "model.homework.iris_processed"
[0m10:54:20.721581 [debug] [Thread-3  ]: On model.homework.iris_processed: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "homework", "target_name": "dev", "node_id": "model.homework.iris_processed"} */

        select percentile_cont(0.5 - 0.5/2) within group (order by sepal_width ) from "analytics"."analytics"."stg_iris"
    
[0m10:54:20.724104 [debug] [Thread-3  ]: SQL status: SELECT 1 in 0.001 seconds
[0m10:54:20.727869 [debug] [Thread-3  ]: Using postgres connection "model.homework.iris_processed"
[0m10:54:20.729694 [debug] [Thread-3  ]: On model.homework.iris_processed: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "homework", "target_name": "dev", "node_id": "model.homework.iris_processed"} */

        select percentile_cont(0.5 + 0.5/2) within group (order by sepal_width ) from "analytics"."analytics"."stg_iris"
    
[0m10:54:20.732356 [debug] [Thread-3  ]: SQL status: SELECT 1 in 0.001 seconds
[0m10:54:20.739222 [debug] [Thread-3  ]: Using postgres connection "model.homework.iris_processed"
[0m10:54:20.741313 [debug] [Thread-3  ]: On model.homework.iris_processed: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "homework", "target_name": "dev", "node_id": "model.homework.iris_processed"} */

        select percentile_cont(0.5) within group (order by petal_length ) from "analytics"."analytics"."stg_iris"
    
[0m10:54:20.744096 [debug] [Thread-3  ]: SQL status: SELECT 1 in 0.001 seconds
[0m10:54:20.748273 [debug] [Thread-3  ]: Using postgres connection "model.homework.iris_processed"
[0m10:54:20.750244 [debug] [Thread-3  ]: On model.homework.iris_processed: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "homework", "target_name": "dev", "node_id": "model.homework.iris_processed"} */

        select percentile_cont(0.5 - 0.5/2) within group (order by petal_length ) from "analytics"."analytics"."stg_iris"
    
[0m10:54:20.753775 [debug] [Thread-3  ]: SQL status: SELECT 1 in 0.001 seconds
[0m10:54:20.758135 [debug] [Thread-3  ]: Using postgres connection "model.homework.iris_processed"
[0m10:54:20.759860 [debug] [Thread-3  ]: On model.homework.iris_processed: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "homework", "target_name": "dev", "node_id": "model.homework.iris_processed"} */

        select percentile_cont(0.5 + 0.5/2) within group (order by petal_length ) from "analytics"."analytics"."stg_iris"
    
[0m10:54:20.762054 [debug] [Thread-3  ]: SQL status: SELECT 1 in 0.001 seconds
[0m10:54:20.768330 [debug] [Thread-3  ]: Using postgres connection "model.homework.iris_processed"
[0m10:54:20.770194 [debug] [Thread-3  ]: On model.homework.iris_processed: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "homework", "target_name": "dev", "node_id": "model.homework.iris_processed"} */

        select percentile_cont(0.5) within group (order by petal_width ) from "analytics"."analytics"."stg_iris"
    
[0m10:54:20.772567 [debug] [Thread-3  ]: SQL status: SELECT 1 in 0.001 seconds
[0m10:54:20.776324 [debug] [Thread-3  ]: Using postgres connection "model.homework.iris_processed"
[0m10:54:20.778088 [debug] [Thread-3  ]: On model.homework.iris_processed: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "homework", "target_name": "dev", "node_id": "model.homework.iris_processed"} */

        select percentile_cont(0.5 - 0.5/2) within group (order by petal_width ) from "analytics"."analytics"."stg_iris"
    
[0m10:54:20.780428 [debug] [Thread-3  ]: SQL status: SELECT 1 in 0.001 seconds
[0m10:54:20.784572 [debug] [Thread-3  ]: Using postgres connection "model.homework.iris_processed"
[0m10:54:20.786720 [debug] [Thread-3  ]: On model.homework.iris_processed: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "homework", "target_name": "dev", "node_id": "model.homework.iris_processed"} */

        select percentile_cont(0.5 + 0.5/2) within group (order by petal_width ) from "analytics"."analytics"."stg_iris"
    
[0m10:54:20.789182 [debug] [Thread-3  ]: SQL status: SELECT 1 in 0.001 seconds
[0m10:54:20.815928 [debug] [Thread-3  ]: Using postgres connection "model.homework.iris_processed"
[0m10:54:20.818635 [debug] [Thread-3  ]: On model.homework.iris_processed: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "homework", "target_name": "dev", "node_id": "model.homework.iris_processed"} */

            select percentile_cont(0.5) within group (order by sepal_length ) from "analytics"."analytics"."stg_iris"
        
[0m10:54:20.821717 [debug] [Thread-3  ]: SQL status: SELECT 1 in 0.001 seconds
[0m10:54:20.826772 [debug] [Thread-3  ]: Using postgres connection "model.homework.iris_processed"
[0m10:54:20.828749 [debug] [Thread-3  ]: On model.homework.iris_processed: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "homework", "target_name": "dev", "node_id": "model.homework.iris_processed"} */

            select percentile_cont(0.5) within group (order by sepal_width ) from "analytics"."analytics"."stg_iris"
        
[0m10:54:20.831216 [debug] [Thread-3  ]: SQL status: SELECT 1 in 0.001 seconds
[0m10:54:20.837083 [debug] [Thread-3  ]: Using postgres connection "model.homework.iris_processed"
[0m10:54:20.839050 [debug] [Thread-3  ]: On model.homework.iris_processed: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "homework", "target_name": "dev", "node_id": "model.homework.iris_processed"} */

            select percentile_cont(0.5) within group (order by petal_length ) from "analytics"."analytics"."stg_iris"
        
[0m10:54:20.841853 [debug] [Thread-3  ]: SQL status: SELECT 1 in 0.001 seconds
[0m10:54:20.846877 [debug] [Thread-3  ]: Using postgres connection "model.homework.iris_processed"
[0m10:54:20.848664 [debug] [Thread-3  ]: On model.homework.iris_processed: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "homework", "target_name": "dev", "node_id": "model.homework.iris_processed"} */

            select percentile_cont(0.5) within group (order by petal_width ) from "analytics"."analytics"."stg_iris"
        
[0m10:54:20.852289 [debug] [Thread-3  ]: SQL status: SELECT 1 in 0.001 seconds
[0m10:54:20.932152 [debug] [Thread-3  ]: Using postgres connection "model.homework.iris_processed"
[0m10:54:20.934745 [debug] [Thread-3  ]: On model.homework.iris_processed: BEGIN
[0m10:54:20.940541 [debug] [Thread-3  ]: SQL status: BEGIN in 0.001 seconds
[0m10:54:20.943195 [debug] [Thread-3  ]: Using postgres connection "model.homework.iris_processed"
[0m10:54:20.945562 [debug] [Thread-3  ]: On model.homework.iris_processed: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "homework", "target_name": "dev", "node_id": "model.homework.iris_processed"} */
select
                species as value

            from "analytics"."analytics"."stg_iris"

            
            where species is not null  and true
            

            group by species
            order by species

            

        
[0m10:54:20.948883 [debug] [Thread-3  ]: SQL status: SELECT 3 in 0.001 seconds
[0m10:54:20.964592 [debug] [Thread-3  ]: Writing injected SQL for node "model.homework.iris_processed"
[0m10:54:20.984436 [debug] [Thread-3  ]: Began executing node model.homework.iris_processed
[0m10:54:21.050193 [debug] [Thread-3  ]: Writing runtime sql for node "model.homework.iris_processed"
[0m10:54:21.061986 [debug] [Thread-3  ]: Using postgres connection "model.homework.iris_processed"
[0m10:54:21.064943 [debug] [Thread-3  ]: On model.homework.iris_processed: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "homework", "target_name": "dev", "node_id": "model.homework.iris_processed"} */

  
    

  create  table "analytics"."analytics"."iris_processed__dbt_tmp"
  
  
    as
  
  (
    

with import_iris as (
    select *
    from "analytics"."analytics"."stg_iris"
)
select
    sepal_length,
    sepal_width,
    petal_length,
    petal_width,
    -- K Bins Discretization
    
        

    
        NTILE(5) over (order by sepal_length)
    

 as sepal_length_quantile_bin,
        

    
        
        floor(
        (
            sepal_length - (min(sepal_length) over ())
        )
        /
        (
            ((max(sepal_length) over ()) - (min(sepal_length) over ())) / 4::float
        )
        ) + 1
    

 as sepal_length_uniform_bin,
    
        

    
        NTILE(5) over (order by sepal_width)
    

 as sepal_width_quantile_bin,
        

    
        
        floor(
        (
            sepal_width - (min(sepal_width) over ())
        )
        /
        (
            ((max(sepal_width) over ()) - (min(sepal_width) over ())) / 4::float
        )
        ) + 1
    

 as sepal_width_uniform_bin,
    
        

    
        NTILE(5) over (order by petal_length)
    

 as petal_length_quantile_bin,
        

    
        
        floor(
        (
            petal_length - (min(petal_length) over ())
        )
        /
        (
            ((max(petal_length) over ()) - (min(petal_length) over ())) / 4::float
        )
        ) + 1
    

 as petal_length_uniform_bin,
    
        

    
        NTILE(5) over (order by petal_width)
    

 as petal_width_quantile_bin,
        

    
        
        floor(
        (
            petal_width - (min(petal_width) over ())
        )
        /
        (
            ((max(petal_width) over ()) - (min(petal_width) over ())) / 4::float
        )
        ) + 1
    

 as petal_width_uniform_bin,
    
-- Scaling
    
        

    

    
    
    

    
    
    

    (
        sepal_length - 5.8
    )
    /
    (
        6.4 - 5.1
    )

 as sepal_length_robust_scaled,
        

    (sepal_length) / (max(abs(sepal_length)) over ())::FLOAT

 as sepal_length_max_absolute_scaled,
        

    
    (
        ((sepal_length) - (min(sepal_length) over ()))
        /
        ((max(sepal_length) over ()) - (min(sepal_length) over ()))::FLOAT
    )
    *
    (1.0 - 0.0)
    +
    0.0

 as sepal_length_max_min_max_scaled,
    
        

    

    
    
    

    
    
    

    (
        sepal_width - 3.0
    )
    /
    (
        3.3 - 2.8
    )

 as sepal_width_robust_scaled,
        

    (sepal_width) / (max(abs(sepal_width)) over ())::FLOAT

 as sepal_width_max_absolute_scaled,
        

    
    (
        ((sepal_width) - (min(sepal_width) over ()))
        /
        ((max(sepal_width) over ()) - (min(sepal_width) over ()))::FLOAT
    )
    *
    (1.0 - 0.0)
    +
    0.0

 as sepal_width_max_min_max_scaled,
    
        

    

    
    
    

    
    
    

    (
        petal_length - 4.35
    )
    /
    (
        5.1 - 1.6
    )

 as petal_length_robust_scaled,
        

    (petal_length) / (max(abs(petal_length)) over ())::FLOAT

 as petal_length_max_absolute_scaled,
        

    
    (
        ((petal_length) - (min(petal_length) over ()))
        /
        ((max(petal_length) over ()) - (min(petal_length) over ()))::FLOAT
    )
    *
    (1.0 - 0.0)
    +
    0.0

 as petal_length_max_min_max_scaled,
    
        

    

    
    
    

    
    
    

    (
        petal_width - 1.3
    )
    /
    (
        1.8 - 0.3
    )

 as petal_width_robust_scaled,
        

    (petal_width) / (max(abs(petal_width)) over ())::FLOAT

 as petal_width_max_absolute_scaled,
        

    
    (
        ((petal_width) - (min(petal_width) over ()))
        /
        ((max(petal_width) over ()) - (min(petal_width) over ()))::FLOAT
    )
    *
    (1.0 - 0.0)
    +
    0.0

 as petal_width_max_min_max_scaled,
    

    -- Log Transformation
    
        

    case
        when sepal_length is null or sepal_length + 0 <= 0 then null
        else log(10, sepal_length + 0)
    end

 as sepal_length_logged,
    
        

    case
        when sepal_width is null or sepal_width + 0 <= 0 then null
        else log(10, sepal_width + 0)
    end

 as sepal_width_logged,
    
        

    case
        when petal_length is null or petal_length + 0 <= 0 then null
        else log(10, petal_length + 0)
    end

 as petal_length_logged,
    
        

    case
        when petal_width is null or petal_width + 0 <= 0 then null
        else log(10, petal_width + 0)
    end

 as petal_width_logged,
    

    -- Binarization
    
        

    

    
        

        
    

    case
        when sepal_length >=
            
                5.8
            
            then 1
        else 0
    end

 as sepal_length_binarized,
    
        

    

    
        

        
    

    case
        when sepal_width >=
            
                3.0
            
            then 1
        else 0
    end

 as sepal_width_binarized,
    
        

    

    
        

        
    

    case
        when petal_length >=
            
                4.35
            
            then 1
        else 0
    end

 as petal_length_binarized,
    
        

    

    
        

        
    

    case
        when petal_width >=
            
                1.3
            
            then 1
        else 0
    end

 as petal_width_binarized,
    

    -- Standardization
    
        

    
    (
        (sepal_length - avg(sepal_length) over ())
        /
        (stddev(sepal_length) over ())::FLOAT
    )
    *
    1
    +
    0

 as sepal_length_standardized,
    
        

    
    (
        (sepal_width - avg(sepal_width) over ())
        /
        (stddev(sepal_width) over ())::FLOAT
    )
    *
    1
    +
    0

 as sepal_width_standardized,
    
        

    
    (
        (petal_length - avg(petal_length) over ())
        /
        (stddev(petal_length) over ())::FLOAT
    )
    *
    1
    +
    0

 as petal_length_standardized,
    
        

    
    (
        (petal_width - avg(petal_width) over ())
        /
        (stddev(petal_width) over ())::FLOAT
    )
    *
    1
    +
    0

 as petal_width_standardized,
    
-- Interactions
    
        
            
            
            

    
        (sepal_length * sepal_width)
    

 as sepal_length_x_sepal_width_interaction,
            

    
        (sepal_length + sepal_width)
    

 as sepal_length_plus_sepal_width_interaction,
        
            
            
            

    
        (sepal_length * petal_length)
    

 as sepal_length_x_petal_length_interaction,
            

    
        (sepal_length + petal_length)
    

 as sepal_length_plus_petal_length_interaction,
        
            
            
            

    
        (sepal_length * petal_width)
    

 as sepal_length_x_petal_width_interaction,
            

    
        (sepal_length + petal_width)
    

 as sepal_length_plus_petal_width_interaction,
        
    
        
            
            
            

    
        (sepal_width * petal_length)
    

 as sepal_width_x_petal_length_interaction,
            

    
        (sepal_width + petal_length)
    

 as sepal_width_plus_petal_length_interaction,
        
            
            
            

    
        (sepal_width * petal_width)
    

 as sepal_width_x_petal_width_interaction,
            

    
        (sepal_width + petal_width)
    

 as sepal_width_plus_petal_width_interaction,
        
    
        
            
            
            

    
        (petal_length * petal_width)
    

 as petal_length_x_petal_width_interaction,
            

    
        (petal_length + petal_width)
    

 as petal_length_plus_petal_width_interaction,
        
    
        
    
species,    
    -- Label Encoding
    

    dense_rank() over (order by species) - 1

 as species_label_encoded,
    -- One Hot Encoding
    

    

    
        
    

    

    

        case
            when species = 'setosa' then 1
            else 0
        end as is_species__setosa,

    

        case
            when species = 'versicolor' then 1
            else 0
        end as is_species__versicolor,

    

        case
            when species = 'virginica' then 1
            else 0
        end as is_species__virginica,

    

    case
        when species is null then 1
        else 0
    end as is_species__


from "analytics"."analytics"."stg_iris"
  );
  
[0m10:54:21.107964 [debug] [Thread-3  ]: SQL status: SELECT 150 in 0.040 seconds
[0m10:54:21.126700 [debug] [Thread-3  ]: Using postgres connection "model.homework.iris_processed"
[0m10:54:21.128582 [debug] [Thread-3  ]: On model.homework.iris_processed: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "homework", "target_name": "dev", "node_id": "model.homework.iris_processed"} */
alter table "analytics"."analytics"."iris_processed" rename to "iris_processed__dbt_backup"
[0m10:54:21.131080 [debug] [Thread-3  ]: SQL status: ALTER TABLE in 0.001 seconds
[0m10:54:21.140822 [debug] [Thread-3  ]: Using postgres connection "model.homework.iris_processed"
[0m10:54:21.142640 [debug] [Thread-3  ]: On model.homework.iris_processed: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "homework", "target_name": "dev", "node_id": "model.homework.iris_processed"} */
alter table "analytics"."analytics"."iris_processed__dbt_tmp" rename to "iris_processed"
[0m10:54:21.144941 [debug] [Thread-3  ]: SQL status: ALTER TABLE in 0.000 seconds
[0m10:54:21.149700 [debug] [Thread-3  ]: On model.homework.iris_processed: COMMIT
[0m10:54:21.151964 [debug] [Thread-3  ]: Using postgres connection "model.homework.iris_processed"
[0m10:54:21.153973 [debug] [Thread-3  ]: On model.homework.iris_processed: COMMIT
[0m10:54:21.159748 [debug] [Thread-3  ]: SQL status: COMMIT in 0.004 seconds
[0m10:54:21.167580 [debug] [Thread-3  ]: Applying DROP to: "analytics"."analytics"."iris_processed__dbt_backup"
[0m10:54:21.174281 [debug] [Thread-3  ]: Using postgres connection "model.homework.iris_processed"
[0m10:54:21.176211 [debug] [Thread-3  ]: On model.homework.iris_processed: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "homework", "target_name": "dev", "node_id": "model.homework.iris_processed"} */
drop table if exists "analytics"."analytics"."iris_processed__dbt_backup" cascade
[0m10:54:21.184324 [debug] [Thread-3  ]: SQL status: DROP TABLE in 0.006 seconds
[0m10:54:21.188491 [debug] [Thread-3  ]: On model.homework.iris_processed: Close
[0m10:54:21.190637 [debug] [Thread-3  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '984b0604-2cef-44c4-9d18-c371171922cb', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd4186c7610>]}
[0m10:54:21.193119 [info ] [Thread-3  ]: 2 of 2 OK created sql table model analytics.iris_processed ..................... [[32mSELECT 150[0m in 0.60s]
[0m10:54:21.195577 [debug] [Thread-3  ]: Finished running node model.homework.iris_processed
[0m10:54:21.199074 [debug] [MainThread]: Using postgres connection "master"
[0m10:54:21.200949 [debug] [MainThread]: On master: BEGIN
[0m10:54:21.203246 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m10:54:21.214833 [debug] [MainThread]: SQL status: BEGIN in 0.011 seconds
[0m10:54:21.217394 [debug] [MainThread]: On master: COMMIT
[0m10:54:21.220369 [debug] [MainThread]: Using postgres connection "master"
[0m10:54:21.222346 [debug] [MainThread]: On master: COMMIT
[0m10:54:21.224592 [debug] [MainThread]: SQL status: COMMIT in 0.000 seconds
[0m10:54:21.226409 [debug] [MainThread]: On master: Close
[0m10:54:21.228671 [debug] [MainThread]: Connection 'master' was properly closed.
[0m10:54:21.230929 [debug] [MainThread]: Connection 'model.homework.stg_iris' was properly closed.
[0m10:54:21.232913 [debug] [MainThread]: Connection 'model.homework.iris_processed' was properly closed.
[0m10:54:21.235354 [info ] [MainThread]: 
[0m10:54:21.237931 [info ] [MainThread]: Finished running 1 table model, 1 view model in 0 hours 0 minutes and 1.26 seconds (1.26s).
[0m10:54:21.241915 [debug] [MainThread]: Command end result
[0m10:54:21.345793 [debug] [MainThread]: Wrote artifact WritableManifest to /opt/airflow/dags/dbt/homework/target/manifest.json
[0m10:54:21.355935 [debug] [MainThread]: Wrote artifact SemanticManifest to /opt/airflow/dags/dbt/homework/target/semantic_manifest.json
[0m10:54:21.377379 [debug] [MainThread]: Wrote artifact RunExecutionResult to /opt/airflow/dags/dbt/homework/target/run_results.json
[0m10:54:21.379513 [info ] [MainThread]: 
[0m10:54:21.381773 [info ] [MainThread]: [32mCompleted successfully[0m
[0m10:54:21.384466 [info ] [MainThread]: 
[0m10:54:21.387022 [info ] [MainThread]: Done. PASS=2 WARN=0 ERROR=0 SKIP=0 TOTAL=2
[0m10:54:21.389959 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": true, "command_wall_clock_time": 5.186063, "process_in_blocks": "0", "process_kernel_time": 0.463323, "process_mem_max_rss": "115084", "process_out_blocks": "0", "process_user_time": 6.285084}
[0m10:54:21.392125 [debug] [MainThread]: Command `dbt run` succeeded at 10:54:21.391925 after 5.19 seconds
[0m10:54:21.394003 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd41d7c2ac0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd41b118460>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd41b079a90>]}
[0m10:54:21.395788 [debug] [MainThread]: Flushing usage events
[0m10:54:22.485349 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m10:54:29.406507 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb5f5f24ac0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb5f5046580>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb5f5046520>]}


============================== 10:54:29.424694 | aaa33410-0e82-4e1a-b882-aead6329f8a9 ==============================
[0m10:54:29.424694 [info ] [MainThread]: Running with dbt=1.9.4
[0m10:54:29.427018 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': '/opt/airflow/dags/dbt', 'fail_fast': 'True', 'debug': 'False', 'log_path': '/opt/airflow/dags/dbt/homework/logs', 'version_check': 'True', 'warn_error': 'None', 'use_colors': 'True', 'use_experimental_parser': 'False', 'empty': 'None', 'quiet': 'False', 'no_print': 'None', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'static_parser': 'True', 'log_format': 'default', 'introspect': 'True', 'target_path': 'None', 'invocation_command': 'dbt --profile homework test --project-dir=/opt/airflow/dags/dbt/homework --vars {"is_test": false, "data_date": "2025-04-23"} --fail-fast', 'send_anonymous_usage_stats': 'True'}
[0m10:54:29.886104 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'aaa33410-0e82-4e1a-b882-aead6329f8a9', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb5f380e610>]}
[0m10:54:30.036587 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': 'aaa33410-0e82-4e1a-b882-aead6329f8a9', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb5f50c3760>]}
[0m10:54:30.039236 [info ] [MainThread]: Registered adapter: postgres=1.9.0
[0m10:54:30.298997 [debug] [MainThread]: checksum: f5df654a850f4b74beb13fbe0c7d8863b5b1a20bd535c3ac287d70e390b64d41, vars: {'data_date': '2025-04-23', 'is_test': False}, profile: homework, target: , version: 1.9.4
[0m10:54:31.815910 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m10:54:31.817768 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m10:54:31.834330 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 1 unused configuration paths:
- seeds.homework.iris_dataset
[0m10:54:31.924008 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'aaa33410-0e82-4e1a-b882-aead6329f8a9', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb5f3374130>]}
[0m10:54:32.253036 [debug] [MainThread]: Wrote artifact WritableManifest to /opt/airflow/dags/dbt/homework/target/manifest.json
[0m10:54:32.273558 [debug] [MainThread]: Wrote artifact SemanticManifest to /opt/airflow/dags/dbt/homework/target/semantic_manifest.json
[0m10:54:32.320318 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'aaa33410-0e82-4e1a-b882-aead6329f8a9', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb5f32b9520>]}
[0m10:54:32.322447 [info ] [MainThread]: Found 2 models, 1 source, 587 macros
[0m10:54:32.324289 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'aaa33410-0e82-4e1a-b882-aead6329f8a9', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb5f50d4910>]}
[0m10:54:32.328012 [warn ] [MainThread]: Nothing to do. Try checking your model configs and model specification args
[0m10:54:32.333126 [debug] [MainThread]: Command end result
[0m10:54:32.477638 [debug] [MainThread]: Wrote artifact WritableManifest to /opt/airflow/dags/dbt/homework/target/manifest.json
[0m10:54:32.490038 [debug] [MainThread]: Wrote artifact SemanticManifest to /opt/airflow/dags/dbt/homework/target/semantic_manifest.json
[0m10:54:32.506077 [debug] [MainThread]: Wrote artifact RunExecutionResult to /opt/airflow/dags/dbt/homework/target/run_results.json
[0m10:54:32.510276 [debug] [MainThread]: Resource report: {"command_name": "test", "command_success": true, "command_wall_clock_time": 3.2821572, "process_in_blocks": "16", "process_kernel_time": 0.361576, "process_mem_max_rss": "104680", "process_out_blocks": "0", "process_user_time": 6.036318}
[0m10:54:32.513112 [debug] [MainThread]: Command `dbt test` succeeded at 10:54:32.512868 after 3.29 seconds
[0m10:54:32.515882 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb5f5f24ac0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb5f5d93310>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb5f3314940>]}
[0m10:54:32.517899 [debug] [MainThread]: Flushing usage events
[0m10:54:33.069084 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m11:04:18.114881 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f502bce1a90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f502ae02460>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f502ae02400>]}


============================== 11:04:18.134271 | 0ae267ef-b146-4c14-8945-3f8059781e50 ==============================
[0m11:04:18.134271 [info ] [MainThread]: Running with dbt=1.9.4
[0m11:04:18.136782 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': '/opt/airflow/dags/dbt', 'debug': 'False', 'warn_error': 'None', 'log_path': '/opt/airflow/dags/dbt/homework/logs', 'version_check': 'True', 'fail_fast': 'False', 'use_colors': 'True', 'use_experimental_parser': 'False', 'empty': 'False', 'quiet': 'False', 'no_print': 'None', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'introspect': 'True', 'log_format': 'default', 'invocation_command': 'dbt --profile homework run --project-dir=/opt/airflow/dags/dbt/homework --vars {"is_test": false, "data_date": "2025-04-23"}', 'target_path': 'None', 'static_parser': 'True', 'send_anonymous_usage_stats': 'True'}
[0m11:04:18.899562 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '0ae267ef-b146-4c14-8945-3f8059781e50', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f50295d47f0>]}
[0m11:04:19.067198 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '0ae267ef-b146-4c14-8945-3f8059781e50', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f502b0225e0>]}
[0m11:04:19.069687 [info ] [MainThread]: Registered adapter: postgres=1.9.0
[0m11:04:19.374562 [debug] [MainThread]: checksum: f5df654a850f4b74beb13fbe0c7d8863b5b1a20bd535c3ac287d70e390b64d41, vars: {'data_date': '2025-04-23', 'is_test': False}, profile: homework, target: , version: 1.9.4
[0m11:04:21.501193 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m11:04:21.503017 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m11:04:21.517648 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 1 unused configuration paths:
- seeds.homework.iris_dataset
[0m11:04:21.606759 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '0ae267ef-b146-4c14-8945-3f8059781e50', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f502912f130>]}
[0m11:04:21.937266 [debug] [MainThread]: Wrote artifact WritableManifest to /opt/airflow/dags/dbt/homework/target/manifest.json
[0m11:04:21.960217 [debug] [MainThread]: Wrote artifact SemanticManifest to /opt/airflow/dags/dbt/homework/target/semantic_manifest.json
[0m11:04:21.996566 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '0ae267ef-b146-4c14-8945-3f8059781e50', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f50290cfc70>]}
[0m11:04:21.998497 [info ] [MainThread]: Found 2 models, 1 source, 587 macros
[0m11:04:22.000155 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '0ae267ef-b146-4c14-8945-3f8059781e50', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f502ae686d0>]}
[0m11:04:22.004787 [info ] [MainThread]: 
[0m11:04:22.007207 [info ] [MainThread]: Concurrency: 4 threads (target='dev')
[0m11:04:22.008923 [info ] [MainThread]: 
[0m11:04:22.010971 [debug] [MainThread]: Acquiring new postgres connection 'master'
[0m11:04:22.021582 [debug] [ThreadPool]: Acquiring new postgres connection 'list_analytics'
[0m11:04:22.094162 [debug] [ThreadPool]: Using postgres connection "list_analytics"
[0m11:04:22.095871 [debug] [ThreadPool]: On list_analytics: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "homework", "target_name": "dev", "connection_name": "list_analytics"} */

    select distinct nspname from pg_namespace
  
[0m11:04:22.097381 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m11:04:22.112775 [debug] [ThreadPool]: SQL status: SELECT 6 in 0.015 seconds
[0m11:04:22.118028 [debug] [ThreadPool]: On list_analytics: Close
[0m11:04:22.122816 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_analytics, now list_analytics_analytics)
[0m11:04:22.141375 [debug] [ThreadPool]: Using postgres connection "list_analytics_analytics"
[0m11:04:22.144992 [debug] [ThreadPool]: On list_analytics_analytics: BEGIN
[0m11:04:22.146905 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m11:04:22.160015 [debug] [ThreadPool]: SQL status: BEGIN in 0.013 seconds
[0m11:04:22.162503 [debug] [ThreadPool]: Using postgres connection "list_analytics_analytics"
[0m11:04:22.165337 [debug] [ThreadPool]: On list_analytics_analytics: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "homework", "target_name": "dev", "connection_name": "list_analytics_analytics"} */
select
      'analytics' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'analytics'
    union all
    select
      'analytics' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'analytics'
    union all
    select
      'analytics' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'analytics'
  
[0m11:04:22.171562 [debug] [ThreadPool]: SQL status: SELECT 3 in 0.004 seconds
[0m11:04:22.175004 [debug] [ThreadPool]: On list_analytics_analytics: ROLLBACK
[0m11:04:22.176936 [debug] [ThreadPool]: On list_analytics_analytics: Close
[0m11:04:22.193183 [debug] [MainThread]: Using postgres connection "master"
[0m11:04:22.195217 [debug] [MainThread]: On master: BEGIN
[0m11:04:22.197086 [debug] [MainThread]: Opening a new connection, currently in state init
[0m11:04:22.214498 [debug] [MainThread]: SQL status: BEGIN in 0.017 seconds
[0m11:04:22.220091 [debug] [MainThread]: Using postgres connection "master"
[0m11:04:22.222795 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "homework", "target_name": "dev", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select distinct
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v', 'm')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
[0m11:04:22.251439 [debug] [MainThread]: SQL status: SELECT 1 in 0.026 seconds
[0m11:04:22.256109 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '0ae267ef-b146-4c14-8945-3f8059781e50', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f502935cd00>]}
[0m11:04:22.258635 [debug] [MainThread]: On master: ROLLBACK
[0m11:04:22.260962 [debug] [MainThread]: Using postgres connection "master"
[0m11:04:22.262913 [debug] [MainThread]: On master: BEGIN
[0m11:04:22.266309 [debug] [MainThread]: SQL status: BEGIN in 0.001 seconds
[0m11:04:22.268977 [debug] [MainThread]: On master: COMMIT
[0m11:04:22.271531 [debug] [MainThread]: Using postgres connection "master"
[0m11:04:22.273925 [debug] [MainThread]: On master: COMMIT
[0m11:04:22.276386 [debug] [MainThread]: SQL status: COMMIT in 0.000 seconds
[0m11:04:22.278642 [debug] [MainThread]: On master: Close
[0m11:04:22.287813 [debug] [Thread-1  ]: Began running node model.homework.stg_iris
[0m11:04:22.290295 [info ] [Thread-1  ]: 1 of 2 START sql view model analytics.stg_iris ................................. [RUN]
[0m11:04:22.292985 [debug] [Thread-1  ]: Re-using an available connection from the pool (formerly list_analytics_analytics, now model.homework.stg_iris)
[0m11:04:22.295388 [debug] [Thread-1  ]: Began compiling node model.homework.stg_iris
[0m11:04:22.317685 [debug] [Thread-1  ]: Writing injected SQL for node "model.homework.stg_iris"
[0m11:04:22.331052 [debug] [Thread-1  ]: Began executing node model.homework.stg_iris
[0m11:04:22.462548 [debug] [Thread-1  ]: Writing runtime sql for node "model.homework.stg_iris"
[0m11:04:22.477288 [debug] [Thread-1  ]: Using postgres connection "model.homework.stg_iris"
[0m11:04:22.479658 [debug] [Thread-1  ]: On model.homework.stg_iris: BEGIN
[0m11:04:22.481613 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
[0m11:04:22.494855 [debug] [Thread-1  ]: SQL status: BEGIN in 0.013 seconds
[0m11:04:22.497705 [debug] [Thread-1  ]: Using postgres connection "model.homework.stg_iris"
[0m11:04:22.500772 [debug] [Thread-1  ]: On model.homework.stg_iris: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "homework", "target_name": "dev", "node_id": "model.homework.stg_iris"} */

  create view "analytics"."analytics"."stg_iris__dbt_tmp"
    
    
  as (
    with source as (
    select * from "analytics"."analytics"."iris_dataset"
)

select
    cast(sepal_length as numeric) as sepal_length,
    cast(sepal_width as numeric) as sepal_width,
    cast(petal_length as numeric) as petal_length,
    cast(petal_width as numeric) as petal_width,
    species
from source
  );
[0m11:04:22.507144 [debug] [Thread-1  ]: SQL status: CREATE VIEW in 0.004 seconds
[0m11:04:22.526854 [debug] [Thread-1  ]: Using postgres connection "model.homework.stg_iris"
[0m11:04:22.528687 [debug] [Thread-1  ]: On model.homework.stg_iris: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "homework", "target_name": "dev", "node_id": "model.homework.stg_iris"} */
alter table "analytics"."analytics"."stg_iris" rename to "stg_iris__dbt_backup"
[0m11:04:22.532409 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.001 seconds
[0m11:04:22.541987 [debug] [Thread-1  ]: Using postgres connection "model.homework.stg_iris"
[0m11:04:22.543952 [debug] [Thread-1  ]: On model.homework.stg_iris: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "homework", "target_name": "dev", "node_id": "model.homework.stg_iris"} */
alter table "analytics"."analytics"."stg_iris__dbt_tmp" rename to "stg_iris"
[0m11:04:22.546435 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.001 seconds
[0m11:04:22.615724 [debug] [Thread-1  ]: On model.homework.stg_iris: COMMIT
[0m11:04:22.617850 [debug] [Thread-1  ]: Using postgres connection "model.homework.stg_iris"
[0m11:04:22.620335 [debug] [Thread-1  ]: On model.homework.stg_iris: COMMIT
[0m11:04:22.626155 [debug] [Thread-1  ]: SQL status: COMMIT in 0.003 seconds
[0m11:04:22.650013 [debug] [Thread-1  ]: Applying DROP to: "analytics"."analytics"."stg_iris__dbt_backup"
[0m11:04:22.670881 [debug] [Thread-1  ]: Using postgres connection "model.homework.stg_iris"
[0m11:04:22.673009 [debug] [Thread-1  ]: On model.homework.stg_iris: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "homework", "target_name": "dev", "node_id": "model.homework.stg_iris"} */
drop view if exists "analytics"."analytics"."stg_iris__dbt_backup" cascade
[0m11:04:22.679852 [debug] [Thread-1  ]: SQL status: DROP VIEW in 0.005 seconds
[0m11:04:22.690081 [debug] [Thread-1  ]: On model.homework.stg_iris: Close
[0m11:04:22.695746 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '0ae267ef-b146-4c14-8945-3f8059781e50', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f50285ecf70>]}
[0m11:04:22.699254 [info ] [Thread-1  ]: 1 of 2 OK created sql view model analytics.stg_iris ............................ [[32mCREATE VIEW[0m in 0.40s]
[0m11:04:22.701562 [debug] [Thread-1  ]: Finished running node model.homework.stg_iris
[0m11:04:22.705414 [debug] [Thread-3  ]: Began running node model.homework.iris_processed
[0m11:04:22.707505 [info ] [Thread-3  ]: 2 of 2 START sql table model analytics.iris_processed .......................... [RUN]
[0m11:04:22.709765 [debug] [Thread-3  ]: Acquiring new postgres connection 'model.homework.iris_processed'
[0m11:04:22.711561 [debug] [Thread-3  ]: Began compiling node model.homework.iris_processed
[0m11:04:22.796343 [debug] [Thread-3  ]: Using postgres connection "model.homework.iris_processed"
[0m11:04:22.798597 [debug] [Thread-3  ]: On model.homework.iris_processed: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "homework", "target_name": "dev", "node_id": "model.homework.iris_processed"} */

        select percentile_cont(0.5) within group (order by sepal_length ) from "analytics"."analytics"."stg_iris"
    
[0m11:04:22.801233 [debug] [Thread-3  ]: Opening a new connection, currently in state init
[0m11:04:22.879447 [debug] [Thread-3  ]: SQL status: SELECT 1 in 0.078 seconds
[0m11:04:22.884126 [debug] [Thread-3  ]: Using postgres connection "model.homework.iris_processed"
[0m11:04:22.885936 [debug] [Thread-3  ]: On model.homework.iris_processed: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "homework", "target_name": "dev", "node_id": "model.homework.iris_processed"} */

        select percentile_cont(0.5 - 0.5/2) within group (order by sepal_length ) from "analytics"."analytics"."stg_iris"
    
[0m11:04:22.889448 [debug] [Thread-3  ]: SQL status: SELECT 1 in 0.002 seconds
[0m11:04:22.894114 [debug] [Thread-3  ]: Using postgres connection "model.homework.iris_processed"
[0m11:04:22.896094 [debug] [Thread-3  ]: On model.homework.iris_processed: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "homework", "target_name": "dev", "node_id": "model.homework.iris_processed"} */

        select percentile_cont(0.5 + 0.5/2) within group (order by sepal_length ) from "analytics"."analytics"."stg_iris"
    
[0m11:04:22.898807 [debug] [Thread-3  ]: SQL status: SELECT 1 in 0.001 seconds
[0m11:04:22.915632 [debug] [Thread-3  ]: Using postgres connection "model.homework.iris_processed"
[0m11:04:22.917731 [debug] [Thread-3  ]: On model.homework.iris_processed: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "homework", "target_name": "dev", "node_id": "model.homework.iris_processed"} */

        select percentile_cont(0.5) within group (order by sepal_width ) from "analytics"."analytics"."stg_iris"
    
[0m11:04:22.920514 [debug] [Thread-3  ]: SQL status: SELECT 1 in 0.001 seconds
[0m11:04:22.925290 [debug] [Thread-3  ]: Using postgres connection "model.homework.iris_processed"
[0m11:04:22.927225 [debug] [Thread-3  ]: On model.homework.iris_processed: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "homework", "target_name": "dev", "node_id": "model.homework.iris_processed"} */

        select percentile_cont(0.5 - 0.5/2) within group (order by sepal_width ) from "analytics"."analytics"."stg_iris"
    
[0m11:04:22.930292 [debug] [Thread-3  ]: SQL status: SELECT 1 in 0.001 seconds
[0m11:04:22.934529 [debug] [Thread-3  ]: Using postgres connection "model.homework.iris_processed"
[0m11:04:22.937096 [debug] [Thread-3  ]: On model.homework.iris_processed: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "homework", "target_name": "dev", "node_id": "model.homework.iris_processed"} */

        select percentile_cont(0.5 + 0.5/2) within group (order by sepal_width ) from "analytics"."analytics"."stg_iris"
    
[0m11:04:22.940234 [debug] [Thread-3  ]: SQL status: SELECT 1 in 0.001 seconds
[0m11:04:22.946527 [debug] [Thread-3  ]: Using postgres connection "model.homework.iris_processed"
[0m11:04:22.948724 [debug] [Thread-3  ]: On model.homework.iris_processed: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "homework", "target_name": "dev", "node_id": "model.homework.iris_processed"} */

        select percentile_cont(0.5) within group (order by petal_length ) from "analytics"."analytics"."stg_iris"
    
[0m11:04:22.951529 [debug] [Thread-3  ]: SQL status: SELECT 1 in 0.001 seconds
[0m11:04:22.956525 [debug] [Thread-3  ]: Using postgres connection "model.homework.iris_processed"
[0m11:04:22.958959 [debug] [Thread-3  ]: On model.homework.iris_processed: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "homework", "target_name": "dev", "node_id": "model.homework.iris_processed"} */

        select percentile_cont(0.5 - 0.5/2) within group (order by petal_length ) from "analytics"."analytics"."stg_iris"
    
[0m11:04:22.962978 [debug] [Thread-3  ]: SQL status: SELECT 1 in 0.001 seconds
[0m11:04:22.968998 [debug] [Thread-3  ]: Using postgres connection "model.homework.iris_processed"
[0m11:04:22.971127 [debug] [Thread-3  ]: On model.homework.iris_processed: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "homework", "target_name": "dev", "node_id": "model.homework.iris_processed"} */

        select percentile_cont(0.5 + 0.5/2) within group (order by petal_length ) from "analytics"."analytics"."stg_iris"
    
[0m11:04:22.973944 [debug] [Thread-3  ]: SQL status: SELECT 1 in 0.001 seconds
[0m11:04:22.979940 [debug] [Thread-3  ]: Using postgres connection "model.homework.iris_processed"
[0m11:04:22.983188 [debug] [Thread-3  ]: On model.homework.iris_processed: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "homework", "target_name": "dev", "node_id": "model.homework.iris_processed"} */

        select percentile_cont(0.5) within group (order by petal_width ) from "analytics"."analytics"."stg_iris"
    
[0m11:04:22.986091 [debug] [Thread-3  ]: SQL status: SELECT 1 in 0.001 seconds
[0m11:04:22.990335 [debug] [Thread-3  ]: Using postgres connection "model.homework.iris_processed"
[0m11:04:22.992213 [debug] [Thread-3  ]: On model.homework.iris_processed: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "homework", "target_name": "dev", "node_id": "model.homework.iris_processed"} */

        select percentile_cont(0.5 - 0.5/2) within group (order by petal_width ) from "analytics"."analytics"."stg_iris"
    
[0m11:04:22.994952 [debug] [Thread-3  ]: SQL status: SELECT 1 in 0.001 seconds
[0m11:04:22.999185 [debug] [Thread-3  ]: Using postgres connection "model.homework.iris_processed"
[0m11:04:23.001212 [debug] [Thread-3  ]: On model.homework.iris_processed: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "homework", "target_name": "dev", "node_id": "model.homework.iris_processed"} */

        select percentile_cont(0.5 + 0.5/2) within group (order by petal_width ) from "analytics"."analytics"."stg_iris"
    
[0m11:04:23.003699 [debug] [Thread-3  ]: SQL status: SELECT 1 in 0.001 seconds
[0m11:04:23.030294 [debug] [Thread-3  ]: Using postgres connection "model.homework.iris_processed"
[0m11:04:23.032591 [debug] [Thread-3  ]: On model.homework.iris_processed: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "homework", "target_name": "dev", "node_id": "model.homework.iris_processed"} */

            select percentile_cont(0.5) within group (order by sepal_length ) from "analytics"."analytics"."stg_iris"
        
[0m11:04:23.035602 [debug] [Thread-3  ]: SQL status: SELECT 1 in 0.001 seconds
[0m11:04:23.042805 [debug] [Thread-3  ]: Using postgres connection "model.homework.iris_processed"
[0m11:04:23.046205 [debug] [Thread-3  ]: On model.homework.iris_processed: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "homework", "target_name": "dev", "node_id": "model.homework.iris_processed"} */

            select percentile_cont(0.5) within group (order by sepal_width ) from "analytics"."analytics"."stg_iris"
        
[0m11:04:23.051397 [debug] [Thread-3  ]: SQL status: SELECT 1 in 0.001 seconds
[0m11:04:23.058320 [debug] [Thread-3  ]: Using postgres connection "model.homework.iris_processed"
[0m11:04:23.060687 [debug] [Thread-3  ]: On model.homework.iris_processed: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "homework", "target_name": "dev", "node_id": "model.homework.iris_processed"} */

            select percentile_cont(0.5) within group (order by petal_length ) from "analytics"."analytics"."stg_iris"
        
[0m11:04:23.063726 [debug] [Thread-3  ]: SQL status: SELECT 1 in 0.001 seconds
[0m11:04:23.070924 [debug] [Thread-3  ]: Using postgres connection "model.homework.iris_processed"
[0m11:04:23.077307 [debug] [Thread-3  ]: On model.homework.iris_processed: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "homework", "target_name": "dev", "node_id": "model.homework.iris_processed"} */

            select percentile_cont(0.5) within group (order by petal_width ) from "analytics"."analytics"."stg_iris"
        
[0m11:04:23.081999 [debug] [Thread-3  ]: SQL status: SELECT 1 in 0.001 seconds
[0m11:04:23.235268 [debug] [Thread-3  ]: Using postgres connection "model.homework.iris_processed"
[0m11:04:23.237473 [debug] [Thread-3  ]: On model.homework.iris_processed: BEGIN
[0m11:04:23.240476 [debug] [Thread-3  ]: SQL status: BEGIN in 0.001 seconds
[0m11:04:23.243243 [debug] [Thread-3  ]: Using postgres connection "model.homework.iris_processed"
[0m11:04:23.245953 [debug] [Thread-3  ]: On model.homework.iris_processed: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "homework", "target_name": "dev", "node_id": "model.homework.iris_processed"} */
select
                species as value

            from "analytics"."analytics"."stg_iris"

            
            where species is not null  and true
            

            group by species
            order by species

            

        
[0m11:04:23.251574 [debug] [Thread-3  ]: SQL status: SELECT 3 in 0.002 seconds
[0m11:04:23.273915 [debug] [Thread-3  ]: Writing injected SQL for node "model.homework.iris_processed"
[0m11:04:23.287836 [debug] [Thread-3  ]: Began executing node model.homework.iris_processed
[0m11:04:23.389683 [debug] [Thread-3  ]: Writing runtime sql for node "model.homework.iris_processed"
[0m11:04:23.404722 [debug] [Thread-3  ]: Using postgres connection "model.homework.iris_processed"
[0m11:04:23.409623 [debug] [Thread-3  ]: On model.homework.iris_processed: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "homework", "target_name": "dev", "node_id": "model.homework.iris_processed"} */

  
    

  create  table "analytics"."analytics"."iris_processed__dbt_tmp"
  
  
    as
  
  (
    

with import_iris as (
    select *
    from "analytics"."analytics"."stg_iris"
)
select
    sepal_length,
    sepal_width,
    petal_length,
    petal_width,
    -- K Bins Discretization
    
        

    
        NTILE(5) over (order by sepal_length)
    

 as sepal_length_quantile_bin,
        

    
        
        floor(
        (
            sepal_length - (min(sepal_length) over ())
        )
        /
        (
            ((max(sepal_length) over ()) - (min(sepal_length) over ())) / 4::float
        )
        ) + 1
    

 as sepal_length_uniform_bin,
    
        

    
        NTILE(5) over (order by sepal_width)
    

 as sepal_width_quantile_bin,
        

    
        
        floor(
        (
            sepal_width - (min(sepal_width) over ())
        )
        /
        (
            ((max(sepal_width) over ()) - (min(sepal_width) over ())) / 4::float
        )
        ) + 1
    

 as sepal_width_uniform_bin,
    
        

    
        NTILE(5) over (order by petal_length)
    

 as petal_length_quantile_bin,
        

    
        
        floor(
        (
            petal_length - (min(petal_length) over ())
        )
        /
        (
            ((max(petal_length) over ()) - (min(petal_length) over ())) / 4::float
        )
        ) + 1
    

 as petal_length_uniform_bin,
    
        

    
        NTILE(5) over (order by petal_width)
    

 as petal_width_quantile_bin,
        

    
        
        floor(
        (
            petal_width - (min(petal_width) over ())
        )
        /
        (
            ((max(petal_width) over ()) - (min(petal_width) over ())) / 4::float
        )
        ) + 1
    

 as petal_width_uniform_bin,
    
-- Scaling
    
        

    

    
    
    

    
    
    

    (
        sepal_length - 5.8
    )
    /
    (
        6.4 - 5.1
    )

 as sepal_length_robust_scaled,
        

    (sepal_length) / (max(abs(sepal_length)) over ())::FLOAT

 as sepal_length_max_absolute_scaled,
        

    
    (
        ((sepal_length) - (min(sepal_length) over ()))
        /
        ((max(sepal_length) over ()) - (min(sepal_length) over ()))::FLOAT
    )
    *
    (1.0 - 0.0)
    +
    0.0

 as sepal_length_max_min_max_scaled,
    
        

    

    
    
    

    
    
    

    (
        sepal_width - 3.0
    )
    /
    (
        3.3 - 2.8
    )

 as sepal_width_robust_scaled,
        

    (sepal_width) / (max(abs(sepal_width)) over ())::FLOAT

 as sepal_width_max_absolute_scaled,
        

    
    (
        ((sepal_width) - (min(sepal_width) over ()))
        /
        ((max(sepal_width) over ()) - (min(sepal_width) over ()))::FLOAT
    )
    *
    (1.0 - 0.0)
    +
    0.0

 as sepal_width_max_min_max_scaled,
    
        

    

    
    
    

    
    
    

    (
        petal_length - 4.35
    )
    /
    (
        5.1 - 1.6
    )

 as petal_length_robust_scaled,
        

    (petal_length) / (max(abs(petal_length)) over ())::FLOAT

 as petal_length_max_absolute_scaled,
        

    
    (
        ((petal_length) - (min(petal_length) over ()))
        /
        ((max(petal_length) over ()) - (min(petal_length) over ()))::FLOAT
    )
    *
    (1.0 - 0.0)
    +
    0.0

 as petal_length_max_min_max_scaled,
    
        

    

    
    
    

    
    
    

    (
        petal_width - 1.3
    )
    /
    (
        1.8 - 0.3
    )

 as petal_width_robust_scaled,
        

    (petal_width) / (max(abs(petal_width)) over ())::FLOAT

 as petal_width_max_absolute_scaled,
        

    
    (
        ((petal_width) - (min(petal_width) over ()))
        /
        ((max(petal_width) over ()) - (min(petal_width) over ()))::FLOAT
    )
    *
    (1.0 - 0.0)
    +
    0.0

 as petal_width_max_min_max_scaled,
    

    -- Log Transformation
    
        

    case
        when sepal_length is null or sepal_length + 0 <= 0 then null
        else log(10, sepal_length + 0)
    end

 as sepal_length_logged,
    
        

    case
        when sepal_width is null or sepal_width + 0 <= 0 then null
        else log(10, sepal_width + 0)
    end

 as sepal_width_logged,
    
        

    case
        when petal_length is null or petal_length + 0 <= 0 then null
        else log(10, petal_length + 0)
    end

 as petal_length_logged,
    
        

    case
        when petal_width is null or petal_width + 0 <= 0 then null
        else log(10, petal_width + 0)
    end

 as petal_width_logged,
    

    -- Binarization
    
        

    

    
        

        
    

    case
        when sepal_length >=
            
                5.8
            
            then 1
        else 0
    end

 as sepal_length_binarized,
    
        

    

    
        

        
    

    case
        when sepal_width >=
            
                3.0
            
            then 1
        else 0
    end

 as sepal_width_binarized,
    
        

    

    
        

        
    

    case
        when petal_length >=
            
                4.35
            
            then 1
        else 0
    end

 as petal_length_binarized,
    
        

    

    
        

        
    

    case
        when petal_width >=
            
                1.3
            
            then 1
        else 0
    end

 as petal_width_binarized,
    

    -- Standardization
    
        

    
    (
        (sepal_length - avg(sepal_length) over ())
        /
        (stddev(sepal_length) over ())::FLOAT
    )
    *
    1
    +
    0

 as sepal_length_standardized,
    
        

    
    (
        (sepal_width - avg(sepal_width) over ())
        /
        (stddev(sepal_width) over ())::FLOAT
    )
    *
    1
    +
    0

 as sepal_width_standardized,
    
        

    
    (
        (petal_length - avg(petal_length) over ())
        /
        (stddev(petal_length) over ())::FLOAT
    )
    *
    1
    +
    0

 as petal_length_standardized,
    
        

    
    (
        (petal_width - avg(petal_width) over ())
        /
        (stddev(petal_width) over ())::FLOAT
    )
    *
    1
    +
    0

 as petal_width_standardized,
    
-- Interactions
    
        
            
            
            

    
        (sepal_length * sepal_width)
    

 as sepal_length_x_sepal_width_interaction,
            

    
        (sepal_length + sepal_width)
    

 as sepal_length_plus_sepal_width_interaction,
        
            
            
            

    
        (sepal_length * petal_length)
    

 as sepal_length_x_petal_length_interaction,
            

    
        (sepal_length + petal_length)
    

 as sepal_length_plus_petal_length_interaction,
        
            
            
            

    
        (sepal_length * petal_width)
    

 as sepal_length_x_petal_width_interaction,
            

    
        (sepal_length + petal_width)
    

 as sepal_length_plus_petal_width_interaction,
        
    
        
            
            
            

    
        (sepal_width * petal_length)
    

 as sepal_width_x_petal_length_interaction,
            

    
        (sepal_width + petal_length)
    

 as sepal_width_plus_petal_length_interaction,
        
            
            
            

    
        (sepal_width * petal_width)
    

 as sepal_width_x_petal_width_interaction,
            

    
        (sepal_width + petal_width)
    

 as sepal_width_plus_petal_width_interaction,
        
    
        
            
            
            

    
        (petal_length * petal_width)
    

 as petal_length_x_petal_width_interaction,
            

    
        (petal_length + petal_width)
    

 as petal_length_plus_petal_width_interaction,
        
    
        
    
species,    
    -- Label Encoding
    

    dense_rank() over (order by species) - 1

 as species_label_encoded,
    -- One Hot Encoding
    

    

    
        
    

    

    

        case
            when species = 'setosa' then 1
            else 0
        end as is_species__setosa,

    

        case
            when species = 'versicolor' then 1
            else 0
        end as is_species__versicolor,

    

        case
            when species = 'virginica' then 1
            else 0
        end as is_species__virginica,

    

    case
        when species is null then 1
        else 0
    end as is_species__


from "analytics"."analytics"."stg_iris"
  );
  
[0m11:04:23.483710 [debug] [Thread-3  ]: SQL status: SELECT 150 in 0.069 seconds
[0m11:04:23.503924 [debug] [Thread-3  ]: Using postgres connection "model.homework.iris_processed"
[0m11:04:23.506018 [debug] [Thread-3  ]: On model.homework.iris_processed: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "homework", "target_name": "dev", "node_id": "model.homework.iris_processed"} */
alter table "analytics"."analytics"."iris_processed" rename to "iris_processed__dbt_backup"
[0m11:04:23.508824 [debug] [Thread-3  ]: SQL status: ALTER TABLE in 0.001 seconds
[0m11:04:23.519479 [debug] [Thread-3  ]: Using postgres connection "model.homework.iris_processed"
[0m11:04:23.521471 [debug] [Thread-3  ]: On model.homework.iris_processed: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "homework", "target_name": "dev", "node_id": "model.homework.iris_processed"} */
alter table "analytics"."analytics"."iris_processed__dbt_tmp" rename to "iris_processed"
[0m11:04:23.523815 [debug] [Thread-3  ]: SQL status: ALTER TABLE in 0.001 seconds
[0m11:04:23.529169 [debug] [Thread-3  ]: On model.homework.iris_processed: COMMIT
[0m11:04:23.531223 [debug] [Thread-3  ]: Using postgres connection "model.homework.iris_processed"
[0m11:04:23.533175 [debug] [Thread-3  ]: On model.homework.iris_processed: COMMIT
[0m11:04:23.538721 [debug] [Thread-3  ]: SQL status: COMMIT in 0.003 seconds
[0m11:04:23.548131 [debug] [Thread-3  ]: Applying DROP to: "analytics"."analytics"."iris_processed__dbt_backup"
[0m11:04:23.557119 [debug] [Thread-3  ]: Using postgres connection "model.homework.iris_processed"
[0m11:04:23.559549 [debug] [Thread-3  ]: On model.homework.iris_processed: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "homework", "target_name": "dev", "node_id": "model.homework.iris_processed"} */
drop table if exists "analytics"."analytics"."iris_processed__dbt_backup" cascade
[0m11:04:23.567597 [debug] [Thread-3  ]: SQL status: DROP TABLE in 0.006 seconds
[0m11:04:23.571852 [debug] [Thread-3  ]: On model.homework.iris_processed: Close
[0m11:04:23.574685 [debug] [Thread-3  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '0ae267ef-b146-4c14-8945-3f8059781e50', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f50283d8fd0>]}
[0m11:04:23.577972 [info ] [Thread-3  ]: 2 of 2 OK created sql table model analytics.iris_processed ..................... [[32mSELECT 150[0m in 0.86s]
[0m11:04:23.580510 [debug] [Thread-3  ]: Finished running node model.homework.iris_processed
[0m11:04:23.585441 [debug] [MainThread]: Using postgres connection "master"
[0m11:04:23.588115 [debug] [MainThread]: On master: BEGIN
[0m11:04:23.590024 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m11:04:23.602847 [debug] [MainThread]: SQL status: BEGIN in 0.013 seconds
[0m11:04:23.605639 [debug] [MainThread]: On master: COMMIT
[0m11:04:23.607953 [debug] [MainThread]: Using postgres connection "master"
[0m11:04:23.610537 [debug] [MainThread]: On master: COMMIT
[0m11:04:23.613005 [debug] [MainThread]: SQL status: COMMIT in 0.000 seconds
[0m11:04:23.614923 [debug] [MainThread]: On master: Close
[0m11:04:23.617025 [debug] [MainThread]: Connection 'master' was properly closed.
[0m11:04:23.619487 [debug] [MainThread]: Connection 'model.homework.stg_iris' was properly closed.
[0m11:04:23.622731 [debug] [MainThread]: Connection 'model.homework.iris_processed' was properly closed.
[0m11:04:23.625901 [info ] [MainThread]: 
[0m11:04:23.630024 [info ] [MainThread]: Finished running 1 table model, 1 view model in 0 hours 0 minutes and 1.62 seconds (1.62s).
[0m11:04:23.637323 [debug] [MainThread]: Command end result
[0m11:04:23.745820 [debug] [MainThread]: Wrote artifact WritableManifest to /opt/airflow/dags/dbt/homework/target/manifest.json
[0m11:04:23.754460 [debug] [MainThread]: Wrote artifact SemanticManifest to /opt/airflow/dags/dbt/homework/target/semantic_manifest.json
[0m11:04:23.822981 [debug] [MainThread]: Wrote artifact RunExecutionResult to /opt/airflow/dags/dbt/homework/target/run_results.json
[0m11:04:23.826017 [info ] [MainThread]: 
[0m11:04:23.829338 [info ] [MainThread]: [32mCompleted successfully[0m
[0m11:04:23.836588 [info ] [MainThread]: 
[0m11:04:23.844164 [info ] [MainThread]: Done. PASS=2 WARN=0 ERROR=0 SKIP=0 TOTAL=2
[0m11:04:23.848778 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": true, "command_wall_clock_time": 6.057457, "process_in_blocks": "0", "process_kernel_time": 0.510469, "process_mem_max_rss": "115228", "process_out_blocks": "0", "process_user_time": 7.326737}
[0m11:04:23.851854 [debug] [MainThread]: Command `dbt run` succeeded at 11:04:23.851503 after 6.06 seconds
[0m11:04:23.853963 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f502bce1a90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f50295d47f0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f50294f3340>]}
[0m11:04:23.855805 [debug] [MainThread]: Flushing usage events
[0m11:04:24.787195 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m11:04:30.678718 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f884fa3faf0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f884eb60520>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f884eb604c0>]}


============================== 11:04:30.691559 | 6a3b1557-ddca-418e-b3bd-e51997227c26 ==============================
[0m11:04:30.691559 [info ] [MainThread]: Running with dbt=1.9.4
[0m11:04:30.694158 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'fail_fast': 'True', 'profiles_dir': '/opt/airflow/dags/dbt', 'log_path': '/opt/airflow/dags/dbt/homework/logs', 'version_check': 'True', 'debug': 'False', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'empty': 'None', 'log_format': 'default', 'static_parser': 'True', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'introspect': 'True', 'target_path': 'None', 'invocation_command': 'dbt --profile homework test --project-dir=/opt/airflow/dags/dbt/homework --vars {"is_test": false, "data_date": "2025-04-23"} --fail-fast', 'send_anonymous_usage_stats': 'True'}
[0m11:04:31.135959 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '6a3b1557-ddca-418e-b3bd-e51997227c26', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f8851426c70>]}
[0m11:04:31.275451 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '6a3b1557-ddca-418e-b3bd-e51997227c26', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f884d2a1520>]}
[0m11:04:31.280113 [info ] [MainThread]: Registered adapter: postgres=1.9.0
[0m11:04:31.667707 [debug] [MainThread]: checksum: f5df654a850f4b74beb13fbe0c7d8863b5b1a20bd535c3ac287d70e390b64d41, vars: {'data_date': '2025-04-23', 'is_test': False}, profile: homework, target: , version: 1.9.4
[0m11:04:33.137831 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m11:04:33.139806 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m11:04:33.160864 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 1 unused configuration paths:
- seeds.homework.iris_dataset
[0m11:04:33.273734 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '6a3b1557-ddca-418e-b3bd-e51997227c26', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f884ce8f130>]}
[0m11:04:33.677461 [debug] [MainThread]: Wrote artifact WritableManifest to /opt/airflow/dags/dbt/homework/target/manifest.json
[0m11:04:33.694870 [debug] [MainThread]: Wrote artifact SemanticManifest to /opt/airflow/dags/dbt/homework/target/semantic_manifest.json
[0m11:04:33.744174 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '6a3b1557-ddca-418e-b3bd-e51997227c26', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f884cd6d580>]}
[0m11:04:33.746492 [info ] [MainThread]: Found 2 models, 1 source, 587 macros
[0m11:04:33.748185 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '6a3b1557-ddca-418e-b3bd-e51997227c26', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f884cdd4a30>]}
[0m11:04:33.752173 [warn ] [MainThread]: Nothing to do. Try checking your model configs and model specification args
[0m11:04:33.757710 [debug] [MainThread]: Command end result
[0m11:04:33.914330 [debug] [MainThread]: Wrote artifact WritableManifest to /opt/airflow/dags/dbt/homework/target/manifest.json
[0m11:04:33.923769 [debug] [MainThread]: Wrote artifact SemanticManifest to /opt/airflow/dags/dbt/homework/target/semantic_manifest.json
[0m11:04:33.935417 [debug] [MainThread]: Wrote artifact RunExecutionResult to /opt/airflow/dags/dbt/homework/target/run_results.json
[0m11:04:33.937972 [debug] [MainThread]: Resource report: {"command_name": "test", "command_success": true, "command_wall_clock_time": 3.4415083, "process_in_blocks": "32", "process_kernel_time": 0.4164, "process_mem_max_rss": "104264", "process_out_blocks": "0", "process_user_time": 5.314061}
[0m11:04:33.940234 [debug] [MainThread]: Command `dbt test` succeeded at 11:04:33.939956 after 3.44 seconds
[0m11:04:33.941991 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f884fa3faf0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f884f9096d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f884d332130>]}
[0m11:04:33.943625 [debug] [MainThread]: Flushing usage events
[0m11:04:34.460921 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m11:07:04.249858 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fa5a61e19a0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fa5a5300d00>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fa5a5300d60>]}


============================== 11:07:04.264389 | e89f1cf0-e758-4d53-9a63-a9bad13fcbca ==============================
[0m11:07:04.264389 [info ] [MainThread]: Running with dbt=1.9.4
[0m11:07:04.267632 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'version_check': 'True', 'debug': 'False', 'log_path': '/opt/airflow/dags/dbt/homework/logs', 'profiles_dir': '/opt/airflow/dags/dbt', 'fail_fast': 'False', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'empty': 'None', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'invocation_command': 'dbt deps --profiles-dir /opt/airflow/dags/dbt --project-dir /opt/airflow/dags/dbt/homework', 'log_format': 'default', 'introspect': 'True', 'target_path': 'None', 'static_parser': 'True', 'send_anonymous_usage_stats': 'True'}
[0m11:07:04.637895 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'e89f1cf0-e758-4d53-9a63-a9bad13fcbca', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fa5a5273a60>]}
[0m11:07:04.843257 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f1fef9239d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f1feea3b2b0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f1feea3b250>]}


============================== 11:07:04.859236 | a526ec78-346f-4a73-a6ac-210b72a6d1c6 ==============================
[0m11:07:04.859236 [info ] [MainThread]: Running with dbt=1.9.4
[0m11:07:04.862415 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': '/opt/airflow/dags/dbt', 'version_check': 'True', 'debug': 'False', 'log_path': '/opt/airflow/dags/dbt/homework/logs', 'warn_error': 'None', 'fail_fast': 'False', 'use_colors': 'True', 'use_experimental_parser': 'False', 'empty': 'None', 'quiet': 'False', 'no_print': 'None', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'introspect': 'True', 'invocation_command': 'dbt deps --profiles-dir /opt/airflow/dags/dbt --project-dir /opt/airflow/dags/dbt/homework', 'static_parser': 'True', 'target_path': 'None', 'log_format': 'default', 'send_anonymous_usage_stats': 'True'}
[0m11:07:05.220520 [debug] [MainThread]: Set downloads directory='/tmp/dbt-downloads-sxq8zt_h'
[0m11:07:05.222450 [debug] [MainThread]: Making package index registry request: GET https://hub.getdbt.com/api/v1/index.json
[0m11:07:05.254017 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'a526ec78-346f-4a73-a6ac-210b72a6d1c6', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f1feea08eb0>]}
[0m11:07:05.301192 [debug] [MainThread]: Set downloads directory='/tmp/dbt-downloads-0jh5lim8'
[0m11:07:05.303081 [debug] [MainThread]: Making package index registry request: GET https://hub.getdbt.com/api/v1/index.json
[0m11:07:05.388554 [debug] [MainThread]: Response from registry index: GET https://hub.getdbt.com/api/v1/index.json 200
[0m11:07:05.390660 [debug] [MainThread]: Making package registry request: GET https://hub.getdbt.com/api/v1/Matts52/dbt_ml_inline_preprocessing.json
[0m11:07:05.395041 [debug] [MainThread]: Response from registry index: GET https://hub.getdbt.com/api/v1/index.json 200
[0m11:07:05.397879 [debug] [MainThread]: Making package registry request: GET https://hub.getdbt.com/api/v1/Matts52/dbt_ml_inline_preprocessing.json
[0m11:07:05.700512 [debug] [MainThread]: Response from registry: GET https://hub.getdbt.com/api/v1/Matts52/dbt_ml_inline_preprocessing.json 200
[0m11:07:05.701139 [debug] [MainThread]: Response from registry: GET https://hub.getdbt.com/api/v1/Matts52/dbt_ml_inline_preprocessing.json 200
[0m11:07:05.705518 [debug] [MainThread]: Making package registry request: GET https://hub.getdbt.com/api/v1/dbt-labs/dbt_utils.json
[0m11:07:05.707076 [debug] [MainThread]: Making package registry request: GET https://hub.getdbt.com/api/v1/dbt-labs/dbt_utils.json
[0m11:07:05.780298 [debug] [MainThread]: Response from registry: GET https://hub.getdbt.com/api/v1/dbt-labs/dbt_utils.json 200
[0m11:07:05.785484 [debug] [MainThread]: Response from registry: GET https://hub.getdbt.com/api/v1/dbt-labs/dbt_utils.json 200
[0m11:07:05.793775 [info ] [MainThread]: Installing Matts52/dbt_ml_inline_preprocessing
[0m11:07:05.802406 [info ] [MainThread]: Installing Matts52/dbt_ml_inline_preprocessing
[0m11:07:07.082083 [info ] [MainThread]: Installed from version 0.2.4
[0m11:07:07.082455 [error] [MainThread]: Encountered an error:
[Errno 2] No such file or directory: 'dbt_packages/dbt-ml-inline-preprocessing-0.2.4/macros/k_bins_discretize.sql'
[0m11:07:07.084475 [info ] [MainThread]: Up to date!
[0m11:07:07.087962 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'package', 'label': 'e89f1cf0-e758-4d53-9a63-a9bad13fcbca', 'property_': 'install', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fa5a5278b80>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fa5a6064250>]}
[0m11:07:07.090686 [info ] [MainThread]: Installing dbt-labs/dbt_utils
[0m11:07:07.092629 [error] [MainThread]: Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/dbt/cli/requires.py", line 153, in wrapper
    result, success = func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.9/site-packages/dbt/cli/requires.py", line 103, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.9/site-packages/dbt/cli/requires.py", line 218, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.9/site-packages/dbt/cli/requires.py", line 264, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.9/site-packages/dbt/cli/main.py", line 455, in deps
    results = task.run()
  File "/home/airflow/.local/lib/python3.9/site-packages/dbt/task/deps.py", line 254, in run
    package.install(self.project, renderer)
  File "/home/airflow/.local/lib/python3.9/site-packages/dbt/deps/registry.py", line 63, in install
    self._install(project, renderer)
  File "/home/airflow/.local/lib/python3.9/site-packages/dbt/deps/base.py", line 121, in _install
    connection_exception_retry(download_untar_fn, 5)
  File "/home/airflow/.local/lib/python3.9/site-packages/dbt_common/utils/connection.py", line 21, in connection_exception_retry
    return fn()
  File "/home/airflow/.local/lib/python3.9/site-packages/dbt/deps/base.py", line 133, in download_and_untar
    system.untar_package(tar_path, deps_path, package_name)
  File "/home/airflow/.local/lib/python3.9/site-packages/dbt_common/clients/system.py", line 641, in untar_package
    safe_extract(tarball, dest_dir)
  File "/home/airflow/.local/lib/python3.9/site-packages/dbt_common/clients/system.py", line 634, in safe_extract
    tarball.extractall(path, members=members)
  File "/usr/local/lib/python3.9/tarfile.py", line 2045, in extractall
    self.extract(tarinfo, path, set_attrs=not tarinfo.isdir(),
  File "/usr/local/lib/python3.9/tarfile.py", line 2086, in extract
    self._extract_member(tarinfo, os.path.join(path, tarinfo.name),
  File "/usr/local/lib/python3.9/tarfile.py", line 2159, in _extract_member
    self.makefile(tarinfo, targetpath)
  File "/usr/local/lib/python3.9/tarfile.py", line 2200, in makefile
    with bltn_open(targetpath, "wb") as target:
FileNotFoundError: [Errno 2] No such file or directory: 'dbt_packages/dbt-ml-inline-preprocessing-0.2.4/macros/k_bins_discretize.sql'

[0m11:07:07.098382 [debug] [MainThread]: Resource report: {"command_name": "deps", "command_success": false, "command_wall_clock_time": 2.4488397, "process_in_blocks": "112", "process_kernel_time": 0.322745, "process_mem_max_rss": "95552", "process_out_blocks": "1136", "process_user_time": 4.29655}
[0m11:07:07.104580 [debug] [MainThread]: Command `dbt deps` failed at 11:07:07.102597 after 2.45 seconds
[0m11:07:07.107892 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f1fef9239d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f1fef7336a0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f1fee88acd0>]}
[0m11:07:07.111643 [debug] [MainThread]: Flushing usage events
[0m11:07:07.747296 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m11:07:11.736589 [info ] [MainThread]: Installed from version 1.3.0
[0m11:07:11.738956 [info ] [MainThread]: Up to date!
[0m11:07:11.742459 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'package', 'label': 'e89f1cf0-e758-4d53-9a63-a9bad13fcbca', 'property_': 'install', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fa5a5278b80>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fa5a5197cd0>]}
[0m11:07:11.746549 [debug] [MainThread]: Resource report: {"command_name": "deps", "command_success": true, "command_wall_clock_time": 7.6529746, "process_in_blocks": "4392", "process_kernel_time": 0.696003, "process_mem_max_rss": "95172", "process_out_blocks": "1304", "process_user_time": 4.488715}
[0m11:07:11.749124 [debug] [MainThread]: Command `dbt deps` succeeded at 11:07:11.748792 after 7.66 seconds
[0m11:07:11.751166 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fa5a61e19a0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fa5a5ffaa00>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fa5a5f94190>]}
[0m11:07:11.753613 [debug] [MainThread]: Flushing usage events
[0m11:07:12.270177 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m11:11:23.018802 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f588a42ab20>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f588954b4c0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f588954b460>]}


============================== 11:11:23.032350 | d3fa995c-cfcb-4f6c-8c68-e97f8e3d3866 ==============================
[0m11:11:23.032350 [info ] [MainThread]: Running with dbt=1.9.4
[0m11:11:23.034974 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': '/opt/airflow/dags/dbt', 'fail_fast': 'False', 'version_check': 'True', 'log_path': '/opt/airflow/dags/dbt/homework/logs', 'warn_error': 'None', 'debug': 'False', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'empty': 'False', 'log_format': 'default', 'introspect': 'True', 'invocation_command': 'dbt --profile homework run --project-dir=/opt/airflow/dags/dbt/homework --vars {"is_test": false, "data_date": "2025-04-23"}', 'static_parser': 'True', 'target_path': 'None', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'send_anonymous_usage_stats': 'True'}
[0m11:11:23.462597 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'd3fa995c-cfcb-4f6c-8c68-e97f8e3d3866', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f58895ecee0>]}
[0m11:11:23.586906 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': 'd3fa995c-cfcb-4f6c-8c68-e97f8e3d3866', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f5889c191c0>]}
[0m11:11:23.589173 [info ] [MainThread]: Registered adapter: postgres=1.9.0
[0m11:11:23.885989 [debug] [MainThread]: checksum: f5df654a850f4b74beb13fbe0c7d8863b5b1a20bd535c3ac287d70e390b64d41, vars: {'data_date': '2025-04-23', 'is_test': False}, profile: homework, target: , version: 1.9.4
[0m11:11:25.540595 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m11:11:25.542543 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m11:11:25.562051 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 1 unused configuration paths:
- seeds.homework.iris_dataset
[0m11:11:25.668674 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'd3fa995c-cfcb-4f6c-8c68-e97f8e3d3866', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f5887877130>]}
[0m11:11:25.984305 [debug] [MainThread]: Wrote artifact WritableManifest to /opt/airflow/dags/dbt/homework/target/manifest.json
[0m11:11:26.003132 [debug] [MainThread]: Wrote artifact SemanticManifest to /opt/airflow/dags/dbt/homework/target/semantic_manifest.json
[0m11:11:26.034762 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'd3fa995c-cfcb-4f6c-8c68-e97f8e3d3866', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f5887817f70>]}
[0m11:11:26.036670 [info ] [MainThread]: Found 2 models, 1 source, 587 macros
[0m11:11:26.038367 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'd3fa995c-cfcb-4f6c-8c68-e97f8e3d3866', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f58895c8a60>]}
[0m11:11:26.042053 [info ] [MainThread]: 
[0m11:11:26.043648 [info ] [MainThread]: Concurrency: 4 threads (target='dev')
[0m11:11:26.046047 [info ] [MainThread]: 
[0m11:11:26.048087 [debug] [MainThread]: Acquiring new postgres connection 'master'
[0m11:11:26.059150 [debug] [ThreadPool]: Acquiring new postgres connection 'list_analytics'
[0m11:11:26.138512 [debug] [ThreadPool]: Using postgres connection "list_analytics"
[0m11:11:26.140336 [debug] [ThreadPool]: On list_analytics: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "homework", "target_name": "dev", "connection_name": "list_analytics"} */

    select distinct nspname from pg_namespace
  
[0m11:11:26.141750 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m11:11:26.164876 [debug] [ThreadPool]: SQL status: SELECT 6 in 0.023 seconds
[0m11:11:26.167922 [debug] [ThreadPool]: On list_analytics: Close
[0m11:11:26.171533 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_analytics, now list_analytics_analytics)
[0m11:11:26.188317 [debug] [ThreadPool]: Using postgres connection "list_analytics_analytics"
[0m11:11:26.190207 [debug] [ThreadPool]: On list_analytics_analytics: BEGIN
[0m11:11:26.192137 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m11:11:26.205072 [debug] [ThreadPool]: SQL status: BEGIN in 0.013 seconds
[0m11:11:26.207699 [debug] [ThreadPool]: Using postgres connection "list_analytics_analytics"
[0m11:11:26.210224 [debug] [ThreadPool]: On list_analytics_analytics: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "homework", "target_name": "dev", "connection_name": "list_analytics_analytics"} */
select
      'analytics' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'analytics'
    union all
    select
      'analytics' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'analytics'
    union all
    select
      'analytics' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'analytics'
  
[0m11:11:26.224816 [debug] [ThreadPool]: SQL status: SELECT 3 in 0.011 seconds
[0m11:11:26.229124 [debug] [ThreadPool]: On list_analytics_analytics: ROLLBACK
[0m11:11:26.231130 [debug] [ThreadPool]: On list_analytics_analytics: Close
[0m11:11:26.247973 [debug] [MainThread]: Using postgres connection "master"
[0m11:11:26.249876 [debug] [MainThread]: On master: BEGIN
[0m11:11:26.252040 [debug] [MainThread]: Opening a new connection, currently in state init
[0m11:11:26.267491 [debug] [MainThread]: SQL status: BEGIN in 0.015 seconds
[0m11:11:26.272560 [debug] [MainThread]: Using postgres connection "master"
[0m11:11:26.275251 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "homework", "target_name": "dev", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select distinct
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v', 'm')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
[0m11:11:26.303556 [debug] [MainThread]: SQL status: SELECT 1 in 0.026 seconds
[0m11:11:26.307468 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'd3fa995c-cfcb-4f6c-8c68-e97f8e3d3866', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f5886dba9d0>]}
[0m11:11:26.309446 [debug] [MainThread]: On master: ROLLBACK
[0m11:11:26.311912 [debug] [MainThread]: Using postgres connection "master"
[0m11:11:26.314296 [debug] [MainThread]: On master: BEGIN
[0m11:11:26.317141 [debug] [MainThread]: SQL status: BEGIN in 0.001 seconds
[0m11:11:26.320756 [debug] [MainThread]: On master: COMMIT
[0m11:11:26.323189 [debug] [MainThread]: Using postgres connection "master"
[0m11:11:26.325376 [debug] [MainThread]: On master: COMMIT
[0m11:11:26.327849 [debug] [MainThread]: SQL status: COMMIT in 0.000 seconds
[0m11:11:26.330524 [debug] [MainThread]: On master: Close
[0m11:11:26.339673 [debug] [Thread-1  ]: Began running node model.homework.stg_iris
[0m11:11:26.341788 [info ] [Thread-1  ]: 1 of 2 START sql view model analytics.stg_iris ................................. [RUN]
[0m11:11:26.343605 [debug] [Thread-1  ]: Re-using an available connection from the pool (formerly list_analytics_analytics, now model.homework.stg_iris)
[0m11:11:26.345964 [debug] [Thread-1  ]: Began compiling node model.homework.stg_iris
[0m11:11:26.368493 [debug] [Thread-1  ]: Writing injected SQL for node "model.homework.stg_iris"
[0m11:11:26.381997 [debug] [Thread-1  ]: Began executing node model.homework.stg_iris
[0m11:11:26.499249 [debug] [Thread-1  ]: Writing runtime sql for node "model.homework.stg_iris"
[0m11:11:26.514486 [debug] [Thread-1  ]: Using postgres connection "model.homework.stg_iris"
[0m11:11:26.517056 [debug] [Thread-1  ]: On model.homework.stg_iris: BEGIN
[0m11:11:26.519150 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
[0m11:11:26.535581 [debug] [Thread-1  ]: SQL status: BEGIN in 0.016 seconds
[0m11:11:26.538940 [debug] [Thread-1  ]: Using postgres connection "model.homework.stg_iris"
[0m11:11:26.542631 [debug] [Thread-1  ]: On model.homework.stg_iris: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "homework", "target_name": "dev", "node_id": "model.homework.stg_iris"} */

  create view "analytics"."analytics"."stg_iris__dbt_tmp"
    
    
  as (
    with source as (
    select * from "analytics"."analytics"."iris_dataset"
)

select
    cast(sepal_length as numeric) as sepal_length,
    cast(sepal_width as numeric) as sepal_width,
    cast(petal_length as numeric) as petal_length,
    cast(petal_width as numeric) as petal_width,
    species
from source
  );
[0m11:11:26.557272 [debug] [Thread-1  ]: SQL status: CREATE VIEW in 0.011 seconds
[0m11:11:26.585758 [debug] [Thread-1  ]: Using postgres connection "model.homework.stg_iris"
[0m11:11:26.589129 [debug] [Thread-1  ]: On model.homework.stg_iris: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "homework", "target_name": "dev", "node_id": "model.homework.stg_iris"} */
alter table "analytics"."analytics"."stg_iris" rename to "stg_iris__dbt_backup"
[0m11:11:26.591955 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.001 seconds
[0m11:11:26.603946 [debug] [Thread-1  ]: Using postgres connection "model.homework.stg_iris"
[0m11:11:26.606514 [debug] [Thread-1  ]: On model.homework.stg_iris: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "homework", "target_name": "dev", "node_id": "model.homework.stg_iris"} */
alter table "analytics"."analytics"."stg_iris__dbt_tmp" rename to "stg_iris"
[0m11:11:26.609857 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.001 seconds
[0m11:11:26.653154 [debug] [Thread-1  ]: On model.homework.stg_iris: COMMIT
[0m11:11:26.654802 [debug] [Thread-1  ]: Using postgres connection "model.homework.stg_iris"
[0m11:11:26.656353 [debug] [Thread-1  ]: On model.homework.stg_iris: COMMIT
[0m11:11:26.661251 [debug] [Thread-1  ]: SQL status: COMMIT in 0.003 seconds
[0m11:11:26.676104 [debug] [Thread-1  ]: Applying DROP to: "analytics"."analytics"."stg_iris__dbt_backup"
[0m11:11:26.686581 [debug] [Thread-1  ]: Using postgres connection "model.homework.stg_iris"
[0m11:11:26.688461 [debug] [Thread-1  ]: On model.homework.stg_iris: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "homework", "target_name": "dev", "node_id": "model.homework.stg_iris"} */
drop view if exists "analytics"."analytics"."stg_iris__dbt_backup" cascade
[0m11:11:26.695763 [debug] [Thread-1  ]: SQL status: DROP VIEW in 0.005 seconds
[0m11:11:26.702437 [debug] [Thread-1  ]: On model.homework.stg_iris: Close
[0m11:11:26.706937 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'd3fa995c-cfcb-4f6c-8c68-e97f8e3d3866', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f5886d35070>]}
[0m11:11:26.709541 [info ] [Thread-1  ]: 1 of 2 OK created sql view model analytics.stg_iris ............................ [[32mCREATE VIEW[0m in 0.36s]
[0m11:11:26.711830 [debug] [Thread-1  ]: Finished running node model.homework.stg_iris
[0m11:11:26.715174 [debug] [Thread-3  ]: Began running node model.homework.iris_processed
[0m11:11:26.717118 [info ] [Thread-3  ]: 2 of 2 START sql table model analytics.iris_processed .......................... [RUN]
[0m11:11:26.719131 [debug] [Thread-3  ]: Acquiring new postgres connection 'model.homework.iris_processed'
[0m11:11:26.720920 [debug] [Thread-3  ]: Began compiling node model.homework.iris_processed
[0m11:11:26.788394 [debug] [Thread-3  ]: Using postgres connection "model.homework.iris_processed"
[0m11:11:26.790287 [debug] [Thread-3  ]: On model.homework.iris_processed: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "homework", "target_name": "dev", "node_id": "model.homework.iris_processed"} */

        select percentile_cont(0.5) within group (order by sepal_length ) from "analytics"."analytics"."stg_iris"
    
[0m11:11:26.791919 [debug] [Thread-3  ]: Opening a new connection, currently in state init
[0m11:11:26.807036 [debug] [Thread-3  ]: SQL status: SELECT 1 in 0.015 seconds
[0m11:11:26.812861 [debug] [Thread-3  ]: Using postgres connection "model.homework.iris_processed"
[0m11:11:26.814985 [debug] [Thread-3  ]: On model.homework.iris_processed: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "homework", "target_name": "dev", "node_id": "model.homework.iris_processed"} */

        select percentile_cont(0.5 - 0.5/2) within group (order by sepal_length ) from "analytics"."analytics"."stg_iris"
    
[0m11:11:26.818383 [debug] [Thread-3  ]: SQL status: SELECT 1 in 0.002 seconds
[0m11:11:26.822522 [debug] [Thread-3  ]: Using postgres connection "model.homework.iris_processed"
[0m11:11:26.824287 [debug] [Thread-3  ]: On model.homework.iris_processed: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "homework", "target_name": "dev", "node_id": "model.homework.iris_processed"} */

        select percentile_cont(0.5 + 0.5/2) within group (order by sepal_length ) from "analytics"."analytics"."stg_iris"
    
[0m11:11:26.826722 [debug] [Thread-3  ]: SQL status: SELECT 1 in 0.001 seconds
[0m11:11:26.846675 [debug] [Thread-3  ]: Using postgres connection "model.homework.iris_processed"
[0m11:11:26.848498 [debug] [Thread-3  ]: On model.homework.iris_processed: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "homework", "target_name": "dev", "node_id": "model.homework.iris_processed"} */

        select percentile_cont(0.5) within group (order by sepal_width ) from "analytics"."analytics"."stg_iris"
    
[0m11:11:26.850934 [debug] [Thread-3  ]: SQL status: SELECT 1 in 0.001 seconds
[0m11:11:26.854648 [debug] [Thread-3  ]: Using postgres connection "model.homework.iris_processed"
[0m11:11:26.856358 [debug] [Thread-3  ]: On model.homework.iris_processed: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "homework", "target_name": "dev", "node_id": "model.homework.iris_processed"} */

        select percentile_cont(0.5 - 0.5/2) within group (order by sepal_width ) from "analytics"."analytics"."stg_iris"
    
[0m11:11:26.858685 [debug] [Thread-3  ]: SQL status: SELECT 1 in 0.001 seconds
[0m11:11:26.862890 [debug] [Thread-3  ]: Using postgres connection "model.homework.iris_processed"
[0m11:11:26.864886 [debug] [Thread-3  ]: On model.homework.iris_processed: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "homework", "target_name": "dev", "node_id": "model.homework.iris_processed"} */

        select percentile_cont(0.5 + 0.5/2) within group (order by sepal_width ) from "analytics"."analytics"."stg_iris"
    
[0m11:11:26.867136 [debug] [Thread-3  ]: SQL status: SELECT 1 in 0.001 seconds
[0m11:11:26.872715 [debug] [Thread-3  ]: Using postgres connection "model.homework.iris_processed"
[0m11:11:26.874456 [debug] [Thread-3  ]: On model.homework.iris_processed: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "homework", "target_name": "dev", "node_id": "model.homework.iris_processed"} */

        select percentile_cont(0.5) within group (order by petal_length ) from "analytics"."analytics"."stg_iris"
    
[0m11:11:26.876965 [debug] [Thread-3  ]: SQL status: SELECT 1 in 0.001 seconds
[0m11:11:26.881381 [debug] [Thread-3  ]: Using postgres connection "model.homework.iris_processed"
[0m11:11:26.883255 [debug] [Thread-3  ]: On model.homework.iris_processed: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "homework", "target_name": "dev", "node_id": "model.homework.iris_processed"} */

        select percentile_cont(0.5 - 0.5/2) within group (order by petal_length ) from "analytics"."analytics"."stg_iris"
    
[0m11:11:26.885743 [debug] [Thread-3  ]: SQL status: SELECT 1 in 0.001 seconds
[0m11:11:26.889346 [debug] [Thread-3  ]: Using postgres connection "model.homework.iris_processed"
[0m11:11:26.891093 [debug] [Thread-3  ]: On model.homework.iris_processed: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "homework", "target_name": "dev", "node_id": "model.homework.iris_processed"} */

        select percentile_cont(0.5 + 0.5/2) within group (order by petal_length ) from "analytics"."analytics"."stg_iris"
    
[0m11:11:26.893360 [debug] [Thread-3  ]: SQL status: SELECT 1 in 0.001 seconds
[0m11:11:26.899647 [debug] [Thread-3  ]: Using postgres connection "model.homework.iris_processed"
[0m11:11:26.901327 [debug] [Thread-3  ]: On model.homework.iris_processed: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "homework", "target_name": "dev", "node_id": "model.homework.iris_processed"} */

        select percentile_cont(0.5) within group (order by petal_width ) from "analytics"."analytics"."stg_iris"
    
[0m11:11:26.903786 [debug] [Thread-3  ]: SQL status: SELECT 1 in 0.001 seconds
[0m11:11:26.907379 [debug] [Thread-3  ]: Using postgres connection "model.homework.iris_processed"
[0m11:11:26.908959 [debug] [Thread-3  ]: On model.homework.iris_processed: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "homework", "target_name": "dev", "node_id": "model.homework.iris_processed"} */

        select percentile_cont(0.5 - 0.5/2) within group (order by petal_width ) from "analytics"."analytics"."stg_iris"
    
[0m11:11:26.911226 [debug] [Thread-3  ]: SQL status: SELECT 1 in 0.001 seconds
[0m11:11:26.916300 [debug] [Thread-3  ]: Using postgres connection "model.homework.iris_processed"
[0m11:11:26.918088 [debug] [Thread-3  ]: On model.homework.iris_processed: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "homework", "target_name": "dev", "node_id": "model.homework.iris_processed"} */

        select percentile_cont(0.5 + 0.5/2) within group (order by petal_width ) from "analytics"."analytics"."stg_iris"
    
[0m11:11:26.920467 [debug] [Thread-3  ]: SQL status: SELECT 1 in 0.001 seconds
[0m11:11:26.947693 [debug] [Thread-3  ]: Using postgres connection "model.homework.iris_processed"
[0m11:11:26.949815 [debug] [Thread-3  ]: On model.homework.iris_processed: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "homework", "target_name": "dev", "node_id": "model.homework.iris_processed"} */

            select percentile_cont(0.5) within group (order by sepal_length ) from "analytics"."analytics"."stg_iris"
        
[0m11:11:26.952751 [debug] [Thread-3  ]: SQL status: SELECT 1 in 0.001 seconds
[0m11:11:26.958319 [debug] [Thread-3  ]: Using postgres connection "model.homework.iris_processed"
[0m11:11:26.960836 [debug] [Thread-3  ]: On model.homework.iris_processed: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "homework", "target_name": "dev", "node_id": "model.homework.iris_processed"} */

            select percentile_cont(0.5) within group (order by sepal_width ) from "analytics"."analytics"."stg_iris"
        
[0m11:11:26.964079 [debug] [Thread-3  ]: SQL status: SELECT 1 in 0.001 seconds
[0m11:11:26.969143 [debug] [Thread-3  ]: Using postgres connection "model.homework.iris_processed"
[0m11:11:26.971157 [debug] [Thread-3  ]: On model.homework.iris_processed: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "homework", "target_name": "dev", "node_id": "model.homework.iris_processed"} */

            select percentile_cont(0.5) within group (order by petal_length ) from "analytics"."analytics"."stg_iris"
        
[0m11:11:26.973599 [debug] [Thread-3  ]: SQL status: SELECT 1 in 0.001 seconds
[0m11:11:26.978655 [debug] [Thread-3  ]: Using postgres connection "model.homework.iris_processed"
[0m11:11:26.981146 [debug] [Thread-3  ]: On model.homework.iris_processed: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "homework", "target_name": "dev", "node_id": "model.homework.iris_processed"} */

            select percentile_cont(0.5) within group (order by petal_width ) from "analytics"."analytics"."stg_iris"
        
[0m11:11:26.983697 [debug] [Thread-3  ]: SQL status: SELECT 1 in 0.001 seconds
[0m11:11:27.072325 [debug] [Thread-3  ]: Using postgres connection "model.homework.iris_processed"
[0m11:11:27.074017 [debug] [Thread-3  ]: On model.homework.iris_processed: BEGIN
[0m11:11:27.075941 [debug] [Thread-3  ]: SQL status: BEGIN in 0.000 seconds
[0m11:11:27.078946 [debug] [Thread-3  ]: Using postgres connection "model.homework.iris_processed"
[0m11:11:27.081830 [debug] [Thread-3  ]: On model.homework.iris_processed: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "homework", "target_name": "dev", "node_id": "model.homework.iris_processed"} */
select
                species as value

            from "analytics"."analytics"."stg_iris"

            
            where species is not null  and true
            

            group by species
            order by species

            

        
[0m11:11:27.086559 [debug] [Thread-3  ]: SQL status: SELECT 3 in 0.001 seconds
[0m11:11:27.107550 [debug] [Thread-3  ]: Writing injected SQL for node "model.homework.iris_processed"
[0m11:11:27.119632 [debug] [Thread-3  ]: Began executing node model.homework.iris_processed
[0m11:11:27.175775 [debug] [Thread-3  ]: Writing runtime sql for node "model.homework.iris_processed"
[0m11:11:27.187721 [debug] [Thread-3  ]: Using postgres connection "model.homework.iris_processed"
[0m11:11:27.190452 [debug] [Thread-3  ]: On model.homework.iris_processed: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "homework", "target_name": "dev", "node_id": "model.homework.iris_processed"} */

  
    

  create  table "analytics"."analytics"."iris_processed__dbt_tmp"
  
  
    as
  
  (
    

with import_iris as (
    select *
    from "analytics"."analytics"."stg_iris"
)
select
    sepal_length,
    sepal_width,
    petal_length,
    petal_width,
    -- K Bins Discretization
    
        

    
        NTILE(5) over (order by sepal_length)
    

 as sepal_length_quantile_bin,
        

    
        
        floor(
        (
            sepal_length - (min(sepal_length) over ())
        )
        /
        (
            ((max(sepal_length) over ()) - (min(sepal_length) over ())) / 4::float
        )
        ) + 1
    

 as sepal_length_uniform_bin,
    
        

    
        NTILE(5) over (order by sepal_width)
    

 as sepal_width_quantile_bin,
        

    
        
        floor(
        (
            sepal_width - (min(sepal_width) over ())
        )
        /
        (
            ((max(sepal_width) over ()) - (min(sepal_width) over ())) / 4::float
        )
        ) + 1
    

 as sepal_width_uniform_bin,
    
        

    
        NTILE(5) over (order by petal_length)
    

 as petal_length_quantile_bin,
        

    
        
        floor(
        (
            petal_length - (min(petal_length) over ())
        )
        /
        (
            ((max(petal_length) over ()) - (min(petal_length) over ())) / 4::float
        )
        ) + 1
    

 as petal_length_uniform_bin,
    
        

    
        NTILE(5) over (order by petal_width)
    

 as petal_width_quantile_bin,
        

    
        
        floor(
        (
            petal_width - (min(petal_width) over ())
        )
        /
        (
            ((max(petal_width) over ()) - (min(petal_width) over ())) / 4::float
        )
        ) + 1
    

 as petal_width_uniform_bin,
    
-- Scaling
    
        

    

    
    
    

    
    
    

    (
        sepal_length - 5.8
    )
    /
    (
        6.4 - 5.1
    )

 as sepal_length_robust_scaled,
        

    (sepal_length) / (max(abs(sepal_length)) over ())::FLOAT

 as sepal_length_max_absolute_scaled,
        

    
    (
        ((sepal_length) - (min(sepal_length) over ()))
        /
        ((max(sepal_length) over ()) - (min(sepal_length) over ()))::FLOAT
    )
    *
    (1.0 - 0.0)
    +
    0.0

 as sepal_length_max_min_max_scaled,
    
        

    

    
    
    

    
    
    

    (
        sepal_width - 3.0
    )
    /
    (
        3.3 - 2.8
    )

 as sepal_width_robust_scaled,
        

    (sepal_width) / (max(abs(sepal_width)) over ())::FLOAT

 as sepal_width_max_absolute_scaled,
        

    
    (
        ((sepal_width) - (min(sepal_width) over ()))
        /
        ((max(sepal_width) over ()) - (min(sepal_width) over ()))::FLOAT
    )
    *
    (1.0 - 0.0)
    +
    0.0

 as sepal_width_max_min_max_scaled,
    
        

    

    
    
    

    
    
    

    (
        petal_length - 4.35
    )
    /
    (
        5.1 - 1.6
    )

 as petal_length_robust_scaled,
        

    (petal_length) / (max(abs(petal_length)) over ())::FLOAT

 as petal_length_max_absolute_scaled,
        

    
    (
        ((petal_length) - (min(petal_length) over ()))
        /
        ((max(petal_length) over ()) - (min(petal_length) over ()))::FLOAT
    )
    *
    (1.0 - 0.0)
    +
    0.0

 as petal_length_max_min_max_scaled,
    
        

    

    
    
    

    
    
    

    (
        petal_width - 1.3
    )
    /
    (
        1.8 - 0.3
    )

 as petal_width_robust_scaled,
        

    (petal_width) / (max(abs(petal_width)) over ())::FLOAT

 as petal_width_max_absolute_scaled,
        

    
    (
        ((petal_width) - (min(petal_width) over ()))
        /
        ((max(petal_width) over ()) - (min(petal_width) over ()))::FLOAT
    )
    *
    (1.0 - 0.0)
    +
    0.0

 as petal_width_max_min_max_scaled,
    

    -- Log Transformation
    
        

    case
        when sepal_length is null or sepal_length + 0 <= 0 then null
        else log(10, sepal_length + 0)
    end

 as sepal_length_logged,
    
        

    case
        when sepal_width is null or sepal_width + 0 <= 0 then null
        else log(10, sepal_width + 0)
    end

 as sepal_width_logged,
    
        

    case
        when petal_length is null or petal_length + 0 <= 0 then null
        else log(10, petal_length + 0)
    end

 as petal_length_logged,
    
        

    case
        when petal_width is null or petal_width + 0 <= 0 then null
        else log(10, petal_width + 0)
    end

 as petal_width_logged,
    

    -- Binarization
    
        

    

    
        

        
    

    case
        when sepal_length >=
            
                5.8
            
            then 1
        else 0
    end

 as sepal_length_binarized,
    
        

    

    
        

        
    

    case
        when sepal_width >=
            
                3.0
            
            then 1
        else 0
    end

 as sepal_width_binarized,
    
        

    

    
        

        
    

    case
        when petal_length >=
            
                4.35
            
            then 1
        else 0
    end

 as petal_length_binarized,
    
        

    

    
        

        
    

    case
        when petal_width >=
            
                1.3
            
            then 1
        else 0
    end

 as petal_width_binarized,
    

    -- Standardization
    
        

    
    (
        (sepal_length - avg(sepal_length) over ())
        /
        (stddev(sepal_length) over ())::FLOAT
    )
    *
    1
    +
    0

 as sepal_length_standardized,
    
        

    
    (
        (sepal_width - avg(sepal_width) over ())
        /
        (stddev(sepal_width) over ())::FLOAT
    )
    *
    1
    +
    0

 as sepal_width_standardized,
    
        

    
    (
        (petal_length - avg(petal_length) over ())
        /
        (stddev(petal_length) over ())::FLOAT
    )
    *
    1
    +
    0

 as petal_length_standardized,
    
        

    
    (
        (petal_width - avg(petal_width) over ())
        /
        (stddev(petal_width) over ())::FLOAT
    )
    *
    1
    +
    0

 as petal_width_standardized,
    
-- Interactions
    
        
            
            
            

    
        (sepal_length * sepal_width)
    

 as sepal_length_x_sepal_width_interaction,
            

    
        (sepal_length + sepal_width)
    

 as sepal_length_plus_sepal_width_interaction,
        
            
            
            

    
        (sepal_length * petal_length)
    

 as sepal_length_x_petal_length_interaction,
            

    
        (sepal_length + petal_length)
    

 as sepal_length_plus_petal_length_interaction,
        
            
            
            

    
        (sepal_length * petal_width)
    

 as sepal_length_x_petal_width_interaction,
            

    
        (sepal_length + petal_width)
    

 as sepal_length_plus_petal_width_interaction,
        
    
        
            
            
            

    
        (sepal_width * petal_length)
    

 as sepal_width_x_petal_length_interaction,
            

    
        (sepal_width + petal_length)
    

 as sepal_width_plus_petal_length_interaction,
        
            
            
            

    
        (sepal_width * petal_width)
    

 as sepal_width_x_petal_width_interaction,
            

    
        (sepal_width + petal_width)
    

 as sepal_width_plus_petal_width_interaction,
        
    
        
            
            
            

    
        (petal_length * petal_width)
    

 as petal_length_x_petal_width_interaction,
            

    
        (petal_length + petal_width)
    

 as petal_length_plus_petal_width_interaction,
        
    
        
    
species,    
    -- Label Encoding
    

    dense_rank() over (order by species) - 1

 as species_label_encoded,
    -- One Hot Encoding
    

    

    
        
    

    

    

        case
            when species = 'setosa' then 1
            else 0
        end as is_species__setosa,

    

        case
            when species = 'versicolor' then 1
            else 0
        end as is_species__versicolor,

    

        case
            when species = 'virginica' then 1
            else 0
        end as is_species__virginica,

    

    case
        when species is null then 1
        else 0
    end as is_species__


from "analytics"."analytics"."stg_iris"
  );
  
[0m11:11:27.229336 [debug] [Thread-3  ]: SQL status: SELECT 150 in 0.036 seconds
[0m11:11:27.244672 [debug] [Thread-3  ]: Using postgres connection "model.homework.iris_processed"
[0m11:11:27.247065 [debug] [Thread-3  ]: On model.homework.iris_processed: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "homework", "target_name": "dev", "node_id": "model.homework.iris_processed"} */
alter table "analytics"."analytics"."iris_processed" rename to "iris_processed__dbt_backup"
[0m11:11:27.249449 [debug] [Thread-3  ]: SQL status: ALTER TABLE in 0.001 seconds
[0m11:11:27.258013 [debug] [Thread-3  ]: Using postgres connection "model.homework.iris_processed"
[0m11:11:27.259728 [debug] [Thread-3  ]: On model.homework.iris_processed: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "homework", "target_name": "dev", "node_id": "model.homework.iris_processed"} */
alter table "analytics"."analytics"."iris_processed__dbt_tmp" rename to "iris_processed"
[0m11:11:27.262706 [debug] [Thread-3  ]: SQL status: ALTER TABLE in 0.001 seconds
[0m11:11:27.267520 [debug] [Thread-3  ]: On model.homework.iris_processed: COMMIT
[0m11:11:27.269150 [debug] [Thread-3  ]: Using postgres connection "model.homework.iris_processed"
[0m11:11:27.270813 [debug] [Thread-3  ]: On model.homework.iris_processed: COMMIT
[0m11:11:27.275755 [debug] [Thread-3  ]: SQL status: COMMIT in 0.003 seconds
[0m11:11:27.283336 [debug] [Thread-3  ]: Applying DROP to: "analytics"."analytics"."iris_processed__dbt_backup"
[0m11:11:27.289626 [debug] [Thread-3  ]: Using postgres connection "model.homework.iris_processed"
[0m11:11:27.291312 [debug] [Thread-3  ]: On model.homework.iris_processed: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "homework", "target_name": "dev", "node_id": "model.homework.iris_processed"} */
drop table if exists "analytics"."analytics"."iris_processed__dbt_backup" cascade
[0m11:11:27.299150 [debug] [Thread-3  ]: SQL status: DROP TABLE in 0.006 seconds
[0m11:11:27.302714 [debug] [Thread-3  ]: On model.homework.iris_processed: Close
[0m11:11:27.304723 [debug] [Thread-3  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'd3fa995c-cfcb-4f6c-8c68-e97f8e3d3866', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f588a680370>]}
[0m11:11:27.307181 [info ] [Thread-3  ]: 2 of 2 OK created sql table model analytics.iris_processed ..................... [[32mSELECT 150[0m in 0.59s]
[0m11:11:27.309721 [debug] [Thread-3  ]: Finished running node model.homework.iris_processed
[0m11:11:27.314106 [debug] [MainThread]: Using postgres connection "master"
[0m11:11:27.315711 [debug] [MainThread]: On master: BEGIN
[0m11:11:27.317237 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m11:11:27.328057 [debug] [MainThread]: SQL status: BEGIN in 0.011 seconds
[0m11:11:27.331116 [debug] [MainThread]: On master: COMMIT
[0m11:11:27.333180 [debug] [MainThread]: Using postgres connection "master"
[0m11:11:27.335304 [debug] [MainThread]: On master: COMMIT
[0m11:11:27.337410 [debug] [MainThread]: SQL status: COMMIT in 0.000 seconds
[0m11:11:27.339280 [debug] [MainThread]: On master: Close
[0m11:11:27.341215 [debug] [MainThread]: Connection 'master' was properly closed.
[0m11:11:27.342905 [debug] [MainThread]: Connection 'model.homework.stg_iris' was properly closed.
[0m11:11:27.344568 [debug] [MainThread]: Connection 'model.homework.iris_processed' was properly closed.
[0m11:11:27.346489 [info ] [MainThread]: 
[0m11:11:27.348285 [info ] [MainThread]: Finished running 1 table model, 1 view model in 0 hours 0 minutes and 1.30 seconds (1.30s).
[0m11:11:27.351433 [debug] [MainThread]: Command end result
[0m11:11:27.450746 [debug] [MainThread]: Wrote artifact WritableManifest to /opt/airflow/dags/dbt/homework/target/manifest.json
[0m11:11:27.457781 [debug] [MainThread]: Wrote artifact SemanticManifest to /opt/airflow/dags/dbt/homework/target/semantic_manifest.json
[0m11:11:27.477679 [debug] [MainThread]: Wrote artifact RunExecutionResult to /opt/airflow/dags/dbt/homework/target/run_results.json
[0m11:11:27.480078 [info ] [MainThread]: 
[0m11:11:27.481922 [info ] [MainThread]: [32mCompleted successfully[0m
[0m11:11:27.483515 [info ] [MainThread]: 
[0m11:11:27.484882 [info ] [MainThread]: Done. PASS=2 WARN=0 ERROR=0 SKIP=0 TOTAL=2
[0m11:11:27.487080 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": true, "command_wall_clock_time": 4.620482, "process_in_blocks": "1312", "process_kernel_time": 0.442, "process_mem_max_rss": "114880", "process_out_blocks": "0", "process_user_time": 6.218148}
[0m11:11:27.488862 [debug] [MainThread]: Command `dbt run` succeeded at 11:11:27.488685 after 4.62 seconds
[0m11:11:27.490545 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f588a42ab20>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f5887ccb550>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f5887ccb580>]}
[0m11:11:27.492217 [debug] [MainThread]: Flushing usage events
[0m11:11:28.413146 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m11:12:14.186862 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f779cfe8ac0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f779c10a580>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f779c10a520>]}


============================== 11:12:14.197797 | dbc1e517-58bb-40a5-aaaa-bf870e4872d6 ==============================
[0m11:12:14.197797 [info ] [MainThread]: Running with dbt=1.9.4
[0m11:12:14.199922 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': '/opt/airflow/dags/dbt', 'debug': 'False', 'warn_error': 'None', 'log_path': '/opt/airflow/dags/dbt/homework/logs', 'version_check': 'True', 'fail_fast': 'True', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'empty': 'None', 'log_format': 'default', 'invocation_command': 'dbt --profile homework test --project-dir=/opt/airflow/dags/dbt/homework --vars {"is_test": false, "data_date": "2025-04-23"} --fail-fast', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'introspect': 'True', 'target_path': 'None', 'static_parser': 'True', 'send_anonymous_usage_stats': 'True'}
[0m11:12:14.589420 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'dbc1e517-58bb-40a5-aaaa-bf870e4872d6', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f779a8d2610>]}
[0m11:12:14.720145 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': 'dbc1e517-58bb-40a5-aaaa-bf870e4872d6', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f779c187760>]}
[0m11:12:14.722887 [info ] [MainThread]: Registered adapter: postgres=1.9.0
[0m11:12:15.017424 [debug] [MainThread]: checksum: f5df654a850f4b74beb13fbe0c7d8863b5b1a20bd535c3ac287d70e390b64d41, vars: {'data_date': '2025-04-23', 'is_test': False}, profile: homework, target: , version: 1.9.4
[0m11:12:16.610891 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m11:12:16.612662 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m11:12:16.628223 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 1 unused configuration paths:
- seeds.homework.iris_dataset
[0m11:12:16.739424 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'dbc1e517-58bb-40a5-aaaa-bf870e4872d6', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f779a437130>]}
[0m11:12:17.061424 [debug] [MainThread]: Wrote artifact WritableManifest to /opt/airflow/dags/dbt/homework/target/manifest.json
[0m11:12:17.078431 [debug] [MainThread]: Wrote artifact SemanticManifest to /opt/airflow/dags/dbt/homework/target/semantic_manifest.json
[0m11:12:17.127247 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'dbc1e517-58bb-40a5-aaaa-bf870e4872d6', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f779a37d520>]}
[0m11:12:17.129127 [info ] [MainThread]: Found 2 models, 1 source, 587 macros
[0m11:12:17.130721 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'dbc1e517-58bb-40a5-aaaa-bf870e4872d6', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f779c198910>]}
[0m11:12:17.133612 [warn ] [MainThread]: Nothing to do. Try checking your model configs and model specification args
[0m11:12:17.138336 [debug] [MainThread]: Command end result
[0m11:12:17.290409 [debug] [MainThread]: Wrote artifact WritableManifest to /opt/airflow/dags/dbt/homework/target/manifest.json
[0m11:12:17.298438 [debug] [MainThread]: Wrote artifact SemanticManifest to /opt/airflow/dags/dbt/homework/target/semantic_manifest.json
[0m11:12:17.309281 [debug] [MainThread]: Wrote artifact RunExecutionResult to /opt/airflow/dags/dbt/homework/target/run_results.json
[0m11:12:17.311727 [debug] [MainThread]: Resource report: {"command_name": "test", "command_success": true, "command_wall_clock_time": 3.2572255, "process_in_blocks": "0", "process_kernel_time": 0.327268, "process_mem_max_rss": "104428", "process_out_blocks": "0", "process_user_time": 4.918937}
[0m11:12:17.313491 [debug] [MainThread]: Command `dbt test` succeeded at 11:12:17.313303 after 3.26 seconds
[0m11:12:17.315108 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f779cfe8ac0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f779ce57310>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f779a3d7940>]}
[0m11:12:17.316650 [debug] [MainThread]: Flushing usage events
[0m11:12:17.858558 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m11:28:05.292705 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fcb1a73eb20>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fcb1985f430>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fcb1985f3d0>]}


============================== 11:28:05.304861 | 022a68dd-80a0-460d-822d-92493534f9e4 ==============================
[0m11:28:05.304861 [info ] [MainThread]: Running with dbt=1.9.4
[0m11:28:05.306975 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': '/opt/airflow/dags/dbt', 'fail_fast': 'False', 'warn_error': 'None', 'log_path': '/opt/airflow/dags/dbt/homework/logs', 'version_check': 'True', 'debug': 'False', 'use_colors': 'True', 'use_experimental_parser': 'False', 'empty': 'False', 'quiet': 'False', 'no_print': 'None', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'invocation_command': 'dbt --profile homework run --project-dir=/opt/airflow/dags/dbt/homework --vars {"is_test": false, "data_date": "2025-04-23"}', 'log_format': 'default', 'introspect': 'True', 'target_path': 'None', 'static_parser': 'True', 'send_anonymous_usage_stats': 'True'}
[0m11:28:05.728176 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '022a68dd-80a0-460d-822d-92493534f9e4', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fcb1989f760>]}
[0m11:28:05.872279 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '022a68dd-80a0-460d-822d-92493534f9e4', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fcb17fe8e80>]}
[0m11:28:05.874653 [info ] [MainThread]: Registered adapter: postgres=1.9.0
[0m11:28:06.201720 [debug] [MainThread]: checksum: f5df654a850f4b74beb13fbe0c7d8863b5b1a20bd535c3ac287d70e390b64d41, vars: {'data_date': '2025-04-23', 'is_test': False}, profile: homework, target: , version: 1.9.4
[0m11:28:07.773540 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m11:28:07.775430 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m11:28:07.802226 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 1 unused configuration paths:
- seeds.homework.iris_dataset
[0m11:28:07.897100 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '022a68dd-80a0-460d-822d-92493534f9e4', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fcb17b8c130>]}
[0m11:28:08.237491 [debug] [MainThread]: Wrote artifact WritableManifest to /opt/airflow/dags/dbt/homework/target/manifest.json
[0m11:28:08.255092 [debug] [MainThread]: Wrote artifact SemanticManifest to /opt/airflow/dags/dbt/homework/target/semantic_manifest.json
[0m11:28:08.290194 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '022a68dd-80a0-460d-822d-92493534f9e4', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fcb17b2c0a0>]}
[0m11:28:08.292090 [info ] [MainThread]: Found 2 models, 1 source, 587 macros
[0m11:28:08.293672 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '022a68dd-80a0-460d-822d-92493534f9e4', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fcb198dcfd0>]}
[0m11:28:08.296798 [info ] [MainThread]: 
[0m11:28:08.298329 [info ] [MainThread]: Concurrency: 4 threads (target='dev')
[0m11:28:08.299791 [info ] [MainThread]: 
[0m11:28:08.302172 [debug] [MainThread]: Acquiring new postgres connection 'master'
[0m11:28:08.312819 [debug] [ThreadPool]: Acquiring new postgres connection 'list_analytics'
[0m11:28:08.384358 [debug] [ThreadPool]: Using postgres connection "list_analytics"
[0m11:28:08.385935 [debug] [ThreadPool]: On list_analytics: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "homework", "target_name": "dev", "connection_name": "list_analytics"} */

    select distinct nspname from pg_namespace
  
[0m11:28:08.387623 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m11:28:08.400871 [debug] [ThreadPool]: SQL status: SELECT 6 in 0.013 seconds
[0m11:28:08.404565 [debug] [ThreadPool]: On list_analytics: Close
[0m11:28:08.408383 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_analytics, now list_analytics_analytics)
[0m11:28:08.424035 [debug] [ThreadPool]: Using postgres connection "list_analytics_analytics"
[0m11:28:08.425687 [debug] [ThreadPool]: On list_analytics_analytics: BEGIN
[0m11:28:08.427206 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m11:28:08.438420 [debug] [ThreadPool]: SQL status: BEGIN in 0.011 seconds
[0m11:28:08.440909 [debug] [ThreadPool]: Using postgres connection "list_analytics_analytics"
[0m11:28:08.443080 [debug] [ThreadPool]: On list_analytics_analytics: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "homework", "target_name": "dev", "connection_name": "list_analytics_analytics"} */
select
      'analytics' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'analytics'
    union all
    select
      'analytics' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'analytics'
    union all
    select
      'analytics' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'analytics'
  
[0m11:28:08.449273 [debug] [ThreadPool]: SQL status: SELECT 3 in 0.004 seconds
[0m11:28:08.452451 [debug] [ThreadPool]: On list_analytics_analytics: ROLLBACK
[0m11:28:08.454415 [debug] [ThreadPool]: On list_analytics_analytics: Close
[0m11:28:08.469483 [debug] [MainThread]: Using postgres connection "master"
[0m11:28:08.472344 [debug] [MainThread]: On master: BEGIN
[0m11:28:08.475454 [debug] [MainThread]: Opening a new connection, currently in state init
[0m11:28:08.488333 [debug] [MainThread]: SQL status: BEGIN in 0.013 seconds
[0m11:28:08.491029 [debug] [MainThread]: Using postgres connection "master"
[0m11:28:08.493451 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "homework", "target_name": "dev", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select distinct
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v', 'm')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
[0m11:28:08.505830 [debug] [MainThread]: SQL status: SELECT 1 in 0.009 seconds
[0m11:28:08.510087 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '022a68dd-80a0-460d-822d-92493534f9e4', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fcb17d577f0>]}
[0m11:28:08.512001 [debug] [MainThread]: On master: ROLLBACK
[0m11:28:08.514578 [debug] [MainThread]: Using postgres connection "master"
[0m11:28:08.516547 [debug] [MainThread]: On master: BEGIN
[0m11:28:08.519145 [debug] [MainThread]: SQL status: BEGIN in 0.001 seconds
[0m11:28:08.523311 [debug] [MainThread]: On master: COMMIT
[0m11:28:08.526974 [debug] [MainThread]: Using postgres connection "master"
[0m11:28:08.529338 [debug] [MainThread]: On master: COMMIT
[0m11:28:08.531405 [debug] [MainThread]: SQL status: COMMIT in 0.000 seconds
[0m11:28:08.533019 [debug] [MainThread]: On master: Close
[0m11:28:08.542837 [debug] [Thread-1  ]: Began running node model.homework.stg_iris
[0m11:28:08.545695 [info ] [Thread-1  ]: 1 of 2 START sql view model analytics.stg_iris ................................. [RUN]
[0m11:28:08.548285 [debug] [Thread-1  ]: Re-using an available connection from the pool (formerly list_analytics_analytics, now model.homework.stg_iris)
[0m11:28:08.550053 [debug] [Thread-1  ]: Began compiling node model.homework.stg_iris
[0m11:28:08.574025 [debug] [Thread-1  ]: Writing injected SQL for node "model.homework.stg_iris"
[0m11:28:08.584076 [debug] [Thread-1  ]: Began executing node model.homework.stg_iris
[0m11:28:08.673083 [debug] [Thread-1  ]: Writing runtime sql for node "model.homework.stg_iris"
[0m11:28:08.685097 [debug] [Thread-1  ]: Using postgres connection "model.homework.stg_iris"
[0m11:28:08.686963 [debug] [Thread-1  ]: On model.homework.stg_iris: BEGIN
[0m11:28:08.689472 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
[0m11:28:08.701233 [debug] [Thread-1  ]: SQL status: BEGIN in 0.012 seconds
[0m11:28:08.703826 [debug] [Thread-1  ]: Using postgres connection "model.homework.stg_iris"
[0m11:28:08.707300 [debug] [Thread-1  ]: On model.homework.stg_iris: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "homework", "target_name": "dev", "node_id": "model.homework.stg_iris"} */

  create view "analytics"."analytics"."stg_iris__dbt_tmp"
    
    
  as (
    with source as (
    select * from "analytics"."analytics"."iris_dataset"
)

select
    cast(sepal_length as numeric) as sepal_length,
    cast(sepal_width as numeric) as sepal_width,
    cast(petal_length as numeric) as petal_length,
    cast(petal_width as numeric) as petal_width,
    species
from source
  );
[0m11:28:08.716740 [debug] [Thread-1  ]: SQL status: CREATE VIEW in 0.007 seconds
[0m11:28:08.741968 [debug] [Thread-1  ]: Using postgres connection "model.homework.stg_iris"
[0m11:28:08.744202 [debug] [Thread-1  ]: On model.homework.stg_iris: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "homework", "target_name": "dev", "node_id": "model.homework.stg_iris"} */
alter table "analytics"."analytics"."stg_iris" rename to "stg_iris__dbt_backup"
[0m11:28:08.747429 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.001 seconds
[0m11:28:08.760732 [debug] [Thread-1  ]: Using postgres connection "model.homework.stg_iris"
[0m11:28:08.764081 [debug] [Thread-1  ]: On model.homework.stg_iris: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "homework", "target_name": "dev", "node_id": "model.homework.stg_iris"} */
alter table "analytics"."analytics"."stg_iris__dbt_tmp" rename to "stg_iris"
[0m11:28:08.768094 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.001 seconds
[0m11:28:08.833712 [debug] [Thread-1  ]: On model.homework.stg_iris: COMMIT
[0m11:28:08.836701 [debug] [Thread-1  ]: Using postgres connection "model.homework.stg_iris"
[0m11:28:08.840310 [debug] [Thread-1  ]: On model.homework.stg_iris: COMMIT
[0m11:28:08.847742 [debug] [Thread-1  ]: SQL status: COMMIT in 0.005 seconds
[0m11:28:08.873255 [debug] [Thread-1  ]: Applying DROP to: "analytics"."analytics"."stg_iris__dbt_backup"
[0m11:28:08.889616 [debug] [Thread-1  ]: Using postgres connection "model.homework.stg_iris"
[0m11:28:08.892344 [debug] [Thread-1  ]: On model.homework.stg_iris: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "homework", "target_name": "dev", "node_id": "model.homework.stg_iris"} */
drop view if exists "analytics"."analytics"."stg_iris__dbt_backup" cascade
[0m11:28:08.900389 [debug] [Thread-1  ]: SQL status: DROP VIEW in 0.005 seconds
[0m11:28:08.909049 [debug] [Thread-1  ]: On model.homework.stg_iris: Close
[0m11:28:08.917702 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '022a68dd-80a0-460d-822d-92493534f9e4', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fcb17049070>]}
[0m11:28:08.921558 [info ] [Thread-1  ]: 1 of 2 OK created sql view model analytics.stg_iris ............................ [[32mCREATE VIEW[0m in 0.36s]
[0m11:28:08.925233 [debug] [Thread-1  ]: Finished running node model.homework.stg_iris
[0m11:28:08.929093 [debug] [Thread-3  ]: Began running node model.homework.iris_processed
[0m11:28:08.932109 [info ] [Thread-3  ]: 2 of 2 START sql table model analytics.iris_processed .......................... [RUN]
[0m11:28:08.935065 [debug] [Thread-3  ]: Acquiring new postgres connection 'model.homework.iris_processed'
[0m11:28:08.937482 [debug] [Thread-3  ]: Began compiling node model.homework.iris_processed
[0m11:28:09.015618 [debug] [Thread-3  ]: Using postgres connection "model.homework.iris_processed"
[0m11:28:09.017304 [debug] [Thread-3  ]: On model.homework.iris_processed: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "homework", "target_name": "dev", "node_id": "model.homework.iris_processed"} */

        select percentile_cont(0.5) within group (order by sepal_length ) from "analytics"."analytics"."stg_iris"
    
[0m11:28:09.019150 [debug] [Thread-3  ]: Opening a new connection, currently in state init
[0m11:28:09.032122 [debug] [Thread-3  ]: SQL status: SELECT 1 in 0.013 seconds
[0m11:28:09.036040 [debug] [Thread-3  ]: Using postgres connection "model.homework.iris_processed"
[0m11:28:09.037932 [debug] [Thread-3  ]: On model.homework.iris_processed: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "homework", "target_name": "dev", "node_id": "model.homework.iris_processed"} */

        select percentile_cont(0.5 - 0.5/2) within group (order by sepal_length ) from "analytics"."analytics"."stg_iris"
    
[0m11:28:09.041395 [debug] [Thread-3  ]: SQL status: SELECT 1 in 0.001 seconds
[0m11:28:09.045363 [debug] [Thread-3  ]: Using postgres connection "model.homework.iris_processed"
[0m11:28:09.047087 [debug] [Thread-3  ]: On model.homework.iris_processed: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "homework", "target_name": "dev", "node_id": "model.homework.iris_processed"} */

        select percentile_cont(0.5 + 0.5/2) within group (order by sepal_length ) from "analytics"."analytics"."stg_iris"
    
[0m11:28:09.049526 [debug] [Thread-3  ]: SQL status: SELECT 1 in 0.001 seconds
[0m11:28:09.069323 [debug] [Thread-3  ]: Using postgres connection "model.homework.iris_processed"
[0m11:28:09.071438 [debug] [Thread-3  ]: On model.homework.iris_processed: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "homework", "target_name": "dev", "node_id": "model.homework.iris_processed"} */

        select percentile_cont(0.5) within group (order by sepal_width ) from "analytics"."analytics"."stg_iris"
    
[0m11:28:09.074848 [debug] [Thread-3  ]: SQL status: SELECT 1 in 0.001 seconds
[0m11:28:09.078798 [debug] [Thread-3  ]: Using postgres connection "model.homework.iris_processed"
[0m11:28:09.080475 [debug] [Thread-3  ]: On model.homework.iris_processed: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "homework", "target_name": "dev", "node_id": "model.homework.iris_processed"} */

        select percentile_cont(0.5 - 0.5/2) within group (order by sepal_width ) from "analytics"."analytics"."stg_iris"
    
[0m11:28:09.082765 [debug] [Thread-3  ]: SQL status: SELECT 1 in 0.001 seconds
[0m11:28:09.086348 [debug] [Thread-3  ]: Using postgres connection "model.homework.iris_processed"
[0m11:28:09.088468 [debug] [Thread-3  ]: On model.homework.iris_processed: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "homework", "target_name": "dev", "node_id": "model.homework.iris_processed"} */

        select percentile_cont(0.5 + 0.5/2) within group (order by sepal_width ) from "analytics"."analytics"."stg_iris"
    
[0m11:28:09.091396 [debug] [Thread-3  ]: SQL status: SELECT 1 in 0.001 seconds
[0m11:28:09.097192 [debug] [Thread-3  ]: Using postgres connection "model.homework.iris_processed"
[0m11:28:09.098845 [debug] [Thread-3  ]: On model.homework.iris_processed: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "homework", "target_name": "dev", "node_id": "model.homework.iris_processed"} */

        select percentile_cont(0.5) within group (order by petal_length ) from "analytics"."analytics"."stg_iris"
    
[0m11:28:09.101204 [debug] [Thread-3  ]: SQL status: SELECT 1 in 0.001 seconds
[0m11:28:09.105347 [debug] [Thread-3  ]: Using postgres connection "model.homework.iris_processed"
[0m11:28:09.107267 [debug] [Thread-3  ]: On model.homework.iris_processed: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "homework", "target_name": "dev", "node_id": "model.homework.iris_processed"} */

        select percentile_cont(0.5 - 0.5/2) within group (order by petal_length ) from "analytics"."analytics"."stg_iris"
    
[0m11:28:09.109862 [debug] [Thread-3  ]: SQL status: SELECT 1 in 0.001 seconds
[0m11:28:09.113634 [debug] [Thread-3  ]: Using postgres connection "model.homework.iris_processed"
[0m11:28:09.115310 [debug] [Thread-3  ]: On model.homework.iris_processed: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "homework", "target_name": "dev", "node_id": "model.homework.iris_processed"} */

        select percentile_cont(0.5 + 0.5/2) within group (order by petal_length ) from "analytics"."analytics"."stg_iris"
    
[0m11:28:09.117711 [debug] [Thread-3  ]: SQL status: SELECT 1 in 0.001 seconds
[0m11:28:09.124397 [debug] [Thread-3  ]: Using postgres connection "model.homework.iris_processed"
[0m11:28:09.126217 [debug] [Thread-3  ]: On model.homework.iris_processed: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "homework", "target_name": "dev", "node_id": "model.homework.iris_processed"} */

        select percentile_cont(0.5) within group (order by petal_width ) from "analytics"."analytics"."stg_iris"
    
[0m11:28:09.128595 [debug] [Thread-3  ]: SQL status: SELECT 1 in 0.001 seconds
[0m11:28:09.132198 [debug] [Thread-3  ]: Using postgres connection "model.homework.iris_processed"
[0m11:28:09.133715 [debug] [Thread-3  ]: On model.homework.iris_processed: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "homework", "target_name": "dev", "node_id": "model.homework.iris_processed"} */

        select percentile_cont(0.5 - 0.5/2) within group (order by petal_width ) from "analytics"."analytics"."stg_iris"
    
[0m11:28:09.135937 [debug] [Thread-3  ]: SQL status: SELECT 1 in 0.001 seconds
[0m11:28:09.140375 [debug] [Thread-3  ]: Using postgres connection "model.homework.iris_processed"
[0m11:28:09.142212 [debug] [Thread-3  ]: On model.homework.iris_processed: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "homework", "target_name": "dev", "node_id": "model.homework.iris_processed"} */

        select percentile_cont(0.5 + 0.5/2) within group (order by petal_width ) from "analytics"."analytics"."stg_iris"
    
[0m11:28:09.144648 [debug] [Thread-3  ]: SQL status: SELECT 1 in 0.001 seconds
[0m11:28:09.169846 [debug] [Thread-3  ]: Using postgres connection "model.homework.iris_processed"
[0m11:28:09.172125 [debug] [Thread-3  ]: On model.homework.iris_processed: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "homework", "target_name": "dev", "node_id": "model.homework.iris_processed"} */

            select percentile_cont(0.5) within group (order by sepal_length ) from "analytics"."analytics"."stg_iris"
        
[0m11:28:09.174998 [debug] [Thread-3  ]: SQL status: SELECT 1 in 0.001 seconds
[0m11:28:09.179673 [debug] [Thread-3  ]: Using postgres connection "model.homework.iris_processed"
[0m11:28:09.181329 [debug] [Thread-3  ]: On model.homework.iris_processed: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "homework", "target_name": "dev", "node_id": "model.homework.iris_processed"} */

            select percentile_cont(0.5) within group (order by sepal_width ) from "analytics"."analytics"."stg_iris"
        
[0m11:28:09.183672 [debug] [Thread-3  ]: SQL status: SELECT 1 in 0.001 seconds
[0m11:28:09.188737 [debug] [Thread-3  ]: Using postgres connection "model.homework.iris_processed"
[0m11:28:09.191112 [debug] [Thread-3  ]: On model.homework.iris_processed: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "homework", "target_name": "dev", "node_id": "model.homework.iris_processed"} */

            select percentile_cont(0.5) within group (order by petal_length ) from "analytics"."analytics"."stg_iris"
        
[0m11:28:09.193680 [debug] [Thread-3  ]: SQL status: SELECT 1 in 0.001 seconds
[0m11:28:09.198952 [debug] [Thread-3  ]: Using postgres connection "model.homework.iris_processed"
[0m11:28:09.200936 [debug] [Thread-3  ]: On model.homework.iris_processed: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "homework", "target_name": "dev", "node_id": "model.homework.iris_processed"} */

            select percentile_cont(0.5) within group (order by petal_width ) from "analytics"."analytics"."stg_iris"
        
[0m11:28:09.203837 [debug] [Thread-3  ]: SQL status: SELECT 1 in 0.001 seconds
[0m11:28:09.301934 [debug] [Thread-3  ]: Using postgres connection "model.homework.iris_processed"
[0m11:28:09.303799 [debug] [Thread-3  ]: On model.homework.iris_processed: BEGIN
[0m11:28:09.307022 [debug] [Thread-3  ]: SQL status: BEGIN in 0.001 seconds
[0m11:28:09.309586 [debug] [Thread-3  ]: Using postgres connection "model.homework.iris_processed"
[0m11:28:09.312193 [debug] [Thread-3  ]: On model.homework.iris_processed: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "homework", "target_name": "dev", "node_id": "model.homework.iris_processed"} */
select
                species as value

            from "analytics"."analytics"."stg_iris"

            
            where species is not null  and true
            

            group by species
            order by species

            

        
[0m11:28:09.315448 [debug] [Thread-3  ]: SQL status: SELECT 3 in 0.001 seconds
[0m11:28:09.327757 [debug] [Thread-3  ]: Writing injected SQL for node "model.homework.iris_processed"
[0m11:28:09.340705 [debug] [Thread-3  ]: Began executing node model.homework.iris_processed
[0m11:28:09.408271 [debug] [Thread-3  ]: Writing runtime sql for node "model.homework.iris_processed"
[0m11:28:09.419052 [debug] [Thread-3  ]: Using postgres connection "model.homework.iris_processed"
[0m11:28:09.422169 [debug] [Thread-3  ]: On model.homework.iris_processed: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "homework", "target_name": "dev", "node_id": "model.homework.iris_processed"} */

  
    

  create  table "analytics"."analytics"."iris_processed__dbt_tmp"
  
  
    as
  
  (
    

with import_iris as (
    select *
    from "analytics"."analytics"."stg_iris"
)
select
    sepal_length,
    sepal_width,
    petal_length,
    petal_width,
    -- K Bins Discretization
    
        

    
        NTILE(5) over (order by sepal_length)
    

 as sepal_length_quantile_bin,
        

    
        
        floor(
        (
            sepal_length - (min(sepal_length) over ())
        )
        /
        (
            ((max(sepal_length) over ()) - (min(sepal_length) over ())) / 4::float
        )
        ) + 1
    

 as sepal_length_uniform_bin,
    
        

    
        NTILE(5) over (order by sepal_width)
    

 as sepal_width_quantile_bin,
        

    
        
        floor(
        (
            sepal_width - (min(sepal_width) over ())
        )
        /
        (
            ((max(sepal_width) over ()) - (min(sepal_width) over ())) / 4::float
        )
        ) + 1
    

 as sepal_width_uniform_bin,
    
        

    
        NTILE(5) over (order by petal_length)
    

 as petal_length_quantile_bin,
        

    
        
        floor(
        (
            petal_length - (min(petal_length) over ())
        )
        /
        (
            ((max(petal_length) over ()) - (min(petal_length) over ())) / 4::float
        )
        ) + 1
    

 as petal_length_uniform_bin,
    
        

    
        NTILE(5) over (order by petal_width)
    

 as petal_width_quantile_bin,
        

    
        
        floor(
        (
            petal_width - (min(petal_width) over ())
        )
        /
        (
            ((max(petal_width) over ()) - (min(petal_width) over ())) / 4::float
        )
        ) + 1
    

 as petal_width_uniform_bin,
    
-- Scaling
    
        

    

    
    
    

    
    
    

    (
        sepal_length - 5.8
    )
    /
    (
        6.4 - 5.1
    )

 as sepal_length_robust_scaled,
        

    (sepal_length) / (max(abs(sepal_length)) over ())::FLOAT

 as sepal_length_max_absolute_scaled,
        

    
    (
        ((sepal_length) - (min(sepal_length) over ()))
        /
        ((max(sepal_length) over ()) - (min(sepal_length) over ()))::FLOAT
    )
    *
    (1.0 - 0.0)
    +
    0.0

 as sepal_length_max_min_max_scaled,
    
        

    

    
    
    

    
    
    

    (
        sepal_width - 3.0
    )
    /
    (
        3.3 - 2.8
    )

 as sepal_width_robust_scaled,
        

    (sepal_width) / (max(abs(sepal_width)) over ())::FLOAT

 as sepal_width_max_absolute_scaled,
        

    
    (
        ((sepal_width) - (min(sepal_width) over ()))
        /
        ((max(sepal_width) over ()) - (min(sepal_width) over ()))::FLOAT
    )
    *
    (1.0 - 0.0)
    +
    0.0

 as sepal_width_max_min_max_scaled,
    
        

    

    
    
    

    
    
    

    (
        petal_length - 4.35
    )
    /
    (
        5.1 - 1.6
    )

 as petal_length_robust_scaled,
        

    (petal_length) / (max(abs(petal_length)) over ())::FLOAT

 as petal_length_max_absolute_scaled,
        

    
    (
        ((petal_length) - (min(petal_length) over ()))
        /
        ((max(petal_length) over ()) - (min(petal_length) over ()))::FLOAT
    )
    *
    (1.0 - 0.0)
    +
    0.0

 as petal_length_max_min_max_scaled,
    
        

    

    
    
    

    
    
    

    (
        petal_width - 1.3
    )
    /
    (
        1.8 - 0.3
    )

 as petal_width_robust_scaled,
        

    (petal_width) / (max(abs(petal_width)) over ())::FLOAT

 as petal_width_max_absolute_scaled,
        

    
    (
        ((petal_width) - (min(petal_width) over ()))
        /
        ((max(petal_width) over ()) - (min(petal_width) over ()))::FLOAT
    )
    *
    (1.0 - 0.0)
    +
    0.0

 as petal_width_max_min_max_scaled,
    

    -- Log Transformation
    
        

    case
        when sepal_length is null or sepal_length + 0 <= 0 then null
        else log(10, sepal_length + 0)
    end

 as sepal_length_logged,
    
        

    case
        when sepal_width is null or sepal_width + 0 <= 0 then null
        else log(10, sepal_width + 0)
    end

 as sepal_width_logged,
    
        

    case
        when petal_length is null or petal_length + 0 <= 0 then null
        else log(10, petal_length + 0)
    end

 as petal_length_logged,
    
        

    case
        when petal_width is null or petal_width + 0 <= 0 then null
        else log(10, petal_width + 0)
    end

 as petal_width_logged,
    

    -- Binarization
    
        

    

    
        

        
    

    case
        when sepal_length >=
            
                5.8
            
            then 1
        else 0
    end

 as sepal_length_binarized,
    
        

    

    
        

        
    

    case
        when sepal_width >=
            
                3.0
            
            then 1
        else 0
    end

 as sepal_width_binarized,
    
        

    

    
        

        
    

    case
        when petal_length >=
            
                4.35
            
            then 1
        else 0
    end

 as petal_length_binarized,
    
        

    

    
        

        
    

    case
        when petal_width >=
            
                1.3
            
            then 1
        else 0
    end

 as petal_width_binarized,
    

    -- Standardization
    
        

    
    (
        (sepal_length - avg(sepal_length) over ())
        /
        (stddev(sepal_length) over ())::FLOAT
    )
    *
    1
    +
    0

 as sepal_length_standardized,
    
        

    
    (
        (sepal_width - avg(sepal_width) over ())
        /
        (stddev(sepal_width) over ())::FLOAT
    )
    *
    1
    +
    0

 as sepal_width_standardized,
    
        

    
    (
        (petal_length - avg(petal_length) over ())
        /
        (stddev(petal_length) over ())::FLOAT
    )
    *
    1
    +
    0

 as petal_length_standardized,
    
        

    
    (
        (petal_width - avg(petal_width) over ())
        /
        (stddev(petal_width) over ())::FLOAT
    )
    *
    1
    +
    0

 as petal_width_standardized,
    
-- Interactions
    
        
            
            
            

    
        (sepal_length * sepal_width)
    

 as sepal_length_x_sepal_width_interaction,
            

    
        (sepal_length + sepal_width)
    

 as sepal_length_plus_sepal_width_interaction,
        
            
            
            

    
        (sepal_length * petal_length)
    

 as sepal_length_x_petal_length_interaction,
            

    
        (sepal_length + petal_length)
    

 as sepal_length_plus_petal_length_interaction,
        
            
            
            

    
        (sepal_length * petal_width)
    

 as sepal_length_x_petal_width_interaction,
            

    
        (sepal_length + petal_width)
    

 as sepal_length_plus_petal_width_interaction,
        
    
        
            
            
            

    
        (sepal_width * petal_length)
    

 as sepal_width_x_petal_length_interaction,
            

    
        (sepal_width + petal_length)
    

 as sepal_width_plus_petal_length_interaction,
        
            
            
            

    
        (sepal_width * petal_width)
    

 as sepal_width_x_petal_width_interaction,
            

    
        (sepal_width + petal_width)
    

 as sepal_width_plus_petal_width_interaction,
        
    
        
            
            
            

    
        (petal_length * petal_width)
    

 as petal_length_x_petal_width_interaction,
            

    
        (petal_length + petal_width)
    

 as petal_length_plus_petal_width_interaction,
        
    
        
    
species,    
    -- Label Encoding
    

    dense_rank() over (order by species) - 1

 as species_label_encoded,
    -- One Hot Encoding
    

    

    
        
    

    

    

        case
            when species = 'setosa' then 1
            else 0
        end as is_species__setosa,

    

        case
            when species = 'versicolor' then 1
            else 0
        end as is_species__versicolor,

    

        case
            when species = 'virginica' then 1
            else 0
        end as is_species__virginica,

    

    case
        when species is null then 1
        else 0
    end as is_species__


from "analytics"."analytics"."stg_iris"
  );
  
[0m11:28:09.465543 [debug] [Thread-3  ]: SQL status: SELECT 150 in 0.040 seconds
[0m11:28:09.481866 [debug] [Thread-3  ]: Using postgres connection "model.homework.iris_processed"
[0m11:28:09.483646 [debug] [Thread-3  ]: On model.homework.iris_processed: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "homework", "target_name": "dev", "node_id": "model.homework.iris_processed"} */
alter table "analytics"."analytics"."iris_processed" rename to "iris_processed__dbt_backup"
[0m11:28:09.486305 [debug] [Thread-3  ]: SQL status: ALTER TABLE in 0.001 seconds
[0m11:28:09.496975 [debug] [Thread-3  ]: Using postgres connection "model.homework.iris_processed"
[0m11:28:09.498849 [debug] [Thread-3  ]: On model.homework.iris_processed: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "homework", "target_name": "dev", "node_id": "model.homework.iris_processed"} */
alter table "analytics"."analytics"."iris_processed__dbt_tmp" rename to "iris_processed"
[0m11:28:09.501428 [debug] [Thread-3  ]: SQL status: ALTER TABLE in 0.001 seconds
[0m11:28:09.506706 [debug] [Thread-3  ]: On model.homework.iris_processed: COMMIT
[0m11:28:09.508508 [debug] [Thread-3  ]: Using postgres connection "model.homework.iris_processed"
[0m11:28:09.510187 [debug] [Thread-3  ]: On model.homework.iris_processed: COMMIT
[0m11:28:09.515301 [debug] [Thread-3  ]: SQL status: COMMIT in 0.003 seconds
[0m11:28:09.523097 [debug] [Thread-3  ]: Applying DROP to: "analytics"."analytics"."iris_processed__dbt_backup"
[0m11:28:09.529597 [debug] [Thread-3  ]: Using postgres connection "model.homework.iris_processed"
[0m11:28:09.531342 [debug] [Thread-3  ]: On model.homework.iris_processed: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "homework", "target_name": "dev", "node_id": "model.homework.iris_processed"} */
drop table if exists "analytics"."analytics"."iris_processed__dbt_backup" cascade
[0m11:28:09.540924 [debug] [Thread-3  ]: SQL status: DROP TABLE in 0.008 seconds
[0m11:28:09.544678 [debug] [Thread-3  ]: On model.homework.iris_processed: Close
[0m11:28:09.547316 [debug] [Thread-3  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '022a68dd-80a0-460d-822d-92493534f9e4', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fcb14642670>]}
[0m11:28:09.550950 [info ] [Thread-3  ]: 2 of 2 OK created sql table model analytics.iris_processed ..................... [[32mSELECT 150[0m in 0.61s]
[0m11:28:09.553525 [debug] [Thread-3  ]: Finished running node model.homework.iris_processed
[0m11:28:09.558312 [debug] [MainThread]: Using postgres connection "master"
[0m11:28:09.560084 [debug] [MainThread]: On master: BEGIN
[0m11:28:09.561513 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m11:28:09.573264 [debug] [MainThread]: SQL status: BEGIN in 0.012 seconds
[0m11:28:09.575456 [debug] [MainThread]: On master: COMMIT
[0m11:28:09.577682 [debug] [MainThread]: Using postgres connection "master"
[0m11:28:09.580177 [debug] [MainThread]: On master: COMMIT
[0m11:28:09.582255 [debug] [MainThread]: SQL status: COMMIT in 0.000 seconds
[0m11:28:09.583964 [debug] [MainThread]: On master: Close
[0m11:28:09.585872 [debug] [MainThread]: Connection 'master' was properly closed.
[0m11:28:09.587436 [debug] [MainThread]: Connection 'model.homework.stg_iris' was properly closed.
[0m11:28:09.589795 [debug] [MainThread]: Connection 'model.homework.iris_processed' was properly closed.
[0m11:28:09.591670 [info ] [MainThread]: 
[0m11:28:09.593463 [info ] [MainThread]: Finished running 1 table model, 1 view model in 0 hours 0 minutes and 1.29 seconds (1.29s).
[0m11:28:09.596770 [debug] [MainThread]: Command end result
[0m11:28:09.691662 [debug] [MainThread]: Wrote artifact WritableManifest to /opt/airflow/dags/dbt/homework/target/manifest.json
[0m11:28:09.698258 [debug] [MainThread]: Wrote artifact SemanticManifest to /opt/airflow/dags/dbt/homework/target/semantic_manifest.json
[0m11:28:09.718357 [debug] [MainThread]: Wrote artifact RunExecutionResult to /opt/airflow/dags/dbt/homework/target/run_results.json
[0m11:28:09.720118 [info ] [MainThread]: 
[0m11:28:09.722383 [info ] [MainThread]: [32mCompleted successfully[0m
[0m11:28:09.724852 [info ] [MainThread]: 
[0m11:28:09.726734 [info ] [MainThread]: Done. PASS=2 WARN=0 ERROR=0 SKIP=0 TOTAL=2
[0m11:28:09.729782 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": true, "command_wall_clock_time": 4.5877786, "process_in_blocks": "0", "process_kernel_time": 0.467312, "process_mem_max_rss": "114696", "process_out_blocks": "0", "process_user_time": 6.333572}
[0m11:28:09.732178 [debug] [MainThread]: Command `dbt run` succeeded at 11:28:09.731928 after 4.59 seconds
[0m11:28:09.734060 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fcb1a73eb20>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fcb17b2c0a0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fcb17bcf1c0>]}
[0m11:28:09.736064 [debug] [MainThread]: Flushing usage events
[0m11:28:10.364273 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m11:28:15.783718 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f7ce272ea60>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f7ce184f550>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f7ce184f4f0>]}


============================== 11:28:15.795357 | 1101c2ad-19ce-453e-9794-570c70cbea87 ==============================
[0m11:28:15.795357 [info ] [MainThread]: Running with dbt=1.9.4
[0m11:28:15.797682 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': '/opt/airflow/dags/dbt', 'debug': 'False', 'warn_error': 'None', 'log_path': '/opt/airflow/dags/dbt/homework/logs', 'version_check': 'True', 'fail_fast': 'True', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'empty': 'None', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'invocation_command': 'dbt --profile homework test --project-dir=/opt/airflow/dags/dbt/homework --vars {"is_test": false, "data_date": "2025-04-23"} --fail-fast', 'static_parser': 'True', 'introspect': 'True', 'target_path': 'None', 'log_format': 'default', 'send_anonymous_usage_stats': 'True'}
[0m11:28:16.173687 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '1101c2ad-19ce-453e-9794-570c70cbea87', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f7cdfff1d30>]}
[0m11:28:16.280224 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '1101c2ad-19ce-453e-9794-570c70cbea87', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f7ce18cd700>]}
[0m11:28:16.282772 [info ] [MainThread]: Registered adapter: postgres=1.9.0
[0m11:28:16.532691 [debug] [MainThread]: checksum: f5df654a850f4b74beb13fbe0c7d8863b5b1a20bd535c3ac287d70e390b64d41, vars: {'data_date': '2025-04-23', 'is_test': False}, profile: homework, target: , version: 1.9.4
[0m11:28:18.061781 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m11:28:18.064205 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m11:28:18.079158 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 1 unused configuration paths:
- seeds.homework.iris_dataset
[0m11:28:18.165709 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '1101c2ad-19ce-453e-9794-570c70cbea87', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f7cdfb7e130>]}
[0m11:28:18.463543 [debug] [MainThread]: Wrote artifact WritableManifest to /opt/airflow/dags/dbt/homework/target/manifest.json
[0m11:28:18.482460 [debug] [MainThread]: Wrote artifact SemanticManifest to /opt/airflow/dags/dbt/homework/target/semantic_manifest.json
[0m11:28:18.528543 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '1101c2ad-19ce-453e-9794-570c70cbea87', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f7cdfac3a30>]}
[0m11:28:18.531054 [info ] [MainThread]: Found 2 models, 1 source, 587 macros
[0m11:28:18.532868 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '1101c2ad-19ce-453e-9794-570c70cbea87', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f7cdff69d30>]}
[0m11:28:18.535969 [warn ] [MainThread]: Nothing to do. Try checking your model configs and model specification args
[0m11:28:18.541033 [debug] [MainThread]: Command end result
[0m11:28:18.637366 [debug] [MainThread]: Wrote artifact WritableManifest to /opt/airflow/dags/dbt/homework/target/manifest.json
[0m11:28:18.647755 [debug] [MainThread]: Wrote artifact SemanticManifest to /opt/airflow/dags/dbt/homework/target/semantic_manifest.json
[0m11:28:18.658601 [debug] [MainThread]: Wrote artifact RunExecutionResult to /opt/airflow/dags/dbt/homework/target/run_results.json
[0m11:28:18.661116 [debug] [MainThread]: Resource report: {"command_name": "test", "command_success": true, "command_wall_clock_time": 3.0206096, "process_in_blocks": "0", "process_kernel_time": 0.345528, "process_mem_max_rss": "104424", "process_out_blocks": "0", "process_user_time": 4.896634}
[0m11:28:18.663091 [debug] [MainThread]: Command `dbt test` succeeded at 11:28:18.662765 after 3.02 seconds
[0m11:28:18.665155 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f7ce272ea60>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f7ce3ba4be0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f7cdffe5040>]}
[0m11:28:18.666846 [debug] [MainThread]: Flushing usage events
[0m11:28:19.203184 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m11:31:34.931765 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7efd706f4b20>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7efd6f815490>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7efd6f815430>]}


============================== 11:31:34.942540 | d2233557-f473-4c45-952b-3952e47759a3 ==============================
[0m11:31:34.942540 [info ] [MainThread]: Running with dbt=1.9.4
[0m11:31:34.945251 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': '/opt/airflow/dags/dbt', 'debug': 'False', 'warn_error': 'None', 'log_path': '/opt/airflow/dags/dbt/homework/logs', 'version_check': 'True', 'fail_fast': 'False', 'use_colors': 'True', 'use_experimental_parser': 'False', 'empty': 'False', 'quiet': 'False', 'no_print': 'None', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'invocation_command': 'dbt --profile homework run --project-dir=/opt/airflow/dags/dbt/homework --vars {"is_test": false, "data_date": "2025-04-23"}', 'static_parser': 'True', 'introspect': 'True', 'target_path': 'None', 'log_format': 'default', 'send_anonymous_usage_stats': 'True'}
[0m11:31:35.475819 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'd2233557-f473-4c45-952b-3952e47759a3', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7efd6e08a880>]}
[0m11:31:35.604847 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': 'd2233557-f473-4c45-952b-3952e47759a3', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7efd6e03b280>]}
[0m11:31:35.607625 [info ] [MainThread]: Registered adapter: postgres=1.9.0
[0m11:31:35.857954 [debug] [MainThread]: checksum: f5df654a850f4b74beb13fbe0c7d8863b5b1a20bd535c3ac287d70e390b64d41, vars: {'data_date': '2025-04-23', 'is_test': False}, profile: homework, target: , version: 1.9.4
[0m11:31:37.234545 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m11:31:37.236205 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m11:31:37.250923 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 1 unused configuration paths:
- seeds.homework.iris_dataset
[0m11:31:37.337671 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'd2233557-f473-4c45-952b-3952e47759a3', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7efd6db41130>]}
[0m11:31:37.646562 [debug] [MainThread]: Wrote artifact WritableManifest to /opt/airflow/dags/dbt/homework/target/manifest.json
[0m11:31:37.668995 [debug] [MainThread]: Wrote artifact SemanticManifest to /opt/airflow/dags/dbt/homework/target/semantic_manifest.json
[0m11:31:37.704402 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'd2233557-f473-4c45-952b-3952e47759a3', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7efd6f87ab50>]}
[0m11:31:37.706191 [info ] [MainThread]: Found 2 models, 1 source, 587 macros
[0m11:31:37.707777 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'd2233557-f473-4c45-952b-3952e47759a3', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7efd713f3d30>]}
[0m11:31:37.712608 [info ] [MainThread]: 
[0m11:31:37.714490 [info ] [MainThread]: Concurrency: 4 threads (target='dev')
[0m11:31:37.716189 [info ] [MainThread]: 
[0m11:31:37.718077 [debug] [MainThread]: Acquiring new postgres connection 'master'
[0m11:31:37.729986 [debug] [ThreadPool]: Acquiring new postgres connection 'list_analytics'
[0m11:31:37.806257 [debug] [ThreadPool]: Using postgres connection "list_analytics"
[0m11:31:37.808031 [debug] [ThreadPool]: On list_analytics: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "homework", "target_name": "dev", "connection_name": "list_analytics"} */

    select distinct nspname from pg_namespace
  
[0m11:31:37.809890 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m11:31:37.824258 [debug] [ThreadPool]: SQL status: SELECT 6 in 0.014 seconds
[0m11:31:37.829439 [debug] [ThreadPool]: On list_analytics: Close
[0m11:31:37.834677 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_analytics, now list_analytics_analytics)
[0m11:31:37.851934 [debug] [ThreadPool]: Using postgres connection "list_analytics_analytics"
[0m11:31:37.853707 [debug] [ThreadPool]: On list_analytics_analytics: BEGIN
[0m11:31:37.855394 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m11:31:37.868163 [debug] [ThreadPool]: SQL status: BEGIN in 0.013 seconds
[0m11:31:37.870715 [debug] [ThreadPool]: Using postgres connection "list_analytics_analytics"
[0m11:31:37.872887 [debug] [ThreadPool]: On list_analytics_analytics: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "homework", "target_name": "dev", "connection_name": "list_analytics_analytics"} */
select
      'analytics' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'analytics'
    union all
    select
      'analytics' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'analytics'
    union all
    select
      'analytics' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'analytics'
  
[0m11:31:37.880325 [debug] [ThreadPool]: SQL status: SELECT 3 in 0.005 seconds
[0m11:31:37.883720 [debug] [ThreadPool]: On list_analytics_analytics: ROLLBACK
[0m11:31:37.885538 [debug] [ThreadPool]: On list_analytics_analytics: Close
[0m11:31:37.898988 [debug] [MainThread]: Using postgres connection "master"
[0m11:31:37.900674 [debug] [MainThread]: On master: BEGIN
[0m11:31:37.902382 [debug] [MainThread]: Opening a new connection, currently in state init
[0m11:31:37.914221 [debug] [MainThread]: SQL status: BEGIN in 0.012 seconds
[0m11:31:37.916784 [debug] [MainThread]: Using postgres connection "master"
[0m11:31:37.920062 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "homework", "target_name": "dev", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select distinct
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v', 'm')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
[0m11:31:37.936691 [debug] [MainThread]: SQL status: SELECT 1 in 0.012 seconds
[0m11:31:37.940857 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'd2233557-f473-4c45-952b-3952e47759a3', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7efd6db788e0>]}
[0m11:31:37.942722 [debug] [MainThread]: On master: ROLLBACK
[0m11:31:37.945313 [debug] [MainThread]: Using postgres connection "master"
[0m11:31:37.947609 [debug] [MainThread]: On master: BEGIN
[0m11:31:37.950314 [debug] [MainThread]: SQL status: BEGIN in 0.001 seconds
[0m11:31:37.952427 [debug] [MainThread]: On master: COMMIT
[0m11:31:37.954504 [debug] [MainThread]: Using postgres connection "master"
[0m11:31:37.956289 [debug] [MainThread]: On master: COMMIT
[0m11:31:37.958366 [debug] [MainThread]: SQL status: COMMIT in 0.000 seconds
[0m11:31:37.960139 [debug] [MainThread]: On master: Close
[0m11:31:37.970611 [debug] [Thread-1  ]: Began running node model.homework.stg_iris
[0m11:31:37.972726 [info ] [Thread-1  ]: 1 of 2 START sql view model analytics.stg_iris ................................. [RUN]
[0m11:31:37.974978 [debug] [Thread-1  ]: Re-using an available connection from the pool (formerly list_analytics_analytics, now model.homework.stg_iris)
[0m11:31:37.976726 [debug] [Thread-1  ]: Began compiling node model.homework.stg_iris
[0m11:31:38.001767 [debug] [Thread-1  ]: Writing injected SQL for node "model.homework.stg_iris"
[0m11:31:38.013993 [debug] [Thread-1  ]: Began executing node model.homework.stg_iris
[0m11:31:38.103461 [debug] [Thread-1  ]: Writing runtime sql for node "model.homework.stg_iris"
[0m11:31:38.114222 [debug] [Thread-1  ]: Using postgres connection "model.homework.stg_iris"
[0m11:31:38.115945 [debug] [Thread-1  ]: On model.homework.stg_iris: BEGIN
[0m11:31:38.117642 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
[0m11:31:38.130744 [debug] [Thread-1  ]: SQL status: BEGIN in 0.013 seconds
[0m11:31:38.134079 [debug] [Thread-1  ]: Using postgres connection "model.homework.stg_iris"
[0m11:31:38.136764 [debug] [Thread-1  ]: On model.homework.stg_iris: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "homework", "target_name": "dev", "node_id": "model.homework.stg_iris"} */

  create view "analytics"."analytics"."stg_iris__dbt_tmp"
    
    
  as (
    with source as (
    select * from "analytics"."analytics"."iris_dataset"
)

select
    cast(sepal_length as numeric) as sepal_length,
    cast(sepal_width as numeric) as sepal_width,
    cast(petal_length as numeric) as petal_length,
    cast(petal_width as numeric) as petal_width,
    species
from source
  );
[0m11:31:38.142634 [debug] [Thread-1  ]: SQL status: CREATE VIEW in 0.003 seconds
[0m11:31:38.169739 [debug] [Thread-1  ]: Using postgres connection "model.homework.stg_iris"
[0m11:31:38.172063 [debug] [Thread-1  ]: On model.homework.stg_iris: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "homework", "target_name": "dev", "node_id": "model.homework.stg_iris"} */
alter table "analytics"."analytics"."stg_iris" rename to "stg_iris__dbt_backup"
[0m11:31:38.174699 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.001 seconds
[0m11:31:38.188246 [debug] [Thread-1  ]: Using postgres connection "model.homework.stg_iris"
[0m11:31:38.190175 [debug] [Thread-1  ]: On model.homework.stg_iris: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "homework", "target_name": "dev", "node_id": "model.homework.stg_iris"} */
alter table "analytics"."analytics"."stg_iris__dbt_tmp" rename to "stg_iris"
[0m11:31:38.192793 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.001 seconds
[0m11:31:38.256805 [debug] [Thread-1  ]: On model.homework.stg_iris: COMMIT
[0m11:31:38.259659 [debug] [Thread-1  ]: Using postgres connection "model.homework.stg_iris"
[0m11:31:38.263156 [debug] [Thread-1  ]: On model.homework.stg_iris: COMMIT
[0m11:31:38.269997 [debug] [Thread-1  ]: SQL status: COMMIT in 0.004 seconds
[0m11:31:38.298857 [debug] [Thread-1  ]: Applying DROP to: "analytics"."analytics"."stg_iris__dbt_backup"
[0m11:31:38.318857 [debug] [Thread-1  ]: Using postgres connection "model.homework.stg_iris"
[0m11:31:38.321469 [debug] [Thread-1  ]: On model.homework.stg_iris: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "homework", "target_name": "dev", "node_id": "model.homework.stg_iris"} */
drop view if exists "analytics"."analytics"."stg_iris__dbt_backup" cascade
[0m11:31:38.328954 [debug] [Thread-1  ]: SQL status: DROP VIEW in 0.005 seconds
[0m11:31:38.338458 [debug] [Thread-1  ]: On model.homework.stg_iris: Close
[0m11:31:38.345790 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'd2233557-f473-4c45-952b-3952e47759a3', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7efd6cfff070>]}
[0m11:31:38.349221 [info ] [Thread-1  ]: 1 of 2 OK created sql view model analytics.stg_iris ............................ [[32mCREATE VIEW[0m in 0.37s]
[0m11:31:38.353001 [debug] [Thread-1  ]: Finished running node model.homework.stg_iris
[0m11:31:38.357065 [debug] [Thread-3  ]: Began running node model.homework.iris_processed
[0m11:31:38.360028 [info ] [Thread-3  ]: 2 of 2 START sql table model analytics.iris_processed .......................... [RUN]
[0m11:31:38.363474 [debug] [Thread-3  ]: Acquiring new postgres connection 'model.homework.iris_processed'
[0m11:31:38.365205 [debug] [Thread-3  ]: Began compiling node model.homework.iris_processed
[0m11:31:38.443412 [debug] [Thread-3  ]: Using postgres connection "model.homework.iris_processed"
[0m11:31:38.445807 [debug] [Thread-3  ]: On model.homework.iris_processed: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "homework", "target_name": "dev", "node_id": "model.homework.iris_processed"} */

        select percentile_cont(0.5) within group (order by sepal_length ) from "analytics"."analytics"."stg_iris"
    
[0m11:31:38.447398 [debug] [Thread-3  ]: Opening a new connection, currently in state init
[0m11:31:38.459717 [debug] [Thread-3  ]: SQL status: SELECT 1 in 0.012 seconds
[0m11:31:38.464034 [debug] [Thread-3  ]: Using postgres connection "model.homework.iris_processed"
[0m11:31:38.465818 [debug] [Thread-3  ]: On model.homework.iris_processed: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "homework", "target_name": "dev", "node_id": "model.homework.iris_processed"} */

        select percentile_cont(0.5 - 0.5/2) within group (order by sepal_length ) from "analytics"."analytics"."stg_iris"
    
[0m11:31:38.468409 [debug] [Thread-3  ]: SQL status: SELECT 1 in 0.001 seconds
[0m11:31:38.472193 [debug] [Thread-3  ]: Using postgres connection "model.homework.iris_processed"
[0m11:31:38.473769 [debug] [Thread-3  ]: On model.homework.iris_processed: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "homework", "target_name": "dev", "node_id": "model.homework.iris_processed"} */

        select percentile_cont(0.5 + 0.5/2) within group (order by sepal_length ) from "analytics"."analytics"."stg_iris"
    
[0m11:31:38.476022 [debug] [Thread-3  ]: SQL status: SELECT 1 in 0.001 seconds
[0m11:31:38.492869 [debug] [Thread-3  ]: Using postgres connection "model.homework.iris_processed"
[0m11:31:38.495268 [debug] [Thread-3  ]: On model.homework.iris_processed: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "homework", "target_name": "dev", "node_id": "model.homework.iris_processed"} */

        select percentile_cont(0.5) within group (order by sepal_width ) from "analytics"."analytics"."stg_iris"
    
[0m11:31:38.498096 [debug] [Thread-3  ]: SQL status: SELECT 1 in 0.001 seconds
[0m11:31:38.502467 [debug] [Thread-3  ]: Using postgres connection "model.homework.iris_processed"
[0m11:31:38.504932 [debug] [Thread-3  ]: On model.homework.iris_processed: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "homework", "target_name": "dev", "node_id": "model.homework.iris_processed"} */

        select percentile_cont(0.5 - 0.5/2) within group (order by sepal_width ) from "analytics"."analytics"."stg_iris"
    
[0m11:31:38.507740 [debug] [Thread-3  ]: SQL status: SELECT 1 in 0.001 seconds
[0m11:31:38.512623 [debug] [Thread-3  ]: Using postgres connection "model.homework.iris_processed"
[0m11:31:38.514338 [debug] [Thread-3  ]: On model.homework.iris_processed: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "homework", "target_name": "dev", "node_id": "model.homework.iris_processed"} */

        select percentile_cont(0.5 + 0.5/2) within group (order by sepal_width ) from "analytics"."analytics"."stg_iris"
    
[0m11:31:38.516717 [debug] [Thread-3  ]: SQL status: SELECT 1 in 0.001 seconds
[0m11:31:38.522290 [debug] [Thread-3  ]: Using postgres connection "model.homework.iris_processed"
[0m11:31:38.524051 [debug] [Thread-3  ]: On model.homework.iris_processed: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "homework", "target_name": "dev", "node_id": "model.homework.iris_processed"} */

        select percentile_cont(0.5) within group (order by petal_length ) from "analytics"."analytics"."stg_iris"
    
[0m11:31:38.526429 [debug] [Thread-3  ]: SQL status: SELECT 1 in 0.001 seconds
[0m11:31:38.531031 [debug] [Thread-3  ]: Using postgres connection "model.homework.iris_processed"
[0m11:31:38.532792 [debug] [Thread-3  ]: On model.homework.iris_processed: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "homework", "target_name": "dev", "node_id": "model.homework.iris_processed"} */

        select percentile_cont(0.5 - 0.5/2) within group (order by petal_length ) from "analytics"."analytics"."stg_iris"
    
[0m11:31:38.535416 [debug] [Thread-3  ]: SQL status: SELECT 1 in 0.001 seconds
[0m11:31:38.539090 [debug] [Thread-3  ]: Using postgres connection "model.homework.iris_processed"
[0m11:31:38.540641 [debug] [Thread-3  ]: On model.homework.iris_processed: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "homework", "target_name": "dev", "node_id": "model.homework.iris_processed"} */

        select percentile_cont(0.5 + 0.5/2) within group (order by petal_length ) from "analytics"."analytics"."stg_iris"
    
[0m11:31:38.543030 [debug] [Thread-3  ]: SQL status: SELECT 1 in 0.001 seconds
[0m11:31:38.549276 [debug] [Thread-3  ]: Using postgres connection "model.homework.iris_processed"
[0m11:31:38.551069 [debug] [Thread-3  ]: On model.homework.iris_processed: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "homework", "target_name": "dev", "node_id": "model.homework.iris_processed"} */

        select percentile_cont(0.5) within group (order by petal_width ) from "analytics"."analytics"."stg_iris"
    
[0m11:31:38.553417 [debug] [Thread-3  ]: SQL status: SELECT 1 in 0.001 seconds
[0m11:31:38.557127 [debug] [Thread-3  ]: Using postgres connection "model.homework.iris_processed"
[0m11:31:38.558778 [debug] [Thread-3  ]: On model.homework.iris_processed: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "homework", "target_name": "dev", "node_id": "model.homework.iris_processed"} */

        select percentile_cont(0.5 - 0.5/2) within group (order by petal_width ) from "analytics"."analytics"."stg_iris"
    
[0m11:31:38.561582 [debug] [Thread-3  ]: SQL status: SELECT 1 in 0.001 seconds
[0m11:31:38.565577 [debug] [Thread-3  ]: Using postgres connection "model.homework.iris_processed"
[0m11:31:38.567402 [debug] [Thread-3  ]: On model.homework.iris_processed: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "homework", "target_name": "dev", "node_id": "model.homework.iris_processed"} */

        select percentile_cont(0.5 + 0.5/2) within group (order by petal_width ) from "analytics"."analytics"."stg_iris"
    
[0m11:31:38.569824 [debug] [Thread-3  ]: SQL status: SELECT 1 in 0.001 seconds
[0m11:31:38.595853 [debug] [Thread-3  ]: Using postgres connection "model.homework.iris_processed"
[0m11:31:38.597682 [debug] [Thread-3  ]: On model.homework.iris_processed: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "homework", "target_name": "dev", "node_id": "model.homework.iris_processed"} */

            select percentile_cont(0.5) within group (order by sepal_length ) from "analytics"."analytics"."stg_iris"
        
[0m11:31:38.600287 [debug] [Thread-3  ]: SQL status: SELECT 1 in 0.001 seconds
[0m11:31:38.605986 [debug] [Thread-3  ]: Using postgres connection "model.homework.iris_processed"
[0m11:31:38.608237 [debug] [Thread-3  ]: On model.homework.iris_processed: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "homework", "target_name": "dev", "node_id": "model.homework.iris_processed"} */

            select percentile_cont(0.5) within group (order by sepal_width ) from "analytics"."analytics"."stg_iris"
        
[0m11:31:38.611230 [debug] [Thread-3  ]: SQL status: SELECT 1 in 0.001 seconds
[0m11:31:38.616794 [debug] [Thread-3  ]: Using postgres connection "model.homework.iris_processed"
[0m11:31:38.618794 [debug] [Thread-3  ]: On model.homework.iris_processed: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "homework", "target_name": "dev", "node_id": "model.homework.iris_processed"} */

            select percentile_cont(0.5) within group (order by petal_length ) from "analytics"."analytics"."stg_iris"
        
[0m11:31:38.621578 [debug] [Thread-3  ]: SQL status: SELECT 1 in 0.001 seconds
[0m11:31:38.627510 [debug] [Thread-3  ]: Using postgres connection "model.homework.iris_processed"
[0m11:31:38.630100 [debug] [Thread-3  ]: On model.homework.iris_processed: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "homework", "target_name": "dev", "node_id": "model.homework.iris_processed"} */

            select percentile_cont(0.5) within group (order by petal_width ) from "analytics"."analytics"."stg_iris"
        
[0m11:31:38.632852 [debug] [Thread-3  ]: SQL status: SELECT 1 in 0.001 seconds
[0m11:31:38.725000 [debug] [Thread-3  ]: Using postgres connection "model.homework.iris_processed"
[0m11:31:38.726869 [debug] [Thread-3  ]: On model.homework.iris_processed: BEGIN
[0m11:31:38.731181 [debug] [Thread-3  ]: SQL status: BEGIN in 0.001 seconds
[0m11:31:38.734875 [debug] [Thread-3  ]: Using postgres connection "model.homework.iris_processed"
[0m11:31:38.737492 [debug] [Thread-3  ]: On model.homework.iris_processed: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "homework", "target_name": "dev", "node_id": "model.homework.iris_processed"} */
select
                species as value

            from "analytics"."analytics"."stg_iris"

            
            where species is not null  and true
            

            group by species
            order by species

            

        
[0m11:31:38.741190 [debug] [Thread-3  ]: SQL status: SELECT 3 in 0.001 seconds
[0m11:31:38.754079 [debug] [Thread-3  ]: Writing injected SQL for node "model.homework.iris_processed"
[0m11:31:38.767209 [debug] [Thread-3  ]: Began executing node model.homework.iris_processed
[0m11:31:38.831857 [debug] [Thread-3  ]: Writing runtime sql for node "model.homework.iris_processed"
[0m11:31:38.842301 [debug] [Thread-3  ]: Using postgres connection "model.homework.iris_processed"
[0m11:31:38.845850 [debug] [Thread-3  ]: On model.homework.iris_processed: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "homework", "target_name": "dev", "node_id": "model.homework.iris_processed"} */

  
    

  create  table "analytics"."analytics"."iris_processed__dbt_tmp"
  
  
    as
  
  (
    

with import_iris as (
    select *
    from "analytics"."analytics"."stg_iris"
)
select
    sepal_length,
    sepal_width,
    petal_length,
    petal_width,
    -- K Bins Discretization
    
        

    
        NTILE(5) over (order by sepal_length)
    

 as sepal_length_quantile_bin,
        

    
        
        floor(
        (
            sepal_length - (min(sepal_length) over ())
        )
        /
        (
            ((max(sepal_length) over ()) - (min(sepal_length) over ())) / 4::float
        )
        ) + 1
    

 as sepal_length_uniform_bin,
    
        

    
        NTILE(5) over (order by sepal_width)
    

 as sepal_width_quantile_bin,
        

    
        
        floor(
        (
            sepal_width - (min(sepal_width) over ())
        )
        /
        (
            ((max(sepal_width) over ()) - (min(sepal_width) over ())) / 4::float
        )
        ) + 1
    

 as sepal_width_uniform_bin,
    
        

    
        NTILE(5) over (order by petal_length)
    

 as petal_length_quantile_bin,
        

    
        
        floor(
        (
            petal_length - (min(petal_length) over ())
        )
        /
        (
            ((max(petal_length) over ()) - (min(petal_length) over ())) / 4::float
        )
        ) + 1
    

 as petal_length_uniform_bin,
    
        

    
        NTILE(5) over (order by petal_width)
    

 as petal_width_quantile_bin,
        

    
        
        floor(
        (
            petal_width - (min(petal_width) over ())
        )
        /
        (
            ((max(petal_width) over ()) - (min(petal_width) over ())) / 4::float
        )
        ) + 1
    

 as petal_width_uniform_bin,
    
-- Scaling
    
        

    

    
    
    

    
    
    

    (
        sepal_length - 5.8
    )
    /
    (
        6.4 - 5.1
    )

 as sepal_length_robust_scaled,
        

    (sepal_length) / (max(abs(sepal_length)) over ())::FLOAT

 as sepal_length_max_absolute_scaled,
        

    
    (
        ((sepal_length) - (min(sepal_length) over ()))
        /
        ((max(sepal_length) over ()) - (min(sepal_length) over ()))::FLOAT
    )
    *
    (1.0 - 0.0)
    +
    0.0

 as sepal_length_max_min_max_scaled,
    
        

    

    
    
    

    
    
    

    (
        sepal_width - 3.0
    )
    /
    (
        3.3 - 2.8
    )

 as sepal_width_robust_scaled,
        

    (sepal_width) / (max(abs(sepal_width)) over ())::FLOAT

 as sepal_width_max_absolute_scaled,
        

    
    (
        ((sepal_width) - (min(sepal_width) over ()))
        /
        ((max(sepal_width) over ()) - (min(sepal_width) over ()))::FLOAT
    )
    *
    (1.0 - 0.0)
    +
    0.0

 as sepal_width_max_min_max_scaled,
    
        

    

    
    
    

    
    
    

    (
        petal_length - 4.35
    )
    /
    (
        5.1 - 1.6
    )

 as petal_length_robust_scaled,
        

    (petal_length) / (max(abs(petal_length)) over ())::FLOAT

 as petal_length_max_absolute_scaled,
        

    
    (
        ((petal_length) - (min(petal_length) over ()))
        /
        ((max(petal_length) over ()) - (min(petal_length) over ()))::FLOAT
    )
    *
    (1.0 - 0.0)
    +
    0.0

 as petal_length_max_min_max_scaled,
    
        

    

    
    
    

    
    
    

    (
        petal_width - 1.3
    )
    /
    (
        1.8 - 0.3
    )

 as petal_width_robust_scaled,
        

    (petal_width) / (max(abs(petal_width)) over ())::FLOAT

 as petal_width_max_absolute_scaled,
        

    
    (
        ((petal_width) - (min(petal_width) over ()))
        /
        ((max(petal_width) over ()) - (min(petal_width) over ()))::FLOAT
    )
    *
    (1.0 - 0.0)
    +
    0.0

 as petal_width_max_min_max_scaled,
    

    -- Log Transformation
    
        

    case
        when sepal_length is null or sepal_length + 0 <= 0 then null
        else log(10, sepal_length + 0)
    end

 as sepal_length_logged,
    
        

    case
        when sepal_width is null or sepal_width + 0 <= 0 then null
        else log(10, sepal_width + 0)
    end

 as sepal_width_logged,
    
        

    case
        when petal_length is null or petal_length + 0 <= 0 then null
        else log(10, petal_length + 0)
    end

 as petal_length_logged,
    
        

    case
        when petal_width is null or petal_width + 0 <= 0 then null
        else log(10, petal_width + 0)
    end

 as petal_width_logged,
    

    -- Binarization
    
        

    

    
        

        
    

    case
        when sepal_length >=
            
                5.8
            
            then 1
        else 0
    end

 as sepal_length_binarized,
    
        

    

    
        

        
    

    case
        when sepal_width >=
            
                3.0
            
            then 1
        else 0
    end

 as sepal_width_binarized,
    
        

    

    
        

        
    

    case
        when petal_length >=
            
                4.35
            
            then 1
        else 0
    end

 as petal_length_binarized,
    
        

    

    
        

        
    

    case
        when petal_width >=
            
                1.3
            
            then 1
        else 0
    end

 as petal_width_binarized,
    

    -- Standardization
    
        

    
    (
        (sepal_length - avg(sepal_length) over ())
        /
        (stddev(sepal_length) over ())::FLOAT
    )
    *
    1
    +
    0

 as sepal_length_standardized,
    
        

    
    (
        (sepal_width - avg(sepal_width) over ())
        /
        (stddev(sepal_width) over ())::FLOAT
    )
    *
    1
    +
    0

 as sepal_width_standardized,
    
        

    
    (
        (petal_length - avg(petal_length) over ())
        /
        (stddev(petal_length) over ())::FLOAT
    )
    *
    1
    +
    0

 as petal_length_standardized,
    
        

    
    (
        (petal_width - avg(petal_width) over ())
        /
        (stddev(petal_width) over ())::FLOAT
    )
    *
    1
    +
    0

 as petal_width_standardized,
    
-- Interactions
    
        
            
            
            

    
        (sepal_length * sepal_width)
    

 as sepal_length_x_sepal_width_interaction,
            

    
        (sepal_length + sepal_width)
    

 as sepal_length_plus_sepal_width_interaction,
        
            
            
            

    
        (sepal_length * petal_length)
    

 as sepal_length_x_petal_length_interaction,
            

    
        (sepal_length + petal_length)
    

 as sepal_length_plus_petal_length_interaction,
        
            
            
            

    
        (sepal_length * petal_width)
    

 as sepal_length_x_petal_width_interaction,
            

    
        (sepal_length + petal_width)
    

 as sepal_length_plus_petal_width_interaction,
        
    
        
            
            
            

    
        (sepal_width * petal_length)
    

 as sepal_width_x_petal_length_interaction,
            

    
        (sepal_width + petal_length)
    

 as sepal_width_plus_petal_length_interaction,
        
            
            
            

    
        (sepal_width * petal_width)
    

 as sepal_width_x_petal_width_interaction,
            

    
        (sepal_width + petal_width)
    

 as sepal_width_plus_petal_width_interaction,
        
    
        
            
            
            

    
        (petal_length * petal_width)
    

 as petal_length_x_petal_width_interaction,
            

    
        (petal_length + petal_width)
    

 as petal_length_plus_petal_width_interaction,
        
    
        
    
species,    
    -- Label Encoding
    

    dense_rank() over (order by species) - 1

 as species_label_encoded,
    -- One Hot Encoding
    

    

    
        
    

    

    

        case
            when species = 'setosa' then 1
            else 0
        end as is_species__setosa,

    

        case
            when species = 'versicolor' then 1
            else 0
        end as is_species__versicolor,

    

        case
            when species = 'virginica' then 1
            else 0
        end as is_species__virginica,

    

    case
        when species is null then 1
        else 0
    end as is_species__


from "analytics"."analytics"."stg_iris"
  );
  
[0m11:31:38.886362 [debug] [Thread-3  ]: SQL status: SELECT 150 in 0.037 seconds
[0m11:31:38.904160 [debug] [Thread-3  ]: Using postgres connection "model.homework.iris_processed"
[0m11:31:38.906256 [debug] [Thread-3  ]: On model.homework.iris_processed: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "homework", "target_name": "dev", "node_id": "model.homework.iris_processed"} */
alter table "analytics"."analytics"."iris_processed" rename to "iris_processed__dbt_backup"
[0m11:31:38.908774 [debug] [Thread-3  ]: SQL status: ALTER TABLE in 0.001 seconds
[0m11:31:38.919239 [debug] [Thread-3  ]: Using postgres connection "model.homework.iris_processed"
[0m11:31:38.920982 [debug] [Thread-3  ]: On model.homework.iris_processed: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "homework", "target_name": "dev", "node_id": "model.homework.iris_processed"} */
alter table "analytics"."analytics"."iris_processed__dbt_tmp" rename to "iris_processed"
[0m11:31:38.923075 [debug] [Thread-3  ]: SQL status: ALTER TABLE in 0.000 seconds
[0m11:31:38.927438 [debug] [Thread-3  ]: On model.homework.iris_processed: COMMIT
[0m11:31:38.930123 [debug] [Thread-3  ]: Using postgres connection "model.homework.iris_processed"
[0m11:31:38.931774 [debug] [Thread-3  ]: On model.homework.iris_processed: COMMIT
[0m11:31:38.937343 [debug] [Thread-3  ]: SQL status: COMMIT in 0.004 seconds
[0m11:31:38.946024 [debug] [Thread-3  ]: Applying DROP to: "analytics"."analytics"."iris_processed__dbt_backup"
[0m11:31:38.952495 [debug] [Thread-3  ]: Using postgres connection "model.homework.iris_processed"
[0m11:31:38.954355 [debug] [Thread-3  ]: On model.homework.iris_processed: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "homework", "target_name": "dev", "node_id": "model.homework.iris_processed"} */
drop table if exists "analytics"."analytics"."iris_processed__dbt_backup" cascade
[0m11:31:38.963091 [debug] [Thread-3  ]: SQL status: DROP TABLE in 0.007 seconds
[0m11:31:38.966631 [debug] [Thread-3  ]: On model.homework.iris_processed: Close
[0m11:31:38.968922 [debug] [Thread-3  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'd2233557-f473-4c45-952b-3952e47759a3', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7efd6c5fb640>]}
[0m11:31:38.971558 [info ] [Thread-3  ]: 2 of 2 OK created sql table model analytics.iris_processed ..................... [[32mSELECT 150[0m in 0.61s]
[0m11:31:38.973757 [debug] [Thread-3  ]: Finished running node model.homework.iris_processed
[0m11:31:38.978057 [debug] [MainThread]: Using postgres connection "master"
[0m11:31:38.980828 [debug] [MainThread]: On master: BEGIN
[0m11:31:38.982590 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m11:31:38.993868 [debug] [MainThread]: SQL status: BEGIN in 0.011 seconds
[0m11:31:38.997242 [debug] [MainThread]: On master: COMMIT
[0m11:31:38.999536 [debug] [MainThread]: Using postgres connection "master"
[0m11:31:39.001604 [debug] [MainThread]: On master: COMMIT
[0m11:31:39.004001 [debug] [MainThread]: SQL status: COMMIT in 0.000 seconds
[0m11:31:39.005906 [debug] [MainThread]: On master: Close
[0m11:31:39.007955 [debug] [MainThread]: Connection 'master' was properly closed.
[0m11:31:39.009832 [debug] [MainThread]: Connection 'model.homework.stg_iris' was properly closed.
[0m11:31:39.011904 [debug] [MainThread]: Connection 'model.homework.iris_processed' was properly closed.
[0m11:31:39.014320 [info ] [MainThread]: 
[0m11:31:39.016479 [info ] [MainThread]: Finished running 1 table model, 1 view model in 0 hours 0 minutes and 1.30 seconds (1.30s).
[0m11:31:39.020709 [debug] [MainThread]: Command end result
[0m11:31:39.116141 [debug] [MainThread]: Wrote artifact WritableManifest to /opt/airflow/dags/dbt/homework/target/manifest.json
[0m11:31:39.123639 [debug] [MainThread]: Wrote artifact SemanticManifest to /opt/airflow/dags/dbt/homework/target/semantic_manifest.json
[0m11:31:39.143657 [debug] [MainThread]: Wrote artifact RunExecutionResult to /opt/airflow/dags/dbt/homework/target/run_results.json
[0m11:31:39.145831 [info ] [MainThread]: 
[0m11:31:39.148153 [info ] [MainThread]: [32mCompleted successfully[0m
[0m11:31:39.150412 [info ] [MainThread]: 
[0m11:31:39.152339 [info ] [MainThread]: Done. PASS=2 WARN=0 ERROR=0 SKIP=0 TOTAL=2
[0m11:31:39.155457 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": true, "command_wall_clock_time": 4.370302, "process_in_blocks": "0", "process_kernel_time": 0.456724, "process_mem_max_rss": "115320", "process_out_blocks": "0", "process_user_time": 6.116139}
[0m11:31:39.157617 [debug] [MainThread]: Command `dbt run` succeeded at 11:31:39.157352 after 4.37 seconds
[0m11:31:39.159994 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7efd706f4b20>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7efd6c6b0460>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7efd6deebf10>]}
[0m11:31:39.162871 [debug] [MainThread]: Flushing usage events
[0m11:31:39.777991 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m11:31:47.338929 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f752ba14b20>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f752ab35640>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f752ab355e0>]}


============================== 11:31:47.355820 | 66b28c72-2fde-4cd4-ad76-8d467dc4e8bd ==============================
[0m11:31:47.355820 [info ] [MainThread]: Running with dbt=1.9.4
[0m11:31:47.358557 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'debug': 'False', 'profiles_dir': '/opt/airflow/dags/dbt', 'log_path': '/opt/airflow/dags/dbt/homework/logs', 'version_check': 'True', 'fail_fast': 'True', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'empty': 'None', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'static_parser': 'True', 'invocation_command': 'dbt --profile homework test --project-dir=/opt/airflow/dags/dbt/homework --vars {"is_test": false, "data_date": "2025-04-23"} --fail-fast', 'introspect': 'True', 'target_path': 'None', 'log_format': 'default', 'send_anonymous_usage_stats': 'True'}
[0m11:31:47.906575 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '66b28c72-2fde-4cd4-ad76-8d467dc4e8bd', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f75292b2a90>]}
[0m11:31:48.097906 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '66b28c72-2fde-4cd4-ad76-8d467dc4e8bd', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f7529277760>]}
[0m11:31:48.100854 [info ] [MainThread]: Registered adapter: postgres=1.9.0
[0m11:31:48.539333 [debug] [MainThread]: checksum: f5df654a850f4b74beb13fbe0c7d8863b5b1a20bd535c3ac287d70e390b64d41, vars: {'data_date': '2025-04-23', 'is_test': False}, profile: homework, target: , version: 1.9.4
[0m11:31:49.938375 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m11:31:49.940441 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m11:31:49.955737 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 1 unused configuration paths:
- seeds.homework.iris_dataset
[0m11:31:50.058552 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '66b28c72-2fde-4cd4-ad76-8d467dc4e8bd', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f7528e64130>]}
[0m11:31:50.537111 [debug] [MainThread]: Wrote artifact WritableManifest to /opt/airflow/dags/dbt/homework/target/manifest.json
[0m11:31:50.583798 [debug] [MainThread]: Wrote artifact SemanticManifest to /opt/airflow/dags/dbt/homework/target/semantic_manifest.json
[0m11:31:50.658796 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '66b28c72-2fde-4cd4-ad76-8d467dc4e8bd', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f7528d42970>]}
[0m11:31:50.662097 [info ] [MainThread]: Found 2 models, 1 source, 587 macros
[0m11:31:50.664454 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '66b28c72-2fde-4cd4-ad76-8d467dc4e8bd', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f752abc4ca0>]}
[0m11:31:50.668752 [warn ] [MainThread]: Nothing to do. Try checking your model configs and model specification args
[0m11:31:50.677496 [debug] [MainThread]: Command end result
[0m11:31:50.803456 [debug] [MainThread]: Wrote artifact WritableManifest to /opt/airflow/dags/dbt/homework/target/manifest.json
[0m11:31:50.816682 [debug] [MainThread]: Wrote artifact SemanticManifest to /opt/airflow/dags/dbt/homework/target/semantic_manifest.json
[0m11:31:50.837558 [debug] [MainThread]: Wrote artifact RunExecutionResult to /opt/airflow/dags/dbt/homework/target/run_results.json
[0m11:31:50.843090 [debug] [MainThread]: Resource report: {"command_name": "test", "command_success": true, "command_wall_clock_time": 3.734035, "process_in_blocks": "0", "process_kernel_time": 0.903544, "process_mem_max_rss": "104672", "process_out_blocks": "0", "process_user_time": 5.725721}
[0m11:31:50.846095 [debug] [MainThread]: Command `dbt test` succeeded at 11:31:50.845556 after 3.74 seconds
[0m11:31:50.849788 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f752ba14b20>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f752c712d30>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f75292d5760>]}
[0m11:31:50.852169 [debug] [MainThread]: Flushing usage events
[0m11:31:51.392184 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m11:34:45.327166 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3203d38ac0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3202e59490>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3202e59430>]}


============================== 11:34:45.339015 | 65235d4a-f690-4cb0-a5ec-0367011bc620 ==============================
[0m11:34:45.339015 [info ] [MainThread]: Running with dbt=1.9.4
[0m11:34:45.341072 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': '/opt/airflow/dags/dbt', 'version_check': 'True', 'debug': 'False', 'log_path': '/opt/airflow/dags/dbt/homework/logs', 'warn_error': 'None', 'fail_fast': 'False', 'use_colors': 'True', 'use_experimental_parser': 'False', 'empty': 'False', 'quiet': 'False', 'no_print': 'None', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'introspect': 'True', 'log_format': 'default', 'invocation_command': 'dbt --profile homework run --project-dir=/opt/airflow/dags/dbt/homework --vars {"is_test": false, "data_date": "2025-04-23"}', 'target_path': 'None', 'static_parser': 'True', 'send_anonymous_usage_stats': 'True'}
[0m11:34:45.761339 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '65235d4a-f690-4cb0-a5ec-0367011bc620', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3202efaf70>]}
[0m11:34:45.951586 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '65235d4a-f690-4cb0-a5ec-0367011bc620', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f32034f0520>]}
[0m11:34:45.954471 [info ] [MainThread]: Registered adapter: postgres=1.9.0
[0m11:34:46.293629 [debug] [MainThread]: checksum: f5df654a850f4b74beb13fbe0c7d8863b5b1a20bd535c3ac287d70e390b64d41, vars: {'data_date': '2025-04-23', 'is_test': False}, profile: homework, target: , version: 1.9.4
[0m11:34:47.964630 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m11:34:47.966266 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m11:34:47.981883 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 1 unused configuration paths:
- seeds.homework.iris_dataset
[0m11:34:48.069889 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '65235d4a-f690-4cb0-a5ec-0367011bc620', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3201185130>]}
[0m11:34:48.377643 [debug] [MainThread]: Wrote artifact WritableManifest to /opt/airflow/dags/dbt/homework/target/manifest.json
[0m11:34:48.396292 [debug] [MainThread]: Wrote artifact SemanticManifest to /opt/airflow/dags/dbt/homework/target/semantic_manifest.json
[0m11:34:48.428529 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '65235d4a-f690-4cb0-a5ec-0367011bc620', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3201125f10>]}
[0m11:34:48.430488 [info ] [MainThread]: Found 2 models, 1 source, 587 macros
[0m11:34:48.432056 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '65235d4a-f690-4cb0-a5ec-0367011bc620', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3202ebeb20>]}
[0m11:34:48.435856 [info ] [MainThread]: 
[0m11:34:48.437759 [info ] [MainThread]: Concurrency: 4 threads (target='dev')
[0m11:34:48.439268 [info ] [MainThread]: 
[0m11:34:48.441122 [debug] [MainThread]: Acquiring new postgres connection 'master'
[0m11:34:48.452493 [debug] [ThreadPool]: Acquiring new postgres connection 'list_analytics'
[0m11:34:48.530563 [debug] [ThreadPool]: Using postgres connection "list_analytics"
[0m11:34:48.532254 [debug] [ThreadPool]: On list_analytics: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "homework", "target_name": "dev", "connection_name": "list_analytics"} */

    select distinct nspname from pg_namespace
  
[0m11:34:48.533879 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m11:34:48.549906 [debug] [ThreadPool]: SQL status: SELECT 6 in 0.016 seconds
[0m11:34:48.553927 [debug] [ThreadPool]: On list_analytics: Close
[0m11:34:48.557764 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_analytics, now list_analytics_analytics)
[0m11:34:48.571879 [debug] [ThreadPool]: Using postgres connection "list_analytics_analytics"
[0m11:34:48.573947 [debug] [ThreadPool]: On list_analytics_analytics: BEGIN
[0m11:34:48.575776 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m11:34:48.589288 [debug] [ThreadPool]: SQL status: BEGIN in 0.013 seconds
[0m11:34:48.591573 [debug] [ThreadPool]: Using postgres connection "list_analytics_analytics"
[0m11:34:48.593881 [debug] [ThreadPool]: On list_analytics_analytics: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "homework", "target_name": "dev", "connection_name": "list_analytics_analytics"} */
select
      'analytics' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'analytics'
    union all
    select
      'analytics' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'analytics'
    union all
    select
      'analytics' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'analytics'
  
[0m11:34:48.600402 [debug] [ThreadPool]: SQL status: SELECT 3 in 0.004 seconds
[0m11:34:48.604249 [debug] [ThreadPool]: On list_analytics_analytics: ROLLBACK
[0m11:34:48.606109 [debug] [ThreadPool]: On list_analytics_analytics: Close
[0m11:34:48.618532 [debug] [MainThread]: Using postgres connection "master"
[0m11:34:48.621165 [debug] [MainThread]: On master: BEGIN
[0m11:34:48.623058 [debug] [MainThread]: Opening a new connection, currently in state init
[0m11:34:48.636455 [debug] [MainThread]: SQL status: BEGIN in 0.013 seconds
[0m11:34:48.639415 [debug] [MainThread]: Using postgres connection "master"
[0m11:34:48.642544 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "homework", "target_name": "dev", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select distinct
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v', 'm')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
[0m11:34:48.661072 [debug] [MainThread]: SQL status: SELECT 1 in 0.016 seconds
[0m11:34:48.664999 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '65235d4a-f690-4cb0-a5ec-0367011bc620', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f32006c8970>]}
[0m11:34:48.666926 [debug] [MainThread]: On master: ROLLBACK
[0m11:34:48.669545 [debug] [MainThread]: Using postgres connection "master"
[0m11:34:48.671926 [debug] [MainThread]: On master: BEGIN
[0m11:34:48.674285 [debug] [MainThread]: SQL status: BEGIN in 0.001 seconds
[0m11:34:48.676557 [debug] [MainThread]: On master: COMMIT
[0m11:34:48.678748 [debug] [MainThread]: Using postgres connection "master"
[0m11:34:48.681017 [debug] [MainThread]: On master: COMMIT
[0m11:34:48.683350 [debug] [MainThread]: SQL status: COMMIT in 0.000 seconds
[0m11:34:48.685692 [debug] [MainThread]: On master: Close
[0m11:34:48.694894 [debug] [Thread-1  ]: Began running node model.homework.stg_iris
[0m11:34:48.697040 [info ] [Thread-1  ]: 1 of 2 START sql view model analytics.stg_iris ................................. [RUN]
[0m11:34:48.699028 [debug] [Thread-1  ]: Re-using an available connection from the pool (formerly list_analytics_analytics, now model.homework.stg_iris)
[0m11:34:48.701013 [debug] [Thread-1  ]: Began compiling node model.homework.stg_iris
[0m11:34:48.728889 [debug] [Thread-1  ]: Writing injected SQL for node "model.homework.stg_iris"
[0m11:34:48.740302 [debug] [Thread-1  ]: Began executing node model.homework.stg_iris
[0m11:34:48.834998 [debug] [Thread-1  ]: Writing runtime sql for node "model.homework.stg_iris"
[0m11:34:48.845477 [debug] [Thread-1  ]: Using postgres connection "model.homework.stg_iris"
[0m11:34:48.847127 [debug] [Thread-1  ]: On model.homework.stg_iris: BEGIN
[0m11:34:48.849044 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
[0m11:34:48.870583 [debug] [Thread-1  ]: SQL status: BEGIN in 0.021 seconds
[0m11:34:48.874285 [debug] [Thread-1  ]: Using postgres connection "model.homework.stg_iris"
[0m11:34:48.877941 [debug] [Thread-1  ]: On model.homework.stg_iris: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "homework", "target_name": "dev", "node_id": "model.homework.stg_iris"} */

  create view "analytics"."analytics"."stg_iris__dbt_tmp"
    
    
  as (
    with source as (
    select * from "analytics"."analytics"."iris_dataset"
)

select
    cast(sepal_length as numeric) as sepal_length,
    cast(sepal_width as numeric) as sepal_width,
    cast(petal_length as numeric) as petal_length,
    cast(petal_width as numeric) as petal_width,
    species
from source
  );
[0m11:34:48.891329 [debug] [Thread-1  ]: SQL status: CREATE VIEW in 0.010 seconds
[0m11:34:48.935466 [debug] [Thread-1  ]: Using postgres connection "model.homework.stg_iris"
[0m11:34:48.941344 [debug] [Thread-1  ]: On model.homework.stg_iris: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "homework", "target_name": "dev", "node_id": "model.homework.stg_iris"} */
alter table "analytics"."analytics"."stg_iris" rename to "stg_iris__dbt_backup"
[0m11:34:48.957475 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.001 seconds
[0m11:34:48.980574 [debug] [Thread-1  ]: Using postgres connection "model.homework.stg_iris"
[0m11:34:48.987671 [debug] [Thread-1  ]: On model.homework.stg_iris: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "homework", "target_name": "dev", "node_id": "model.homework.stg_iris"} */
alter table "analytics"."analytics"."stg_iris__dbt_tmp" rename to "stg_iris"
[0m11:34:48.993511 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.001 seconds
[0m11:34:49.075427 [debug] [Thread-1  ]: On model.homework.stg_iris: COMMIT
[0m11:34:49.078069 [debug] [Thread-1  ]: Using postgres connection "model.homework.stg_iris"
[0m11:34:49.080795 [debug] [Thread-1  ]: On model.homework.stg_iris: COMMIT
[0m11:34:49.087682 [debug] [Thread-1  ]: SQL status: COMMIT in 0.004 seconds
[0m11:34:49.121372 [debug] [Thread-1  ]: Applying DROP to: "analytics"."analytics"."stg_iris__dbt_backup"
[0m11:34:49.140751 [debug] [Thread-1  ]: Using postgres connection "model.homework.stg_iris"
[0m11:34:49.142681 [debug] [Thread-1  ]: On model.homework.stg_iris: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "homework", "target_name": "dev", "node_id": "model.homework.stg_iris"} */
drop view if exists "analytics"."analytics"."stg_iris__dbt_backup" cascade
[0m11:34:49.148899 [debug] [Thread-1  ]: SQL status: DROP VIEW in 0.004 seconds
[0m11:34:49.156922 [debug] [Thread-1  ]: On model.homework.stg_iris: Close
[0m11:34:49.162723 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '65235d4a-f690-4cb0-a5ec-0367011bc620', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3200643070>]}
[0m11:34:49.165328 [info ] [Thread-1  ]: 1 of 2 OK created sql view model analytics.stg_iris ............................ [[32mCREATE VIEW[0m in 0.46s]
[0m11:34:49.167495 [debug] [Thread-1  ]: Finished running node model.homework.stg_iris
[0m11:34:49.171081 [debug] [Thread-3  ]: Began running node model.homework.iris_processed
[0m11:34:49.173400 [info ] [Thread-3  ]: 2 of 2 START sql table model analytics.iris_processed .......................... [RUN]
[0m11:34:49.176189 [debug] [Thread-3  ]: Acquiring new postgres connection 'model.homework.iris_processed'
[0m11:34:49.178379 [debug] [Thread-3  ]: Began compiling node model.homework.iris_processed
[0m11:34:49.295844 [debug] [Thread-3  ]: Using postgres connection "model.homework.iris_processed"
[0m11:34:49.300137 [debug] [Thread-3  ]: On model.homework.iris_processed: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "homework", "target_name": "dev", "node_id": "model.homework.iris_processed"} */

        select percentile_cont(0.5) within group (order by sepal_length ) from "analytics"."analytics"."stg_iris"
    
[0m11:34:49.305090 [debug] [Thread-3  ]: Opening a new connection, currently in state init
[0m11:34:49.327251 [debug] [Thread-3  ]: SQL status: SELECT 1 in 0.023 seconds
[0m11:34:49.331844 [debug] [Thread-3  ]: Using postgres connection "model.homework.iris_processed"
[0m11:34:49.334071 [debug] [Thread-3  ]: On model.homework.iris_processed: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "homework", "target_name": "dev", "node_id": "model.homework.iris_processed"} */

        select percentile_cont(0.5 - 0.5/2) within group (order by sepal_length ) from "analytics"."analytics"."stg_iris"
    
[0m11:34:49.338311 [debug] [Thread-3  ]: SQL status: SELECT 1 in 0.001 seconds
[0m11:34:49.344025 [debug] [Thread-3  ]: Using postgres connection "model.homework.iris_processed"
[0m11:34:49.346524 [debug] [Thread-3  ]: On model.homework.iris_processed: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "homework", "target_name": "dev", "node_id": "model.homework.iris_processed"} */

        select percentile_cont(0.5 + 0.5/2) within group (order by sepal_length ) from "analytics"."analytics"."stg_iris"
    
[0m11:34:49.350466 [debug] [Thread-3  ]: SQL status: SELECT 1 in 0.001 seconds
[0m11:34:49.376251 [debug] [Thread-3  ]: Using postgres connection "model.homework.iris_processed"
[0m11:34:49.378367 [debug] [Thread-3  ]: On model.homework.iris_processed: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "homework", "target_name": "dev", "node_id": "model.homework.iris_processed"} */

        select percentile_cont(0.5) within group (order by sepal_width ) from "analytics"."analytics"."stg_iris"
    
[0m11:34:49.381971 [debug] [Thread-3  ]: SQL status: SELECT 1 in 0.001 seconds
[0m11:34:49.388391 [debug] [Thread-3  ]: Using postgres connection "model.homework.iris_processed"
[0m11:34:49.391009 [debug] [Thread-3  ]: On model.homework.iris_processed: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "homework", "target_name": "dev", "node_id": "model.homework.iris_processed"} */

        select percentile_cont(0.5 - 0.5/2) within group (order by sepal_width ) from "analytics"."analytics"."stg_iris"
    
[0m11:34:49.394386 [debug] [Thread-3  ]: SQL status: SELECT 1 in 0.001 seconds
[0m11:34:49.409186 [debug] [Thread-3  ]: Using postgres connection "model.homework.iris_processed"
[0m11:34:49.412345 [debug] [Thread-3  ]: On model.homework.iris_processed: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "homework", "target_name": "dev", "node_id": "model.homework.iris_processed"} */

        select percentile_cont(0.5 + 0.5/2) within group (order by sepal_width ) from "analytics"."analytics"."stg_iris"
    
[0m11:34:49.416818 [debug] [Thread-3  ]: SQL status: SELECT 1 in 0.001 seconds
[0m11:34:49.424646 [debug] [Thread-3  ]: Using postgres connection "model.homework.iris_processed"
[0m11:34:49.426652 [debug] [Thread-3  ]: On model.homework.iris_processed: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "homework", "target_name": "dev", "node_id": "model.homework.iris_processed"} */

        select percentile_cont(0.5) within group (order by petal_length ) from "analytics"."analytics"."stg_iris"
    
[0m11:34:49.429654 [debug] [Thread-3  ]: SQL status: SELECT 1 in 0.001 seconds
[0m11:34:49.434357 [debug] [Thread-3  ]: Using postgres connection "model.homework.iris_processed"
[0m11:34:49.436951 [debug] [Thread-3  ]: On model.homework.iris_processed: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "homework", "target_name": "dev", "node_id": "model.homework.iris_processed"} */

        select percentile_cont(0.5 - 0.5/2) within group (order by petal_length ) from "analytics"."analytics"."stg_iris"
    
[0m11:34:49.440183 [debug] [Thread-3  ]: SQL status: SELECT 1 in 0.001 seconds
[0m11:34:49.444169 [debug] [Thread-3  ]: Using postgres connection "model.homework.iris_processed"
[0m11:34:49.445771 [debug] [Thread-3  ]: On model.homework.iris_processed: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "homework", "target_name": "dev", "node_id": "model.homework.iris_processed"} */

        select percentile_cont(0.5 + 0.5/2) within group (order by petal_length ) from "analytics"."analytics"."stg_iris"
    
[0m11:34:49.447969 [debug] [Thread-3  ]: SQL status: SELECT 1 in 0.001 seconds
[0m11:34:49.453956 [debug] [Thread-3  ]: Using postgres connection "model.homework.iris_processed"
[0m11:34:49.455678 [debug] [Thread-3  ]: On model.homework.iris_processed: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "homework", "target_name": "dev", "node_id": "model.homework.iris_processed"} */

        select percentile_cont(0.5) within group (order by petal_width ) from "analytics"."analytics"."stg_iris"
    
[0m11:34:49.458183 [debug] [Thread-3  ]: SQL status: SELECT 1 in 0.001 seconds
[0m11:34:49.462114 [debug] [Thread-3  ]: Using postgres connection "model.homework.iris_processed"
[0m11:34:49.463726 [debug] [Thread-3  ]: On model.homework.iris_processed: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "homework", "target_name": "dev", "node_id": "model.homework.iris_processed"} */

        select percentile_cont(0.5 - 0.5/2) within group (order by petal_width ) from "analytics"."analytics"."stg_iris"
    
[0m11:34:49.465928 [debug] [Thread-3  ]: SQL status: SELECT 1 in 0.001 seconds
[0m11:34:49.470061 [debug] [Thread-3  ]: Using postgres connection "model.homework.iris_processed"
[0m11:34:49.471843 [debug] [Thread-3  ]: On model.homework.iris_processed: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "homework", "target_name": "dev", "node_id": "model.homework.iris_processed"} */

        select percentile_cont(0.5 + 0.5/2) within group (order by petal_width ) from "analytics"."analytics"."stg_iris"
    
[0m11:34:49.474063 [debug] [Thread-3  ]: SQL status: SELECT 1 in 0.001 seconds
[0m11:34:49.499462 [debug] [Thread-3  ]: Using postgres connection "model.homework.iris_processed"
[0m11:34:49.501236 [debug] [Thread-3  ]: On model.homework.iris_processed: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "homework", "target_name": "dev", "node_id": "model.homework.iris_processed"} */

            select percentile_cont(0.5) within group (order by sepal_length ) from "analytics"."analytics"."stg_iris"
        
[0m11:34:49.504017 [debug] [Thread-3  ]: SQL status: SELECT 1 in 0.001 seconds
[0m11:34:49.508665 [debug] [Thread-3  ]: Using postgres connection "model.homework.iris_processed"
[0m11:34:49.510255 [debug] [Thread-3  ]: On model.homework.iris_processed: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "homework", "target_name": "dev", "node_id": "model.homework.iris_processed"} */

            select percentile_cont(0.5) within group (order by sepal_width ) from "analytics"."analytics"."stg_iris"
        
[0m11:34:49.512647 [debug] [Thread-3  ]: SQL status: SELECT 1 in 0.001 seconds
[0m11:34:49.517095 [debug] [Thread-3  ]: Using postgres connection "model.homework.iris_processed"
[0m11:34:49.519055 [debug] [Thread-3  ]: On model.homework.iris_processed: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "homework", "target_name": "dev", "node_id": "model.homework.iris_processed"} */

            select percentile_cont(0.5) within group (order by petal_length ) from "analytics"."analytics"."stg_iris"
        
[0m11:34:49.522004 [debug] [Thread-3  ]: SQL status: SELECT 1 in 0.001 seconds
[0m11:34:49.526431 [debug] [Thread-3  ]: Using postgres connection "model.homework.iris_processed"
[0m11:34:49.528035 [debug] [Thread-3  ]: On model.homework.iris_processed: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "homework", "target_name": "dev", "node_id": "model.homework.iris_processed"} */

            select percentile_cont(0.5) within group (order by petal_width ) from "analytics"."analytics"."stg_iris"
        
[0m11:34:49.530425 [debug] [Thread-3  ]: SQL status: SELECT 1 in 0.001 seconds
[0m11:34:49.609217 [debug] [Thread-3  ]: Using postgres connection "model.homework.iris_processed"
[0m11:34:49.611191 [debug] [Thread-3  ]: On model.homework.iris_processed: BEGIN
[0m11:34:49.613635 [debug] [Thread-3  ]: SQL status: BEGIN in 0.000 seconds
[0m11:34:49.616108 [debug] [Thread-3  ]: Using postgres connection "model.homework.iris_processed"
[0m11:34:49.618396 [debug] [Thread-3  ]: On model.homework.iris_processed: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "homework", "target_name": "dev", "node_id": "model.homework.iris_processed"} */
select
                species as value

            from "analytics"."analytics"."stg_iris"

            
            where species is not null  and true
            

            group by species
            order by species

            

        
[0m11:34:49.622684 [debug] [Thread-3  ]: SQL status: SELECT 3 in 0.001 seconds
[0m11:34:49.640535 [debug] [Thread-3  ]: Writing injected SQL for node "model.homework.iris_processed"
[0m11:34:49.650765 [debug] [Thread-3  ]: Began executing node model.homework.iris_processed
[0m11:34:49.707521 [debug] [Thread-3  ]: Writing runtime sql for node "model.homework.iris_processed"
[0m11:34:49.717615 [debug] [Thread-3  ]: Using postgres connection "model.homework.iris_processed"
[0m11:34:49.721108 [debug] [Thread-3  ]: On model.homework.iris_processed: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "homework", "target_name": "dev", "node_id": "model.homework.iris_processed"} */

  
    

  create  table "analytics"."analytics"."iris_processed__dbt_tmp"
  
  
    as
  
  (
    

with import_iris as (
    select *
    from "analytics"."analytics"."stg_iris"
)
select
    sepal_length,
    sepal_width,
    petal_length,
    petal_width,
    -- K Bins Discretization
    
        

    
        NTILE(5) over (order by sepal_length)
    

 as sepal_length_quantile_bin,
        

    
        
        floor(
        (
            sepal_length - (min(sepal_length) over ())
        )
        /
        (
            ((max(sepal_length) over ()) - (min(sepal_length) over ())) / 4::float
        )
        ) + 1
    

 as sepal_length_uniform_bin,
    
        

    
        NTILE(5) over (order by sepal_width)
    

 as sepal_width_quantile_bin,
        

    
        
        floor(
        (
            sepal_width - (min(sepal_width) over ())
        )
        /
        (
            ((max(sepal_width) over ()) - (min(sepal_width) over ())) / 4::float
        )
        ) + 1
    

 as sepal_width_uniform_bin,
    
        

    
        NTILE(5) over (order by petal_length)
    

 as petal_length_quantile_bin,
        

    
        
        floor(
        (
            petal_length - (min(petal_length) over ())
        )
        /
        (
            ((max(petal_length) over ()) - (min(petal_length) over ())) / 4::float
        )
        ) + 1
    

 as petal_length_uniform_bin,
    
        

    
        NTILE(5) over (order by petal_width)
    

 as petal_width_quantile_bin,
        

    
        
        floor(
        (
            petal_width - (min(petal_width) over ())
        )
        /
        (
            ((max(petal_width) over ()) - (min(petal_width) over ())) / 4::float
        )
        ) + 1
    

 as petal_width_uniform_bin,
    
-- Scaling
    
        

    

    
    
    

    
    
    

    (
        sepal_length - 5.8
    )
    /
    (
        6.4 - 5.1
    )

 as sepal_length_robust_scaled,
        

    (sepal_length) / (max(abs(sepal_length)) over ())::FLOAT

 as sepal_length_max_absolute_scaled,
        

    
    (
        ((sepal_length) - (min(sepal_length) over ()))
        /
        ((max(sepal_length) over ()) - (min(sepal_length) over ()))::FLOAT
    )
    *
    (1.0 - 0.0)
    +
    0.0

 as sepal_length_max_min_max_scaled,
    
        

    

    
    
    

    
    
    

    (
        sepal_width - 3.0
    )
    /
    (
        3.3 - 2.8
    )

 as sepal_width_robust_scaled,
        

    (sepal_width) / (max(abs(sepal_width)) over ())::FLOAT

 as sepal_width_max_absolute_scaled,
        

    
    (
        ((sepal_width) - (min(sepal_width) over ()))
        /
        ((max(sepal_width) over ()) - (min(sepal_width) over ()))::FLOAT
    )
    *
    (1.0 - 0.0)
    +
    0.0

 as sepal_width_max_min_max_scaled,
    
        

    

    
    
    

    
    
    

    (
        petal_length - 4.35
    )
    /
    (
        5.1 - 1.6
    )

 as petal_length_robust_scaled,
        

    (petal_length) / (max(abs(petal_length)) over ())::FLOAT

 as petal_length_max_absolute_scaled,
        

    
    (
        ((petal_length) - (min(petal_length) over ()))
        /
        ((max(petal_length) over ()) - (min(petal_length) over ()))::FLOAT
    )
    *
    (1.0 - 0.0)
    +
    0.0

 as petal_length_max_min_max_scaled,
    
        

    

    
    
    

    
    
    

    (
        petal_width - 1.3
    )
    /
    (
        1.8 - 0.3
    )

 as petal_width_robust_scaled,
        

    (petal_width) / (max(abs(petal_width)) over ())::FLOAT

 as petal_width_max_absolute_scaled,
        

    
    (
        ((petal_width) - (min(petal_width) over ()))
        /
        ((max(petal_width) over ()) - (min(petal_width) over ()))::FLOAT
    )
    *
    (1.0 - 0.0)
    +
    0.0

 as petal_width_max_min_max_scaled,
    

    -- Log Transformation
    
        

    case
        when sepal_length is null or sepal_length + 0 <= 0 then null
        else log(10, sepal_length + 0)
    end

 as sepal_length_logged,
    
        

    case
        when sepal_width is null or sepal_width + 0 <= 0 then null
        else log(10, sepal_width + 0)
    end

 as sepal_width_logged,
    
        

    case
        when petal_length is null or petal_length + 0 <= 0 then null
        else log(10, petal_length + 0)
    end

 as petal_length_logged,
    
        

    case
        when petal_width is null or petal_width + 0 <= 0 then null
        else log(10, petal_width + 0)
    end

 as petal_width_logged,
    

    -- Binarization
    
        

    

    
        

        
    

    case
        when sepal_length >=
            
                5.8
            
            then 1
        else 0
    end

 as sepal_length_binarized,
    
        

    

    
        

        
    

    case
        when sepal_width >=
            
                3.0
            
            then 1
        else 0
    end

 as sepal_width_binarized,
    
        

    

    
        

        
    

    case
        when petal_length >=
            
                4.35
            
            then 1
        else 0
    end

 as petal_length_binarized,
    
        

    

    
        

        
    

    case
        when petal_width >=
            
                1.3
            
            then 1
        else 0
    end

 as petal_width_binarized,
    

    -- Standardization
    
        

    
    (
        (sepal_length - avg(sepal_length) over ())
        /
        (stddev(sepal_length) over ())::FLOAT
    )
    *
    1
    +
    0

 as sepal_length_standardized,
    
        

    
    (
        (sepal_width - avg(sepal_width) over ())
        /
        (stddev(sepal_width) over ())::FLOAT
    )
    *
    1
    +
    0

 as sepal_width_standardized,
    
        

    
    (
        (petal_length - avg(petal_length) over ())
        /
        (stddev(petal_length) over ())::FLOAT
    )
    *
    1
    +
    0

 as petal_length_standardized,
    
        

    
    (
        (petal_width - avg(petal_width) over ())
        /
        (stddev(petal_width) over ())::FLOAT
    )
    *
    1
    +
    0

 as petal_width_standardized,
    
-- Interactions
    
        
            
            
            

    
        (sepal_length * sepal_width)
    

 as sepal_length_x_sepal_width_interaction,
            

    
        (sepal_length + sepal_width)
    

 as sepal_length_plus_sepal_width_interaction,
        
            
            
            

    
        (sepal_length * petal_length)
    

 as sepal_length_x_petal_length_interaction,
            

    
        (sepal_length + petal_length)
    

 as sepal_length_plus_petal_length_interaction,
        
            
            
            

    
        (sepal_length * petal_width)
    

 as sepal_length_x_petal_width_interaction,
            

    
        (sepal_length + petal_width)
    

 as sepal_length_plus_petal_width_interaction,
        
    
        
            
            
            

    
        (sepal_width * petal_length)
    

 as sepal_width_x_petal_length_interaction,
            

    
        (sepal_width + petal_length)
    

 as sepal_width_plus_petal_length_interaction,
        
            
            
            

    
        (sepal_width * petal_width)
    

 as sepal_width_x_petal_width_interaction,
            

    
        (sepal_width + petal_width)
    

 as sepal_width_plus_petal_width_interaction,
        
    
        
            
            
            

    
        (petal_length * petal_width)
    

 as petal_length_x_petal_width_interaction,
            

    
        (petal_length + petal_width)
    

 as petal_length_plus_petal_width_interaction,
        
    
        
    
species,    
    -- Label Encoding
    

    dense_rank() over (order by species) - 1

 as species_label_encoded,
    -- One Hot Encoding
    

    

    
        
    

    

    

        case
            when species = 'setosa' then 1
            else 0
        end as is_species__setosa,

    

        case
            when species = 'versicolor' then 1
            else 0
        end as is_species__versicolor,

    

        case
            when species = 'virginica' then 1
            else 0
        end as is_species__virginica,

    

    case
        when species is null then 1
        else 0
    end as is_species__


from "analytics"."analytics"."stg_iris"
  );
  
[0m11:34:49.765380 [debug] [Thread-3  ]: SQL status: SELECT 150 in 0.041 seconds
[0m11:34:49.781659 [debug] [Thread-3  ]: Using postgres connection "model.homework.iris_processed"
[0m11:34:49.783371 [debug] [Thread-3  ]: On model.homework.iris_processed: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "homework", "target_name": "dev", "node_id": "model.homework.iris_processed"} */
alter table "analytics"."analytics"."iris_processed" rename to "iris_processed__dbt_backup"
[0m11:34:49.786134 [debug] [Thread-3  ]: SQL status: ALTER TABLE in 0.001 seconds
[0m11:34:49.795630 [debug] [Thread-3  ]: Using postgres connection "model.homework.iris_processed"
[0m11:34:49.797601 [debug] [Thread-3  ]: On model.homework.iris_processed: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "homework", "target_name": "dev", "node_id": "model.homework.iris_processed"} */
alter table "analytics"."analytics"."iris_processed__dbt_tmp" rename to "iris_processed"
[0m11:34:49.800127 [debug] [Thread-3  ]: SQL status: ALTER TABLE in 0.001 seconds
[0m11:34:49.807403 [debug] [Thread-3  ]: On model.homework.iris_processed: COMMIT
[0m11:34:49.809457 [debug] [Thread-3  ]: Using postgres connection "model.homework.iris_processed"
[0m11:34:49.811656 [debug] [Thread-3  ]: On model.homework.iris_processed: COMMIT
[0m11:34:49.817744 [debug] [Thread-3  ]: SQL status: COMMIT in 0.004 seconds
[0m11:34:49.827000 [debug] [Thread-3  ]: Applying DROP to: "analytics"."analytics"."iris_processed__dbt_backup"
[0m11:34:49.834215 [debug] [Thread-3  ]: Using postgres connection "model.homework.iris_processed"
[0m11:34:49.836638 [debug] [Thread-3  ]: On model.homework.iris_processed: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "homework", "target_name": "dev", "node_id": "model.homework.iris_processed"} */
drop table if exists "analytics"."analytics"."iris_processed__dbt_backup" cascade
[0m11:34:49.846213 [debug] [Thread-3  ]: SQL status: DROP TABLE in 0.007 seconds
[0m11:34:49.850449 [debug] [Thread-3  ]: On model.homework.iris_processed: Close
[0m11:34:49.853674 [debug] [Thread-3  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '65235d4a-f690-4cb0-a5ec-0367011bc620', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3200440610>]}
[0m11:34:49.857123 [info ] [Thread-3  ]: 2 of 2 OK created sql table model analytics.iris_processed ..................... [[32mSELECT 150[0m in 0.68s]
[0m11:34:49.859990 [debug] [Thread-3  ]: Finished running node model.homework.iris_processed
[0m11:34:49.864312 [debug] [MainThread]: Using postgres connection "master"
[0m11:34:49.866373 [debug] [MainThread]: On master: BEGIN
[0m11:34:49.868103 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m11:34:49.880591 [debug] [MainThread]: SQL status: BEGIN in 0.012 seconds
[0m11:34:49.883167 [debug] [MainThread]: On master: COMMIT
[0m11:34:49.885416 [debug] [MainThread]: Using postgres connection "master"
[0m11:34:49.888228 [debug] [MainThread]: On master: COMMIT
[0m11:34:49.890473 [debug] [MainThread]: SQL status: COMMIT in 0.000 seconds
[0m11:34:49.891990 [debug] [MainThread]: On master: Close
[0m11:34:49.893698 [debug] [MainThread]: Connection 'master' was properly closed.
[0m11:34:49.895243 [debug] [MainThread]: Connection 'model.homework.stg_iris' was properly closed.
[0m11:34:49.897158 [debug] [MainThread]: Connection 'model.homework.iris_processed' was properly closed.
[0m11:34:49.899297 [info ] [MainThread]: 
[0m11:34:49.901447 [info ] [MainThread]: Finished running 1 table model, 1 view model in 0 hours 0 minutes and 1.46 seconds (1.46s).
[0m11:34:49.906673 [debug] [MainThread]: Command end result
[0m11:34:49.999760 [debug] [MainThread]: Wrote artifact WritableManifest to /opt/airflow/dags/dbt/homework/target/manifest.json
[0m11:34:50.007343 [debug] [MainThread]: Wrote artifact SemanticManifest to /opt/airflow/dags/dbt/homework/target/semantic_manifest.json
[0m11:34:50.026838 [debug] [MainThread]: Wrote artifact RunExecutionResult to /opt/airflow/dags/dbt/homework/target/run_results.json
[0m11:34:50.028577 [info ] [MainThread]: 
[0m11:34:50.030203 [info ] [MainThread]: [32mCompleted successfully[0m
[0m11:34:50.031663 [info ] [MainThread]: 
[0m11:34:50.033306 [info ] [MainThread]: Done. PASS=2 WARN=0 ERROR=0 SKIP=0 TOTAL=2
[0m11:34:50.036230 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": true, "command_wall_clock_time": 4.8503532, "process_in_blocks": "0", "process_kernel_time": 0.387582, "process_mem_max_rss": "114896", "process_out_blocks": "0", "process_user_time": 6.823487}
[0m11:34:50.038646 [debug] [MainThread]: Command `dbt run` succeeded at 11:34:50.038415 after 4.85 seconds
[0m11:34:50.040303 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3203d38ac0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3204a95c70>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3204b99e50>]}
[0m11:34:50.041954 [debug] [MainThread]: Flushing usage events
[0m11:34:50.634831 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m11:34:57.571219 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb62f0b2af0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb62e1d3520>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb62e1d34c0>]}


============================== 11:34:57.583272 | 940a45b8-ce2f-45dc-90ec-3c4222cf6540 ==============================
[0m11:34:57.583272 [info ] [MainThread]: Running with dbt=1.9.4
[0m11:34:57.585417 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'version_check': 'True', 'debug': 'False', 'log_path': '/opt/airflow/dags/dbt/homework/logs', 'profiles_dir': '/opt/airflow/dags/dbt', 'fail_fast': 'True', 'use_colors': 'True', 'use_experimental_parser': 'False', 'empty': 'None', 'quiet': 'False', 'no_print': 'None', 'log_format': 'default', 'invocation_command': 'dbt --profile homework test --project-dir=/opt/airflow/dags/dbt/homework --vars {"is_test": false, "data_date": "2025-04-23"} --fail-fast', 'introspect': 'True', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'target_path': 'None', 'static_parser': 'True', 'send_anonymous_usage_stats': 'True'}
[0m11:34:58.017869 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '940a45b8-ce2f-45dc-90ec-3c4222cf6540', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb630a99c70>]}
[0m11:34:58.188938 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '940a45b8-ce2f-45dc-90ec-3c4222cf6540', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb62c914520>]}
[0m11:34:58.192491 [info ] [MainThread]: Registered adapter: postgres=1.9.0
[0m11:34:58.502750 [debug] [MainThread]: checksum: f5df654a850f4b74beb13fbe0c7d8863b5b1a20bd535c3ac287d70e390b64d41, vars: {'data_date': '2025-04-23', 'is_test': False}, profile: homework, target: , version: 1.9.4
[0m11:35:00.255786 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m11:35:00.257077 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m11:35:00.270786 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 1 unused configuration paths:
- seeds.homework.iris_dataset
[0m11:35:00.365637 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '940a45b8-ce2f-45dc-90ec-3c4222cf6540', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb62c503130>]}
[0m11:35:00.725078 [debug] [MainThread]: Wrote artifact WritableManifest to /opt/airflow/dags/dbt/homework/target/manifest.json
[0m11:35:00.742746 [debug] [MainThread]: Wrote artifact SemanticManifest to /opt/airflow/dags/dbt/homework/target/semantic_manifest.json
[0m11:35:00.788404 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '940a45b8-ce2f-45dc-90ec-3c4222cf6540', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb62c3e0580>]}
[0m11:35:00.790260 [info ] [MainThread]: Found 2 models, 1 source, 587 macros
[0m11:35:00.791759 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '940a45b8-ce2f-45dc-90ec-3c4222cf6540', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb62c447a30>]}
[0m11:35:00.795339 [warn ] [MainThread]: Nothing to do. Try checking your model configs and model specification args
[0m11:35:00.800298 [debug] [MainThread]: Command end result
[0m11:35:00.900147 [debug] [MainThread]: Wrote artifact WritableManifest to /opt/airflow/dags/dbt/homework/target/manifest.json
[0m11:35:00.909040 [debug] [MainThread]: Wrote artifact SemanticManifest to /opt/airflow/dags/dbt/homework/target/semantic_manifest.json
[0m11:35:00.920802 [debug] [MainThread]: Wrote artifact RunExecutionResult to /opt/airflow/dags/dbt/homework/target/run_results.json
[0m11:35:00.923402 [debug] [MainThread]: Resource report: {"command_name": "test", "command_success": true, "command_wall_clock_time": 3.4936252, "process_in_blocks": "0", "process_kernel_time": 0.411517, "process_mem_max_rss": "104588", "process_out_blocks": "0", "process_user_time": 5.038576}
[0m11:35:00.925163 [debug] [MainThread]: Command `dbt test` succeeded at 11:35:00.924966 after 3.50 seconds
[0m11:35:00.926779 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb62f0b2af0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb62ef7c6d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb62c9a6130>]}
[0m11:35:00.929222 [debug] [MainThread]: Flushing usage events
[0m11:35:01.464388 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m11:48:36.181235 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f40ccef9b80>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f40cc01b4c0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f40cc01b460>]}


============================== 11:48:36.194832 | afaf7fbc-656e-40b9-bf7b-77d9db0b0238 ==============================
[0m11:48:36.194832 [info ] [MainThread]: Running with dbt=1.9.4
[0m11:48:36.197003 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': '/opt/airflow/dags/dbt', 'fail_fast': 'False', 'version_check': 'True', 'log_path': '/opt/airflow/dags/dbt/homework/logs', 'debug': 'False', 'warn_error': 'None', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'empty': 'False', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'static_parser': 'True', 'log_format': 'default', 'invocation_command': 'dbt --profile homework run --project-dir=/opt/airflow/dags/dbt/homework --vars {"is_test": false, "data_date": "2025-04-22"}', 'target_path': 'None', 'introspect': 'True', 'send_anonymous_usage_stats': 'True'}
[0m11:48:36.708824 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'afaf7fbc-656e-40b9-bf7b-77d9db0b0238', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f40cc0aa8b0>]}
[0m11:48:36.847759 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': 'afaf7fbc-656e-40b9-bf7b-77d9db0b0238', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f40cc0bc310>]}
[0m11:48:36.851496 [info ] [MainThread]: Registered adapter: postgres=1.9.0
[0m11:48:37.167491 [debug] [MainThread]: checksum: b4b46bb6a239f66694dfdd44ef1792882cb61f2fd7b1ea66b3c7a170d2bb602d, vars: {'data_date': '2025-04-22', 'is_test': False}, profile: homework, target: , version: 1.9.4
[0m11:48:37.459728 [info ] [MainThread]: Unable to do partial parsing because config vars, config profile, or config target have changed
[0m11:48:37.461397 [debug] [MainThread]: previous checksum: b4b46bb6a239f66694dfdd44ef1792882cb61f2fd7b1ea66b3c7a170d2bb602d, current checksum: f5df654a850f4b74beb13fbe0c7d8863b5b1a20bd535c3ac287d70e390b64d41
[0m11:48:37.463085 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'partial_parser', 'label': 'afaf7fbc-656e-40b9-bf7b-77d9db0b0238', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f40ccc89220>]}
[0m11:48:42.876235 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 1 unused configuration paths:
- seeds.homework.iris_dataset
[0m11:48:42.911962 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'afaf7fbc-656e-40b9-bf7b-77d9db0b0238', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f40ca4c9dc0>]}
[0m11:48:43.173915 [debug] [MainThread]: Wrote artifact WritableManifest to /opt/airflow/dags/dbt/homework/target/manifest.json
[0m11:48:43.196440 [debug] [MainThread]: Wrote artifact SemanticManifest to /opt/airflow/dags/dbt/homework/target/semantic_manifest.json
[0m11:48:43.243321 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'afaf7fbc-656e-40b9-bf7b-77d9db0b0238', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f40ca4ae280>]}
[0m11:48:43.245602 [info ] [MainThread]: Found 2 models, 1 source, 587 macros
[0m11:48:43.247407 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'afaf7fbc-656e-40b9-bf7b-77d9db0b0238', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f40ca4ae520>]}
[0m11:48:43.250611 [info ] [MainThread]: 
[0m11:48:43.252355 [info ] [MainThread]: Concurrency: 4 threads (target='dev')
[0m11:48:43.254023 [info ] [MainThread]: 
[0m11:48:43.256141 [debug] [MainThread]: Acquiring new postgres connection 'master'
[0m11:48:43.266342 [debug] [ThreadPool]: Acquiring new postgres connection 'list_analytics'
[0m11:48:43.355450 [debug] [ThreadPool]: Using postgres connection "list_analytics"
[0m11:48:43.358363 [debug] [ThreadPool]: On list_analytics: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "homework", "target_name": "dev", "connection_name": "list_analytics"} */

    select distinct nspname from pg_namespace
  
[0m11:48:43.360311 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m11:48:43.381508 [debug] [ThreadPool]: SQL status: SELECT 7 in 0.021 seconds
[0m11:48:43.385956 [debug] [ThreadPool]: On list_analytics: Close
[0m11:48:43.391192 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_analytics, now list_analytics_analytics)
[0m11:48:43.413968 [debug] [ThreadPool]: Using postgres connection "list_analytics_analytics"
[0m11:48:43.415998 [debug] [ThreadPool]: On list_analytics_analytics: BEGIN
[0m11:48:43.417854 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m11:48:43.436417 [debug] [ThreadPool]: SQL status: BEGIN in 0.018 seconds
[0m11:48:43.439561 [debug] [ThreadPool]: Using postgres connection "list_analytics_analytics"
[0m11:48:43.442810 [debug] [ThreadPool]: On list_analytics_analytics: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "homework", "target_name": "dev", "connection_name": "list_analytics_analytics"} */
select
      'analytics' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'analytics'
    union all
    select
      'analytics' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'analytics'
    union all
    select
      'analytics' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'analytics'
  
[0m11:48:43.453158 [debug] [ThreadPool]: SQL status: SELECT 3 in 0.008 seconds
[0m11:48:43.457050 [debug] [ThreadPool]: On list_analytics_analytics: ROLLBACK
[0m11:48:43.459538 [debug] [ThreadPool]: On list_analytics_analytics: Close
[0m11:48:43.472822 [debug] [MainThread]: Using postgres connection "master"
[0m11:48:43.479661 [debug] [MainThread]: On master: BEGIN
[0m11:48:43.483711 [debug] [MainThread]: Opening a new connection, currently in state init
[0m11:48:43.496166 [debug] [MainThread]: SQL status: BEGIN in 0.012 seconds
[0m11:48:43.498842 [debug] [MainThread]: Using postgres connection "master"
[0m11:48:43.501075 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "homework", "target_name": "dev", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select distinct
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v', 'm')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
[0m11:48:43.518314 [debug] [MainThread]: SQL status: SELECT 1 in 0.015 seconds
[0m11:48:43.521866 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'afaf7fbc-656e-40b9-bf7b-77d9db0b0238', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f40c9340220>]}
[0m11:48:43.525021 [debug] [MainThread]: On master: ROLLBACK
[0m11:48:43.528129 [debug] [MainThread]: Using postgres connection "master"
[0m11:48:43.530384 [debug] [MainThread]: On master: BEGIN
[0m11:48:43.532764 [debug] [MainThread]: SQL status: BEGIN in 0.001 seconds
[0m11:48:43.535316 [debug] [MainThread]: On master: COMMIT
[0m11:48:43.537317 [debug] [MainThread]: Using postgres connection "master"
[0m11:48:43.539062 [debug] [MainThread]: On master: COMMIT
[0m11:48:43.542730 [debug] [MainThread]: SQL status: COMMIT in 0.000 seconds
[0m11:48:43.545186 [debug] [MainThread]: On master: Close
[0m11:48:43.554192 [debug] [Thread-1  ]: Began running node model.homework.stg_iris
[0m11:48:43.556723 [info ] [Thread-1  ]: 1 of 2 START sql view model analytics.stg_iris ................................. [RUN]
[0m11:48:43.560040 [debug] [Thread-1  ]: Re-using an available connection from the pool (formerly list_analytics_analytics, now model.homework.stg_iris)
[0m11:48:43.562144 [debug] [Thread-1  ]: Began compiling node model.homework.stg_iris
[0m11:48:43.581721 [debug] [Thread-1  ]: Writing injected SQL for node "model.homework.stg_iris"
[0m11:48:43.594424 [debug] [Thread-1  ]: Began executing node model.homework.stg_iris
[0m11:48:43.662649 [debug] [Thread-1  ]: Writing runtime sql for node "model.homework.stg_iris"
[0m11:48:43.675102 [debug] [Thread-1  ]: Using postgres connection "model.homework.stg_iris"
[0m11:48:43.677403 [debug] [Thread-1  ]: On model.homework.stg_iris: BEGIN
[0m11:48:43.679438 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
[0m11:48:43.691440 [debug] [Thread-1  ]: SQL status: BEGIN in 0.012 seconds
[0m11:48:43.694312 [debug] [Thread-1  ]: Using postgres connection "model.homework.stg_iris"
[0m11:48:43.696887 [debug] [Thread-1  ]: On model.homework.stg_iris: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "homework", "target_name": "dev", "node_id": "model.homework.stg_iris"} */

  create view "analytics"."analytics"."stg_iris__dbt_tmp"
    
    
  as (
    with source as (
    select * from "analytics"."analytics"."iris_dataset"
)

select
    cast(sepal_length as numeric) as sepal_length,
    cast(sepal_width as numeric) as sepal_width,
    cast(petal_length as numeric) as petal_length,
    cast(petal_width as numeric) as petal_width,
    species
from source
  );
[0m11:48:43.707254 [debug] [Thread-1  ]: SQL status: CREATE VIEW in 0.007 seconds
[0m11:48:43.734283 [debug] [Thread-1  ]: Using postgres connection "model.homework.stg_iris"
[0m11:48:43.737471 [debug] [Thread-1  ]: On model.homework.stg_iris: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "homework", "target_name": "dev", "node_id": "model.homework.stg_iris"} */
alter table "analytics"."analytics"."stg_iris" rename to "stg_iris__dbt_backup"
[0m11:48:43.741737 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.001 seconds
[0m11:48:43.752956 [debug] [Thread-1  ]: Using postgres connection "model.homework.stg_iris"
[0m11:48:43.755407 [debug] [Thread-1  ]: On model.homework.stg_iris: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "homework", "target_name": "dev", "node_id": "model.homework.stg_iris"} */
alter table "analytics"."analytics"."stg_iris__dbt_tmp" rename to "stg_iris"
[0m11:48:43.760246 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.001 seconds
[0m11:48:43.801151 [debug] [Thread-1  ]: On model.homework.stg_iris: COMMIT
[0m11:48:43.803100 [debug] [Thread-1  ]: Using postgres connection "model.homework.stg_iris"
[0m11:48:43.804634 [debug] [Thread-1  ]: On model.homework.stg_iris: COMMIT
[0m11:48:43.810673 [debug] [Thread-1  ]: SQL status: COMMIT in 0.004 seconds
[0m11:48:43.828760 [debug] [Thread-1  ]: Applying DROP to: "analytics"."analytics"."stg_iris__dbt_backup"
[0m11:48:43.841658 [debug] [Thread-1  ]: Using postgres connection "model.homework.stg_iris"
[0m11:48:43.844141 [debug] [Thread-1  ]: On model.homework.stg_iris: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "homework", "target_name": "dev", "node_id": "model.homework.stg_iris"} */
drop view if exists "analytics"."analytics"."stg_iris__dbt_backup" cascade
[0m11:48:43.850644 [debug] [Thread-1  ]: SQL status: DROP VIEW in 0.004 seconds
[0m11:48:43.858253 [debug] [Thread-1  ]: On model.homework.stg_iris: Close
[0m11:48:43.863898 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'afaf7fbc-656e-40b9-bf7b-77d9db0b0238', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f40ca4cda60>]}
[0m11:48:43.867711 [info ] [Thread-1  ]: 1 of 2 OK created sql view model analytics.stg_iris ............................ [[32mCREATE VIEW[0m in 0.30s]
[0m11:48:43.870172 [debug] [Thread-1  ]: Finished running node model.homework.stg_iris
[0m11:48:43.872837 [debug] [Thread-3  ]: Began running node model.homework.iris_processed
[0m11:48:43.875595 [info ] [Thread-3  ]: 2 of 2 START sql table model analytics.iris_processed .......................... [RUN]
[0m11:48:43.877676 [debug] [Thread-3  ]: Acquiring new postgres connection 'model.homework.iris_processed'
[0m11:48:43.879180 [debug] [Thread-3  ]: Began compiling node model.homework.iris_processed
[0m11:48:43.927905 [debug] [Thread-3  ]: Using postgres connection "model.homework.iris_processed"
[0m11:48:43.930268 [debug] [Thread-3  ]: On model.homework.iris_processed: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "homework", "target_name": "dev", "node_id": "model.homework.iris_processed"} */

        select percentile_cont(0.5) within group (order by sepal_length ) from "analytics"."analytics"."stg_iris"
    
[0m11:48:43.932137 [debug] [Thread-3  ]: Opening a new connection, currently in state init
[0m11:48:43.959628 [debug] [Thread-3  ]: SQL status: SELECT 1 in 0.027 seconds
[0m11:48:43.963817 [debug] [Thread-3  ]: Using postgres connection "model.homework.iris_processed"
[0m11:48:43.965937 [debug] [Thread-3  ]: On model.homework.iris_processed: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "homework", "target_name": "dev", "node_id": "model.homework.iris_processed"} */

        select percentile_cont(0.5 - 0.5/2) within group (order by sepal_length ) from "analytics"."analytics"."stg_iris"
    
[0m11:48:43.969698 [debug] [Thread-3  ]: SQL status: SELECT 1 in 0.002 seconds
[0m11:48:43.973893 [debug] [Thread-3  ]: Using postgres connection "model.homework.iris_processed"
[0m11:48:43.976004 [debug] [Thread-3  ]: On model.homework.iris_processed: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "homework", "target_name": "dev", "node_id": "model.homework.iris_processed"} */

        select percentile_cont(0.5 + 0.5/2) within group (order by sepal_length ) from "analytics"."analytics"."stg_iris"
    
[0m11:48:43.978296 [debug] [Thread-3  ]: SQL status: SELECT 1 in 0.001 seconds
[0m11:48:43.983164 [debug] [Thread-3  ]: Using postgres connection "model.homework.iris_processed"
[0m11:48:43.984644 [debug] [Thread-3  ]: On model.homework.iris_processed: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "homework", "target_name": "dev", "node_id": "model.homework.iris_processed"} */

        select percentile_cont(0.5) within group (order by sepal_width ) from "analytics"."analytics"."stg_iris"
    
[0m11:48:43.986670 [debug] [Thread-3  ]: SQL status: SELECT 1 in 0.000 seconds
[0m11:48:43.989857 [debug] [Thread-3  ]: Using postgres connection "model.homework.iris_processed"
[0m11:48:43.992789 [debug] [Thread-3  ]: On model.homework.iris_processed: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "homework", "target_name": "dev", "node_id": "model.homework.iris_processed"} */

        select percentile_cont(0.5 - 0.5/2) within group (order by sepal_width ) from "analytics"."analytics"."stg_iris"
    
[0m11:48:43.995482 [debug] [Thread-3  ]: SQL status: SELECT 1 in 0.001 seconds
[0m11:48:43.999037 [debug] [Thread-3  ]: Using postgres connection "model.homework.iris_processed"
[0m11:48:44.000494 [debug] [Thread-3  ]: On model.homework.iris_processed: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "homework", "target_name": "dev", "node_id": "model.homework.iris_processed"} */

        select percentile_cont(0.5 + 0.5/2) within group (order by sepal_width ) from "analytics"."analytics"."stg_iris"
    
[0m11:48:44.002473 [debug] [Thread-3  ]: SQL status: SELECT 1 in 0.001 seconds
[0m11:48:44.008231 [debug] [Thread-3  ]: Using postgres connection "model.homework.iris_processed"
[0m11:48:44.010307 [debug] [Thread-3  ]: On model.homework.iris_processed: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "homework", "target_name": "dev", "node_id": "model.homework.iris_processed"} */

        select percentile_cont(0.5) within group (order by petal_length ) from "analytics"."analytics"."stg_iris"
    
[0m11:48:44.013073 [debug] [Thread-3  ]: SQL status: SELECT 1 in 0.001 seconds
[0m11:48:44.017027 [debug] [Thread-3  ]: Using postgres connection "model.homework.iris_processed"
[0m11:48:44.019020 [debug] [Thread-3  ]: On model.homework.iris_processed: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "homework", "target_name": "dev", "node_id": "model.homework.iris_processed"} */

        select percentile_cont(0.5 - 0.5/2) within group (order by petal_length ) from "analytics"."analytics"."stg_iris"
    
[0m11:48:44.021617 [debug] [Thread-3  ]: SQL status: SELECT 1 in 0.001 seconds
[0m11:48:44.026049 [debug] [Thread-3  ]: Using postgres connection "model.homework.iris_processed"
[0m11:48:44.028278 [debug] [Thread-3  ]: On model.homework.iris_processed: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "homework", "target_name": "dev", "node_id": "model.homework.iris_processed"} */

        select percentile_cont(0.5 + 0.5/2) within group (order by petal_length ) from "analytics"."analytics"."stg_iris"
    
[0m11:48:44.030884 [debug] [Thread-3  ]: SQL status: SELECT 1 in 0.001 seconds
[0m11:48:44.035807 [debug] [Thread-3  ]: Using postgres connection "model.homework.iris_processed"
[0m11:48:44.037656 [debug] [Thread-3  ]: On model.homework.iris_processed: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "homework", "target_name": "dev", "node_id": "model.homework.iris_processed"} */

        select percentile_cont(0.5) within group (order by petal_width ) from "analytics"."analytics"."stg_iris"
    
[0m11:48:44.040348 [debug] [Thread-3  ]: SQL status: SELECT 1 in 0.001 seconds
[0m11:48:44.044812 [debug] [Thread-3  ]: Using postgres connection "model.homework.iris_processed"
[0m11:48:44.046702 [debug] [Thread-3  ]: On model.homework.iris_processed: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "homework", "target_name": "dev", "node_id": "model.homework.iris_processed"} */

        select percentile_cont(0.5 - 0.5/2) within group (order by petal_width ) from "analytics"."analytics"."stg_iris"
    
[0m11:48:44.049173 [debug] [Thread-3  ]: SQL status: SELECT 1 in 0.001 seconds
[0m11:48:44.052677 [debug] [Thread-3  ]: Using postgres connection "model.homework.iris_processed"
[0m11:48:44.054534 [debug] [Thread-3  ]: On model.homework.iris_processed: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "homework", "target_name": "dev", "node_id": "model.homework.iris_processed"} */

        select percentile_cont(0.5 + 0.5/2) within group (order by petal_width ) from "analytics"."analytics"."stg_iris"
    
[0m11:48:44.057748 [debug] [Thread-3  ]: SQL status: SELECT 1 in 0.001 seconds
[0m11:48:44.065409 [debug] [Thread-3  ]: Using postgres connection "model.homework.iris_processed"
[0m11:48:44.067402 [debug] [Thread-3  ]: On model.homework.iris_processed: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "homework", "target_name": "dev", "node_id": "model.homework.iris_processed"} */

            select percentile_cont(0.5) within group (order by sepal_length ) from "analytics"."analytics"."stg_iris"
        
[0m11:48:44.069876 [debug] [Thread-3  ]: SQL status: SELECT 1 in 0.001 seconds
[0m11:48:44.074922 [debug] [Thread-3  ]: Using postgres connection "model.homework.iris_processed"
[0m11:48:44.077066 [debug] [Thread-3  ]: On model.homework.iris_processed: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "homework", "target_name": "dev", "node_id": "model.homework.iris_processed"} */

            select percentile_cont(0.5) within group (order by sepal_width ) from "analytics"."analytics"."stg_iris"
        
[0m11:48:44.079429 [debug] [Thread-3  ]: SQL status: SELECT 1 in 0.001 seconds
[0m11:48:44.083459 [debug] [Thread-3  ]: Using postgres connection "model.homework.iris_processed"
[0m11:48:44.085256 [debug] [Thread-3  ]: On model.homework.iris_processed: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "homework", "target_name": "dev", "node_id": "model.homework.iris_processed"} */

            select percentile_cont(0.5) within group (order by petal_length ) from "analytics"."analytics"."stg_iris"
        
[0m11:48:44.087627 [debug] [Thread-3  ]: SQL status: SELECT 1 in 0.001 seconds
[0m11:48:44.093458 [debug] [Thread-3  ]: Using postgres connection "model.homework.iris_processed"
[0m11:48:44.095543 [debug] [Thread-3  ]: On model.homework.iris_processed: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "homework", "target_name": "dev", "node_id": "model.homework.iris_processed"} */

            select percentile_cont(0.5) within group (order by petal_width ) from "analytics"."analytics"."stg_iris"
        
[0m11:48:44.098064 [debug] [Thread-3  ]: SQL status: SELECT 1 in 0.001 seconds
[0m11:48:44.117192 [debug] [Thread-3  ]: Using postgres connection "model.homework.iris_processed"
[0m11:48:44.119861 [debug] [Thread-3  ]: On model.homework.iris_processed: BEGIN
[0m11:48:44.122643 [debug] [Thread-3  ]: SQL status: BEGIN in 0.001 seconds
[0m11:48:44.126231 [debug] [Thread-3  ]: Using postgres connection "model.homework.iris_processed"
[0m11:48:44.129309 [debug] [Thread-3  ]: On model.homework.iris_processed: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "homework", "target_name": "dev", "node_id": "model.homework.iris_processed"} */
select
                species as value

            from "analytics"."analytics"."stg_iris"

            
            where species is not null  and true
            

            group by species
            order by species

            

        
[0m11:48:44.133944 [debug] [Thread-3  ]: SQL status: SELECT 3 in 0.002 seconds
[0m11:48:44.144634 [debug] [Thread-3  ]: Writing injected SQL for node "model.homework.iris_processed"
[0m11:48:44.159937 [debug] [Thread-3  ]: Began executing node model.homework.iris_processed
[0m11:48:44.205440 [debug] [Thread-3  ]: Writing runtime sql for node "model.homework.iris_processed"
[0m11:48:44.219776 [debug] [Thread-3  ]: Using postgres connection "model.homework.iris_processed"
[0m11:48:44.222350 [debug] [Thread-3  ]: On model.homework.iris_processed: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "homework", "target_name": "dev", "node_id": "model.homework.iris_processed"} */

  
    

  create  table "analytics"."analytics"."iris_processed__dbt_tmp"
  
  
    as
  
  (
    

with import_iris as (
    select *
    from "analytics"."analytics"."stg_iris"
)
select
    sepal_length,
    sepal_width,
    petal_length,
    petal_width,
    -- K Bins Discretization
    
        

    
        NTILE(5) over (order by sepal_length)
    

 as sepal_length_quantile_bin,
        

    
        
        floor(
        (
            sepal_length - (min(sepal_length) over ())
        )
        /
        (
            ((max(sepal_length) over ()) - (min(sepal_length) over ())) / 4::float
        )
        ) + 1
    

 as sepal_length_uniform_bin,
    
        

    
        NTILE(5) over (order by sepal_width)
    

 as sepal_width_quantile_bin,
        

    
        
        floor(
        (
            sepal_width - (min(sepal_width) over ())
        )
        /
        (
            ((max(sepal_width) over ()) - (min(sepal_width) over ())) / 4::float
        )
        ) + 1
    

 as sepal_width_uniform_bin,
    
        

    
        NTILE(5) over (order by petal_length)
    

 as petal_length_quantile_bin,
        

    
        
        floor(
        (
            petal_length - (min(petal_length) over ())
        )
        /
        (
            ((max(petal_length) over ()) - (min(petal_length) over ())) / 4::float
        )
        ) + 1
    

 as petal_length_uniform_bin,
    
        

    
        NTILE(5) over (order by petal_width)
    

 as petal_width_quantile_bin,
        

    
        
        floor(
        (
            petal_width - (min(petal_width) over ())
        )
        /
        (
            ((max(petal_width) over ()) - (min(petal_width) over ())) / 4::float
        )
        ) + 1
    

 as petal_width_uniform_bin,
    
-- Scaling
    
        

    

    
    
    

    
    
    

    (
        sepal_length - 5.8
    )
    /
    (
        6.4 - 5.1
    )

 as sepal_length_robust_scaled,
        

    (sepal_length) / (max(abs(sepal_length)) over ())::FLOAT

 as sepal_length_max_absolute_scaled,
        

    
    (
        ((sepal_length) - (min(sepal_length) over ()))
        /
        ((max(sepal_length) over ()) - (min(sepal_length) over ()))::FLOAT
    )
    *
    (1.0 - 0.0)
    +
    0.0

 as sepal_length_max_min_max_scaled,
    
        

    

    
    
    

    
    
    

    (
        sepal_width - 3.0
    )
    /
    (
        3.3 - 2.8
    )

 as sepal_width_robust_scaled,
        

    (sepal_width) / (max(abs(sepal_width)) over ())::FLOAT

 as sepal_width_max_absolute_scaled,
        

    
    (
        ((sepal_width) - (min(sepal_width) over ()))
        /
        ((max(sepal_width) over ()) - (min(sepal_width) over ()))::FLOAT
    )
    *
    (1.0 - 0.0)
    +
    0.0

 as sepal_width_max_min_max_scaled,
    
        

    

    
    
    

    
    
    

    (
        petal_length - 4.35
    )
    /
    (
        5.1 - 1.6
    )

 as petal_length_robust_scaled,
        

    (petal_length) / (max(abs(petal_length)) over ())::FLOAT

 as petal_length_max_absolute_scaled,
        

    
    (
        ((petal_length) - (min(petal_length) over ()))
        /
        ((max(petal_length) over ()) - (min(petal_length) over ()))::FLOAT
    )
    *
    (1.0 - 0.0)
    +
    0.0

 as petal_length_max_min_max_scaled,
    
        

    

    
    
    

    
    
    

    (
        petal_width - 1.3
    )
    /
    (
        1.8 - 0.3
    )

 as petal_width_robust_scaled,
        

    (petal_width) / (max(abs(petal_width)) over ())::FLOAT

 as petal_width_max_absolute_scaled,
        

    
    (
        ((petal_width) - (min(petal_width) over ()))
        /
        ((max(petal_width) over ()) - (min(petal_width) over ()))::FLOAT
    )
    *
    (1.0 - 0.0)
    +
    0.0

 as petal_width_max_min_max_scaled,
    

    -- Log Transformation
    
        

    case
        when sepal_length is null or sepal_length + 0 <= 0 then null
        else log(10, sepal_length + 0)
    end

 as sepal_length_logged,
    
        

    case
        when sepal_width is null or sepal_width + 0 <= 0 then null
        else log(10, sepal_width + 0)
    end

 as sepal_width_logged,
    
        

    case
        when petal_length is null or petal_length + 0 <= 0 then null
        else log(10, petal_length + 0)
    end

 as petal_length_logged,
    
        

    case
        when petal_width is null or petal_width + 0 <= 0 then null
        else log(10, petal_width + 0)
    end

 as petal_width_logged,
    

    -- Binarization
    
        

    

    
        

        
    

    case
        when sepal_length >=
            
                5.8
            
            then 1
        else 0
    end

 as sepal_length_binarized,
    
        

    

    
        

        
    

    case
        when sepal_width >=
            
                3.0
            
            then 1
        else 0
    end

 as sepal_width_binarized,
    
        

    

    
        

        
    

    case
        when petal_length >=
            
                4.35
            
            then 1
        else 0
    end

 as petal_length_binarized,
    
        

    

    
        

        
    

    case
        when petal_width >=
            
                1.3
            
            then 1
        else 0
    end

 as petal_width_binarized,
    

    -- Standardization
    
        

    
    (
        (sepal_length - avg(sepal_length) over ())
        /
        (stddev(sepal_length) over ())::FLOAT
    )
    *
    1
    +
    0

 as sepal_length_standardized,
    
        

    
    (
        (sepal_width - avg(sepal_width) over ())
        /
        (stddev(sepal_width) over ())::FLOAT
    )
    *
    1
    +
    0

 as sepal_width_standardized,
    
        

    
    (
        (petal_length - avg(petal_length) over ())
        /
        (stddev(petal_length) over ())::FLOAT
    )
    *
    1
    +
    0

 as petal_length_standardized,
    
        

    
    (
        (petal_width - avg(petal_width) over ())
        /
        (stddev(petal_width) over ())::FLOAT
    )
    *
    1
    +
    0

 as petal_width_standardized,
    
-- Interactions
    
        
            
            
            

    
        (sepal_length * sepal_width)
    

 as sepal_length_x_sepal_width_interaction,
            

    
        (sepal_length + sepal_width)
    

 as sepal_length_plus_sepal_width_interaction,
        
            
            
            

    
        (sepal_length * petal_length)
    

 as sepal_length_x_petal_length_interaction,
            

    
        (sepal_length + petal_length)
    

 as sepal_length_plus_petal_length_interaction,
        
            
            
            

    
        (sepal_length * petal_width)
    

 as sepal_length_x_petal_width_interaction,
            

    
        (sepal_length + petal_width)
    

 as sepal_length_plus_petal_width_interaction,
        
    
        
            
            
            

    
        (sepal_width * petal_length)
    

 as sepal_width_x_petal_length_interaction,
            

    
        (sepal_width + petal_length)
    

 as sepal_width_plus_petal_length_interaction,
        
            
            
            

    
        (sepal_width * petal_width)
    

 as sepal_width_x_petal_width_interaction,
            

    
        (sepal_width + petal_width)
    

 as sepal_width_plus_petal_width_interaction,
        
    
        
            
            
            

    
        (petal_length * petal_width)
    

 as petal_length_x_petal_width_interaction,
            

    
        (petal_length + petal_width)
    

 as petal_length_plus_petal_width_interaction,
        
    
        
    
species,    
    -- Label Encoding
    

    dense_rank() over (order by species) - 1

 as species_label_encoded,
    -- One Hot Encoding
    

    

    
        
    

    

    

        case
            when species = 'setosa' then 1
            else 0
        end as is_species__setosa,

    

        case
            when species = 'versicolor' then 1
            else 0
        end as is_species__versicolor,

    

        case
            when species = 'virginica' then 1
            else 0
        end as is_species__virginica,

    

    case
        when species is null then 1
        else 0
    end as is_species__


from "analytics"."analytics"."stg_iris"
  );
  
[0m11:48:44.273409 [debug] [Thread-3  ]: SQL status: SELECT 150 in 0.047 seconds
[0m11:48:44.292125 [debug] [Thread-3  ]: Using postgres connection "model.homework.iris_processed"
[0m11:48:44.294614 [debug] [Thread-3  ]: On model.homework.iris_processed: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "homework", "target_name": "dev", "node_id": "model.homework.iris_processed"} */
alter table "analytics"."analytics"."iris_processed" rename to "iris_processed__dbt_backup"
[0m11:48:44.297927 [debug] [Thread-3  ]: SQL status: ALTER TABLE in 0.001 seconds
[0m11:48:44.305794 [debug] [Thread-3  ]: Using postgres connection "model.homework.iris_processed"
[0m11:48:44.308806 [debug] [Thread-3  ]: On model.homework.iris_processed: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "homework", "target_name": "dev", "node_id": "model.homework.iris_processed"} */
alter table "analytics"."analytics"."iris_processed__dbt_tmp" rename to "iris_processed"
[0m11:48:44.313412 [debug] [Thread-3  ]: SQL status: ALTER TABLE in 0.001 seconds
[0m11:48:44.317923 [debug] [Thread-3  ]: On model.homework.iris_processed: COMMIT
[0m11:48:44.320164 [debug] [Thread-3  ]: Using postgres connection "model.homework.iris_processed"
[0m11:48:44.322600 [debug] [Thread-3  ]: On model.homework.iris_processed: COMMIT
[0m11:48:44.330384 [debug] [Thread-3  ]: SQL status: COMMIT in 0.005 seconds
[0m11:48:44.345544 [debug] [Thread-3  ]: Applying DROP to: "analytics"."analytics"."iris_processed__dbt_backup"
[0m11:48:44.353893 [debug] [Thread-3  ]: Using postgres connection "model.homework.iris_processed"
[0m11:48:44.356237 [debug] [Thread-3  ]: On model.homework.iris_processed: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "homework", "target_name": "dev", "node_id": "model.homework.iris_processed"} */
drop table if exists "analytics"."analytics"."iris_processed__dbt_backup" cascade
[0m11:48:44.370681 [debug] [Thread-3  ]: SQL status: DROP TABLE in 0.011 seconds
[0m11:48:44.377466 [debug] [Thread-3  ]: On model.homework.iris_processed: Close
[0m11:48:44.380819 [debug] [Thread-3  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'afaf7fbc-656e-40b9-bf7b-77d9db0b0238', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f40c85b1d90>]}
[0m11:48:44.383763 [info ] [Thread-3  ]: 2 of 2 OK created sql table model analytics.iris_processed ..................... [[32mSELECT 150[0m in 0.50s]
[0m11:48:44.386443 [debug] [Thread-3  ]: Finished running node model.homework.iris_processed
[0m11:48:44.391132 [debug] [MainThread]: Using postgres connection "master"
[0m11:48:44.395588 [debug] [MainThread]: On master: BEGIN
[0m11:48:44.397718 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m11:48:44.411137 [debug] [MainThread]: SQL status: BEGIN in 0.013 seconds
[0m11:48:44.414682 [debug] [MainThread]: On master: COMMIT
[0m11:48:44.417744 [debug] [MainThread]: Using postgres connection "master"
[0m11:48:44.420346 [debug] [MainThread]: On master: COMMIT
[0m11:48:44.423085 [debug] [MainThread]: SQL status: COMMIT in 0.000 seconds
[0m11:48:44.427471 [debug] [MainThread]: On master: Close
[0m11:48:44.430644 [debug] [MainThread]: Connection 'master' was properly closed.
[0m11:48:44.433587 [debug] [MainThread]: Connection 'model.homework.stg_iris' was properly closed.
[0m11:48:44.436117 [debug] [MainThread]: Connection 'model.homework.iris_processed' was properly closed.
[0m11:48:44.438755 [info ] [MainThread]: 
[0m11:48:44.444355 [info ] [MainThread]: Finished running 1 table model, 1 view model in 0 hours 0 minutes and 1.18 seconds (1.18s).
[0m11:48:44.451243 [debug] [MainThread]: Command end result
[0m11:48:44.597523 [debug] [MainThread]: Wrote artifact WritableManifest to /opt/airflow/dags/dbt/homework/target/manifest.json
[0m11:48:44.607233 [debug] [MainThread]: Wrote artifact SemanticManifest to /opt/airflow/dags/dbt/homework/target/semantic_manifest.json
[0m11:48:44.630679 [debug] [MainThread]: Wrote artifact RunExecutionResult to /opt/airflow/dags/dbt/homework/target/run_results.json
[0m11:48:44.632419 [info ] [MainThread]: 
[0m11:48:44.634414 [info ] [MainThread]: [32mCompleted successfully[0m
[0m11:48:44.635990 [info ] [MainThread]: 
[0m11:48:44.637455 [info ] [MainThread]: Done. PASS=2 WARN=0 ERROR=0 SKIP=0 TOTAL=2
[0m11:48:44.640114 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": true, "command_wall_clock_time": 8.609109, "process_in_blocks": "0", "process_kernel_time": 1.028084, "process_mem_max_rss": "120916", "process_out_blocks": "0", "process_user_time": 10.081214}
[0m11:48:44.644253 [debug] [MainThread]: Command `dbt run` succeeded at 11:48:44.643946 after 8.61 seconds
[0m11:48:44.646083 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f40ccef9b80>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f40c92df0d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f40ca4ae280>]}
[0m11:48:44.647573 [debug] [MainThread]: Flushing usage events
[0m11:48:45.301105 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m11:48:53.050603 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f91e81c7b20>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f91e72e9640>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f91e72e95e0>]}


============================== 11:48:53.063914 | b465e3de-917e-4446-920e-b7623ec06a64 ==============================
[0m11:48:53.063914 [info ] [MainThread]: Running with dbt=1.9.4
[0m11:48:53.066210 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': '/opt/airflow/dags/dbt', 'fail_fast': 'True', 'debug': 'False', 'log_path': '/opt/airflow/dags/dbt/homework/logs', 'warn_error': 'None', 'version_check': 'True', 'use_colors': 'True', 'use_experimental_parser': 'False', 'empty': 'None', 'quiet': 'False', 'no_print': 'None', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'static_parser': 'True', 'log_format': 'default', 'introspect': 'True', 'target_path': 'None', 'invocation_command': 'dbt --profile homework test --project-dir=/opt/airflow/dags/dbt/homework --vars {"is_test": false, "data_date": "2025-04-22"} --fail-fast', 'send_anonymous_usage_stats': 'True'}
[0m11:48:53.464010 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'b465e3de-917e-4446-920e-b7623ec06a64', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f91e5a65a90>]}
[0m11:48:53.587912 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': 'b465e3de-917e-4446-920e-b7623ec06a64', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f91e5a26760>]}
[0m11:48:53.590166 [info ] [MainThread]: Registered adapter: postgres=1.9.0
[0m11:48:53.879938 [debug] [MainThread]: checksum: b4b46bb6a239f66694dfdd44ef1792882cb61f2fd7b1ea66b3c7a170d2bb602d, vars: {'data_date': '2025-04-22', 'is_test': False}, profile: homework, target: , version: 1.9.4
[0m11:48:55.637703 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m11:48:55.639890 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m11:48:55.657012 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 1 unused configuration paths:
- seeds.homework.iris_dataset
[0m11:48:55.766326 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'b465e3de-917e-4446-920e-b7623ec06a64', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f91e5617130>]}
[0m11:48:56.230796 [debug] [MainThread]: Wrote artifact WritableManifest to /opt/airflow/dags/dbt/homework/target/manifest.json
[0m11:48:56.251490 [debug] [MainThread]: Wrote artifact SemanticManifest to /opt/airflow/dags/dbt/homework/target/semantic_manifest.json
[0m11:48:56.335711 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'b465e3de-917e-4446-920e-b7623ec06a64', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f91e54f5970>]}
[0m11:48:56.337932 [info ] [MainThread]: Found 2 models, 1 source, 587 macros
[0m11:48:56.339965 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'b465e3de-917e-4446-920e-b7623ec06a64', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f91e7377ca0>]}
[0m11:48:56.343569 [warn ] [MainThread]: Nothing to do. Try checking your model configs and model specification args
[0m11:48:56.348420 [debug] [MainThread]: Command end result
[0m11:48:56.508589 [debug] [MainThread]: Wrote artifact WritableManifest to /opt/airflow/dags/dbt/homework/target/manifest.json
[0m11:48:56.518203 [debug] [MainThread]: Wrote artifact SemanticManifest to /opt/airflow/dags/dbt/homework/target/semantic_manifest.json
[0m11:48:56.530659 [debug] [MainThread]: Wrote artifact RunExecutionResult to /opt/airflow/dags/dbt/homework/target/run_results.json
[0m11:48:56.533778 [debug] [MainThread]: Resource report: {"command_name": "test", "command_success": true, "command_wall_clock_time": 3.6219375, "process_in_blocks": "0", "process_kernel_time": 0.318332, "process_mem_max_rss": "104580", "process_out_blocks": "0", "process_user_time": 5.312176}
[0m11:48:56.536070 [debug] [MainThread]: Command `dbt test` succeeded at 11:48:56.535801 after 3.62 seconds
[0m11:48:56.538157 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f91e81c7b20>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f91e8ec5d30>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f91e5a88760>]}
[0m11:48:56.540050 [debug] [MainThread]: Flushing usage events
[0m11:48:57.077723 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m12:02:51.086518 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff1f745fb50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff1f65814f0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff1f6581490>]}


============================== 12:02:51.102841 | 621edb59-1667-43f4-a537-b767b3f7afe2 ==============================
[0m12:02:51.102841 [info ] [MainThread]: Running with dbt=1.9.4
[0m12:02:51.105064 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'version_check': 'True', 'profiles_dir': '/opt/airflow/dags/dbt', 'log_path': '/opt/airflow/dags/dbt/homework/logs', 'debug': 'False', 'fail_fast': 'False', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'empty': 'False', 'log_format': 'default', 'invocation_command': 'dbt --profile homework run --project-dir=/opt/airflow/dags/dbt/homework --vars {"is_test": false, "data_date": "2025-04-22"}', 'static_parser': 'True', 'introspect': 'True', 'target_path': 'None', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'send_anonymous_usage_stats': 'True'}
[0m12:02:51.545386 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '621edb59-1667-43f4-a537-b767b3f7afe2', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff1f65c1fa0>]}
[0m12:02:51.678772 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '621edb59-1667-43f4-a537-b767b3f7afe2', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff1f4da74f0>]}
[0m12:02:51.681083 [info ] [MainThread]: Registered adapter: postgres=1.9.0
[0m12:02:51.995973 [debug] [MainThread]: checksum: b4b46bb6a239f66694dfdd44ef1792882cb61f2fd7b1ea66b3c7a170d2bb602d, vars: {'data_date': '2025-04-22', 'is_test': False}, profile: homework, target: , version: 1.9.4
[0m12:02:53.643264 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m12:02:53.645429 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m12:02:53.659759 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 1 unused configuration paths:
- seeds.homework.iris_dataset
[0m12:02:53.739892 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '621edb59-1667-43f4-a537-b767b3f7afe2', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff1f48ad130>]}
[0m12:02:54.054540 [debug] [MainThread]: Wrote artifact WritableManifest to /opt/airflow/dags/dbt/homework/target/manifest.json
[0m12:02:54.072882 [debug] [MainThread]: Wrote artifact SemanticManifest to /opt/airflow/dags/dbt/homework/target/semantic_manifest.json
[0m12:02:54.104891 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '621edb59-1667-43f4-a537-b767b3f7afe2', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff1f488d370>]}
[0m12:02:54.106864 [info ] [MainThread]: Found 2 models, 1 source, 587 macros
[0m12:02:54.108828 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '621edb59-1667-43f4-a537-b767b3f7afe2', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff1f65fe1f0>]}
[0m12:02:54.112923 [info ] [MainThread]: 
[0m12:02:54.114682 [info ] [MainThread]: Concurrency: 4 threads (target='dev')
[0m12:02:54.116268 [info ] [MainThread]: 
[0m12:02:54.118117 [debug] [MainThread]: Acquiring new postgres connection 'master'
[0m12:02:54.129254 [debug] [ThreadPool]: Acquiring new postgres connection 'list_analytics'
[0m12:02:54.208899 [debug] [ThreadPool]: Using postgres connection "list_analytics"
[0m12:02:54.211039 [debug] [ThreadPool]: On list_analytics: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "homework", "target_name": "dev", "connection_name": "list_analytics"} */

    select distinct nspname from pg_namespace
  
[0m12:02:54.212523 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m12:02:54.225924 [debug] [ThreadPool]: SQL status: SELECT 7 in 0.013 seconds
[0m12:02:54.229360 [debug] [ThreadPool]: On list_analytics: Close
[0m12:02:54.232818 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_analytics, now list_analytics_analytics)
[0m12:02:54.250225 [debug] [ThreadPool]: Using postgres connection "list_analytics_analytics"
[0m12:02:54.251939 [debug] [ThreadPool]: On list_analytics_analytics: BEGIN
[0m12:02:54.253528 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m12:02:54.267027 [debug] [ThreadPool]: SQL status: BEGIN in 0.013 seconds
[0m12:02:54.269794 [debug] [ThreadPool]: Using postgres connection "list_analytics_analytics"
[0m12:02:54.272693 [debug] [ThreadPool]: On list_analytics_analytics: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "homework", "target_name": "dev", "connection_name": "list_analytics_analytics"} */
select
      'analytics' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'analytics'
    union all
    select
      'analytics' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'analytics'
    union all
    select
      'analytics' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'analytics'
  
[0m12:02:54.279731 [debug] [ThreadPool]: SQL status: SELECT 3 in 0.004 seconds
[0m12:02:54.283377 [debug] [ThreadPool]: On list_analytics_analytics: ROLLBACK
[0m12:02:54.285534 [debug] [ThreadPool]: On list_analytics_analytics: Close
[0m12:02:54.303632 [debug] [MainThread]: Using postgres connection "master"
[0m12:02:54.305889 [debug] [MainThread]: On master: BEGIN
[0m12:02:54.308297 [debug] [MainThread]: Opening a new connection, currently in state init
[0m12:02:54.323295 [debug] [MainThread]: SQL status: BEGIN in 0.015 seconds
[0m12:02:54.326561 [debug] [MainThread]: Using postgres connection "master"
[0m12:02:54.329274 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "homework", "target_name": "dev", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select distinct
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v', 'm')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
[0m12:02:54.346112 [debug] [MainThread]: SQL status: SELECT 1 in 0.014 seconds
[0m12:02:54.352589 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '621edb59-1667-43f4-a537-b767b3f7afe2', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff1f3d09a90>]}
[0m12:02:54.355542 [debug] [MainThread]: On master: ROLLBACK
[0m12:02:54.357442 [debug] [MainThread]: Using postgres connection "master"
[0m12:02:54.359621 [debug] [MainThread]: On master: BEGIN
[0m12:02:54.362018 [debug] [MainThread]: SQL status: BEGIN in 0.001 seconds
[0m12:02:54.364456 [debug] [MainThread]: On master: COMMIT
[0m12:02:54.367354 [debug] [MainThread]: Using postgres connection "master"
[0m12:02:54.370102 [debug] [MainThread]: On master: COMMIT
[0m12:02:54.372321 [debug] [MainThread]: SQL status: COMMIT in 0.000 seconds
[0m12:02:54.374051 [debug] [MainThread]: On master: Close
[0m12:02:54.383191 [debug] [Thread-1  ]: Began running node model.homework.stg_iris
[0m12:02:54.385140 [info ] [Thread-1  ]: 1 of 2 START sql view model analytics.stg_iris ................................. [RUN]
[0m12:02:54.387305 [debug] [Thread-1  ]: Re-using an available connection from the pool (formerly list_analytics_analytics, now model.homework.stg_iris)
[0m12:02:54.389208 [debug] [Thread-1  ]: Began compiling node model.homework.stg_iris
[0m12:02:54.411256 [debug] [Thread-1  ]: Writing injected SQL for node "model.homework.stg_iris"
[0m12:02:54.423695 [debug] [Thread-1  ]: Began executing node model.homework.stg_iris
[0m12:02:54.506420 [debug] [Thread-1  ]: Writing runtime sql for node "model.homework.stg_iris"
[0m12:02:54.517949 [debug] [Thread-1  ]: Using postgres connection "model.homework.stg_iris"
[0m12:02:54.519817 [debug] [Thread-1  ]: On model.homework.stg_iris: BEGIN
[0m12:02:54.521428 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
[0m12:02:54.535228 [debug] [Thread-1  ]: SQL status: BEGIN in 0.013 seconds
[0m12:02:54.538723 [debug] [Thread-1  ]: Using postgres connection "model.homework.stg_iris"
[0m12:02:54.542595 [debug] [Thread-1  ]: On model.homework.stg_iris: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "homework", "target_name": "dev", "node_id": "model.homework.stg_iris"} */

  create view "analytics"."analytics"."stg_iris__dbt_tmp"
    
    
  as (
    with source as (
    select * from "analytics"."analytics"."iris_dataset"
)

select
    cast(sepal_length as numeric) as sepal_length,
    cast(sepal_width as numeric) as sepal_width,
    cast(petal_length as numeric) as petal_length,
    cast(petal_width as numeric) as petal_width,
    species
from source
  );
[0m12:02:54.552444 [debug] [Thread-1  ]: SQL status: CREATE VIEW in 0.007 seconds
[0m12:02:54.581172 [debug] [Thread-1  ]: Using postgres connection "model.homework.stg_iris"
[0m12:02:54.584250 [debug] [Thread-1  ]: On model.homework.stg_iris: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "homework", "target_name": "dev", "node_id": "model.homework.stg_iris"} */
alter table "analytics"."analytics"."stg_iris" rename to "stg_iris__dbt_backup"
[0m12:02:54.589756 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.001 seconds
[0m12:02:54.603649 [debug] [Thread-1  ]: Using postgres connection "model.homework.stg_iris"
[0m12:02:54.606184 [debug] [Thread-1  ]: On model.homework.stg_iris: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "homework", "target_name": "dev", "node_id": "model.homework.stg_iris"} */
alter table "analytics"."analytics"."stg_iris__dbt_tmp" rename to "stg_iris"
[0m12:02:54.609753 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.001 seconds
[0m12:02:54.667311 [debug] [Thread-1  ]: On model.homework.stg_iris: COMMIT
[0m12:02:54.669119 [debug] [Thread-1  ]: Using postgres connection "model.homework.stg_iris"
[0m12:02:54.670878 [debug] [Thread-1  ]: On model.homework.stg_iris: COMMIT
[0m12:02:54.676096 [debug] [Thread-1  ]: SQL status: COMMIT in 0.003 seconds
[0m12:02:54.693829 [debug] [Thread-1  ]: Applying DROP to: "analytics"."analytics"."stg_iris__dbt_backup"
[0m12:02:54.706237 [debug] [Thread-1  ]: Using postgres connection "model.homework.stg_iris"
[0m12:02:54.707971 [debug] [Thread-1  ]: On model.homework.stg_iris: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "homework", "target_name": "dev", "node_id": "model.homework.stg_iris"} */
drop view if exists "analytics"."analytics"."stg_iris__dbt_backup" cascade
[0m12:02:54.713623 [debug] [Thread-1  ]: SQL status: DROP VIEW in 0.003 seconds
[0m12:02:54.719785 [debug] [Thread-1  ]: On model.homework.stg_iris: Close
[0m12:02:54.724322 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '621edb59-1667-43f4-a537-b767b3f7afe2', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff1f3d6e1c0>]}
[0m12:02:54.727518 [info ] [Thread-1  ]: 1 of 2 OK created sql view model analytics.stg_iris ............................ [[32mCREATE VIEW[0m in 0.33s]
[0m12:02:54.729774 [debug] [Thread-1  ]: Finished running node model.homework.stg_iris
[0m12:02:54.732483 [debug] [Thread-3  ]: Began running node model.homework.iris_processed
[0m12:02:54.734398 [info ] [Thread-3  ]: 2 of 2 START sql table model analytics.iris_processed .......................... [RUN]
[0m12:02:54.736607 [debug] [Thread-3  ]: Acquiring new postgres connection 'model.homework.iris_processed'
[0m12:02:54.738336 [debug] [Thread-3  ]: Began compiling node model.homework.iris_processed
[0m12:02:54.817921 [debug] [Thread-3  ]: Using postgres connection "model.homework.iris_processed"
[0m12:02:54.819685 [debug] [Thread-3  ]: On model.homework.iris_processed: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "homework", "target_name": "dev", "node_id": "model.homework.iris_processed"} */

        select percentile_cont(0.5) within group (order by sepal_length ) from "analytics"."analytics"."stg_iris"
    
[0m12:02:54.821345 [debug] [Thread-3  ]: Opening a new connection, currently in state init
[0m12:02:54.834459 [debug] [Thread-3  ]: SQL status: SELECT 1 in 0.013 seconds
[0m12:02:54.838169 [debug] [Thread-3  ]: Using postgres connection "model.homework.iris_processed"
[0m12:02:54.840047 [debug] [Thread-3  ]: On model.homework.iris_processed: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "homework", "target_name": "dev", "node_id": "model.homework.iris_processed"} */

        select percentile_cont(0.5 - 0.5/2) within group (order by sepal_length ) from "analytics"."analytics"."stg_iris"
    
[0m12:02:54.843333 [debug] [Thread-3  ]: SQL status: SELECT 1 in 0.001 seconds
[0m12:02:54.847655 [debug] [Thread-3  ]: Using postgres connection "model.homework.iris_processed"
[0m12:02:54.849297 [debug] [Thread-3  ]: On model.homework.iris_processed: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "homework", "target_name": "dev", "node_id": "model.homework.iris_processed"} */

        select percentile_cont(0.5 + 0.5/2) within group (order by sepal_length ) from "analytics"."analytics"."stg_iris"
    
[0m12:02:54.851768 [debug] [Thread-3  ]: SQL status: SELECT 1 in 0.001 seconds
[0m12:02:54.868371 [debug] [Thread-3  ]: Using postgres connection "model.homework.iris_processed"
[0m12:02:54.870286 [debug] [Thread-3  ]: On model.homework.iris_processed: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "homework", "target_name": "dev", "node_id": "model.homework.iris_processed"} */

        select percentile_cont(0.5) within group (order by sepal_width ) from "analytics"."analytics"."stg_iris"
    
[0m12:02:54.873138 [debug] [Thread-3  ]: SQL status: SELECT 1 in 0.001 seconds
[0m12:02:54.878036 [debug] [Thread-3  ]: Using postgres connection "model.homework.iris_processed"
[0m12:02:54.879870 [debug] [Thread-3  ]: On model.homework.iris_processed: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "homework", "target_name": "dev", "node_id": "model.homework.iris_processed"} */

        select percentile_cont(0.5 - 0.5/2) within group (order by sepal_width ) from "analytics"."analytics"."stg_iris"
    
[0m12:02:54.882180 [debug] [Thread-3  ]: SQL status: SELECT 1 in 0.001 seconds
[0m12:02:54.885934 [debug] [Thread-3  ]: Using postgres connection "model.homework.iris_processed"
[0m12:02:54.887896 [debug] [Thread-3  ]: On model.homework.iris_processed: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "homework", "target_name": "dev", "node_id": "model.homework.iris_processed"} */

        select percentile_cont(0.5 + 0.5/2) within group (order by sepal_width ) from "analytics"."analytics"."stg_iris"
    
[0m12:02:54.890813 [debug] [Thread-3  ]: SQL status: SELECT 1 in 0.001 seconds
[0m12:02:54.897057 [debug] [Thread-3  ]: Using postgres connection "model.homework.iris_processed"
[0m12:02:54.898625 [debug] [Thread-3  ]: On model.homework.iris_processed: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "homework", "target_name": "dev", "node_id": "model.homework.iris_processed"} */

        select percentile_cont(0.5) within group (order by petal_length ) from "analytics"."analytics"."stg_iris"
    
[0m12:02:54.900959 [debug] [Thread-3  ]: SQL status: SELECT 1 in 0.001 seconds
[0m12:02:54.904480 [debug] [Thread-3  ]: Using postgres connection "model.homework.iris_processed"
[0m12:02:54.906263 [debug] [Thread-3  ]: On model.homework.iris_processed: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "homework", "target_name": "dev", "node_id": "model.homework.iris_processed"} */

        select percentile_cont(0.5 - 0.5/2) within group (order by petal_length ) from "analytics"."analytics"."stg_iris"
    
[0m12:02:54.909160 [debug] [Thread-3  ]: SQL status: SELECT 1 in 0.001 seconds
[0m12:02:54.913800 [debug] [Thread-3  ]: Using postgres connection "model.homework.iris_processed"
[0m12:02:54.915535 [debug] [Thread-3  ]: On model.homework.iris_processed: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "homework", "target_name": "dev", "node_id": "model.homework.iris_processed"} */

        select percentile_cont(0.5 + 0.5/2) within group (order by petal_length ) from "analytics"."analytics"."stg_iris"
    
[0m12:02:54.917913 [debug] [Thread-3  ]: SQL status: SELECT 1 in 0.001 seconds
[0m12:02:54.923153 [debug] [Thread-3  ]: Using postgres connection "model.homework.iris_processed"
[0m12:02:54.924979 [debug] [Thread-3  ]: On model.homework.iris_processed: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "homework", "target_name": "dev", "node_id": "model.homework.iris_processed"} */

        select percentile_cont(0.5) within group (order by petal_width ) from "analytics"."analytics"."stg_iris"
    
[0m12:02:54.928727 [debug] [Thread-3  ]: SQL status: SELECT 1 in 0.001 seconds
[0m12:02:54.932424 [debug] [Thread-3  ]: Using postgres connection "model.homework.iris_processed"
[0m12:02:54.934026 [debug] [Thread-3  ]: On model.homework.iris_processed: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "homework", "target_name": "dev", "node_id": "model.homework.iris_processed"} */

        select percentile_cont(0.5 - 0.5/2) within group (order by petal_width ) from "analytics"."analytics"."stg_iris"
    
[0m12:02:54.936392 [debug] [Thread-3  ]: SQL status: SELECT 1 in 0.001 seconds
[0m12:02:54.939920 [debug] [Thread-3  ]: Using postgres connection "model.homework.iris_processed"
[0m12:02:54.941524 [debug] [Thread-3  ]: On model.homework.iris_processed: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "homework", "target_name": "dev", "node_id": "model.homework.iris_processed"} */

        select percentile_cont(0.5 + 0.5/2) within group (order by petal_width ) from "analytics"."analytics"."stg_iris"
    
[0m12:02:54.944694 [debug] [Thread-3  ]: SQL status: SELECT 1 in 0.001 seconds
[0m12:02:54.969495 [debug] [Thread-3  ]: Using postgres connection "model.homework.iris_processed"
[0m12:02:54.970473 [debug] [Thread-3  ]: On model.homework.iris_processed: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "homework", "target_name": "dev", "node_id": "model.homework.iris_processed"} */

            select percentile_cont(0.5) within group (order by sepal_length ) from "analytics"."analytics"."stg_iris"
        
[0m12:02:54.973166 [debug] [Thread-3  ]: SQL status: SELECT 1 in 0.001 seconds
[0m12:02:54.979086 [debug] [Thread-3  ]: Using postgres connection "model.homework.iris_processed"
[0m12:02:54.980886 [debug] [Thread-3  ]: On model.homework.iris_processed: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "homework", "target_name": "dev", "node_id": "model.homework.iris_processed"} */

            select percentile_cont(0.5) within group (order by sepal_width ) from "analytics"."analytics"."stg_iris"
        
[0m12:02:54.983026 [debug] [Thread-3  ]: SQL status: SELECT 1 in 0.001 seconds
[0m12:02:54.987582 [debug] [Thread-3  ]: Using postgres connection "model.homework.iris_processed"
[0m12:02:54.989207 [debug] [Thread-3  ]: On model.homework.iris_processed: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "homework", "target_name": "dev", "node_id": "model.homework.iris_processed"} */

            select percentile_cont(0.5) within group (order by petal_length ) from "analytics"."analytics"."stg_iris"
        
[0m12:02:54.992229 [debug] [Thread-3  ]: SQL status: SELECT 1 in 0.001 seconds
[0m12:02:54.997530 [debug] [Thread-3  ]: Using postgres connection "model.homework.iris_processed"
[0m12:02:54.999545 [debug] [Thread-3  ]: On model.homework.iris_processed: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "homework", "target_name": "dev", "node_id": "model.homework.iris_processed"} */

            select percentile_cont(0.5) within group (order by petal_width ) from "analytics"."analytics"."stg_iris"
        
[0m12:02:55.002276 [debug] [Thread-3  ]: SQL status: SELECT 1 in 0.001 seconds
[0m12:02:55.087782 [debug] [Thread-3  ]: Using postgres connection "model.homework.iris_processed"
[0m12:02:55.089466 [debug] [Thread-3  ]: On model.homework.iris_processed: BEGIN
[0m12:02:55.092675 [debug] [Thread-3  ]: SQL status: BEGIN in 0.001 seconds
[0m12:02:55.095711 [debug] [Thread-3  ]: Using postgres connection "model.homework.iris_processed"
[0m12:02:55.098456 [debug] [Thread-3  ]: On model.homework.iris_processed: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "homework", "target_name": "dev", "node_id": "model.homework.iris_processed"} */
select
                species as value

            from "analytics"."analytics"."stg_iris"

            
            where species is not null  and true
            

            group by species
            order by species

            

        
[0m12:02:55.104853 [debug] [Thread-3  ]: SQL status: SELECT 3 in 0.003 seconds
[0m12:02:55.120442 [debug] [Thread-3  ]: Writing injected SQL for node "model.homework.iris_processed"
[0m12:02:55.137072 [debug] [Thread-3  ]: Began executing node model.homework.iris_processed
[0m12:02:55.194538 [debug] [Thread-3  ]: Writing runtime sql for node "model.homework.iris_processed"
[0m12:02:55.204775 [debug] [Thread-3  ]: Using postgres connection "model.homework.iris_processed"
[0m12:02:55.207665 [debug] [Thread-3  ]: On model.homework.iris_processed: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "homework", "target_name": "dev", "node_id": "model.homework.iris_processed"} */

  
    

  create  table "analytics"."analytics"."iris_processed__dbt_tmp"
  
  
    as
  
  (
    

with import_iris as (
    select *
    from "analytics"."analytics"."stg_iris"
)
select
    sepal_length,
    sepal_width,
    petal_length,
    petal_width,
    -- K Bins Discretization
    
        

    
        NTILE(5) over (order by sepal_length)
    

 as sepal_length_quantile_bin,
        

    
        
        floor(
        (
            sepal_length - (min(sepal_length) over ())
        )
        /
        (
            ((max(sepal_length) over ()) - (min(sepal_length) over ())) / 4::float
        )
        ) + 1
    

 as sepal_length_uniform_bin,
    
        

    
        NTILE(5) over (order by sepal_width)
    

 as sepal_width_quantile_bin,
        

    
        
        floor(
        (
            sepal_width - (min(sepal_width) over ())
        )
        /
        (
            ((max(sepal_width) over ()) - (min(sepal_width) over ())) / 4::float
        )
        ) + 1
    

 as sepal_width_uniform_bin,
    
        

    
        NTILE(5) over (order by petal_length)
    

 as petal_length_quantile_bin,
        

    
        
        floor(
        (
            petal_length - (min(petal_length) over ())
        )
        /
        (
            ((max(petal_length) over ()) - (min(petal_length) over ())) / 4::float
        )
        ) + 1
    

 as petal_length_uniform_bin,
    
        

    
        NTILE(5) over (order by petal_width)
    

 as petal_width_quantile_bin,
        

    
        
        floor(
        (
            petal_width - (min(petal_width) over ())
        )
        /
        (
            ((max(petal_width) over ()) - (min(petal_width) over ())) / 4::float
        )
        ) + 1
    

 as petal_width_uniform_bin,
    
-- Scaling
    
        

    

    
    
    

    
    
    

    (
        sepal_length - 5.8
    )
    /
    (
        6.4 - 5.1
    )

 as sepal_length_robust_scaled,
        

    (sepal_length) / (max(abs(sepal_length)) over ())::FLOAT

 as sepal_length_max_absolute_scaled,
        

    
    (
        ((sepal_length) - (min(sepal_length) over ()))
        /
        ((max(sepal_length) over ()) - (min(sepal_length) over ()))::FLOAT
    )
    *
    (1.0 - 0.0)
    +
    0.0

 as sepal_length_max_min_max_scaled,
    
        

    

    
    
    

    
    
    

    (
        sepal_width - 3.0
    )
    /
    (
        3.3 - 2.8
    )

 as sepal_width_robust_scaled,
        

    (sepal_width) / (max(abs(sepal_width)) over ())::FLOAT

 as sepal_width_max_absolute_scaled,
        

    
    (
        ((sepal_width) - (min(sepal_width) over ()))
        /
        ((max(sepal_width) over ()) - (min(sepal_width) over ()))::FLOAT
    )
    *
    (1.0 - 0.0)
    +
    0.0

 as sepal_width_max_min_max_scaled,
    
        

    

    
    
    

    
    
    

    (
        petal_length - 4.35
    )
    /
    (
        5.1 - 1.6
    )

 as petal_length_robust_scaled,
        

    (petal_length) / (max(abs(petal_length)) over ())::FLOAT

 as petal_length_max_absolute_scaled,
        

    
    (
        ((petal_length) - (min(petal_length) over ()))
        /
        ((max(petal_length) over ()) - (min(petal_length) over ()))::FLOAT
    )
    *
    (1.0 - 0.0)
    +
    0.0

 as petal_length_max_min_max_scaled,
    
        

    

    
    
    

    
    
    

    (
        petal_width - 1.3
    )
    /
    (
        1.8 - 0.3
    )

 as petal_width_robust_scaled,
        

    (petal_width) / (max(abs(petal_width)) over ())::FLOAT

 as petal_width_max_absolute_scaled,
        

    
    (
        ((petal_width) - (min(petal_width) over ()))
        /
        ((max(petal_width) over ()) - (min(petal_width) over ()))::FLOAT
    )
    *
    (1.0 - 0.0)
    +
    0.0

 as petal_width_max_min_max_scaled,
    

    -- Log Transformation
    
        

    case
        when sepal_length is null or sepal_length + 0 <= 0 then null
        else log(10, sepal_length + 0)
    end

 as sepal_length_logged,
    
        

    case
        when sepal_width is null or sepal_width + 0 <= 0 then null
        else log(10, sepal_width + 0)
    end

 as sepal_width_logged,
    
        

    case
        when petal_length is null or petal_length + 0 <= 0 then null
        else log(10, petal_length + 0)
    end

 as petal_length_logged,
    
        

    case
        when petal_width is null or petal_width + 0 <= 0 then null
        else log(10, petal_width + 0)
    end

 as petal_width_logged,
    

    -- Binarization
    
        

    

    
        

        
    

    case
        when sepal_length >=
            
                5.8
            
            then 1
        else 0
    end

 as sepal_length_binarized,
    
        

    

    
        

        
    

    case
        when sepal_width >=
            
                3.0
            
            then 1
        else 0
    end

 as sepal_width_binarized,
    
        

    

    
        

        
    

    case
        when petal_length >=
            
                4.35
            
            then 1
        else 0
    end

 as petal_length_binarized,
    
        

    

    
        

        
    

    case
        when petal_width >=
            
                1.3
            
            then 1
        else 0
    end

 as petal_width_binarized,
    

    -- Standardization
    
        

    
    (
        (sepal_length - avg(sepal_length) over ())
        /
        (stddev(sepal_length) over ())::FLOAT
    )
    *
    1
    +
    0

 as sepal_length_standardized,
    
        

    
    (
        (sepal_width - avg(sepal_width) over ())
        /
        (stddev(sepal_width) over ())::FLOAT
    )
    *
    1
    +
    0

 as sepal_width_standardized,
    
        

    
    (
        (petal_length - avg(petal_length) over ())
        /
        (stddev(petal_length) over ())::FLOAT
    )
    *
    1
    +
    0

 as petal_length_standardized,
    
        

    
    (
        (petal_width - avg(petal_width) over ())
        /
        (stddev(petal_width) over ())::FLOAT
    )
    *
    1
    +
    0

 as petal_width_standardized,
    
-- Interactions
    
        
            
            
            

    
        (sepal_length * sepal_width)
    

 as sepal_length_x_sepal_width_interaction,
            

    
        (sepal_length + sepal_width)
    

 as sepal_length_plus_sepal_width_interaction,
        
            
            
            

    
        (sepal_length * petal_length)
    

 as sepal_length_x_petal_length_interaction,
            

    
        (sepal_length + petal_length)
    

 as sepal_length_plus_petal_length_interaction,
        
            
            
            

    
        (sepal_length * petal_width)
    

 as sepal_length_x_petal_width_interaction,
            

    
        (sepal_length + petal_width)
    

 as sepal_length_plus_petal_width_interaction,
        
    
        
            
            
            

    
        (sepal_width * petal_length)
    

 as sepal_width_x_petal_length_interaction,
            

    
        (sepal_width + petal_length)
    

 as sepal_width_plus_petal_length_interaction,
        
            
            
            

    
        (sepal_width * petal_width)
    

 as sepal_width_x_petal_width_interaction,
            

    
        (sepal_width + petal_width)
    

 as sepal_width_plus_petal_width_interaction,
        
    
        
            
            
            

    
        (petal_length * petal_width)
    

 as petal_length_x_petal_width_interaction,
            

    
        (petal_length + petal_width)
    

 as petal_length_plus_petal_width_interaction,
        
    
        
    
species,    
    -- Label Encoding
    

    dense_rank() over (order by species) - 1

 as species_label_encoded,
    -- One Hot Encoding
    

    

    
        
    

    

    

        case
            when species = 'setosa' then 1
            else 0
        end as is_species__setosa,

    

        case
            when species = 'versicolor' then 1
            else 0
        end as is_species__versicolor,

    

        case
            when species = 'virginica' then 1
            else 0
        end as is_species__virginica,

    

    case
        when species is null then 1
        else 0
    end as is_species__


from "analytics"."analytics"."stg_iris"
  );
  
[0m12:02:55.250315 [debug] [Thread-3  ]: SQL status: SELECT 150 in 0.039 seconds
[0m12:02:55.267323 [debug] [Thread-3  ]: Using postgres connection "model.homework.iris_processed"
[0m12:02:55.269238 [debug] [Thread-3  ]: On model.homework.iris_processed: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "homework", "target_name": "dev", "node_id": "model.homework.iris_processed"} */
alter table "analytics"."analytics"."iris_processed" rename to "iris_processed__dbt_backup"
[0m12:02:55.271742 [debug] [Thread-3  ]: SQL status: ALTER TABLE in 0.001 seconds
[0m12:02:55.281646 [debug] [Thread-3  ]: Using postgres connection "model.homework.iris_processed"
[0m12:02:55.283338 [debug] [Thread-3  ]: On model.homework.iris_processed: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "homework", "target_name": "dev", "node_id": "model.homework.iris_processed"} */
alter table "analytics"."analytics"."iris_processed__dbt_tmp" rename to "iris_processed"
[0m12:02:55.285650 [debug] [Thread-3  ]: SQL status: ALTER TABLE in 0.000 seconds
[0m12:02:55.290198 [debug] [Thread-3  ]: On model.homework.iris_processed: COMMIT
[0m12:02:55.292385 [debug] [Thread-3  ]: Using postgres connection "model.homework.iris_processed"
[0m12:02:55.294177 [debug] [Thread-3  ]: On model.homework.iris_processed: COMMIT
[0m12:02:55.299443 [debug] [Thread-3  ]: SQL status: COMMIT in 0.003 seconds
[0m12:02:55.306803 [debug] [Thread-3  ]: Applying DROP to: "analytics"."analytics"."iris_processed__dbt_backup"
[0m12:02:55.313621 [debug] [Thread-3  ]: Using postgres connection "model.homework.iris_processed"
[0m12:02:55.315400 [debug] [Thread-3  ]: On model.homework.iris_processed: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "homework", "target_name": "dev", "node_id": "model.homework.iris_processed"} */
drop table if exists "analytics"."analytics"."iris_processed__dbt_backup" cascade
[0m12:02:55.328541 [debug] [Thread-3  ]: SQL status: DROP TABLE in 0.011 seconds
[0m12:02:55.332546 [debug] [Thread-3  ]: On model.homework.iris_processed: Close
[0m12:02:55.335282 [debug] [Thread-3  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '621edb59-1667-43f4-a537-b767b3f7afe2', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff1f72e2700>]}
[0m12:02:55.338585 [info ] [Thread-3  ]: 2 of 2 OK created sql table model analytics.iris_processed ..................... [[32mSELECT 150[0m in 0.60s]
[0m12:02:55.341732 [debug] [Thread-3  ]: Finished running node model.homework.iris_processed
[0m12:02:55.346155 [debug] [MainThread]: Using postgres connection "master"
[0m12:02:55.348051 [debug] [MainThread]: On master: BEGIN
[0m12:02:55.349814 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m12:02:55.362541 [debug] [MainThread]: SQL status: BEGIN in 0.013 seconds
[0m12:02:55.365429 [debug] [MainThread]: On master: COMMIT
[0m12:02:55.368132 [debug] [MainThread]: Using postgres connection "master"
[0m12:02:55.370486 [debug] [MainThread]: On master: COMMIT
[0m12:02:55.372873 [debug] [MainThread]: SQL status: COMMIT in 0.000 seconds
[0m12:02:55.375627 [debug] [MainThread]: On master: Close
[0m12:02:55.377840 [debug] [MainThread]: Connection 'master' was properly closed.
[0m12:02:55.379601 [debug] [MainThread]: Connection 'model.homework.stg_iris' was properly closed.
[0m12:02:55.381370 [debug] [MainThread]: Connection 'model.homework.iris_processed' was properly closed.
[0m12:02:55.383920 [info ] [MainThread]: 
[0m12:02:55.386439 [info ] [MainThread]: Finished running 1 table model, 1 view model in 0 hours 0 minutes and 1.27 seconds (1.27s).
[0m12:02:55.390352 [debug] [MainThread]: Command end result
[0m12:02:55.485244 [debug] [MainThread]: Wrote artifact WritableManifest to /opt/airflow/dags/dbt/homework/target/manifest.json
[0m12:02:55.492695 [debug] [MainThread]: Wrote artifact SemanticManifest to /opt/airflow/dags/dbt/homework/target/semantic_manifest.json
[0m12:02:55.511076 [debug] [MainThread]: Wrote artifact RunExecutionResult to /opt/airflow/dags/dbt/homework/target/run_results.json
[0m12:02:55.512570 [info ] [MainThread]: 
[0m12:02:55.514175 [info ] [MainThread]: [32mCompleted successfully[0m
[0m12:02:55.515688 [info ] [MainThread]: 
[0m12:02:55.517806 [info ] [MainThread]: Done. PASS=2 WARN=0 ERROR=0 SKIP=0 TOTAL=2
[0m12:02:55.520202 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": true, "command_wall_clock_time": 4.5864882, "process_in_blocks": "0", "process_kernel_time": 0.517001, "process_mem_max_rss": "113816", "process_out_blocks": "0", "process_user_time": 6.224292}
[0m12:02:55.522153 [debug] [MainThread]: Command `dbt run` succeeded at 12:02:55.521928 after 4.59 seconds
[0m12:02:55.523833 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff1f745fb50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff1f49f88e0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff1f49f81c0>]}
[0m12:02:55.526069 [debug] [MainThread]: Flushing usage events
[0m12:02:56.127876 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m12:03:04.046400 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f85a98dfb20>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f85a8a00640>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f85a8a005e0>]}


============================== 12:03:04.074047 | c705700a-596b-4133-9783-860bc9078508 ==============================
[0m12:03:04.074047 [info ] [MainThread]: Running with dbt=1.9.4
[0m12:03:04.077150 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': '/opt/airflow/dags/dbt', 'debug': 'False', 'warn_error': 'None', 'log_path': '/opt/airflow/dags/dbt/homework/logs', 'fail_fast': 'True', 'version_check': 'True', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'empty': 'None', 'log_format': 'default', 'static_parser': 'True', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'introspect': 'True', 'target_path': 'None', 'invocation_command': 'dbt --profile homework test --project-dir=/opt/airflow/dags/dbt/homework --vars {"is_test": false, "data_date": "2025-04-22"} --fail-fast', 'send_anonymous_usage_stats': 'True'}
[0m12:03:04.608362 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'c705700a-596b-4133-9783-860bc9078508', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f85a717dcd0>]}
[0m12:03:04.810325 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': 'c705700a-596b-4133-9783-860bc9078508', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f85a7141760>]}
[0m12:03:04.813758 [info ] [MainThread]: Registered adapter: postgres=1.9.0
[0m12:03:05.208080 [debug] [MainThread]: checksum: b4b46bb6a239f66694dfdd44ef1792882cb61f2fd7b1ea66b3c7a170d2bb602d, vars: {'data_date': '2025-04-22', 'is_test': False}, profile: homework, target: , version: 1.9.4
[0m12:03:07.116950 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m12:03:07.123979 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m12:03:07.163380 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 1 unused configuration paths:
- seeds.homework.iris_dataset
[0m12:03:07.360867 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'c705700a-596b-4133-9783-860bc9078508', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f85a6d2f130>]}
[0m12:03:08.007500 [debug] [MainThread]: Wrote artifact WritableManifest to /opt/airflow/dags/dbt/homework/target/manifest.json
[0m12:03:08.034975 [debug] [MainThread]: Wrote artifact SemanticManifest to /opt/airflow/dags/dbt/homework/target/semantic_manifest.json
[0m12:03:08.127756 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'c705700a-596b-4133-9783-860bc9078508', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f85a6c0d970>]}
[0m12:03:08.130233 [info ] [MainThread]: Found 2 models, 1 source, 587 macros
[0m12:03:08.132811 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'c705700a-596b-4133-9783-860bc9078508', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f85a8a8fca0>]}
[0m12:03:08.140636 [warn ] [MainThread]: Nothing to do. Try checking your model configs and model specification args
[0m12:03:08.148045 [debug] [MainThread]: Command end result
[0m12:03:08.330981 [debug] [MainThread]: Wrote artifact WritableManifest to /opt/airflow/dags/dbt/homework/target/manifest.json
[0m12:03:08.345789 [debug] [MainThread]: Wrote artifact SemanticManifest to /opt/airflow/dags/dbt/homework/target/semantic_manifest.json
[0m12:03:08.366976 [debug] [MainThread]: Wrote artifact RunExecutionResult to /opt/airflow/dags/dbt/homework/target/run_results.json
[0m12:03:08.372194 [debug] [MainThread]: Resource report: {"command_name": "test", "command_success": true, "command_wall_clock_time": 4.5307064, "process_in_blocks": "0", "process_kernel_time": 0.629519, "process_mem_max_rss": "104268", "process_out_blocks": "0", "process_user_time": 6.213965}
[0m12:03:08.376136 [debug] [MainThread]: Command `dbt test` succeeded at 12:03:08.375709 after 4.54 seconds
[0m12:03:08.379130 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f85a98dfb20>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f85aa5dfd30>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f85a71a0d60>]}
[0m12:03:08.384628 [debug] [MainThread]: Flushing usage events
[0m12:03:08.961342 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m12:04:54.471224 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f9a3457aac0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f9a3369b4c0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f9a3369b460>]}


============================== 12:04:54.483946 | 483dd016-e32e-4051-8fdd-48958fdf2665 ==============================
[0m12:04:54.483946 [info ] [MainThread]: Running with dbt=1.9.4
[0m12:04:54.485975 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': '/opt/airflow/dags/dbt', 'debug': 'False', 'version_check': 'True', 'log_path': '/opt/airflow/dags/dbt/homework/logs', 'warn_error': 'None', 'fail_fast': 'False', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'empty': 'False', 'log_format': 'default', 'introspect': 'True', 'static_parser': 'True', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'target_path': 'None', 'invocation_command': 'dbt --profile homework run --project-dir=/opt/airflow/dags/dbt/homework --vars {"is_test": false, "data_date": "2025-04-23"}', 'send_anonymous_usage_stats': 'True'}
[0m12:04:54.917441 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '483dd016-e32e-4051-8fdd-48958fdf2665', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f9a31ed1460>]}
[0m12:04:55.060888 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '483dd016-e32e-4051-8fdd-48958fdf2665', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f9a33732220>]}
[0m12:04:55.063854 [info ] [MainThread]: Registered adapter: postgres=1.9.0
[0m12:04:55.380372 [debug] [MainThread]: checksum: f5df654a850f4b74beb13fbe0c7d8863b5b1a20bd535c3ac287d70e390b64d41, vars: {'data_date': '2025-04-23', 'is_test': False}, profile: homework, target: , version: 1.9.4
[0m12:04:55.644665 [info ] [MainThread]: Unable to do partial parsing because config vars, config profile, or config target have changed
[0m12:04:55.646412 [debug] [MainThread]: previous checksum: f5df654a850f4b74beb13fbe0c7d8863b5b1a20bd535c3ac287d70e390b64d41, current checksum: b4b46bb6a239f66694dfdd44ef1792882cb61f2fd7b1ea66b3c7a170d2bb602d
[0m12:04:55.648011 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'partial_parser', 'label': '483dd016-e32e-4051-8fdd-48958fdf2665', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f9a33db8d30>]}
[0m12:05:00.604659 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 1 unused configuration paths:
- seeds.homework.iris_dataset
[0m12:05:00.634682 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '483dd016-e32e-4051-8fdd-48958fdf2665', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f9a31b40130>]}
[0m12:05:00.863979 [debug] [MainThread]: Wrote artifact WritableManifest to /opt/airflow/dags/dbt/homework/target/manifest.json
[0m12:05:00.881414 [debug] [MainThread]: Wrote artifact SemanticManifest to /opt/airflow/dags/dbt/homework/target/semantic_manifest.json
[0m12:05:00.918123 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '483dd016-e32e-4051-8fdd-48958fdf2665', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f9a3075e130>]}
[0m12:05:00.919895 [info ] [MainThread]: Found 2 models, 1 source, 587 macros
[0m12:05:00.921396 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '483dd016-e32e-4051-8fdd-48958fdf2665', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f9a30801550>]}
[0m12:05:00.924978 [info ] [MainThread]: 
[0m12:05:00.926571 [info ] [MainThread]: Concurrency: 4 threads (target='dev')
[0m12:05:00.929542 [info ] [MainThread]: 
[0m12:05:00.931917 [debug] [MainThread]: Acquiring new postgres connection 'master'
[0m12:05:00.943133 [debug] [ThreadPool]: Acquiring new postgres connection 'list_analytics'
[0m12:05:01.006915 [debug] [ThreadPool]: Using postgres connection "list_analytics"
[0m12:05:01.008484 [debug] [ThreadPool]: On list_analytics: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "homework", "target_name": "dev", "connection_name": "list_analytics"} */

    select distinct nspname from pg_namespace
  
[0m12:05:01.009878 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m12:05:01.028700 [debug] [ThreadPool]: SQL status: SELECT 7 in 0.019 seconds
[0m12:05:01.034009 [debug] [ThreadPool]: On list_analytics: Close
[0m12:05:01.038361 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_analytics, now list_analytics_analytics)
[0m12:05:01.057167 [debug] [ThreadPool]: Using postgres connection "list_analytics_analytics"
[0m12:05:01.059112 [debug] [ThreadPool]: On list_analytics_analytics: BEGIN
[0m12:05:01.061925 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m12:05:01.074835 [debug] [ThreadPool]: SQL status: BEGIN in 0.013 seconds
[0m12:05:01.079046 [debug] [ThreadPool]: Using postgres connection "list_analytics_analytics"
[0m12:05:01.082196 [debug] [ThreadPool]: On list_analytics_analytics: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "homework", "target_name": "dev", "connection_name": "list_analytics_analytics"} */
select
      'analytics' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'analytics'
    union all
    select
      'analytics' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'analytics'
    union all
    select
      'analytics' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'analytics'
  
[0m12:05:01.088418 [debug] [ThreadPool]: SQL status: SELECT 3 in 0.004 seconds
[0m12:05:01.092088 [debug] [ThreadPool]: On list_analytics_analytics: ROLLBACK
[0m12:05:01.093933 [debug] [ThreadPool]: On list_analytics_analytics: Close
[0m12:05:01.109473 [debug] [MainThread]: Using postgres connection "master"
[0m12:05:01.112308 [debug] [MainThread]: On master: BEGIN
[0m12:05:01.119228 [debug] [MainThread]: Opening a new connection, currently in state init
[0m12:05:01.158103 [debug] [MainThread]: SQL status: BEGIN in 0.039 seconds
[0m12:05:01.164716 [debug] [MainThread]: Using postgres connection "master"
[0m12:05:01.170241 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "homework", "target_name": "dev", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select distinct
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v', 'm')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
[0m12:05:01.188800 [debug] [MainThread]: SQL status: SELECT 1 in 0.015 seconds
[0m12:05:01.193700 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '483dd016-e32e-4051-8fdd-48958fdf2665', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f9a307e0880>]}
[0m12:05:01.197489 [debug] [MainThread]: On master: ROLLBACK
[0m12:05:01.200780 [debug] [MainThread]: Using postgres connection "master"
[0m12:05:01.203462 [debug] [MainThread]: On master: BEGIN
[0m12:05:01.207161 [debug] [MainThread]: SQL status: BEGIN in 0.001 seconds
[0m12:05:01.210265 [debug] [MainThread]: On master: COMMIT
[0m12:05:01.213804 [debug] [MainThread]: Using postgres connection "master"
[0m12:05:01.217530 [debug] [MainThread]: On master: COMMIT
[0m12:05:01.220686 [debug] [MainThread]: SQL status: COMMIT in 0.000 seconds
[0m12:05:01.223936 [debug] [MainThread]: On master: Close
[0m12:05:01.239658 [debug] [Thread-1  ]: Began running node model.homework.stg_iris
[0m12:05:01.243158 [info ] [Thread-1  ]: 1 of 2 START sql view model analytics.stg_iris ................................. [RUN]
[0m12:05:01.249818 [debug] [Thread-1  ]: Re-using an available connection from the pool (formerly list_analytics_analytics, now model.homework.stg_iris)
[0m12:05:01.256669 [debug] [Thread-1  ]: Began compiling node model.homework.stg_iris
[0m12:05:01.295502 [debug] [Thread-1  ]: Writing injected SQL for node "model.homework.stg_iris"
[0m12:05:01.305782 [debug] [Thread-1  ]: Began executing node model.homework.stg_iris
[0m12:05:01.397773 [debug] [Thread-1  ]: Writing runtime sql for node "model.homework.stg_iris"
[0m12:05:01.407870 [debug] [Thread-1  ]: Using postgres connection "model.homework.stg_iris"
[0m12:05:01.409599 [debug] [Thread-1  ]: On model.homework.stg_iris: BEGIN
[0m12:05:01.411550 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
[0m12:05:01.422862 [debug] [Thread-1  ]: SQL status: BEGIN in 0.011 seconds
[0m12:05:01.425256 [debug] [Thread-1  ]: Using postgres connection "model.homework.stg_iris"
[0m12:05:01.427428 [debug] [Thread-1  ]: On model.homework.stg_iris: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "homework", "target_name": "dev", "node_id": "model.homework.stg_iris"} */

  create view "analytics"."analytics"."stg_iris__dbt_tmp"
    
    
  as (
    with source as (
    select * from "analytics"."analytics"."iris_dataset"
)

select
    cast(sepal_length as numeric) as sepal_length,
    cast(sepal_width as numeric) as sepal_width,
    cast(petal_length as numeric) as petal_length,
    cast(petal_width as numeric) as petal_width,
    species
from source
  );
[0m12:05:01.433743 [debug] [Thread-1  ]: SQL status: CREATE VIEW in 0.003 seconds
[0m12:05:01.453668 [debug] [Thread-1  ]: Using postgres connection "model.homework.stg_iris"
[0m12:05:01.455529 [debug] [Thread-1  ]: On model.homework.stg_iris: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "homework", "target_name": "dev", "node_id": "model.homework.stg_iris"} */
alter table "analytics"."analytics"."stg_iris" rename to "stg_iris__dbt_backup"
[0m12:05:01.457843 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.001 seconds
[0m12:05:01.468521 [debug] [Thread-1  ]: Using postgres connection "model.homework.stg_iris"
[0m12:05:01.470386 [debug] [Thread-1  ]: On model.homework.stg_iris: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "homework", "target_name": "dev", "node_id": "model.homework.stg_iris"} */
alter table "analytics"."analytics"."stg_iris__dbt_tmp" rename to "stg_iris"
[0m12:05:01.472707 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.001 seconds
[0m12:05:01.514415 [debug] [Thread-1  ]: On model.homework.stg_iris: COMMIT
[0m12:05:01.516441 [debug] [Thread-1  ]: Using postgres connection "model.homework.stg_iris"
[0m12:05:01.518261 [debug] [Thread-1  ]: On model.homework.stg_iris: COMMIT
[0m12:05:01.523386 [debug] [Thread-1  ]: SQL status: COMMIT in 0.003 seconds
[0m12:05:01.541463 [debug] [Thread-1  ]: Applying DROP to: "analytics"."analytics"."stg_iris__dbt_backup"
[0m12:05:01.555571 [debug] [Thread-1  ]: Using postgres connection "model.homework.stg_iris"
[0m12:05:01.557704 [debug] [Thread-1  ]: On model.homework.stg_iris: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "homework", "target_name": "dev", "node_id": "model.homework.stg_iris"} */
drop view if exists "analytics"."analytics"."stg_iris__dbt_backup" cascade
[0m12:05:01.565157 [debug] [Thread-1  ]: SQL status: DROP VIEW in 0.005 seconds
[0m12:05:01.572657 [debug] [Thread-1  ]: On model.homework.stg_iris: Close
[0m12:05:01.579864 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '483dd016-e32e-4051-8fdd-48958fdf2665', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f9a31b652e0>]}
[0m12:05:01.582857 [info ] [Thread-1  ]: 1 of 2 OK created sql view model analytics.stg_iris ............................ [[32mCREATE VIEW[0m in 0.33s]
[0m12:05:01.586525 [debug] [Thread-1  ]: Finished running node model.homework.stg_iris
[0m12:05:01.589887 [debug] [Thread-3  ]: Began running node model.homework.iris_processed
[0m12:05:01.592129 [info ] [Thread-3  ]: 2 of 2 START sql table model analytics.iris_processed .......................... [RUN]
[0m12:05:01.594315 [debug] [Thread-3  ]: Acquiring new postgres connection 'model.homework.iris_processed'
[0m12:05:01.597682 [debug] [Thread-3  ]: Began compiling node model.homework.iris_processed
[0m12:05:01.657963 [debug] [Thread-3  ]: Using postgres connection "model.homework.iris_processed"
[0m12:05:01.660247 [debug] [Thread-3  ]: On model.homework.iris_processed: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "homework", "target_name": "dev", "node_id": "model.homework.iris_processed"} */

        select percentile_cont(0.5) within group (order by sepal_length ) from "analytics"."analytics"."stg_iris"
    
[0m12:05:01.663374 [debug] [Thread-3  ]: Opening a new connection, currently in state init
[0m12:05:01.680129 [debug] [Thread-3  ]: SQL status: SELECT 1 in 0.017 seconds
[0m12:05:01.685440 [debug] [Thread-3  ]: Using postgres connection "model.homework.iris_processed"
[0m12:05:01.687808 [debug] [Thread-3  ]: On model.homework.iris_processed: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "homework", "target_name": "dev", "node_id": "model.homework.iris_processed"} */

        select percentile_cont(0.5 - 0.5/2) within group (order by sepal_length ) from "analytics"."analytics"."stg_iris"
    
[0m12:05:01.690653 [debug] [Thread-3  ]: SQL status: SELECT 1 in 0.001 seconds
[0m12:05:01.695474 [debug] [Thread-3  ]: Using postgres connection "model.homework.iris_processed"
[0m12:05:01.698095 [debug] [Thread-3  ]: On model.homework.iris_processed: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "homework", "target_name": "dev", "node_id": "model.homework.iris_processed"} */

        select percentile_cont(0.5 + 0.5/2) within group (order by sepal_length ) from "analytics"."analytics"."stg_iris"
    
[0m12:05:01.700836 [debug] [Thread-3  ]: SQL status: SELECT 1 in 0.001 seconds
[0m12:05:01.707572 [debug] [Thread-3  ]: Using postgres connection "model.homework.iris_processed"
[0m12:05:01.709618 [debug] [Thread-3  ]: On model.homework.iris_processed: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "homework", "target_name": "dev", "node_id": "model.homework.iris_processed"} */

        select percentile_cont(0.5) within group (order by sepal_width ) from "analytics"."analytics"."stg_iris"
    
[0m12:05:01.713077 [debug] [Thread-3  ]: SQL status: SELECT 1 in 0.001 seconds
[0m12:05:01.717864 [debug] [Thread-3  ]: Using postgres connection "model.homework.iris_processed"
[0m12:05:01.719513 [debug] [Thread-3  ]: On model.homework.iris_processed: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "homework", "target_name": "dev", "node_id": "model.homework.iris_processed"} */

        select percentile_cont(0.5 - 0.5/2) within group (order by sepal_width ) from "analytics"."analytics"."stg_iris"
    
[0m12:05:01.722057 [debug] [Thread-3  ]: SQL status: SELECT 1 in 0.001 seconds
[0m12:05:01.726152 [debug] [Thread-3  ]: Using postgres connection "model.homework.iris_processed"
[0m12:05:01.728176 [debug] [Thread-3  ]: On model.homework.iris_processed: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "homework", "target_name": "dev", "node_id": "model.homework.iris_processed"} */

        select percentile_cont(0.5 + 0.5/2) within group (order by sepal_width ) from "analytics"."analytics"."stg_iris"
    
[0m12:05:01.731154 [debug] [Thread-3  ]: SQL status: SELECT 1 in 0.001 seconds
[0m12:05:01.737940 [debug] [Thread-3  ]: Using postgres connection "model.homework.iris_processed"
[0m12:05:01.739791 [debug] [Thread-3  ]: On model.homework.iris_processed: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "homework", "target_name": "dev", "node_id": "model.homework.iris_processed"} */

        select percentile_cont(0.5) within group (order by petal_length ) from "analytics"."analytics"."stg_iris"
    
[0m12:05:01.742278 [debug] [Thread-3  ]: SQL status: SELECT 1 in 0.001 seconds
[0m12:05:01.747403 [debug] [Thread-3  ]: Using postgres connection "model.homework.iris_processed"
[0m12:05:01.749642 [debug] [Thread-3  ]: On model.homework.iris_processed: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "homework", "target_name": "dev", "node_id": "model.homework.iris_processed"} */

        select percentile_cont(0.5 - 0.5/2) within group (order by petal_length ) from "analytics"."analytics"."stg_iris"
    
[0m12:05:01.752240 [debug] [Thread-3  ]: SQL status: SELECT 1 in 0.001 seconds
[0m12:05:01.756069 [debug] [Thread-3  ]: Using postgres connection "model.homework.iris_processed"
[0m12:05:01.757767 [debug] [Thread-3  ]: On model.homework.iris_processed: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "homework", "target_name": "dev", "node_id": "model.homework.iris_processed"} */

        select percentile_cont(0.5 + 0.5/2) within group (order by petal_length ) from "analytics"."analytics"."stg_iris"
    
[0m12:05:01.760114 [debug] [Thread-3  ]: SQL status: SELECT 1 in 0.001 seconds
[0m12:05:01.766297 [debug] [Thread-3  ]: Using postgres connection "model.homework.iris_processed"
[0m12:05:01.768222 [debug] [Thread-3  ]: On model.homework.iris_processed: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "homework", "target_name": "dev", "node_id": "model.homework.iris_processed"} */

        select percentile_cont(0.5) within group (order by petal_width ) from "analytics"."analytics"."stg_iris"
    
[0m12:05:01.770678 [debug] [Thread-3  ]: SQL status: SELECT 1 in 0.001 seconds
[0m12:05:01.774916 [debug] [Thread-3  ]: Using postgres connection "model.homework.iris_processed"
[0m12:05:01.776657 [debug] [Thread-3  ]: On model.homework.iris_processed: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "homework", "target_name": "dev", "node_id": "model.homework.iris_processed"} */

        select percentile_cont(0.5 - 0.5/2) within group (order by petal_width ) from "analytics"."analytics"."stg_iris"
    
[0m12:05:01.779759 [debug] [Thread-3  ]: SQL status: SELECT 1 in 0.001 seconds
[0m12:05:01.784183 [debug] [Thread-3  ]: Using postgres connection "model.homework.iris_processed"
[0m12:05:01.785896 [debug] [Thread-3  ]: On model.homework.iris_processed: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "homework", "target_name": "dev", "node_id": "model.homework.iris_processed"} */

        select percentile_cont(0.5 + 0.5/2) within group (order by petal_width ) from "analytics"."analytics"."stg_iris"
    
[0m12:05:01.788354 [debug] [Thread-3  ]: SQL status: SELECT 1 in 0.001 seconds
[0m12:05:01.796776 [debug] [Thread-3  ]: Using postgres connection "model.homework.iris_processed"
[0m12:05:01.798669 [debug] [Thread-3  ]: On model.homework.iris_processed: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "homework", "target_name": "dev", "node_id": "model.homework.iris_processed"} */

            select percentile_cont(0.5) within group (order by sepal_length ) from "analytics"."analytics"."stg_iris"
        
[0m12:05:01.801111 [debug] [Thread-3  ]: SQL status: SELECT 1 in 0.001 seconds
[0m12:05:01.805629 [debug] [Thread-3  ]: Using postgres connection "model.homework.iris_processed"
[0m12:05:01.807343 [debug] [Thread-3  ]: On model.homework.iris_processed: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "homework", "target_name": "dev", "node_id": "model.homework.iris_processed"} */

            select percentile_cont(0.5) within group (order by sepal_width ) from "analytics"."analytics"."stg_iris"
        
[0m12:05:01.809723 [debug] [Thread-3  ]: SQL status: SELECT 1 in 0.001 seconds
[0m12:05:01.815206 [debug] [Thread-3  ]: Using postgres connection "model.homework.iris_processed"
[0m12:05:01.817087 [debug] [Thread-3  ]: On model.homework.iris_processed: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "homework", "target_name": "dev", "node_id": "model.homework.iris_processed"} */

            select percentile_cont(0.5) within group (order by petal_length ) from "analytics"."analytics"."stg_iris"
        
[0m12:05:01.819446 [debug] [Thread-3  ]: SQL status: SELECT 1 in 0.001 seconds
[0m12:05:01.824533 [debug] [Thread-3  ]: Using postgres connection "model.homework.iris_processed"
[0m12:05:01.826324 [debug] [Thread-3  ]: On model.homework.iris_processed: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "homework", "target_name": "dev", "node_id": "model.homework.iris_processed"} */

            select percentile_cont(0.5) within group (order by petal_width ) from "analytics"."analytics"."stg_iris"
        
[0m12:05:01.829453 [debug] [Thread-3  ]: SQL status: SELECT 1 in 0.001 seconds
[0m12:05:01.854013 [debug] [Thread-3  ]: Using postgres connection "model.homework.iris_processed"
[0m12:05:01.855729 [debug] [Thread-3  ]: On model.homework.iris_processed: BEGIN
[0m12:05:01.860102 [debug] [Thread-3  ]: SQL status: BEGIN in 0.003 seconds
[0m12:05:01.863367 [debug] [Thread-3  ]: Using postgres connection "model.homework.iris_processed"
[0m12:05:01.865657 [debug] [Thread-3  ]: On model.homework.iris_processed: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "homework", "target_name": "dev", "node_id": "model.homework.iris_processed"} */
select
                species as value

            from "analytics"."analytics"."stg_iris"

            
            where species is not null  and true
            

            group by species
            order by species

            

        
[0m12:05:01.868848 [debug] [Thread-3  ]: SQL status: SELECT 3 in 0.001 seconds
[0m12:05:01.883982 [debug] [Thread-3  ]: Writing injected SQL for node "model.homework.iris_processed"
[0m12:05:01.894876 [debug] [Thread-3  ]: Began executing node model.homework.iris_processed
[0m12:05:01.953666 [debug] [Thread-3  ]: Writing runtime sql for node "model.homework.iris_processed"
[0m12:05:01.965180 [debug] [Thread-3  ]: Using postgres connection "model.homework.iris_processed"
[0m12:05:01.968399 [debug] [Thread-3  ]: On model.homework.iris_processed: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "homework", "target_name": "dev", "node_id": "model.homework.iris_processed"} */

  
    

  create  table "analytics"."analytics"."iris_processed__dbt_tmp"
  
  
    as
  
  (
    

with import_iris as (
    select *
    from "analytics"."analytics"."stg_iris"
)
select
    sepal_length,
    sepal_width,
    petal_length,
    petal_width,
    -- K Bins Discretization
    
        

    
        NTILE(5) over (order by sepal_length)
    

 as sepal_length_quantile_bin,
        

    
        
        floor(
        (
            sepal_length - (min(sepal_length) over ())
        )
        /
        (
            ((max(sepal_length) over ()) - (min(sepal_length) over ())) / 4::float
        )
        ) + 1
    

 as sepal_length_uniform_bin,
    
        

    
        NTILE(5) over (order by sepal_width)
    

 as sepal_width_quantile_bin,
        

    
        
        floor(
        (
            sepal_width - (min(sepal_width) over ())
        )
        /
        (
            ((max(sepal_width) over ()) - (min(sepal_width) over ())) / 4::float
        )
        ) + 1
    

 as sepal_width_uniform_bin,
    
        

    
        NTILE(5) over (order by petal_length)
    

 as petal_length_quantile_bin,
        

    
        
        floor(
        (
            petal_length - (min(petal_length) over ())
        )
        /
        (
            ((max(petal_length) over ()) - (min(petal_length) over ())) / 4::float
        )
        ) + 1
    

 as petal_length_uniform_bin,
    
        

    
        NTILE(5) over (order by petal_width)
    

 as petal_width_quantile_bin,
        

    
        
        floor(
        (
            petal_width - (min(petal_width) over ())
        )
        /
        (
            ((max(petal_width) over ()) - (min(petal_width) over ())) / 4::float
        )
        ) + 1
    

 as petal_width_uniform_bin,
    
-- Scaling
    
        

    

    
    
    

    
    
    

    (
        sepal_length - 5.8
    )
    /
    (
        6.4 - 5.1
    )

 as sepal_length_robust_scaled,
        

    (sepal_length) / (max(abs(sepal_length)) over ())::FLOAT

 as sepal_length_max_absolute_scaled,
        

    
    (
        ((sepal_length) - (min(sepal_length) over ()))
        /
        ((max(sepal_length) over ()) - (min(sepal_length) over ()))::FLOAT
    )
    *
    (1.0 - 0.0)
    +
    0.0

 as sepal_length_max_min_max_scaled,
    
        

    

    
    
    

    
    
    

    (
        sepal_width - 3.0
    )
    /
    (
        3.3 - 2.8
    )

 as sepal_width_robust_scaled,
        

    (sepal_width) / (max(abs(sepal_width)) over ())::FLOAT

 as sepal_width_max_absolute_scaled,
        

    
    (
        ((sepal_width) - (min(sepal_width) over ()))
        /
        ((max(sepal_width) over ()) - (min(sepal_width) over ()))::FLOAT
    )
    *
    (1.0 - 0.0)
    +
    0.0

 as sepal_width_max_min_max_scaled,
    
        

    

    
    
    

    
    
    

    (
        petal_length - 4.35
    )
    /
    (
        5.1 - 1.6
    )

 as petal_length_robust_scaled,
        

    (petal_length) / (max(abs(petal_length)) over ())::FLOAT

 as petal_length_max_absolute_scaled,
        

    
    (
        ((petal_length) - (min(petal_length) over ()))
        /
        ((max(petal_length) over ()) - (min(petal_length) over ()))::FLOAT
    )
    *
    (1.0 - 0.0)
    +
    0.0

 as petal_length_max_min_max_scaled,
    
        

    

    
    
    

    
    
    

    (
        petal_width - 1.3
    )
    /
    (
        1.8 - 0.3
    )

 as petal_width_robust_scaled,
        

    (petal_width) / (max(abs(petal_width)) over ())::FLOAT

 as petal_width_max_absolute_scaled,
        

    
    (
        ((petal_width) - (min(petal_width) over ()))
        /
        ((max(petal_width) over ()) - (min(petal_width) over ()))::FLOAT
    )
    *
    (1.0 - 0.0)
    +
    0.0

 as petal_width_max_min_max_scaled,
    

    -- Log Transformation
    
        

    case
        when sepal_length is null or sepal_length + 0 <= 0 then null
        else log(10, sepal_length + 0)
    end

 as sepal_length_logged,
    
        

    case
        when sepal_width is null or sepal_width + 0 <= 0 then null
        else log(10, sepal_width + 0)
    end

 as sepal_width_logged,
    
        

    case
        when petal_length is null or petal_length + 0 <= 0 then null
        else log(10, petal_length + 0)
    end

 as petal_length_logged,
    
        

    case
        when petal_width is null or petal_width + 0 <= 0 then null
        else log(10, petal_width + 0)
    end

 as petal_width_logged,
    

    -- Binarization
    
        

    

    
        

        
    

    case
        when sepal_length >=
            
                5.8
            
            then 1
        else 0
    end

 as sepal_length_binarized,
    
        

    

    
        

        
    

    case
        when sepal_width >=
            
                3.0
            
            then 1
        else 0
    end

 as sepal_width_binarized,
    
        

    

    
        

        
    

    case
        when petal_length >=
            
                4.35
            
            then 1
        else 0
    end

 as petal_length_binarized,
    
        

    

    
        

        
    

    case
        when petal_width >=
            
                1.3
            
            then 1
        else 0
    end

 as petal_width_binarized,
    

    -- Standardization
    
        

    
    (
        (sepal_length - avg(sepal_length) over ())
        /
        (stddev(sepal_length) over ())::FLOAT
    )
    *
    1
    +
    0

 as sepal_length_standardized,
    
        

    
    (
        (sepal_width - avg(sepal_width) over ())
        /
        (stddev(sepal_width) over ())::FLOAT
    )
    *
    1
    +
    0

 as sepal_width_standardized,
    
        

    
    (
        (petal_length - avg(petal_length) over ())
        /
        (stddev(petal_length) over ())::FLOAT
    )
    *
    1
    +
    0

 as petal_length_standardized,
    
        

    
    (
        (petal_width - avg(petal_width) over ())
        /
        (stddev(petal_width) over ())::FLOAT
    )
    *
    1
    +
    0

 as petal_width_standardized,
    
-- Interactions
    
        
            
            
            

    
        (sepal_length * sepal_width)
    

 as sepal_length_x_sepal_width_interaction,
            

    
        (sepal_length + sepal_width)
    

 as sepal_length_plus_sepal_width_interaction,
        
            
            
            

    
        (sepal_length * petal_length)
    

 as sepal_length_x_petal_length_interaction,
            

    
        (sepal_length + petal_length)
    

 as sepal_length_plus_petal_length_interaction,
        
            
            
            

    
        (sepal_length * petal_width)
    

 as sepal_length_x_petal_width_interaction,
            

    
        (sepal_length + petal_width)
    

 as sepal_length_plus_petal_width_interaction,
        
    
        
            
            
            

    
        (sepal_width * petal_length)
    

 as sepal_width_x_petal_length_interaction,
            

    
        (sepal_width + petal_length)
    

 as sepal_width_plus_petal_length_interaction,
        
            
            
            

    
        (sepal_width * petal_width)
    

 as sepal_width_x_petal_width_interaction,
            

    
        (sepal_width + petal_width)
    

 as sepal_width_plus_petal_width_interaction,
        
    
        
            
            
            

    
        (petal_length * petal_width)
    

 as petal_length_x_petal_width_interaction,
            

    
        (petal_length + petal_width)
    

 as petal_length_plus_petal_width_interaction,
        
    
        
    
species,    
    -- Label Encoding
    

    dense_rank() over (order by species) - 1

 as species_label_encoded,
    -- One Hot Encoding
    

    

    
        
    

    

    

        case
            when species = 'setosa' then 1
            else 0
        end as is_species__setosa,

    

        case
            when species = 'versicolor' then 1
            else 0
        end as is_species__versicolor,

    

        case
            when species = 'virginica' then 1
            else 0
        end as is_species__virginica,

    

    case
        when species is null then 1
        else 0
    end as is_species__


from "analytics"."analytics"."stg_iris"
  );
  
[0m12:05:02.010982 [debug] [Thread-3  ]: SQL status: SELECT 150 in 0.039 seconds
[0m12:05:02.031050 [debug] [Thread-3  ]: Using postgres connection "model.homework.iris_processed"
[0m12:05:02.033109 [debug] [Thread-3  ]: On model.homework.iris_processed: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "homework", "target_name": "dev", "node_id": "model.homework.iris_processed"} */
alter table "analytics"."analytics"."iris_processed" rename to "iris_processed__dbt_backup"
[0m12:05:02.035509 [debug] [Thread-3  ]: SQL status: ALTER TABLE in 0.001 seconds
[0m12:05:02.044124 [debug] [Thread-3  ]: Using postgres connection "model.homework.iris_processed"
[0m12:05:02.046457 [debug] [Thread-3  ]: On model.homework.iris_processed: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "homework", "target_name": "dev", "node_id": "model.homework.iris_processed"} */
alter table "analytics"."analytics"."iris_processed__dbt_tmp" rename to "iris_processed"
[0m12:05:02.049129 [debug] [Thread-3  ]: SQL status: ALTER TABLE in 0.001 seconds
[0m12:05:02.054054 [debug] [Thread-3  ]: On model.homework.iris_processed: COMMIT
[0m12:05:02.055821 [debug] [Thread-3  ]: Using postgres connection "model.homework.iris_processed"
[0m12:05:02.057447 [debug] [Thread-3  ]: On model.homework.iris_processed: COMMIT
[0m12:05:02.063424 [debug] [Thread-3  ]: SQL status: COMMIT in 0.004 seconds
[0m12:05:02.071561 [debug] [Thread-3  ]: Applying DROP to: "analytics"."analytics"."iris_processed__dbt_backup"
[0m12:05:02.079465 [debug] [Thread-3  ]: Using postgres connection "model.homework.iris_processed"
[0m12:05:02.081710 [debug] [Thread-3  ]: On model.homework.iris_processed: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "homework", "target_name": "dev", "node_id": "model.homework.iris_processed"} */
drop table if exists "analytics"."analytics"."iris_processed__dbt_backup" cascade
[0m12:05:02.089501 [debug] [Thread-3  ]: SQL status: DROP TABLE in 0.006 seconds
[0m12:05:02.093297 [debug] [Thread-3  ]: On model.homework.iris_processed: Close
[0m12:05:02.096249 [debug] [Thread-3  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '483dd016-e32e-4051-8fdd-48958fdf2665', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f9a3029cd00>]}
[0m12:05:02.099343 [info ] [Thread-3  ]: 2 of 2 OK created sql table model analytics.iris_processed ..................... [[32mSELECT 150[0m in 0.50s]
[0m12:05:02.101872 [debug] [Thread-3  ]: Finished running node model.homework.iris_processed
[0m12:05:02.106578 [debug] [MainThread]: Using postgres connection "master"
[0m12:05:02.108439 [debug] [MainThread]: On master: BEGIN
[0m12:05:02.110153 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m12:05:02.124105 [debug] [MainThread]: SQL status: BEGIN in 0.014 seconds
[0m12:05:02.127059 [debug] [MainThread]: On master: COMMIT
[0m12:05:02.130415 [debug] [MainThread]: Using postgres connection "master"
[0m12:05:02.133339 [debug] [MainThread]: On master: COMMIT
[0m12:05:02.135717 [debug] [MainThread]: SQL status: COMMIT in 0.000 seconds
[0m12:05:02.138183 [debug] [MainThread]: On master: Close
[0m12:05:02.140745 [debug] [MainThread]: Connection 'master' was properly closed.
[0m12:05:02.142516 [debug] [MainThread]: Connection 'model.homework.stg_iris' was properly closed.
[0m12:05:02.144440 [debug] [MainThread]: Connection 'model.homework.iris_processed' was properly closed.
[0m12:05:02.147372 [info ] [MainThread]: 
[0m12:05:02.149524 [info ] [MainThread]: Finished running 1 table model, 1 view model in 0 hours 0 minutes and 1.22 seconds (1.22s).
[0m12:05:02.152366 [debug] [MainThread]: Command end result
[0m12:05:02.253881 [debug] [MainThread]: Wrote artifact WritableManifest to /opt/airflow/dags/dbt/homework/target/manifest.json
[0m12:05:02.260944 [debug] [MainThread]: Wrote artifact SemanticManifest to /opt/airflow/dags/dbt/homework/target/semantic_manifest.json
[0m12:05:02.278815 [debug] [MainThread]: Wrote artifact RunExecutionResult to /opt/airflow/dags/dbt/homework/target/run_results.json
[0m12:05:02.281131 [info ] [MainThread]: 
[0m12:05:02.282963 [info ] [MainThread]: [32mCompleted successfully[0m
[0m12:05:02.284628 [info ] [MainThread]: 
[0m12:05:02.286303 [info ] [MainThread]: Done. PASS=2 WARN=0 ERROR=0 SKIP=0 TOTAL=2
[0m12:05:02.288965 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": true, "command_wall_clock_time": 7.9698997, "process_in_blocks": "0", "process_kernel_time": 0.52554, "process_mem_max_rss": "118888", "process_out_blocks": "0", "process_user_time": 9.298023}
[0m12:05:02.290863 [debug] [MainThread]: Command `dbt run` succeeded at 12:05:02.290631 after 7.97 seconds
[0m12:05:02.292551 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f9a3457aac0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f9a33732220>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f9a343a7160>]}
[0m12:05:02.294236 [debug] [MainThread]: Flushing usage events
[0m12:05:02.907981 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m12:05:10.811739 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3b3abc4b50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3b39ce76a0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3b39ce7640>]}


============================== 12:05:10.827036 | 94d91907-f85c-418a-9cf8-43b72603d1bc ==============================
[0m12:05:10.827036 [info ] [MainThread]: Running with dbt=1.9.4
[0m12:05:10.829474 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': '/opt/airflow/dags/dbt', 'version_check': 'True', 'debug': 'False', 'log_path': '/opt/airflow/dags/dbt/homework/logs', 'fail_fast': 'True', 'warn_error': 'None', 'use_colors': 'True', 'use_experimental_parser': 'False', 'empty': 'None', 'quiet': 'False', 'no_print': 'None', 'log_format': 'default', 'invocation_command': 'dbt --profile homework test --project-dir=/opt/airflow/dags/dbt/homework --vars {"is_test": false, "data_date": "2025-04-23"} --fail-fast', 'static_parser': 'True', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'target_path': 'None', 'introspect': 'True', 'send_anonymous_usage_stats': 'True'}
[0m12:05:11.418563 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '94d91907-f85c-418a-9cf8-43b72603d1bc', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3b3c5ac9a0>]}
[0m12:05:11.572168 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '94d91907-f85c-418a-9cf8-43b72603d1bc', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3b39eaf040>]}
[0m12:05:11.575817 [info ] [MainThread]: Registered adapter: postgres=1.9.0
[0m12:05:11.868831 [debug] [MainThread]: checksum: f5df654a850f4b74beb13fbe0c7d8863b5b1a20bd535c3ac287d70e390b64d41, vars: {'data_date': '2025-04-23', 'is_test': False}, profile: homework, target: , version: 1.9.4
[0m12:05:13.108687 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m12:05:13.110487 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m12:05:13.128128 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 1 unused configuration paths:
- seeds.homework.iris_dataset
[0m12:05:13.210375 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '94d91907-f85c-418a-9cf8-43b72603d1bc', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3b38015130>]}
[0m12:05:13.530381 [debug] [MainThread]: Wrote artifact WritableManifest to /opt/airflow/dags/dbt/homework/target/manifest.json
[0m12:05:13.552124 [debug] [MainThread]: Wrote artifact SemanticManifest to /opt/airflow/dags/dbt/homework/target/semantic_manifest.json
[0m12:05:13.624566 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '94d91907-f85c-418a-9cf8-43b72603d1bc', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3b37ef3d00>]}
[0m12:05:13.626775 [info ] [MainThread]: Found 2 models, 1 source, 587 macros
[0m12:05:13.628890 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '94d91907-f85c-418a-9cf8-43b72603d1bc', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3b37effdf0>]}
[0m12:05:13.632644 [warn ] [MainThread]: Nothing to do. Try checking your model configs and model specification args
[0m12:05:13.638438 [debug] [MainThread]: Command end result
[0m12:05:13.737076 [debug] [MainThread]: Wrote artifact WritableManifest to /opt/airflow/dags/dbt/homework/target/manifest.json
[0m12:05:13.746871 [debug] [MainThread]: Wrote artifact SemanticManifest to /opt/airflow/dags/dbt/homework/target/semantic_manifest.json
[0m12:05:13.758436 [debug] [MainThread]: Wrote artifact RunExecutionResult to /opt/airflow/dags/dbt/homework/target/run_results.json
[0m12:05:13.760855 [debug] [MainThread]: Resource report: {"command_name": "test", "command_success": true, "command_wall_clock_time": 3.0985467, "process_in_blocks": "0", "process_kernel_time": 0.331905, "process_mem_max_rss": "104536", "process_out_blocks": "0", "process_user_time": 5.370839}
[0m12:05:13.762749 [debug] [MainThread]: Command `dbt test` succeeded at 12:05:13.762528 after 3.10 seconds
[0m12:05:13.764559 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3b3abc4b50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3b3aa834f0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3b39eaf040>]}
[0m12:05:13.766308 [debug] [MainThread]: Flushing usage events
[0m12:05:14.287194 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m12:09:58.231808 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6addcf8b20>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6adce19490>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6adce19430>]}


============================== 12:09:58.255896 | 7eb3bf65-45e0-4ffc-8950-a407449a6ca1 ==============================
[0m12:09:58.255896 [info ] [MainThread]: Running with dbt=1.9.4
[0m12:09:58.259636 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': '/opt/airflow/dags/dbt', 'version_check': 'True', 'warn_error': 'None', 'log_path': '/opt/airflow/dags/dbt/homework/logs', 'debug': 'False', 'fail_fast': 'False', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'empty': 'False', 'log_format': 'default', 'introspect': 'True', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'static_parser': 'True', 'target_path': 'None', 'invocation_command': 'dbt --profile homework run --project-dir=/opt/airflow/dags/dbt/homework --vars {"is_test": false, "data_date": "2025-04-23"}', 'send_anonymous_usage_stats': 'True'}
[0m12:09:58.611309 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3edc04eb50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3edb1704f0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3edb170490>]}


============================== 12:09:58.648764 | f6e14081-fb1e-4635-b585-accb55251936 ==============================
[0m12:09:58.648764 [info ] [MainThread]: Running with dbt=1.9.4
[0m12:09:58.651496 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'debug': 'False', 'fail_fast': 'False', 'log_path': '/opt/airflow/dags/dbt/homework/logs', 'version_check': 'True', 'profiles_dir': '/opt/airflow/dags/dbt', 'use_colors': 'True', 'use_experimental_parser': 'False', 'empty': 'False', 'quiet': 'False', 'no_print': 'None', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'invocation_command': 'dbt --profile homework run --project-dir=/opt/airflow/dags/dbt/homework --vars {"is_test": false, "data_date": "2025-04-22"}', 'static_parser': 'True', 'introspect': 'True', 'target_path': 'None', 'log_format': 'default', 'send_anonymous_usage_stats': 'True'}
[0m12:09:58.903740 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '7eb3bf65-45e0-4ffc-8950-a407449a6ca1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6adb68e880>]}
[0m12:09:59.084185 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '7eb3bf65-45e0-4ffc-8950-a407449a6ca1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6adb63f280>]}
[0m12:09:59.086696 [info ] [MainThread]: Registered adapter: postgres=1.9.0
[0m12:09:59.240558 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'f6e14081-fb1e-4635-b585-accb55251936', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3edb1b0fa0>]}
[0m12:09:59.428413 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': 'f6e14081-fb1e-4635-b585-accb55251936', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3edb831040>]}
[0m12:09:59.431808 [info ] [MainThread]: Registered adapter: postgres=1.9.0
[0m12:09:59.467615 [debug] [MainThread]: checksum: f5df654a850f4b74beb13fbe0c7d8863b5b1a20bd535c3ac287d70e390b64d41, vars: {'data_date': '2025-04-23', 'is_test': False}, profile: homework, target: , version: 1.9.4
[0m12:09:59.860634 [debug] [MainThread]: checksum: b4b46bb6a239f66694dfdd44ef1792882cb61f2fd7b1ea66b3c7a170d2bb602d, vars: {'data_date': '2025-04-22', 'is_test': False}, profile: homework, target: , version: 1.9.4
[0m12:10:00.326052 [info ] [MainThread]: Unable to do partial parsing because config vars, config profile, or config target have changed
[0m12:10:00.328016 [debug] [MainThread]: previous checksum: b4b46bb6a239f66694dfdd44ef1792882cb61f2fd7b1ea66b3c7a170d2bb602d, current checksum: f5df654a850f4b74beb13fbe0c7d8863b5b1a20bd535c3ac287d70e390b64d41
[0m12:10:00.330003 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'partial_parser', 'label': 'f6e14081-fb1e-4635-b585-accb55251936', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3edb831070>]}
[0m12:10:01.275252 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m12:10:01.278258 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m12:10:01.300587 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 1 unused configuration paths:
- seeds.homework.iris_dataset
[0m12:10:01.497860 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '7eb3bf65-45e0-4ffc-8950-a407449a6ca1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6adb146130>]}
[0m12:10:02.058711 [debug] [MainThread]: Wrote artifact WritableManifest to /opt/airflow/dags/dbt/homework/target/manifest.json
[0m12:10:02.092128 [debug] [MainThread]: Wrote artifact SemanticManifest to /opt/airflow/dags/dbt/homework/target/semantic_manifest.json
[0m12:10:02.147713 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '7eb3bf65-45e0-4ffc-8950-a407449a6ca1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6adce7fb50>]}
[0m12:10:02.150657 [info ] [MainThread]: Found 2 models, 1 source, 587 macros
[0m12:10:02.152487 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '7eb3bf65-45e0-4ffc-8950-a407449a6ca1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6adeb0a550>]}
[0m12:10:02.156413 [info ] [MainThread]: 
[0m12:10:02.158403 [info ] [MainThread]: Concurrency: 4 threads (target='dev')
[0m12:10:02.161103 [info ] [MainThread]: 
[0m12:10:02.166033 [debug] [MainThread]: Acquiring new postgres connection 'master'
[0m12:10:02.192347 [debug] [ThreadPool]: Acquiring new postgres connection 'list_analytics'
[0m12:10:02.375465 [debug] [ThreadPool]: Using postgres connection "list_analytics"
[0m12:10:02.379314 [debug] [ThreadPool]: On list_analytics: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "homework", "target_name": "dev", "connection_name": "list_analytics"} */

    select distinct nspname from pg_namespace
  
[0m12:10:02.382622 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m12:10:02.432010 [debug] [ThreadPool]: SQL status: SELECT 7 in 0.049 seconds
[0m12:10:02.439183 [debug] [ThreadPool]: On list_analytics: Close
[0m12:10:02.449223 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_analytics, now list_analytics_analytics)
[0m12:10:02.487787 [debug] [ThreadPool]: Using postgres connection "list_analytics_analytics"
[0m12:10:02.491153 [debug] [ThreadPool]: On list_analytics_analytics: BEGIN
[0m12:10:02.495651 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m12:10:02.517817 [debug] [ThreadPool]: SQL status: BEGIN in 0.022 seconds
[0m12:10:02.521742 [debug] [ThreadPool]: Using postgres connection "list_analytics_analytics"
[0m12:10:02.526077 [debug] [ThreadPool]: On list_analytics_analytics: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "homework", "target_name": "dev", "connection_name": "list_analytics_analytics"} */
select
      'analytics' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'analytics'
    union all
    select
      'analytics' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'analytics'
    union all
    select
      'analytics' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'analytics'
  
[0m12:10:02.539783 [debug] [ThreadPool]: SQL status: SELECT 3 in 0.010 seconds
[0m12:10:02.546021 [debug] [ThreadPool]: On list_analytics_analytics: ROLLBACK
[0m12:10:02.551233 [debug] [ThreadPool]: On list_analytics_analytics: Close
[0m12:10:02.581523 [debug] [MainThread]: Using postgres connection "master"
[0m12:10:02.584233 [debug] [MainThread]: On master: BEGIN
[0m12:10:02.586421 [debug] [MainThread]: Opening a new connection, currently in state init
[0m12:10:02.619694 [debug] [MainThread]: SQL status: BEGIN in 0.033 seconds
[0m12:10:02.623529 [debug] [MainThread]: Using postgres connection "master"
[0m12:10:02.640971 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "homework", "target_name": "dev", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select distinct
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v', 'm')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
[0m12:10:02.698052 [debug] [MainThread]: SQL status: SELECT 1 in 0.048 seconds
[0m12:10:02.706723 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '7eb3bf65-45e0-4ffc-8950-a407449a6ca1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6adb17cbe0>]}
[0m12:10:02.709447 [debug] [MainThread]: On master: ROLLBACK
[0m12:10:02.714711 [debug] [MainThread]: Using postgres connection "master"
[0m12:10:02.723825 [debug] [MainThread]: On master: BEGIN
[0m12:10:02.729700 [debug] [MainThread]: SQL status: BEGIN in 0.002 seconds
[0m12:10:02.733661 [debug] [MainThread]: On master: COMMIT
[0m12:10:02.740977 [debug] [MainThread]: Using postgres connection "master"
[0m12:10:02.745425 [debug] [MainThread]: On master: COMMIT
[0m12:10:02.748987 [debug] [MainThread]: SQL status: COMMIT in 0.000 seconds
[0m12:10:02.753905 [debug] [MainThread]: On master: Close
[0m12:10:02.791242 [debug] [Thread-1  ]: Began running node model.homework.stg_iris
[0m12:10:02.794087 [info ] [Thread-1  ]: 1 of 2 START sql view model analytics.stg_iris ................................. [RUN]
[0m12:10:02.797348 [debug] [Thread-1  ]: Re-using an available connection from the pool (formerly list_analytics_analytics, now model.homework.stg_iris)
[0m12:10:02.799214 [debug] [Thread-1  ]: Began compiling node model.homework.stg_iris
[0m12:10:02.827716 [debug] [Thread-1  ]: Writing injected SQL for node "model.homework.stg_iris"
[0m12:10:02.839034 [debug] [Thread-1  ]: Began executing node model.homework.stg_iris
[0m12:10:02.955979 [debug] [Thread-1  ]: Writing runtime sql for node "model.homework.stg_iris"
[0m12:10:02.973086 [debug] [Thread-1  ]: Using postgres connection "model.homework.stg_iris"
[0m12:10:02.978144 [debug] [Thread-1  ]: On model.homework.stg_iris: BEGIN
[0m12:10:02.982073 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
[0m12:10:03.048408 [debug] [Thread-1  ]: SQL status: BEGIN in 0.066 seconds
[0m12:10:03.056645 [debug] [Thread-1  ]: Using postgres connection "model.homework.stg_iris"
[0m12:10:03.063579 [debug] [Thread-1  ]: On model.homework.stg_iris: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "homework", "target_name": "dev", "node_id": "model.homework.stg_iris"} */

  create view "analytics"."analytics"."stg_iris__dbt_tmp"
    
    
  as (
    with source as (
    select * from "analytics"."analytics"."iris_dataset"
)

select
    cast(sepal_length as numeric) as sepal_length,
    cast(sepal_width as numeric) as sepal_width,
    cast(petal_length as numeric) as petal_length,
    cast(petal_width as numeric) as petal_width,
    species
from source
  );
[0m12:10:03.106246 [debug] [Thread-1  ]: SQL status: CREATE VIEW in 0.031 seconds
[0m12:10:03.136802 [debug] [Thread-1  ]: Using postgres connection "model.homework.stg_iris"
[0m12:10:03.138826 [debug] [Thread-1  ]: On model.homework.stg_iris: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "homework", "target_name": "dev", "node_id": "model.homework.stg_iris"} */
alter table "analytics"."analytics"."stg_iris" rename to "stg_iris__dbt_backup"
[0m12:10:03.141954 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.001 seconds
[0m12:10:03.153734 [debug] [Thread-1  ]: Using postgres connection "model.homework.stg_iris"
[0m12:10:03.156239 [debug] [Thread-1  ]: On model.homework.stg_iris: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "homework", "target_name": "dev", "node_id": "model.homework.stg_iris"} */
alter table "analytics"."analytics"."stg_iris__dbt_tmp" rename to "stg_iris"
[0m12:10:03.158741 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.001 seconds
[0m12:10:03.204267 [debug] [Thread-1  ]: On model.homework.stg_iris: COMMIT
[0m12:10:03.207689 [debug] [Thread-1  ]: Using postgres connection "model.homework.stg_iris"
[0m12:10:03.210673 [debug] [Thread-1  ]: On model.homework.stg_iris: COMMIT
[0m12:10:03.223386 [debug] [Thread-1  ]: SQL status: COMMIT in 0.008 seconds
[0m12:10:03.252326 [debug] [Thread-1  ]: Applying DROP to: "analytics"."analytics"."stg_iris__dbt_backup"
[0m12:10:03.277587 [debug] [Thread-1  ]: Using postgres connection "model.homework.stg_iris"
[0m12:10:03.282044 [debug] [Thread-1  ]: On model.homework.stg_iris: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "homework", "target_name": "dev", "node_id": "model.homework.stg_iris"} */
drop view if exists "analytics"."analytics"."stg_iris__dbt_backup" cascade
[0m12:10:03.289719 [debug] [Thread-1  ]: SQL status: DROP VIEW in 0.005 seconds
[0m12:10:03.300466 [debug] [Thread-1  ]: On model.homework.stg_iris: Close
[0m12:10:03.309639 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '7eb3bf65-45e0-4ffc-8950-a407449a6ca1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6ada603250>]}
[0m12:10:03.314000 [info ] [Thread-1  ]: 1 of 2 OK created sql view model analytics.stg_iris ............................ [[32mCREATE VIEW[0m in 0.51s]
[0m12:10:03.318233 [debug] [Thread-1  ]: Finished running node model.homework.stg_iris
[0m12:10:03.322110 [debug] [Thread-3  ]: Began running node model.homework.iris_processed
[0m12:10:03.324546 [info ] [Thread-3  ]: 2 of 2 START sql table model analytics.iris_processed .......................... [RUN]
[0m12:10:03.327226 [debug] [Thread-3  ]: Acquiring new postgres connection 'model.homework.iris_processed'
[0m12:10:03.329546 [debug] [Thread-3  ]: Began compiling node model.homework.iris_processed
[0m12:10:03.473484 [debug] [Thread-3  ]: Using postgres connection "model.homework.iris_processed"
[0m12:10:03.475630 [debug] [Thread-3  ]: On model.homework.iris_processed: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "homework", "target_name": "dev", "node_id": "model.homework.iris_processed"} */

        select percentile_cont(0.5) within group (order by sepal_length ) from "analytics"."analytics"."stg_iris"
    
[0m12:10:03.477508 [debug] [Thread-3  ]: Opening a new connection, currently in state init
[0m12:10:03.492634 [debug] [Thread-3  ]: SQL status: SELECT 1 in 0.015 seconds
[0m12:10:03.497576 [debug] [Thread-3  ]: Using postgres connection "model.homework.iris_processed"
[0m12:10:03.499703 [debug] [Thread-3  ]: On model.homework.iris_processed: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "homework", "target_name": "dev", "node_id": "model.homework.iris_processed"} */

        select percentile_cont(0.5 - 0.5/2) within group (order by sepal_length ) from "analytics"."analytics"."stg_iris"
    
[0m12:10:03.502976 [debug] [Thread-3  ]: SQL status: SELECT 1 in 0.001 seconds
[0m12:10:03.507551 [debug] [Thread-3  ]: Using postgres connection "model.homework.iris_processed"
[0m12:10:03.510832 [debug] [Thread-3  ]: On model.homework.iris_processed: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "homework", "target_name": "dev", "node_id": "model.homework.iris_processed"} */

        select percentile_cont(0.5 + 0.5/2) within group (order by sepal_length ) from "analytics"."analytics"."stg_iris"
    
[0m12:10:03.514610 [debug] [Thread-3  ]: SQL status: SELECT 1 in 0.001 seconds
[0m12:10:03.539290 [debug] [Thread-3  ]: Using postgres connection "model.homework.iris_processed"
[0m12:10:03.542016 [debug] [Thread-3  ]: On model.homework.iris_processed: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "homework", "target_name": "dev", "node_id": "model.homework.iris_processed"} */

        select percentile_cont(0.5) within group (order by sepal_width ) from "analytics"."analytics"."stg_iris"
    
[0m12:10:03.545447 [debug] [Thread-3  ]: SQL status: SELECT 1 in 0.001 seconds
[0m12:10:03.550128 [debug] [Thread-3  ]: Using postgres connection "model.homework.iris_processed"
[0m12:10:03.552380 [debug] [Thread-3  ]: On model.homework.iris_processed: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "homework", "target_name": "dev", "node_id": "model.homework.iris_processed"} */

        select percentile_cont(0.5 - 0.5/2) within group (order by sepal_width ) from "analytics"."analytics"."stg_iris"
    
[0m12:10:03.555355 [debug] [Thread-3  ]: SQL status: SELECT 1 in 0.001 seconds
[0m12:10:03.560964 [debug] [Thread-3  ]: Using postgres connection "model.homework.iris_processed"
[0m12:10:03.564193 [debug] [Thread-3  ]: On model.homework.iris_processed: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "homework", "target_name": "dev", "node_id": "model.homework.iris_processed"} */

        select percentile_cont(0.5 + 0.5/2) within group (order by sepal_width ) from "analytics"."analytics"."stg_iris"
    
[0m12:10:03.567442 [debug] [Thread-3  ]: SQL status: SELECT 1 in 0.001 seconds
[0m12:10:03.574517 [debug] [Thread-3  ]: Using postgres connection "model.homework.iris_processed"
[0m12:10:03.577145 [debug] [Thread-3  ]: On model.homework.iris_processed: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "homework", "target_name": "dev", "node_id": "model.homework.iris_processed"} */

        select percentile_cont(0.5) within group (order by petal_length ) from "analytics"."analytics"."stg_iris"
    
[0m12:10:03.581337 [debug] [Thread-3  ]: SQL status: SELECT 1 in 0.001 seconds
[0m12:10:03.586745 [debug] [Thread-3  ]: Using postgres connection "model.homework.iris_processed"
[0m12:10:03.588917 [debug] [Thread-3  ]: On model.homework.iris_processed: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "homework", "target_name": "dev", "node_id": "model.homework.iris_processed"} */

        select percentile_cont(0.5 - 0.5/2) within group (order by petal_length ) from "analytics"."analytics"."stg_iris"
    
[0m12:10:03.592492 [debug] [Thread-3  ]: SQL status: SELECT 1 in 0.001 seconds
[0m12:10:03.599815 [debug] [Thread-3  ]: Using postgres connection "model.homework.iris_processed"
[0m12:10:03.602732 [debug] [Thread-3  ]: On model.homework.iris_processed: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "homework", "target_name": "dev", "node_id": "model.homework.iris_processed"} */

        select percentile_cont(0.5 + 0.5/2) within group (order by petal_length ) from "analytics"."analytics"."stg_iris"
    
[0m12:10:03.606424 [debug] [Thread-3  ]: SQL status: SELECT 1 in 0.001 seconds
[0m12:10:03.617474 [debug] [Thread-3  ]: Using postgres connection "model.homework.iris_processed"
[0m12:10:03.622604 [debug] [Thread-3  ]: On model.homework.iris_processed: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "homework", "target_name": "dev", "node_id": "model.homework.iris_processed"} */

        select percentile_cont(0.5) within group (order by petal_width ) from "analytics"."analytics"."stg_iris"
    
[0m12:10:03.632482 [debug] [Thread-3  ]: SQL status: SELECT 1 in 0.003 seconds
[0m12:10:03.640143 [debug] [Thread-3  ]: Using postgres connection "model.homework.iris_processed"
[0m12:10:03.642324 [debug] [Thread-3  ]: On model.homework.iris_processed: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "homework", "target_name": "dev", "node_id": "model.homework.iris_processed"} */

        select percentile_cont(0.5 - 0.5/2) within group (order by petal_width ) from "analytics"."analytics"."stg_iris"
    
[0m12:10:03.646629 [debug] [Thread-3  ]: SQL status: SELECT 1 in 0.002 seconds
[0m12:10:03.651967 [debug] [Thread-3  ]: Using postgres connection "model.homework.iris_processed"
[0m12:10:03.653955 [debug] [Thread-3  ]: On model.homework.iris_processed: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "homework", "target_name": "dev", "node_id": "model.homework.iris_processed"} */

        select percentile_cont(0.5 + 0.5/2) within group (order by petal_width ) from "analytics"."analytics"."stg_iris"
    
[0m12:10:03.657397 [debug] [Thread-3  ]: SQL status: SELECT 1 in 0.001 seconds
[0m12:10:03.703557 [debug] [Thread-3  ]: Using postgres connection "model.homework.iris_processed"
[0m12:10:03.706261 [debug] [Thread-3  ]: On model.homework.iris_processed: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "homework", "target_name": "dev", "node_id": "model.homework.iris_processed"} */

            select percentile_cont(0.5) within group (order by sepal_length ) from "analytics"."analytics"."stg_iris"
        
[0m12:10:03.711094 [debug] [Thread-3  ]: SQL status: SELECT 1 in 0.001 seconds
[0m12:10:03.719813 [debug] [Thread-3  ]: Using postgres connection "model.homework.iris_processed"
[0m12:10:03.722867 [debug] [Thread-3  ]: On model.homework.iris_processed: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "homework", "target_name": "dev", "node_id": "model.homework.iris_processed"} */

            select percentile_cont(0.5) within group (order by sepal_width ) from "analytics"."analytics"."stg_iris"
        
[0m12:10:03.726494 [debug] [Thread-3  ]: SQL status: SELECT 1 in 0.001 seconds
[0m12:10:03.734770 [debug] [Thread-3  ]: Using postgres connection "model.homework.iris_processed"
[0m12:10:03.737606 [debug] [Thread-3  ]: On model.homework.iris_processed: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "homework", "target_name": "dev", "node_id": "model.homework.iris_processed"} */

            select percentile_cont(0.5) within group (order by petal_length ) from "analytics"."analytics"."stg_iris"
        
[0m12:10:03.742032 [debug] [Thread-3  ]: SQL status: SELECT 1 in 0.001 seconds
[0m12:10:03.751398 [debug] [Thread-3  ]: Using postgres connection "model.homework.iris_processed"
[0m12:10:03.754775 [debug] [Thread-3  ]: On model.homework.iris_processed: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "homework", "target_name": "dev", "node_id": "model.homework.iris_processed"} */

            select percentile_cont(0.5) within group (order by petal_width ) from "analytics"."analytics"."stg_iris"
        
[0m12:10:03.760559 [debug] [Thread-3  ]: SQL status: SELECT 1 in 0.001 seconds
[0m12:10:03.867443 [debug] [Thread-3  ]: Using postgres connection "model.homework.iris_processed"
[0m12:10:03.869819 [debug] [Thread-3  ]: On model.homework.iris_processed: BEGIN
[0m12:10:03.872705 [debug] [Thread-3  ]: SQL status: BEGIN in 0.000 seconds
[0m12:10:03.875664 [debug] [Thread-3  ]: Using postgres connection "model.homework.iris_processed"
[0m12:10:03.879241 [debug] [Thread-3  ]: On model.homework.iris_processed: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "homework", "target_name": "dev", "node_id": "model.homework.iris_processed"} */
select
                species as value

            from "analytics"."analytics"."stg_iris"

            
            where species is not null  and true
            

            group by species
            order by species

            

        
[0m12:10:03.886920 [debug] [Thread-3  ]: SQL status: SELECT 3 in 0.002 seconds
[0m12:10:03.970069 [debug] [Thread-3  ]: Writing injected SQL for node "model.homework.iris_processed"
[0m12:10:03.997829 [debug] [Thread-3  ]: Began executing node model.homework.iris_processed
[0m12:10:04.066889 [debug] [Thread-3  ]: Writing runtime sql for node "model.homework.iris_processed"
[0m12:10:04.079508 [debug] [Thread-3  ]: Using postgres connection "model.homework.iris_processed"
[0m12:10:04.082824 [debug] [Thread-3  ]: On model.homework.iris_processed: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "homework", "target_name": "dev", "node_id": "model.homework.iris_processed"} */

  
    

  create  table "analytics"."analytics"."iris_processed__dbt_tmp"
  
  
    as
  
  (
    

with import_iris as (
    select *
    from "analytics"."analytics"."stg_iris"
)
select
    sepal_length,
    sepal_width,
    petal_length,
    petal_width,
    -- K Bins Discretization
    
        

    
        NTILE(5) over (order by sepal_length)
    

 as sepal_length_quantile_bin,
        

    
        
        floor(
        (
            sepal_length - (min(sepal_length) over ())
        )
        /
        (
            ((max(sepal_length) over ()) - (min(sepal_length) over ())) / 4::float
        )
        ) + 1
    

 as sepal_length_uniform_bin,
    
        

    
        NTILE(5) over (order by sepal_width)
    

 as sepal_width_quantile_bin,
        

    
        
        floor(
        (
            sepal_width - (min(sepal_width) over ())
        )
        /
        (
            ((max(sepal_width) over ()) - (min(sepal_width) over ())) / 4::float
        )
        ) + 1
    

 as sepal_width_uniform_bin,
    
        

    
        NTILE(5) over (order by petal_length)
    

 as petal_length_quantile_bin,
        

    
        
        floor(
        (
            petal_length - (min(petal_length) over ())
        )
        /
        (
            ((max(petal_length) over ()) - (min(petal_length) over ())) / 4::float
        )
        ) + 1
    

 as petal_length_uniform_bin,
    
        

    
        NTILE(5) over (order by petal_width)
    

 as petal_width_quantile_bin,
        

    
        
        floor(
        (
            petal_width - (min(petal_width) over ())
        )
        /
        (
            ((max(petal_width) over ()) - (min(petal_width) over ())) / 4::float
        )
        ) + 1
    

 as petal_width_uniform_bin,
    
-- Scaling
    
        

    

    
    
    

    
    
    

    (
        sepal_length - 5.8
    )
    /
    (
        6.4 - 5.1
    )

 as sepal_length_robust_scaled,
        

    (sepal_length) / (max(abs(sepal_length)) over ())::FLOAT

 as sepal_length_max_absolute_scaled,
        

    
    (
        ((sepal_length) - (min(sepal_length) over ()))
        /
        ((max(sepal_length) over ()) - (min(sepal_length) over ()))::FLOAT
    )
    *
    (1.0 - 0.0)
    +
    0.0

 as sepal_length_max_min_max_scaled,
    
        

    

    
    
    

    
    
    

    (
        sepal_width - 3.0
    )
    /
    (
        3.3 - 2.8
    )

 as sepal_width_robust_scaled,
        

    (sepal_width) / (max(abs(sepal_width)) over ())::FLOAT

 as sepal_width_max_absolute_scaled,
        

    
    (
        ((sepal_width) - (min(sepal_width) over ()))
        /
        ((max(sepal_width) over ()) - (min(sepal_width) over ()))::FLOAT
    )
    *
    (1.0 - 0.0)
    +
    0.0

 as sepal_width_max_min_max_scaled,
    
        

    

    
    
    

    
    
    

    (
        petal_length - 4.35
    )
    /
    (
        5.1 - 1.6
    )

 as petal_length_robust_scaled,
        

    (petal_length) / (max(abs(petal_length)) over ())::FLOAT

 as petal_length_max_absolute_scaled,
        

    
    (
        ((petal_length) - (min(petal_length) over ()))
        /
        ((max(petal_length) over ()) - (min(petal_length) over ()))::FLOAT
    )
    *
    (1.0 - 0.0)
    +
    0.0

 as petal_length_max_min_max_scaled,
    
        

    

    
    
    

    
    
    

    (
        petal_width - 1.3
    )
    /
    (
        1.8 - 0.3
    )

 as petal_width_robust_scaled,
        

    (petal_width) / (max(abs(petal_width)) over ())::FLOAT

 as petal_width_max_absolute_scaled,
        

    
    (
        ((petal_width) - (min(petal_width) over ()))
        /
        ((max(petal_width) over ()) - (min(petal_width) over ()))::FLOAT
    )
    *
    (1.0 - 0.0)
    +
    0.0

 as petal_width_max_min_max_scaled,
    

    -- Log Transformation
    
        

    case
        when sepal_length is null or sepal_length + 0 <= 0 then null
        else log(10, sepal_length + 0)
    end

 as sepal_length_logged,
    
        

    case
        when sepal_width is null or sepal_width + 0 <= 0 then null
        else log(10, sepal_width + 0)
    end

 as sepal_width_logged,
    
        

    case
        when petal_length is null or petal_length + 0 <= 0 then null
        else log(10, petal_length + 0)
    end

 as petal_length_logged,
    
        

    case
        when petal_width is null or petal_width + 0 <= 0 then null
        else log(10, petal_width + 0)
    end

 as petal_width_logged,
    

    -- Binarization
    
        

    

    
        

        
    

    case
        when sepal_length >=
            
                5.8
            
            then 1
        else 0
    end

 as sepal_length_binarized,
    
        

    

    
        

        
    

    case
        when sepal_width >=
            
                3.0
            
            then 1
        else 0
    end

 as sepal_width_binarized,
    
        

    

    
        

        
    

    case
        when petal_length >=
            
                4.35
            
            then 1
        else 0
    end

 as petal_length_binarized,
    
        

    

    
        

        
    

    case
        when petal_width >=
            
                1.3
            
            then 1
        else 0
    end

 as petal_width_binarized,
    

    -- Standardization
    
        

    
    (
        (sepal_length - avg(sepal_length) over ())
        /
        (stddev(sepal_length) over ())::FLOAT
    )
    *
    1
    +
    0

 as sepal_length_standardized,
    
        

    
    (
        (sepal_width - avg(sepal_width) over ())
        /
        (stddev(sepal_width) over ())::FLOAT
    )
    *
    1
    +
    0

 as sepal_width_standardized,
    
        

    
    (
        (petal_length - avg(petal_length) over ())
        /
        (stddev(petal_length) over ())::FLOAT
    )
    *
    1
    +
    0

 as petal_length_standardized,
    
        

    
    (
        (petal_width - avg(petal_width) over ())
        /
        (stddev(petal_width) over ())::FLOAT
    )
    *
    1
    +
    0

 as petal_width_standardized,
    
-- Interactions
    
        
            
            
            

    
        (sepal_length * sepal_width)
    

 as sepal_length_x_sepal_width_interaction,
            

    
        (sepal_length + sepal_width)
    

 as sepal_length_plus_sepal_width_interaction,
        
            
            
            

    
        (sepal_length * petal_length)
    

 as sepal_length_x_petal_length_interaction,
            

    
        (sepal_length + petal_length)
    

 as sepal_length_plus_petal_length_interaction,
        
            
            
            

    
        (sepal_length * petal_width)
    

 as sepal_length_x_petal_width_interaction,
            

    
        (sepal_length + petal_width)
    

 as sepal_length_plus_petal_width_interaction,
        
    
        
            
            
            

    
        (sepal_width * petal_length)
    

 as sepal_width_x_petal_length_interaction,
            

    
        (sepal_width + petal_length)
    

 as sepal_width_plus_petal_length_interaction,
        
            
            
            

    
        (sepal_width * petal_width)
    

 as sepal_width_x_petal_width_interaction,
            

    
        (sepal_width + petal_width)
    

 as sepal_width_plus_petal_width_interaction,
        
    
        
            
            
            

    
        (petal_length * petal_width)
    

 as petal_length_x_petal_width_interaction,
            

    
        (petal_length + petal_width)
    

 as petal_length_plus_petal_width_interaction,
        
    
        
    
species,    
    -- Label Encoding
    

    dense_rank() over (order by species) - 1

 as species_label_encoded,
    -- One Hot Encoding
    

    

    
        
    

    

    

        case
            when species = 'setosa' then 1
            else 0
        end as is_species__setosa,

    

        case
            when species = 'versicolor' then 1
            else 0
        end as is_species__versicolor,

    

        case
            when species = 'virginica' then 1
            else 0
        end as is_species__virginica,

    

    case
        when species is null then 1
        else 0
    end as is_species__


from "analytics"."analytics"."stg_iris"
  );
  
[0m12:10:04.133939 [debug] [Thread-3  ]: SQL status: SELECT 150 in 0.048 seconds
[0m12:10:04.154245 [debug] [Thread-3  ]: Using postgres connection "model.homework.iris_processed"
[0m12:10:04.156403 [debug] [Thread-3  ]: On model.homework.iris_processed: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "homework", "target_name": "dev", "node_id": "model.homework.iris_processed"} */
alter table "analytics"."analytics"."iris_processed" rename to "iris_processed__dbt_backup"
[0m12:10:04.159548 [debug] [Thread-3  ]: SQL status: ALTER TABLE in 0.001 seconds
[0m12:10:04.169851 [debug] [Thread-3  ]: Using postgres connection "model.homework.iris_processed"
[0m12:10:04.172010 [debug] [Thread-3  ]: On model.homework.iris_processed: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "homework", "target_name": "dev", "node_id": "model.homework.iris_processed"} */
alter table "analytics"."analytics"."iris_processed__dbt_tmp" rename to "iris_processed"
[0m12:10:04.174640 [debug] [Thread-3  ]: SQL status: ALTER TABLE in 0.001 seconds
[0m12:10:04.180132 [debug] [Thread-3  ]: On model.homework.iris_processed: COMMIT
[0m12:10:04.182444 [debug] [Thread-3  ]: Using postgres connection "model.homework.iris_processed"
[0m12:10:04.184627 [debug] [Thread-3  ]: On model.homework.iris_processed: COMMIT
[0m12:10:04.189845 [debug] [Thread-3  ]: SQL status: COMMIT in 0.003 seconds
[0m12:10:04.197793 [debug] [Thread-3  ]: Applying DROP to: "analytics"."analytics"."iris_processed__dbt_backup"
[0m12:10:04.205676 [debug] [Thread-3  ]: Using postgres connection "model.homework.iris_processed"
[0m12:10:04.207843 [debug] [Thread-3  ]: On model.homework.iris_processed: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "homework", "target_name": "dev", "node_id": "model.homework.iris_processed"} */
drop table if exists "analytics"."analytics"."iris_processed__dbt_backup" cascade
[0m12:10:04.219292 [debug] [Thread-3  ]: SQL status: DROP TABLE in 0.009 seconds
[0m12:10:04.223681 [debug] [Thread-3  ]: On model.homework.iris_processed: Close
[0m12:10:04.226403 [debug] [Thread-3  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '7eb3bf65-45e0-4ffc-8950-a407449a6ca1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6ad83fc640>]}
[0m12:10:04.229164 [info ] [Thread-3  ]: 2 of 2 OK created sql table model analytics.iris_processed ..................... [[32mSELECT 150[0m in 0.90s]
[0m12:10:04.231919 [debug] [Thread-3  ]: Finished running node model.homework.iris_processed
[0m12:10:04.236691 [debug] [MainThread]: Using postgres connection "master"
[0m12:10:04.238514 [debug] [MainThread]: On master: BEGIN
[0m12:10:04.240322 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m12:10:04.253000 [debug] [MainThread]: SQL status: BEGIN in 0.013 seconds
[0m12:10:04.255484 [debug] [MainThread]: On master: COMMIT
[0m12:10:04.257859 [debug] [MainThread]: Using postgres connection "master"
[0m12:10:04.260154 [debug] [MainThread]: On master: COMMIT
[0m12:10:04.262550 [debug] [MainThread]: SQL status: COMMIT in 0.000 seconds
[0m12:10:04.264355 [debug] [MainThread]: On master: Close
[0m12:10:04.267636 [debug] [MainThread]: Connection 'master' was properly closed.
[0m12:10:04.270334 [debug] [MainThread]: Connection 'model.homework.stg_iris' was properly closed.
[0m12:10:04.272847 [debug] [MainThread]: Connection 'model.homework.iris_processed' was properly closed.
[0m12:10:04.275787 [info ] [MainThread]: 
[0m12:10:04.279370 [info ] [MainThread]: Finished running 1 table model, 1 view model in 0 hours 0 minutes and 2.11 seconds (2.11s).
[0m12:10:04.284789 [debug] [MainThread]: Command end result
[0m12:10:04.389687 [debug] [MainThread]: Wrote artifact WritableManifest to /opt/airflow/dags/dbt/homework/target/manifest.json
[0m12:10:04.397914 [debug] [MainThread]: Wrote artifact SemanticManifest to /opt/airflow/dags/dbt/homework/target/semantic_manifest.json
[0m12:10:04.419079 [debug] [MainThread]: Wrote artifact RunExecutionResult to /opt/airflow/dags/dbt/homework/target/run_results.json
[0m12:10:04.421054 [info ] [MainThread]: 
[0m12:10:04.423160 [info ] [MainThread]: [32mCompleted successfully[0m
[0m12:10:04.424944 [info ] [MainThread]: 
[0m12:10:04.426775 [info ] [MainThread]: Done. PASS=2 WARN=0 ERROR=0 SKIP=0 TOTAL=2
[0m12:10:04.429822 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": true, "command_wall_clock_time": 6.420196, "process_in_blocks": "0", "process_kernel_time": 1.264203, "process_mem_max_rss": "115048", "process_out_blocks": "0", "process_user_time": 8.272074}
[0m12:10:04.432102 [debug] [MainThread]: Command `dbt run` succeeded at 12:10:04.431824 after 6.42 seconds
[0m12:10:04.434054 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6addcf8b20>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6adcea7f10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6adcea7220>]}
[0m12:10:04.435853 [debug] [MainThread]: Flushing usage events
[0m12:10:05.011572 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m12:10:08.340597 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 1 unused configuration paths:
- seeds.homework.iris_dataset
[0m12:10:08.375126 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'f6e14081-fb1e-4635-b585-accb55251936', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3ed960d130>]}
[0m12:10:08.628881 [debug] [MainThread]: Wrote artifact WritableManifest to /opt/airflow/dags/dbt/homework/target/manifest.json
[0m12:10:08.654478 [debug] [MainThread]: Wrote artifact SemanticManifest to /opt/airflow/dags/dbt/homework/target/semantic_manifest.json
[0m12:10:08.702263 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'f6e14081-fb1e-4635-b585-accb55251936', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3ed95f8880>]}
[0m12:10:08.704648 [info ] [MainThread]: Found 2 models, 1 source, 587 macros
[0m12:10:08.706861 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'f6e14081-fb1e-4635-b585-accb55251936', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3ed95f8d00>]}
[0m12:10:08.711208 [info ] [MainThread]: 
[0m12:10:08.713243 [info ] [MainThread]: Concurrency: 4 threads (target='dev')
[0m12:10:08.715262 [info ] [MainThread]: 
[0m12:10:08.718351 [debug] [MainThread]: Acquiring new postgres connection 'master'
[0m12:10:08.732517 [debug] [ThreadPool]: Acquiring new postgres connection 'list_analytics'
[0m12:10:08.831198 [debug] [ThreadPool]: Using postgres connection "list_analytics"
[0m12:10:08.834765 [debug] [ThreadPool]: On list_analytics: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "homework", "target_name": "dev", "connection_name": "list_analytics"} */

    select distinct nspname from pg_namespace
  
[0m12:10:08.838016 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m12:10:08.871772 [debug] [ThreadPool]: SQL status: SELECT 7 in 0.034 seconds
[0m12:10:08.878847 [debug] [ThreadPool]: On list_analytics: Close
[0m12:10:08.887253 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_analytics, now list_analytics_analytics)
[0m12:10:08.941556 [debug] [ThreadPool]: Using postgres connection "list_analytics_analytics"
[0m12:10:08.945293 [debug] [ThreadPool]: On list_analytics_analytics: BEGIN
[0m12:10:08.948411 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m12:10:08.971322 [debug] [ThreadPool]: SQL status: BEGIN in 0.023 seconds
[0m12:10:08.974321 [debug] [ThreadPool]: Using postgres connection "list_analytics_analytics"
[0m12:10:08.977177 [debug] [ThreadPool]: On list_analytics_analytics: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "homework", "target_name": "dev", "connection_name": "list_analytics_analytics"} */
select
      'analytics' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'analytics'
    union all
    select
      'analytics' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'analytics'
    union all
    select
      'analytics' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'analytics'
  
[0m12:10:08.986133 [debug] [ThreadPool]: SQL status: SELECT 3 in 0.007 seconds
[0m12:10:08.991942 [debug] [ThreadPool]: On list_analytics_analytics: ROLLBACK
[0m12:10:08.994732 [debug] [ThreadPool]: On list_analytics_analytics: Close
[0m12:10:09.027010 [debug] [MainThread]: Using postgres connection "master"
[0m12:10:09.029347 [debug] [MainThread]: On master: BEGIN
[0m12:10:09.031715 [debug] [MainThread]: Opening a new connection, currently in state init
[0m12:10:09.055085 [debug] [MainThread]: SQL status: BEGIN in 0.022 seconds
[0m12:10:09.059628 [debug] [MainThread]: Using postgres connection "master"
[0m12:10:09.063729 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "homework", "target_name": "dev", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select distinct
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v', 'm')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
[0m12:10:09.119205 [debug] [MainThread]: SQL status: SELECT 1 in 0.050 seconds
[0m12:10:09.129103 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'f6e14081-fb1e-4635-b585-accb55251936', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3ed937e4c0>]}
[0m12:10:09.135589 [debug] [MainThread]: On master: ROLLBACK
[0m12:10:09.139370 [debug] [MainThread]: Using postgres connection "master"
[0m12:10:09.142369 [debug] [MainThread]: On master: BEGIN
[0m12:10:09.146072 [debug] [MainThread]: SQL status: BEGIN in 0.001 seconds
[0m12:10:09.150065 [debug] [MainThread]: On master: COMMIT
[0m12:10:09.157218 [debug] [MainThread]: Using postgres connection "master"
[0m12:10:09.163277 [debug] [MainThread]: On master: COMMIT
[0m12:10:09.168888 [debug] [MainThread]: SQL status: COMMIT in 0.001 seconds
[0m12:10:09.177683 [debug] [MainThread]: On master: Close
[0m12:10:09.208910 [debug] [Thread-1  ]: Began running node model.homework.stg_iris
[0m12:10:09.215586 [info ] [Thread-1  ]: 1 of 2 START sql view model analytics.stg_iris ................................. [RUN]
[0m12:10:09.223469 [debug] [Thread-1  ]: Re-using an available connection from the pool (formerly list_analytics_analytics, now model.homework.stg_iris)
[0m12:10:09.227253 [debug] [Thread-1  ]: Began compiling node model.homework.stg_iris
[0m12:10:09.273661 [debug] [Thread-1  ]: Writing injected SQL for node "model.homework.stg_iris"
[0m12:10:09.291863 [debug] [Thread-1  ]: Began executing node model.homework.stg_iris
[0m12:10:09.492180 [debug] [Thread-1  ]: Writing runtime sql for node "model.homework.stg_iris"
[0m12:10:09.506405 [debug] [Thread-1  ]: Using postgres connection "model.homework.stg_iris"
[0m12:10:09.509025 [debug] [Thread-1  ]: On model.homework.stg_iris: BEGIN
[0m12:10:09.511223 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
[0m12:10:09.529184 [debug] [Thread-1  ]: SQL status: BEGIN in 0.018 seconds
[0m12:10:09.532702 [debug] [Thread-1  ]: Using postgres connection "model.homework.stg_iris"
[0m12:10:09.535845 [debug] [Thread-1  ]: On model.homework.stg_iris: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "homework", "target_name": "dev", "node_id": "model.homework.stg_iris"} */

  create view "analytics"."analytics"."stg_iris__dbt_tmp"
    
    
  as (
    with source as (
    select * from "analytics"."analytics"."iris_dataset"
)

select
    cast(sepal_length as numeric) as sepal_length,
    cast(sepal_width as numeric) as sepal_width,
    cast(petal_length as numeric) as petal_length,
    cast(petal_width as numeric) as petal_width,
    species
from source
  );
[0m12:10:09.543635 [debug] [Thread-1  ]: SQL status: CREATE VIEW in 0.004 seconds
[0m12:10:09.575128 [debug] [Thread-1  ]: Using postgres connection "model.homework.stg_iris"
[0m12:10:09.578477 [debug] [Thread-1  ]: On model.homework.stg_iris: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "homework", "target_name": "dev", "node_id": "model.homework.stg_iris"} */
alter table "analytics"."analytics"."stg_iris" rename to "stg_iris__dbt_backup"
[0m12:10:09.582096 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.001 seconds
[0m12:10:09.604233 [debug] [Thread-1  ]: Using postgres connection "model.homework.stg_iris"
[0m12:10:09.607203 [debug] [Thread-1  ]: On model.homework.stg_iris: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "homework", "target_name": "dev", "node_id": "model.homework.stg_iris"} */
alter table "analytics"."analytics"."stg_iris__dbt_tmp" rename to "stg_iris"
[0m12:10:09.611208 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.001 seconds
[0m12:10:09.697014 [debug] [Thread-1  ]: On model.homework.stg_iris: COMMIT
[0m12:10:09.700043 [debug] [Thread-1  ]: Using postgres connection "model.homework.stg_iris"
[0m12:10:09.702512 [debug] [Thread-1  ]: On model.homework.stg_iris: COMMIT
[0m12:10:09.709509 [debug] [Thread-1  ]: SQL status: COMMIT in 0.005 seconds
[0m12:10:09.729444 [debug] [Thread-1  ]: Applying DROP to: "analytics"."analytics"."stg_iris__dbt_backup"
[0m12:10:09.742801 [debug] [Thread-1  ]: Using postgres connection "model.homework.stg_iris"
[0m12:10:09.745235 [debug] [Thread-1  ]: On model.homework.stg_iris: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "homework", "target_name": "dev", "node_id": "model.homework.stg_iris"} */
drop view if exists "analytics"."analytics"."stg_iris__dbt_backup" cascade
[0m12:10:09.751746 [debug] [Thread-1  ]: SQL status: DROP VIEW in 0.004 seconds
[0m12:10:09.759141 [debug] [Thread-1  ]: On model.homework.stg_iris: Close
[0m12:10:09.765649 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'f6e14081-fb1e-4635-b585-accb55251936', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3ed960f190>]}
[0m12:10:09.769019 [info ] [Thread-1  ]: 1 of 2 OK created sql view model analytics.stg_iris ............................ [[32mCREATE VIEW[0m in 0.54s]
[0m12:10:09.772152 [debug] [Thread-1  ]: Finished running node model.homework.stg_iris
[0m12:10:09.775251 [debug] [Thread-3  ]: Began running node model.homework.iris_processed
[0m12:10:09.777855 [info ] [Thread-3  ]: 2 of 2 START sql table model analytics.iris_processed .......................... [RUN]
[0m12:10:09.780154 [debug] [Thread-3  ]: Acquiring new postgres connection 'model.homework.iris_processed'
[0m12:10:09.782141 [debug] [Thread-3  ]: Began compiling node model.homework.iris_processed
[0m12:10:09.825252 [debug] [Thread-3  ]: Using postgres connection "model.homework.iris_processed"
[0m12:10:09.827317 [debug] [Thread-3  ]: On model.homework.iris_processed: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "homework", "target_name": "dev", "node_id": "model.homework.iris_processed"} */

        select percentile_cont(0.5) within group (order by sepal_length ) from "analytics"."analytics"."stg_iris"
    
[0m12:10:09.829335 [debug] [Thread-3  ]: Opening a new connection, currently in state init
[0m12:10:09.843692 [debug] [Thread-3  ]: SQL status: SELECT 1 in 0.014 seconds
[0m12:10:09.848179 [debug] [Thread-3  ]: Using postgres connection "model.homework.iris_processed"
[0m12:10:09.850687 [debug] [Thread-3  ]: On model.homework.iris_processed: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "homework", "target_name": "dev", "node_id": "model.homework.iris_processed"} */

        select percentile_cont(0.5 - 0.5/2) within group (order by sepal_length ) from "analytics"."analytics"."stg_iris"
    
[0m12:10:09.853700 [debug] [Thread-3  ]: SQL status: SELECT 1 in 0.001 seconds
[0m12:10:09.858032 [debug] [Thread-3  ]: Using postgres connection "model.homework.iris_processed"
[0m12:10:09.860087 [debug] [Thread-3  ]: On model.homework.iris_processed: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "homework", "target_name": "dev", "node_id": "model.homework.iris_processed"} */

        select percentile_cont(0.5 + 0.5/2) within group (order by sepal_length ) from "analytics"."analytics"."stg_iris"
    
[0m12:10:09.862869 [debug] [Thread-3  ]: SQL status: SELECT 1 in 0.001 seconds
[0m12:10:09.869131 [debug] [Thread-3  ]: Using postgres connection "model.homework.iris_processed"
[0m12:10:09.871260 [debug] [Thread-3  ]: On model.homework.iris_processed: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "homework", "target_name": "dev", "node_id": "model.homework.iris_processed"} */

        select percentile_cont(0.5) within group (order by sepal_width ) from "analytics"."analytics"."stg_iris"
    
[0m12:10:09.873993 [debug] [Thread-3  ]: SQL status: SELECT 1 in 0.001 seconds
[0m12:10:09.878393 [debug] [Thread-3  ]: Using postgres connection "model.homework.iris_processed"
[0m12:10:09.880544 [debug] [Thread-3  ]: On model.homework.iris_processed: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "homework", "target_name": "dev", "node_id": "model.homework.iris_processed"} */

        select percentile_cont(0.5 - 0.5/2) within group (order by sepal_width ) from "analytics"."analytics"."stg_iris"
    
[0m12:10:09.883552 [debug] [Thread-3  ]: SQL status: SELECT 1 in 0.001 seconds
[0m12:10:09.887792 [debug] [Thread-3  ]: Using postgres connection "model.homework.iris_processed"
[0m12:10:09.889881 [debug] [Thread-3  ]: On model.homework.iris_processed: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "homework", "target_name": "dev", "node_id": "model.homework.iris_processed"} */

        select percentile_cont(0.5 + 0.5/2) within group (order by sepal_width ) from "analytics"."analytics"."stg_iris"
    
[0m12:10:09.892917 [debug] [Thread-3  ]: SQL status: SELECT 1 in 0.001 seconds
[0m12:10:09.899461 [debug] [Thread-3  ]: Using postgres connection "model.homework.iris_processed"
[0m12:10:09.901565 [debug] [Thread-3  ]: On model.homework.iris_processed: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "homework", "target_name": "dev", "node_id": "model.homework.iris_processed"} */

        select percentile_cont(0.5) within group (order by petal_length ) from "analytics"."analytics"."stg_iris"
    
[0m12:10:09.904305 [debug] [Thread-3  ]: SQL status: SELECT 1 in 0.001 seconds
[0m12:10:09.908778 [debug] [Thread-3  ]: Using postgres connection "model.homework.iris_processed"
[0m12:10:09.911065 [debug] [Thread-3  ]: On model.homework.iris_processed: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "homework", "target_name": "dev", "node_id": "model.homework.iris_processed"} */

        select percentile_cont(0.5 - 0.5/2) within group (order by petal_length ) from "analytics"."analytics"."stg_iris"
    
[0m12:10:09.914602 [debug] [Thread-3  ]: SQL status: SELECT 1 in 0.001 seconds
[0m12:10:09.920021 [debug] [Thread-3  ]: Using postgres connection "model.homework.iris_processed"
[0m12:10:09.922090 [debug] [Thread-3  ]: On model.homework.iris_processed: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "homework", "target_name": "dev", "node_id": "model.homework.iris_processed"} */

        select percentile_cont(0.5 + 0.5/2) within group (order by petal_length ) from "analytics"."analytics"."stg_iris"
    
[0m12:10:09.924663 [debug] [Thread-3  ]: SQL status: SELECT 1 in 0.001 seconds
[0m12:10:09.930801 [debug] [Thread-3  ]: Using postgres connection "model.homework.iris_processed"
[0m12:10:09.932922 [debug] [Thread-3  ]: On model.homework.iris_processed: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "homework", "target_name": "dev", "node_id": "model.homework.iris_processed"} */

        select percentile_cont(0.5) within group (order by petal_width ) from "analytics"."analytics"."stg_iris"
    
[0m12:10:09.936792 [debug] [Thread-3  ]: SQL status: SELECT 1 in 0.001 seconds
[0m12:10:09.941600 [debug] [Thread-3  ]: Using postgres connection "model.homework.iris_processed"
[0m12:10:09.943910 [debug] [Thread-3  ]: On model.homework.iris_processed: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "homework", "target_name": "dev", "node_id": "model.homework.iris_processed"} */

        select percentile_cont(0.5 - 0.5/2) within group (order by petal_width ) from "analytics"."analytics"."stg_iris"
    
[0m12:10:09.946860 [debug] [Thread-3  ]: SQL status: SELECT 1 in 0.001 seconds
[0m12:10:09.951890 [debug] [Thread-3  ]: Using postgres connection "model.homework.iris_processed"
[0m12:10:09.953949 [debug] [Thread-3  ]: On model.homework.iris_processed: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "homework", "target_name": "dev", "node_id": "model.homework.iris_processed"} */

        select percentile_cont(0.5 + 0.5/2) within group (order by petal_width ) from "analytics"."analytics"."stg_iris"
    
[0m12:10:09.956561 [debug] [Thread-3  ]: SQL status: SELECT 1 in 0.001 seconds
[0m12:10:09.965444 [debug] [Thread-3  ]: Using postgres connection "model.homework.iris_processed"
[0m12:10:09.967557 [debug] [Thread-3  ]: On model.homework.iris_processed: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "homework", "target_name": "dev", "node_id": "model.homework.iris_processed"} */

            select percentile_cont(0.5) within group (order by sepal_length ) from "analytics"."analytics"."stg_iris"
        
[0m12:10:09.970355 [debug] [Thread-3  ]: SQL status: SELECT 1 in 0.001 seconds
[0m12:10:09.975575 [debug] [Thread-3  ]: Using postgres connection "model.homework.iris_processed"
[0m12:10:09.977846 [debug] [Thread-3  ]: On model.homework.iris_processed: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "homework", "target_name": "dev", "node_id": "model.homework.iris_processed"} */

            select percentile_cont(0.5) within group (order by sepal_width ) from "analytics"."analytics"."stg_iris"
        
[0m12:10:09.980886 [debug] [Thread-3  ]: SQL status: SELECT 1 in 0.001 seconds
[0m12:10:09.986673 [debug] [Thread-3  ]: Using postgres connection "model.homework.iris_processed"
[0m12:10:09.989042 [debug] [Thread-3  ]: On model.homework.iris_processed: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "homework", "target_name": "dev", "node_id": "model.homework.iris_processed"} */

            select percentile_cont(0.5) within group (order by petal_length ) from "analytics"."analytics"."stg_iris"
        
[0m12:10:09.992022 [debug] [Thread-3  ]: SQL status: SELECT 1 in 0.001 seconds
[0m12:10:09.997783 [debug] [Thread-3  ]: Using postgres connection "model.homework.iris_processed"
[0m12:10:10.001494 [debug] [Thread-3  ]: On model.homework.iris_processed: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "homework", "target_name": "dev", "node_id": "model.homework.iris_processed"} */

            select percentile_cont(0.5) within group (order by petal_width ) from "analytics"."analytics"."stg_iris"
        
[0m12:10:10.005669 [debug] [Thread-3  ]: SQL status: SELECT 1 in 0.001 seconds
[0m12:10:10.045124 [debug] [Thread-3  ]: Using postgres connection "model.homework.iris_processed"
[0m12:10:10.047539 [debug] [Thread-3  ]: On model.homework.iris_processed: BEGIN
[0m12:10:10.050394 [debug] [Thread-3  ]: SQL status: BEGIN in 0.001 seconds
[0m12:10:10.053713 [debug] [Thread-3  ]: Using postgres connection "model.homework.iris_processed"
[0m12:10:10.057049 [debug] [Thread-3  ]: On model.homework.iris_processed: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "homework", "target_name": "dev", "node_id": "model.homework.iris_processed"} */
select
                species as value

            from "analytics"."analytics"."stg_iris"

            
            where species is not null  and true
            

            group by species
            order by species

            

        
[0m12:10:10.060975 [debug] [Thread-3  ]: SQL status: SELECT 3 in 0.001 seconds
[0m12:10:10.079605 [debug] [Thread-3  ]: Writing injected SQL for node "model.homework.iris_processed"
[0m12:10:10.094546 [debug] [Thread-3  ]: Began executing node model.homework.iris_processed
[0m12:10:10.158708 [debug] [Thread-3  ]: Writing runtime sql for node "model.homework.iris_processed"
[0m12:10:10.185249 [debug] [Thread-3  ]: Using postgres connection "model.homework.iris_processed"
[0m12:10:10.192274 [debug] [Thread-3  ]: On model.homework.iris_processed: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "homework", "target_name": "dev", "node_id": "model.homework.iris_processed"} */

  
    

  create  table "analytics"."analytics"."iris_processed__dbt_tmp"
  
  
    as
  
  (
    

with import_iris as (
    select *
    from "analytics"."analytics"."stg_iris"
)
select
    sepal_length,
    sepal_width,
    petal_length,
    petal_width,
    -- K Bins Discretization
    
        

    
        NTILE(5) over (order by sepal_length)
    

 as sepal_length_quantile_bin,
        

    
        
        floor(
        (
            sepal_length - (min(sepal_length) over ())
        )
        /
        (
            ((max(sepal_length) over ()) - (min(sepal_length) over ())) / 4::float
        )
        ) + 1
    

 as sepal_length_uniform_bin,
    
        

    
        NTILE(5) over (order by sepal_width)
    

 as sepal_width_quantile_bin,
        

    
        
        floor(
        (
            sepal_width - (min(sepal_width) over ())
        )
        /
        (
            ((max(sepal_width) over ()) - (min(sepal_width) over ())) / 4::float
        )
        ) + 1
    

 as sepal_width_uniform_bin,
    
        

    
        NTILE(5) over (order by petal_length)
    

 as petal_length_quantile_bin,
        

    
        
        floor(
        (
            petal_length - (min(petal_length) over ())
        )
        /
        (
            ((max(petal_length) over ()) - (min(petal_length) over ())) / 4::float
        )
        ) + 1
    

 as petal_length_uniform_bin,
    
        

    
        NTILE(5) over (order by petal_width)
    

 as petal_width_quantile_bin,
        

    
        
        floor(
        (
            petal_width - (min(petal_width) over ())
        )
        /
        (
            ((max(petal_width) over ()) - (min(petal_width) over ())) / 4::float
        )
        ) + 1
    

 as petal_width_uniform_bin,
    
-- Scaling
    
        

    

    
    
    

    
    
    

    (
        sepal_length - 5.8
    )
    /
    (
        6.4 - 5.1
    )

 as sepal_length_robust_scaled,
        

    (sepal_length) / (max(abs(sepal_length)) over ())::FLOAT

 as sepal_length_max_absolute_scaled,
        

    
    (
        ((sepal_length) - (min(sepal_length) over ()))
        /
        ((max(sepal_length) over ()) - (min(sepal_length) over ()))::FLOAT
    )
    *
    (1.0 - 0.0)
    +
    0.0

 as sepal_length_max_min_max_scaled,
    
        

    

    
    
    

    
    
    

    (
        sepal_width - 3.0
    )
    /
    (
        3.3 - 2.8
    )

 as sepal_width_robust_scaled,
        

    (sepal_width) / (max(abs(sepal_width)) over ())::FLOAT

 as sepal_width_max_absolute_scaled,
        

    
    (
        ((sepal_width) - (min(sepal_width) over ()))
        /
        ((max(sepal_width) over ()) - (min(sepal_width) over ()))::FLOAT
    )
    *
    (1.0 - 0.0)
    +
    0.0

 as sepal_width_max_min_max_scaled,
    
        

    

    
    
    

    
    
    

    (
        petal_length - 4.35
    )
    /
    (
        5.1 - 1.6
    )

 as petal_length_robust_scaled,
        

    (petal_length) / (max(abs(petal_length)) over ())::FLOAT

 as petal_length_max_absolute_scaled,
        

    
    (
        ((petal_length) - (min(petal_length) over ()))
        /
        ((max(petal_length) over ()) - (min(petal_length) over ()))::FLOAT
    )
    *
    (1.0 - 0.0)
    +
    0.0

 as petal_length_max_min_max_scaled,
    
        

    

    
    
    

    
    
    

    (
        petal_width - 1.3
    )
    /
    (
        1.8 - 0.3
    )

 as petal_width_robust_scaled,
        

    (petal_width) / (max(abs(petal_width)) over ())::FLOAT

 as petal_width_max_absolute_scaled,
        

    
    (
        ((petal_width) - (min(petal_width) over ()))
        /
        ((max(petal_width) over ()) - (min(petal_width) over ()))::FLOAT
    )
    *
    (1.0 - 0.0)
    +
    0.0

 as petal_width_max_min_max_scaled,
    

    -- Log Transformation
    
        

    case
        when sepal_length is null or sepal_length + 0 <= 0 then null
        else log(10, sepal_length + 0)
    end

 as sepal_length_logged,
    
        

    case
        when sepal_width is null or sepal_width + 0 <= 0 then null
        else log(10, sepal_width + 0)
    end

 as sepal_width_logged,
    
        

    case
        when petal_length is null or petal_length + 0 <= 0 then null
        else log(10, petal_length + 0)
    end

 as petal_length_logged,
    
        

    case
        when petal_width is null or petal_width + 0 <= 0 then null
        else log(10, petal_width + 0)
    end

 as petal_width_logged,
    

    -- Binarization
    
        

    

    
        

        
    

    case
        when sepal_length >=
            
                5.8
            
            then 1
        else 0
    end

 as sepal_length_binarized,
    
        

    

    
        

        
    

    case
        when sepal_width >=
            
                3.0
            
            then 1
        else 0
    end

 as sepal_width_binarized,
    
        

    

    
        

        
    

    case
        when petal_length >=
            
                4.35
            
            then 1
        else 0
    end

 as petal_length_binarized,
    
        

    

    
        

        
    

    case
        when petal_width >=
            
                1.3
            
            then 1
        else 0
    end

 as petal_width_binarized,
    

    -- Standardization
    
        

    
    (
        (sepal_length - avg(sepal_length) over ())
        /
        (stddev(sepal_length) over ())::FLOAT
    )
    *
    1
    +
    0

 as sepal_length_standardized,
    
        

    
    (
        (sepal_width - avg(sepal_width) over ())
        /
        (stddev(sepal_width) over ())::FLOAT
    )
    *
    1
    +
    0

 as sepal_width_standardized,
    
        

    
    (
        (petal_length - avg(petal_length) over ())
        /
        (stddev(petal_length) over ())::FLOAT
    )
    *
    1
    +
    0

 as petal_length_standardized,
    
        

    
    (
        (petal_width - avg(petal_width) over ())
        /
        (stddev(petal_width) over ())::FLOAT
    )
    *
    1
    +
    0

 as petal_width_standardized,
    
-- Interactions
    
        
            
            
            

    
        (sepal_length * sepal_width)
    

 as sepal_length_x_sepal_width_interaction,
            

    
        (sepal_length + sepal_width)
    

 as sepal_length_plus_sepal_width_interaction,
        
            
            
            

    
        (sepal_length * petal_length)
    

 as sepal_length_x_petal_length_interaction,
            

    
        (sepal_length + petal_length)
    

 as sepal_length_plus_petal_length_interaction,
        
            
            
            

    
        (sepal_length * petal_width)
    

 as sepal_length_x_petal_width_interaction,
            

    
        (sepal_length + petal_width)
    

 as sepal_length_plus_petal_width_interaction,
        
    
        
            
            
            

    
        (sepal_width * petal_length)
    

 as sepal_width_x_petal_length_interaction,
            

    
        (sepal_width + petal_length)
    

 as sepal_width_plus_petal_length_interaction,
        
            
            
            

    
        (sepal_width * petal_width)
    

 as sepal_width_x_petal_width_interaction,
            

    
        (sepal_width + petal_width)
    

 as sepal_width_plus_petal_width_interaction,
        
    
        
            
            
            

    
        (petal_length * petal_width)
    

 as petal_length_x_petal_width_interaction,
            

    
        (petal_length + petal_width)
    

 as petal_length_plus_petal_width_interaction,
        
    
        
    
species,    
    -- Label Encoding
    

    dense_rank() over (order by species) - 1

 as species_label_encoded,
    -- One Hot Encoding
    

    

    
        
    

    

    

        case
            when species = 'setosa' then 1
            else 0
        end as is_species__setosa,

    

        case
            when species = 'versicolor' then 1
            else 0
        end as is_species__versicolor,

    

        case
            when species = 'virginica' then 1
            else 0
        end as is_species__virginica,

    

    case
        when species is null then 1
        else 0
    end as is_species__


from "analytics"."analytics"."stg_iris"
  );
  
[0m12:10:10.283944 [debug] [Thread-3  ]: SQL status: SELECT 150 in 0.087 seconds
[0m12:10:10.313250 [debug] [Thread-3  ]: Using postgres connection "model.homework.iris_processed"
[0m12:10:10.314983 [debug] [Thread-3  ]: On model.homework.iris_processed: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "homework", "target_name": "dev", "node_id": "model.homework.iris_processed"} */
alter table "analytics"."analytics"."iris_processed" rename to "iris_processed__dbt_backup"
[0m12:10:10.317379 [debug] [Thread-3  ]: SQL status: ALTER TABLE in 0.001 seconds
[0m12:10:10.326832 [debug] [Thread-3  ]: Using postgres connection "model.homework.iris_processed"
[0m12:10:10.328694 [debug] [Thread-3  ]: On model.homework.iris_processed: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "homework", "target_name": "dev", "node_id": "model.homework.iris_processed"} */
alter table "analytics"."analytics"."iris_processed__dbt_tmp" rename to "iris_processed"
[0m12:10:10.331444 [debug] [Thread-3  ]: SQL status: ALTER TABLE in 0.001 seconds
[0m12:10:10.336447 [debug] [Thread-3  ]: On model.homework.iris_processed: COMMIT
[0m12:10:10.338193 [debug] [Thread-3  ]: Using postgres connection "model.homework.iris_processed"
[0m12:10:10.339899 [debug] [Thread-3  ]: On model.homework.iris_processed: COMMIT
[0m12:10:10.345587 [debug] [Thread-3  ]: SQL status: COMMIT in 0.004 seconds
[0m12:10:10.356531 [debug] [Thread-3  ]: Applying DROP to: "analytics"."analytics"."iris_processed__dbt_backup"
[0m12:10:10.365361 [debug] [Thread-3  ]: Using postgres connection "model.homework.iris_processed"
[0m12:10:10.367472 [debug] [Thread-3  ]: On model.homework.iris_processed: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "homework", "target_name": "dev", "node_id": "model.homework.iris_processed"} */
drop table if exists "analytics"."analytics"."iris_processed__dbt_backup" cascade
[0m12:10:10.548803 [debug] [Thread-3  ]: SQL status: DROP TABLE in 0.179 seconds
[0m12:10:10.553123 [debug] [Thread-3  ]: On model.homework.iris_processed: Close
[0m12:10:10.556062 [debug] [Thread-3  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'f6e14081-fb1e-4635-b585-accb55251936', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3eb853bf10>]}
[0m12:10:10.559183 [info ] [Thread-3  ]: 2 of 2 OK created sql table model analytics.iris_processed ..................... [[32mSELECT 150[0m in 0.78s]
[0m12:10:10.562076 [debug] [Thread-3  ]: Finished running node model.homework.iris_processed
[0m12:10:10.567930 [debug] [MainThread]: Using postgres connection "master"
[0m12:10:10.570301 [debug] [MainThread]: On master: BEGIN
[0m12:10:10.572722 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m12:10:10.589006 [debug] [MainThread]: SQL status: BEGIN in 0.016 seconds
[0m12:10:10.592516 [debug] [MainThread]: On master: COMMIT
[0m12:10:10.595875 [debug] [MainThread]: Using postgres connection "master"
[0m12:10:10.599322 [debug] [MainThread]: On master: COMMIT
[0m12:10:10.602556 [debug] [MainThread]: SQL status: COMMIT in 0.000 seconds
[0m12:10:10.605625 [debug] [MainThread]: On master: Close
[0m12:10:10.613687 [debug] [MainThread]: Connection 'master' was properly closed.
[0m12:10:10.617580 [debug] [MainThread]: Connection 'model.homework.stg_iris' was properly closed.
[0m12:10:10.626713 [debug] [MainThread]: Connection 'model.homework.iris_processed' was properly closed.
[0m12:10:10.629844 [info ] [MainThread]: 
[0m12:10:10.632694 [info ] [MainThread]: Finished running 1 table model, 1 view model in 0 hours 0 minutes and 1.91 seconds (1.91s).
[0m12:10:10.640701 [debug] [MainThread]: Command end result
[0m12:10:10.776311 [debug] [MainThread]: Wrote artifact WritableManifest to /opt/airflow/dags/dbt/homework/target/manifest.json
[0m12:10:10.788653 [debug] [MainThread]: Wrote artifact SemanticManifest to /opt/airflow/dags/dbt/homework/target/semantic_manifest.json
[0m12:10:10.813471 [debug] [MainThread]: Wrote artifact RunExecutionResult to /opt/airflow/dags/dbt/homework/target/run_results.json
[0m12:10:10.815986 [info ] [MainThread]: 
[0m12:10:10.818413 [info ] [MainThread]: [32mCompleted successfully[0m
[0m12:10:10.831199 [info ] [MainThread]: 
[0m12:10:10.834090 [info ] [MainThread]: Done. PASS=2 WARN=0 ERROR=0 SKIP=0 TOTAL=2
[0m12:10:10.837522 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": true, "command_wall_clock_time": 12.494822, "process_in_blocks": "0", "process_kernel_time": 1.511311, "process_mem_max_rss": "118856", "process_out_blocks": "0", "process_user_time": 14.122258}
[0m12:10:10.840058 [debug] [MainThread]: Command `dbt run` succeeded at 12:10:10.839761 after 12.50 seconds
[0m12:10:10.842482 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3edc04eb50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3edbeccd60>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3edbf0e400>]}
[0m12:10:10.846107 [debug] [MainThread]: Flushing usage events
[0m12:10:12.269539 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m12:10:19.252321 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fba9f1c2b80>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fba9e2e6670>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fba9e2e6610>]}


============================== 12:10:19.267943 | 99a46869-1f08-4e2a-9623-1dc2a5f0e62e ==============================
[0m12:10:19.267943 [info ] [MainThread]: Running with dbt=1.9.4
[0m12:10:19.270361 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'fail_fast': 'True', 'profiles_dir': '/opt/airflow/dags/dbt', 'log_path': '/opt/airflow/dags/dbt/homework/logs', 'version_check': 'True', 'debug': 'False', 'use_colors': 'True', 'use_experimental_parser': 'False', 'empty': 'None', 'quiet': 'False', 'no_print': 'None', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'invocation_command': 'dbt --profile homework test --project-dir=/opt/airflow/dags/dbt/homework --vars {"is_test": false, "data_date": "2025-04-23"} --fail-fast', 'introspect': 'True', 'log_format': 'default', 'target_path': 'None', 'static_parser': 'True', 'send_anonymous_usage_stats': 'True'}
[0m12:10:19.849532 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '99a46869-1f08-4e2a-9623-1dc2a5f0e62e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fbaa0bab670>]}
[0m12:10:20.040611 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '99a46869-1f08-4e2a-9623-1dc2a5f0e62e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fba9e310970>]}
[0m12:10:20.043704 [info ] [MainThread]: Registered adapter: postgres=1.9.0
[0m12:10:20.356551 [debug] [MainThread]: checksum: f5df654a850f4b74beb13fbe0c7d8863b5b1a20bd535c3ac287d70e390b64d41, vars: {'data_date': '2025-04-23', 'is_test': False}, profile: homework, target: , version: 1.9.4
[0m12:10:20.680093 [info ] [MainThread]: Unable to do partial parsing because config vars, config profile, or config target have changed
[0m12:10:20.682101 [debug] [MainThread]: previous checksum: f5df654a850f4b74beb13fbe0c7d8863b5b1a20bd535c3ac287d70e390b64d41, current checksum: b4b46bb6a239f66694dfdd44ef1792882cb61f2fd7b1ea66b3c7a170d2bb602d
[0m12:10:20.684083 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'partial_parser', 'label': '99a46869-1f08-4e2a-9623-1dc2a5f0e62e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fba9ef53220>]}
[0m12:10:22.724569 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f5850746ac0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f584f8685e0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f584f868580>]}


============================== 12:10:22.752596 | aeb8b0d3-3d04-429a-8f4f-aa504a5b1a70 ==============================
[0m12:10:22.752596 [info ] [MainThread]: Running with dbt=1.9.4
[0m12:10:22.755843 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': '/opt/airflow/dags/dbt', 'fail_fast': 'True', 'debug': 'False', 'log_path': '/opt/airflow/dags/dbt/homework/logs', 'version_check': 'True', 'warn_error': 'None', 'use_colors': 'True', 'use_experimental_parser': 'False', 'empty': 'None', 'quiet': 'False', 'no_print': 'None', 'log_format': 'default', 'invocation_command': 'dbt --profile homework test --project-dir=/opt/airflow/dags/dbt/homework --vars {"is_test": false, "data_date": "2025-04-22"} --fail-fast', 'introspect': 'True', 'static_parser': 'True', 'target_path': 'None', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'send_anonymous_usage_stats': 'True'}
[0m12:10:23.443123 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'aeb8b0d3-3d04-429a-8f4f-aa504a5b1a70', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f584ff7f5e0>]}
[0m12:10:23.631344 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': 'aeb8b0d3-3d04-429a-8f4f-aa504a5b1a70', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f584e082670>]}
[0m12:10:23.634168 [info ] [MainThread]: Registered adapter: postgres=1.9.0
[0m12:10:24.002090 [debug] [MainThread]: checksum: b4b46bb6a239f66694dfdd44ef1792882cb61f2fd7b1ea66b3c7a170d2bb602d, vars: {'data_date': '2025-04-22', 'is_test': False}, profile: homework, target: , version: 1.9.4
[0m12:10:26.237041 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m12:10:26.238795 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m12:10:26.258288 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 1 unused configuration paths:
- seeds.homework.iris_dataset
[0m12:10:26.357042 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'aeb8b0d3-3d04-429a-8f4f-aa504a5b1a70', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f584db96130>]}
[0m12:10:26.709121 [debug] [MainThread]: Wrote artifact WritableManifest to /opt/airflow/dags/dbt/homework/target/manifest.json
[0m12:10:26.733990 [debug] [MainThread]: Wrote artifact SemanticManifest to /opt/airflow/dags/dbt/homework/target/semantic_manifest.json
[0m12:10:26.792916 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'aeb8b0d3-3d04-429a-8f4f-aa504a5b1a70', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f584f8e53a0>]}
[0m12:10:26.794976 [info ] [MainThread]: Found 2 models, 1 source, 587 macros
[0m12:10:26.798605 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'aeb8b0d3-3d04-429a-8f4f-aa504a5b1a70', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f584f8f6c70>]}
[0m12:10:26.802278 [warn ] [MainThread]: Nothing to do. Try checking your model configs and model specification args
[0m12:10:26.807339 [debug] [MainThread]: Command end result
[0m12:10:26.952212 [debug] [MainThread]: Wrote artifact WritableManifest to /opt/airflow/dags/dbt/homework/target/manifest.json
[0m12:10:26.967778 [debug] [MainThread]: Wrote artifact SemanticManifest to /opt/airflow/dags/dbt/homework/target/semantic_manifest.json
[0m12:10:26.985824 [debug] [MainThread]: Wrote artifact RunExecutionResult to /opt/airflow/dags/dbt/homework/target/run_results.json
[0m12:10:26.989134 [debug] [MainThread]: Resource report: {"command_name": "test", "command_success": true, "command_wall_clock_time": 4.468254, "process_in_blocks": "0", "process_kernel_time": 0.831059, "process_mem_max_rss": "104596", "process_out_blocks": "0", "process_user_time": 6.567398}
[0m12:10:26.991809 [debug] [MainThread]: Command `dbt test` succeeded at 12:10:26.991405 after 4.47 seconds
[0m12:10:26.994627 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f5850746ac0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f584ff7f5e0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f58514bb460>]}
[0m12:10:26.998333 [debug] [MainThread]: Flushing usage events
[0m12:10:27.595568 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m12:10:27.949378 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 1 unused configuration paths:
- seeds.homework.iris_dataset
[0m12:10:27.994724 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '99a46869-1f08-4e2a-9623-1dc2a5f0e62e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fba9c73df10>]}
[0m12:10:28.409804 [debug] [MainThread]: Wrote artifact WritableManifest to /opt/airflow/dags/dbt/homework/target/manifest.json
[0m12:10:28.437751 [debug] [MainThread]: Wrote artifact SemanticManifest to /opt/airflow/dags/dbt/homework/target/semantic_manifest.json
[0m12:10:28.497511 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '99a46869-1f08-4e2a-9623-1dc2a5f0e62e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fba971ef6a0>]}
[0m12:10:28.501864 [info ] [MainThread]: Found 2 models, 1 source, 587 macros
[0m12:10:28.505648 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '99a46869-1f08-4e2a-9623-1dc2a5f0e62e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fba9c60ca60>]}
[0m12:10:28.514389 [warn ] [MainThread]: Nothing to do. Try checking your model configs and model specification args
[0m12:10:28.519564 [debug] [MainThread]: Command end result
[0m12:10:28.705320 [debug] [MainThread]: Wrote artifact WritableManifest to /opt/airflow/dags/dbt/homework/target/manifest.json
[0m12:10:28.719013 [debug] [MainThread]: Wrote artifact SemanticManifest to /opt/airflow/dags/dbt/homework/target/semantic_manifest.json
[0m12:10:28.734669 [debug] [MainThread]: Wrote artifact RunExecutionResult to /opt/airflow/dags/dbt/homework/target/run_results.json
[0m12:10:28.737500 [debug] [MainThread]: Resource report: {"command_name": "test", "command_success": true, "command_wall_clock_time": 9.660517, "process_in_blocks": "0", "process_kernel_time": 0.554091, "process_mem_max_rss": "113048", "process_out_blocks": "0", "process_user_time": 12.935524}
[0m12:10:28.739679 [debug] [MainThread]: Command `dbt test` succeeded at 12:10:28.739436 after 9.66 seconds
[0m12:10:28.741682 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fba9f1c2b80>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fba9f04ba60>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fba9eff14f0>]}
[0m12:10:28.743555 [debug] [MainThread]: Flushing usage events
[0m12:10:29.375144 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m12:12:19.285817 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f7477d91ac0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f7476eb2490>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f7476eb2430>]}


============================== 12:12:19.300034 | ea4821e8-fdd8-41eb-b631-51a54a7923ca ==============================
[0m12:12:19.300034 [info ] [MainThread]: Running with dbt=1.9.4
[0m12:12:19.302537 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': '/opt/airflow/dags/dbt', 'fail_fast': 'False', 'debug': 'False', 'log_path': '/opt/airflow/dags/dbt/homework/logs', 'warn_error': 'None', 'version_check': 'True', 'use_colors': 'True', 'use_experimental_parser': 'False', 'empty': 'False', 'quiet': 'False', 'no_print': 'None', 'log_format': 'default', 'introspect': 'True', 'invocation_command': 'dbt --profile homework run --project-dir=/opt/airflow/dags/dbt/homework --vars {"is_test": false, "data_date": "2025-04-22"}', 'static_parser': 'True', 'target_path': 'None', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'send_anonymous_usage_stats': 'True'}
[0m12:12:19.752011 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'ea4821e8-fdd8-41eb-b631-51a54a7923ca', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f7476f52f70>]}
[0m12:12:19.878994 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': 'ea4821e8-fdd8-41eb-b631-51a54a7923ca', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f7477549520>]}
[0m12:12:19.881474 [info ] [MainThread]: Registered adapter: postgres=1.9.0
[0m12:12:20.226719 [debug] [MainThread]: checksum: b4b46bb6a239f66694dfdd44ef1792882cb61f2fd7b1ea66b3c7a170d2bb602d, vars: {'data_date': '2025-04-22', 'is_test': False}, profile: homework, target: , version: 1.9.4
[0m12:12:20.556742 [info ] [MainThread]: Unable to do partial parsing because config vars, config profile, or config target have changed
[0m12:12:20.558689 [debug] [MainThread]: previous checksum: b4b46bb6a239f66694dfdd44ef1792882cb61f2fd7b1ea66b3c7a170d2bb602d, current checksum: f5df654a850f4b74beb13fbe0c7d8863b5b1a20bd535c3ac287d70e390b64d41
[0m12:12:20.560721 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'partial_parser', 'label': 'ea4821e8-fdd8-41eb-b631-51a54a7923ca', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f74775cfd30>]}
[0m12:12:26.137642 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 1 unused configuration paths:
- seeds.homework.iris_dataset
[0m12:12:26.165825 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'ea4821e8-fdd8-41eb-b631-51a54a7923ca', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f747534a130>]}
[0m12:12:26.399096 [debug] [MainThread]: Wrote artifact WritableManifest to /opt/airflow/dags/dbt/homework/target/manifest.json
[0m12:12:26.417386 [debug] [MainThread]: Wrote artifact SemanticManifest to /opt/airflow/dags/dbt/homework/target/semantic_manifest.json
[0m12:12:26.452302 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'ea4821e8-fdd8-41eb-b631-51a54a7923ca', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f747532f3a0>]}
[0m12:12:26.454370 [info ] [MainThread]: Found 2 models, 1 source, 587 macros
[0m12:12:26.456013 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'ea4821e8-fdd8-41eb-b631-51a54a7923ca', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f747532ffa0>]}
[0m12:12:26.459570 [info ] [MainThread]: 
[0m12:12:26.461251 [info ] [MainThread]: Concurrency: 4 threads (target='dev')
[0m12:12:26.463638 [info ] [MainThread]: 
[0m12:12:26.466020 [debug] [MainThread]: Acquiring new postgres connection 'master'
[0m12:12:26.475829 [debug] [ThreadPool]: Acquiring new postgres connection 'list_analytics'
[0m12:12:26.552812 [debug] [ThreadPool]: Using postgres connection "list_analytics"
[0m12:12:26.554952 [debug] [ThreadPool]: On list_analytics: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "homework", "target_name": "dev", "connection_name": "list_analytics"} */

    select distinct nspname from pg_namespace
  
[0m12:12:26.556933 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m12:12:26.571963 [debug] [ThreadPool]: SQL status: SELECT 7 in 0.015 seconds
[0m12:12:26.575405 [debug] [ThreadPool]: On list_analytics: Close
[0m12:12:26.579700 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_analytics, now list_analytics_analytics)
[0m12:12:26.597737 [debug] [ThreadPool]: Using postgres connection "list_analytics_analytics"
[0m12:12:26.599415 [debug] [ThreadPool]: On list_analytics_analytics: BEGIN
[0m12:12:26.600920 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m12:12:26.613020 [debug] [ThreadPool]: SQL status: BEGIN in 0.012 seconds
[0m12:12:26.615404 [debug] [ThreadPool]: Using postgres connection "list_analytics_analytics"
[0m12:12:26.617699 [debug] [ThreadPool]: On list_analytics_analytics: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "homework", "target_name": "dev", "connection_name": "list_analytics_analytics"} */
select
      'analytics' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'analytics'
    union all
    select
      'analytics' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'analytics'
    union all
    select
      'analytics' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'analytics'
  
[0m12:12:26.623950 [debug] [ThreadPool]: SQL status: SELECT 3 in 0.004 seconds
[0m12:12:26.628034 [debug] [ThreadPool]: On list_analytics_analytics: ROLLBACK
[0m12:12:26.631163 [debug] [ThreadPool]: On list_analytics_analytics: Close
[0m12:12:26.645779 [debug] [MainThread]: Using postgres connection "master"
[0m12:12:26.648496 [debug] [MainThread]: On master: BEGIN
[0m12:12:26.650479 [debug] [MainThread]: Opening a new connection, currently in state init
[0m12:12:26.662850 [debug] [MainThread]: SQL status: BEGIN in 0.012 seconds
[0m12:12:26.668812 [debug] [MainThread]: Using postgres connection "master"
[0m12:12:26.671627 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "homework", "target_name": "dev", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select distinct
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v', 'm')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
[0m12:12:26.685666 [debug] [MainThread]: SQL status: SELECT 1 in 0.011 seconds
[0m12:12:26.689594 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'ea4821e8-fdd8-41eb-b631-51a54a7923ca', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f7474033250>]}
[0m12:12:26.691518 [debug] [MainThread]: On master: ROLLBACK
[0m12:12:26.693615 [debug] [MainThread]: Using postgres connection "master"
[0m12:12:26.695610 [debug] [MainThread]: On master: BEGIN
[0m12:12:26.698398 [debug] [MainThread]: SQL status: BEGIN in 0.001 seconds
[0m12:12:26.701117 [debug] [MainThread]: On master: COMMIT
[0m12:12:26.707942 [debug] [MainThread]: Using postgres connection "master"
[0m12:12:26.710319 [debug] [MainThread]: On master: COMMIT
[0m12:12:26.713662 [debug] [MainThread]: SQL status: COMMIT in 0.000 seconds
[0m12:12:26.716169 [debug] [MainThread]: On master: Close
[0m12:12:26.727169 [debug] [Thread-1  ]: Began running node model.homework.stg_iris
[0m12:12:26.730163 [info ] [Thread-1  ]: 1 of 2 START sql view model analytics.stg_iris ................................. [RUN]
[0m12:12:26.732723 [debug] [Thread-1  ]: Re-using an available connection from the pool (formerly list_analytics_analytics, now model.homework.stg_iris)
[0m12:12:26.735158 [debug] [Thread-1  ]: Began compiling node model.homework.stg_iris
[0m12:12:26.757892 [debug] [Thread-1  ]: Writing injected SQL for node "model.homework.stg_iris"
[0m12:12:26.770529 [debug] [Thread-1  ]: Began executing node model.homework.stg_iris
[0m12:12:26.851583 [debug] [Thread-1  ]: Writing runtime sql for node "model.homework.stg_iris"
[0m12:12:26.860718 [debug] [Thread-1  ]: Using postgres connection "model.homework.stg_iris"
[0m12:12:26.862689 [debug] [Thread-1  ]: On model.homework.stg_iris: BEGIN
[0m12:12:26.864497 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
[0m12:12:26.875977 [debug] [Thread-1  ]: SQL status: BEGIN in 0.011 seconds
[0m12:12:26.879121 [debug] [Thread-1  ]: Using postgres connection "model.homework.stg_iris"
[0m12:12:26.882714 [debug] [Thread-1  ]: On model.homework.stg_iris: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "homework", "target_name": "dev", "node_id": "model.homework.stg_iris"} */

  create view "analytics"."analytics"."stg_iris__dbt_tmp"
    
    
  as (
    with source as (
    select * from "analytics"."analytics"."iris_dataset"
)

select
    cast(sepal_length as numeric) as sepal_length,
    cast(sepal_width as numeric) as sepal_width,
    cast(petal_length as numeric) as petal_length,
    cast(petal_width as numeric) as petal_width,
    species
from source
  );
[0m12:12:26.895267 [debug] [Thread-1  ]: SQL status: CREATE VIEW in 0.009 seconds
[0m12:12:26.924283 [debug] [Thread-1  ]: Using postgres connection "model.homework.stg_iris"
[0m12:12:26.928349 [debug] [Thread-1  ]: On model.homework.stg_iris: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "homework", "target_name": "dev", "node_id": "model.homework.stg_iris"} */
alter table "analytics"."analytics"."stg_iris" rename to "stg_iris__dbt_backup"
[0m12:12:26.935965 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.001 seconds
[0m12:12:26.952304 [debug] [Thread-1  ]: Using postgres connection "model.homework.stg_iris"
[0m12:12:26.955059 [debug] [Thread-1  ]: On model.homework.stg_iris: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "homework", "target_name": "dev", "node_id": "model.homework.stg_iris"} */
alter table "analytics"."analytics"."stg_iris__dbt_tmp" rename to "stg_iris"
[0m12:12:26.958427 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.001 seconds
[0m12:12:27.090488 [debug] [Thread-1  ]: On model.homework.stg_iris: COMMIT
[0m12:12:27.101332 [debug] [Thread-1  ]: Using postgres connection "model.homework.stg_iris"
[0m12:12:27.104987 [debug] [Thread-1  ]: On model.homework.stg_iris: COMMIT
[0m12:12:27.111081 [debug] [Thread-1  ]: SQL status: COMMIT in 0.003 seconds
[0m12:12:27.153738 [debug] [Thread-1  ]: Applying DROP to: "analytics"."analytics"."stg_iris__dbt_backup"
[0m12:12:27.190602 [debug] [Thread-1  ]: Using postgres connection "model.homework.stg_iris"
[0m12:12:27.194081 [debug] [Thread-1  ]: On model.homework.stg_iris: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "homework", "target_name": "dev", "node_id": "model.homework.stg_iris"} */
drop view if exists "analytics"."analytics"."stg_iris__dbt_backup" cascade
[0m12:12:27.205528 [debug] [Thread-1  ]: SQL status: DROP VIEW in 0.006 seconds
[0m12:12:27.236413 [debug] [Thread-1  ]: On model.homework.stg_iris: Close
[0m12:12:27.244834 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'ea4821e8-fdd8-41eb-b631-51a54a7923ca', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f7475351130>]}
[0m12:12:27.251659 [info ] [Thread-1  ]: 1 of 2 OK created sql view model analytics.stg_iris ............................ [[32mCREATE VIEW[0m in 0.51s]
[0m12:12:27.254496 [debug] [Thread-1  ]: Finished running node model.homework.stg_iris
[0m12:12:27.257700 [debug] [Thread-3  ]: Began running node model.homework.iris_processed
[0m12:12:27.259882 [info ] [Thread-3  ]: 2 of 2 START sql table model analytics.iris_processed .......................... [RUN]
[0m12:12:27.262492 [debug] [Thread-3  ]: Acquiring new postgres connection 'model.homework.iris_processed'
[0m12:12:27.267807 [debug] [Thread-3  ]: Began compiling node model.homework.iris_processed
[0m12:12:27.311432 [debug] [Thread-3  ]: Using postgres connection "model.homework.iris_processed"
[0m12:12:27.314676 [debug] [Thread-3  ]: On model.homework.iris_processed: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "homework", "target_name": "dev", "node_id": "model.homework.iris_processed"} */

        select percentile_cont(0.5) within group (order by sepal_length ) from "analytics"."analytics"."stg_iris"
    
[0m12:12:27.317225 [debug] [Thread-3  ]: Opening a new connection, currently in state init
[0m12:12:27.331700 [debug] [Thread-3  ]: SQL status: SELECT 1 in 0.014 seconds
[0m12:12:27.337729 [debug] [Thread-3  ]: Using postgres connection "model.homework.iris_processed"
[0m12:12:27.340024 [debug] [Thread-3  ]: On model.homework.iris_processed: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "homework", "target_name": "dev", "node_id": "model.homework.iris_processed"} */

        select percentile_cont(0.5 - 0.5/2) within group (order by sepal_length ) from "analytics"."analytics"."stg_iris"
    
[0m12:12:27.343165 [debug] [Thread-3  ]: SQL status: SELECT 1 in 0.001 seconds
[0m12:12:27.349495 [debug] [Thread-3  ]: Using postgres connection "model.homework.iris_processed"
[0m12:12:27.351560 [debug] [Thread-3  ]: On model.homework.iris_processed: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "homework", "target_name": "dev", "node_id": "model.homework.iris_processed"} */

        select percentile_cont(0.5 + 0.5/2) within group (order by sepal_length ) from "analytics"."analytics"."stg_iris"
    
[0m12:12:27.354388 [debug] [Thread-3  ]: SQL status: SELECT 1 in 0.001 seconds
[0m12:12:27.361478 [debug] [Thread-3  ]: Using postgres connection "model.homework.iris_processed"
[0m12:12:27.364878 [debug] [Thread-3  ]: On model.homework.iris_processed: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "homework", "target_name": "dev", "node_id": "model.homework.iris_processed"} */

        select percentile_cont(0.5) within group (order by sepal_width ) from "analytics"."analytics"."stg_iris"
    
[0m12:12:27.368245 [debug] [Thread-3  ]: SQL status: SELECT 1 in 0.001 seconds
[0m12:12:27.372919 [debug] [Thread-3  ]: Using postgres connection "model.homework.iris_processed"
[0m12:12:27.375336 [debug] [Thread-3  ]: On model.homework.iris_processed: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "homework", "target_name": "dev", "node_id": "model.homework.iris_processed"} */

        select percentile_cont(0.5 - 0.5/2) within group (order by sepal_width ) from "analytics"."analytics"."stg_iris"
    
[0m12:12:27.383336 [debug] [Thread-3  ]: SQL status: SELECT 1 in 0.002 seconds
[0m12:12:27.388910 [debug] [Thread-3  ]: Using postgres connection "model.homework.iris_processed"
[0m12:12:27.390742 [debug] [Thread-3  ]: On model.homework.iris_processed: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "homework", "target_name": "dev", "node_id": "model.homework.iris_processed"} */

        select percentile_cont(0.5 + 0.5/2) within group (order by sepal_width ) from "analytics"."analytics"."stg_iris"
    
[0m12:12:27.393794 [debug] [Thread-3  ]: SQL status: SELECT 1 in 0.001 seconds
[0m12:12:27.403795 [debug] [Thread-3  ]: Using postgres connection "model.homework.iris_processed"
[0m12:12:27.405539 [debug] [Thread-3  ]: On model.homework.iris_processed: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "homework", "target_name": "dev", "node_id": "model.homework.iris_processed"} */

        select percentile_cont(0.5) within group (order by petal_length ) from "analytics"."analytics"."stg_iris"
    
[0m12:12:27.408278 [debug] [Thread-3  ]: SQL status: SELECT 1 in 0.001 seconds
[0m12:12:27.412495 [debug] [Thread-3  ]: Using postgres connection "model.homework.iris_processed"
[0m12:12:27.416676 [debug] [Thread-3  ]: On model.homework.iris_processed: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "homework", "target_name": "dev", "node_id": "model.homework.iris_processed"} */

        select percentile_cont(0.5 - 0.5/2) within group (order by petal_length ) from "analytics"."analytics"."stg_iris"
    
[0m12:12:27.419569 [debug] [Thread-3  ]: SQL status: SELECT 1 in 0.001 seconds
[0m12:12:27.425056 [debug] [Thread-3  ]: Using postgres connection "model.homework.iris_processed"
[0m12:12:27.427145 [debug] [Thread-3  ]: On model.homework.iris_processed: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "homework", "target_name": "dev", "node_id": "model.homework.iris_processed"} */

        select percentile_cont(0.5 + 0.5/2) within group (order by petal_length ) from "analytics"."analytics"."stg_iris"
    
[0m12:12:27.431007 [debug] [Thread-3  ]: SQL status: SELECT 1 in 0.001 seconds
[0m12:12:27.437319 [debug] [Thread-3  ]: Using postgres connection "model.homework.iris_processed"
[0m12:12:27.439247 [debug] [Thread-3  ]: On model.homework.iris_processed: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "homework", "target_name": "dev", "node_id": "model.homework.iris_processed"} */

        select percentile_cont(0.5) within group (order by petal_width ) from "analytics"."analytics"."stg_iris"
    
[0m12:12:27.442644 [debug] [Thread-3  ]: SQL status: SELECT 1 in 0.001 seconds
[0m12:12:27.448394 [debug] [Thread-3  ]: Using postgres connection "model.homework.iris_processed"
[0m12:12:27.450335 [debug] [Thread-3  ]: On model.homework.iris_processed: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "homework", "target_name": "dev", "node_id": "model.homework.iris_processed"} */

        select percentile_cont(0.5 - 0.5/2) within group (order by petal_width ) from "analytics"."analytics"."stg_iris"
    
[0m12:12:27.452858 [debug] [Thread-3  ]: SQL status: SELECT 1 in 0.001 seconds
[0m12:12:27.457196 [debug] [Thread-3  ]: Using postgres connection "model.homework.iris_processed"
[0m12:12:27.459017 [debug] [Thread-3  ]: On model.homework.iris_processed: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "homework", "target_name": "dev", "node_id": "model.homework.iris_processed"} */

        select percentile_cont(0.5 + 0.5/2) within group (order by petal_width ) from "analytics"."analytics"."stg_iris"
    
[0m12:12:27.461637 [debug] [Thread-3  ]: SQL status: SELECT 1 in 0.001 seconds
[0m12:12:27.470386 [debug] [Thread-3  ]: Using postgres connection "model.homework.iris_processed"
[0m12:12:27.472298 [debug] [Thread-3  ]: On model.homework.iris_processed: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "homework", "target_name": "dev", "node_id": "model.homework.iris_processed"} */

            select percentile_cont(0.5) within group (order by sepal_length ) from "analytics"."analytics"."stg_iris"
        
[0m12:12:27.474861 [debug] [Thread-3  ]: SQL status: SELECT 1 in 0.001 seconds
[0m12:12:27.480047 [debug] [Thread-3  ]: Using postgres connection "model.homework.iris_processed"
[0m12:12:27.483128 [debug] [Thread-3  ]: On model.homework.iris_processed: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "homework", "target_name": "dev", "node_id": "model.homework.iris_processed"} */

            select percentile_cont(0.5) within group (order by sepal_width ) from "analytics"."analytics"."stg_iris"
        
[0m12:12:27.486840 [debug] [Thread-3  ]: SQL status: SELECT 1 in 0.001 seconds
[0m12:12:27.494745 [debug] [Thread-3  ]: Using postgres connection "model.homework.iris_processed"
[0m12:12:27.497469 [debug] [Thread-3  ]: On model.homework.iris_processed: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "homework", "target_name": "dev", "node_id": "model.homework.iris_processed"} */

            select percentile_cont(0.5) within group (order by petal_length ) from "analytics"."analytics"."stg_iris"
        
[0m12:12:27.500893 [debug] [Thread-3  ]: SQL status: SELECT 1 in 0.001 seconds
[0m12:12:27.506855 [debug] [Thread-3  ]: Using postgres connection "model.homework.iris_processed"
[0m12:12:27.509112 [debug] [Thread-3  ]: On model.homework.iris_processed: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "homework", "target_name": "dev", "node_id": "model.homework.iris_processed"} */

            select percentile_cont(0.5) within group (order by petal_width ) from "analytics"."analytics"."stg_iris"
        
[0m12:12:27.511951 [debug] [Thread-3  ]: SQL status: SELECT 1 in 0.001 seconds
[0m12:12:27.546019 [debug] [Thread-3  ]: Using postgres connection "model.homework.iris_processed"
[0m12:12:27.551848 [debug] [Thread-3  ]: On model.homework.iris_processed: BEGIN
[0m12:12:27.555133 [debug] [Thread-3  ]: SQL status: BEGIN in 0.000 seconds
[0m12:12:27.558209 [debug] [Thread-3  ]: Using postgres connection "model.homework.iris_processed"
[0m12:12:27.561523 [debug] [Thread-3  ]: On model.homework.iris_processed: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "homework", "target_name": "dev", "node_id": "model.homework.iris_processed"} */
select
                species as value

            from "analytics"."analytics"."stg_iris"

            
            where species is not null  and true
            

            group by species
            order by species

            

        
[0m12:12:27.567729 [debug] [Thread-3  ]: SQL status: SELECT 3 in 0.001 seconds
[0m12:12:27.588246 [debug] [Thread-3  ]: Writing injected SQL for node "model.homework.iris_processed"
[0m12:12:27.602730 [debug] [Thread-3  ]: Began executing node model.homework.iris_processed
[0m12:12:27.667702 [debug] [Thread-3  ]: Writing runtime sql for node "model.homework.iris_processed"
[0m12:12:27.677204 [debug] [Thread-3  ]: Using postgres connection "model.homework.iris_processed"
[0m12:12:27.680315 [debug] [Thread-3  ]: On model.homework.iris_processed: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "homework", "target_name": "dev", "node_id": "model.homework.iris_processed"} */

  
    

  create  table "analytics"."analytics"."iris_processed__dbt_tmp"
  
  
    as
  
  (
    

with import_iris as (
    select *
    from "analytics"."analytics"."stg_iris"
)
select
    sepal_length,
    sepal_width,
    petal_length,
    petal_width,
    -- K Bins Discretization
    
        

    
        NTILE(5) over (order by sepal_length)
    

 as sepal_length_quantile_bin,
        

    
        
        floor(
        (
            sepal_length - (min(sepal_length) over ())
        )
        /
        (
            ((max(sepal_length) over ()) - (min(sepal_length) over ())) / 4::float
        )
        ) + 1
    

 as sepal_length_uniform_bin,
    
        

    
        NTILE(5) over (order by sepal_width)
    

 as sepal_width_quantile_bin,
        

    
        
        floor(
        (
            sepal_width - (min(sepal_width) over ())
        )
        /
        (
            ((max(sepal_width) over ()) - (min(sepal_width) over ())) / 4::float
        )
        ) + 1
    

 as sepal_width_uniform_bin,
    
        

    
        NTILE(5) over (order by petal_length)
    

 as petal_length_quantile_bin,
        

    
        
        floor(
        (
            petal_length - (min(petal_length) over ())
        )
        /
        (
            ((max(petal_length) over ()) - (min(petal_length) over ())) / 4::float
        )
        ) + 1
    

 as petal_length_uniform_bin,
    
        

    
        NTILE(5) over (order by petal_width)
    

 as petal_width_quantile_bin,
        

    
        
        floor(
        (
            petal_width - (min(petal_width) over ())
        )
        /
        (
            ((max(petal_width) over ()) - (min(petal_width) over ())) / 4::float
        )
        ) + 1
    

 as petal_width_uniform_bin,
    
-- Scaling
    
        

    

    
    
    

    
    
    

    (
        sepal_length - 5.8
    )
    /
    (
        6.4 - 5.1
    )

 as sepal_length_robust_scaled,
        

    (sepal_length) / (max(abs(sepal_length)) over ())::FLOAT

 as sepal_length_max_absolute_scaled,
        

    
    (
        ((sepal_length) - (min(sepal_length) over ()))
        /
        ((max(sepal_length) over ()) - (min(sepal_length) over ()))::FLOAT
    )
    *
    (1.0 - 0.0)
    +
    0.0

 as sepal_length_max_min_max_scaled,
    
        

    

    
    
    

    
    
    

    (
        sepal_width - 3.0
    )
    /
    (
        3.3 - 2.8
    )

 as sepal_width_robust_scaled,
        

    (sepal_width) / (max(abs(sepal_width)) over ())::FLOAT

 as sepal_width_max_absolute_scaled,
        

    
    (
        ((sepal_width) - (min(sepal_width) over ()))
        /
        ((max(sepal_width) over ()) - (min(sepal_width) over ()))::FLOAT
    )
    *
    (1.0 - 0.0)
    +
    0.0

 as sepal_width_max_min_max_scaled,
    
        

    

    
    
    

    
    
    

    (
        petal_length - 4.35
    )
    /
    (
        5.1 - 1.6
    )

 as petal_length_robust_scaled,
        

    (petal_length) / (max(abs(petal_length)) over ())::FLOAT

 as petal_length_max_absolute_scaled,
        

    
    (
        ((petal_length) - (min(petal_length) over ()))
        /
        ((max(petal_length) over ()) - (min(petal_length) over ()))::FLOAT
    )
    *
    (1.0 - 0.0)
    +
    0.0

 as petal_length_max_min_max_scaled,
    
        

    

    
    
    

    
    
    

    (
        petal_width - 1.3
    )
    /
    (
        1.8 - 0.3
    )

 as petal_width_robust_scaled,
        

    (petal_width) / (max(abs(petal_width)) over ())::FLOAT

 as petal_width_max_absolute_scaled,
        

    
    (
        ((petal_width) - (min(petal_width) over ()))
        /
        ((max(petal_width) over ()) - (min(petal_width) over ()))::FLOAT
    )
    *
    (1.0 - 0.0)
    +
    0.0

 as petal_width_max_min_max_scaled,
    

    -- Log Transformation
    
        

    case
        when sepal_length is null or sepal_length + 0 <= 0 then null
        else log(10, sepal_length + 0)
    end

 as sepal_length_logged,
    
        

    case
        when sepal_width is null or sepal_width + 0 <= 0 then null
        else log(10, sepal_width + 0)
    end

 as sepal_width_logged,
    
        

    case
        when petal_length is null or petal_length + 0 <= 0 then null
        else log(10, petal_length + 0)
    end

 as petal_length_logged,
    
        

    case
        when petal_width is null or petal_width + 0 <= 0 then null
        else log(10, petal_width + 0)
    end

 as petal_width_logged,
    

    -- Binarization
    
        

    

    
        

        
    

    case
        when sepal_length >=
            
                5.8
            
            then 1
        else 0
    end

 as sepal_length_binarized,
    
        

    

    
        

        
    

    case
        when sepal_width >=
            
                3.0
            
            then 1
        else 0
    end

 as sepal_width_binarized,
    
        

    

    
        

        
    

    case
        when petal_length >=
            
                4.35
            
            then 1
        else 0
    end

 as petal_length_binarized,
    
        

    

    
        

        
    

    case
        when petal_width >=
            
                1.3
            
            then 1
        else 0
    end

 as petal_width_binarized,
    

    -- Standardization
    
        

    
    (
        (sepal_length - avg(sepal_length) over ())
        /
        (stddev(sepal_length) over ())::FLOAT
    )
    *
    1
    +
    0

 as sepal_length_standardized,
    
        

    
    (
        (sepal_width - avg(sepal_width) over ())
        /
        (stddev(sepal_width) over ())::FLOAT
    )
    *
    1
    +
    0

 as sepal_width_standardized,
    
        

    
    (
        (petal_length - avg(petal_length) over ())
        /
        (stddev(petal_length) over ())::FLOAT
    )
    *
    1
    +
    0

 as petal_length_standardized,
    
        

    
    (
        (petal_width - avg(petal_width) over ())
        /
        (stddev(petal_width) over ())::FLOAT
    )
    *
    1
    +
    0

 as petal_width_standardized,
    
-- Interactions
    
        
            
            
            

    
        (sepal_length * sepal_width)
    

 as sepal_length_x_sepal_width_interaction,
            

    
        (sepal_length + sepal_width)
    

 as sepal_length_plus_sepal_width_interaction,
        
            
            
            

    
        (sepal_length * petal_length)
    

 as sepal_length_x_petal_length_interaction,
            

    
        (sepal_length + petal_length)
    

 as sepal_length_plus_petal_length_interaction,
        
            
            
            

    
        (sepal_length * petal_width)
    

 as sepal_length_x_petal_width_interaction,
            

    
        (sepal_length + petal_width)
    

 as sepal_length_plus_petal_width_interaction,
        
    
        
            
            
            

    
        (sepal_width * petal_length)
    

 as sepal_width_x_petal_length_interaction,
            

    
        (sepal_width + petal_length)
    

 as sepal_width_plus_petal_length_interaction,
        
            
            
            

    
        (sepal_width * petal_width)
    

 as sepal_width_x_petal_width_interaction,
            

    
        (sepal_width + petal_width)
    

 as sepal_width_plus_petal_width_interaction,
        
    
        
            
            
            

    
        (petal_length * petal_width)
    

 as petal_length_x_petal_width_interaction,
            

    
        (petal_length + petal_width)
    

 as petal_length_plus_petal_width_interaction,
        
    
        
    
species,    
    -- Label Encoding
    

    dense_rank() over (order by species) - 1

 as species_label_encoded,
    -- One Hot Encoding
    

    

    
        
    

    

    

        case
            when species = 'setosa' then 1
            else 0
        end as is_species__setosa,

    

        case
            when species = 'versicolor' then 1
            else 0
        end as is_species__versicolor,

    

        case
            when species = 'virginica' then 1
            else 0
        end as is_species__virginica,

    

    case
        when species is null then 1
        else 0
    end as is_species__


from "analytics"."analytics"."stg_iris"
  );
  
[0m12:12:27.723338 [debug] [Thread-3  ]: SQL status: SELECT 150 in 0.040 seconds
[0m12:12:27.740109 [debug] [Thread-3  ]: Using postgres connection "model.homework.iris_processed"
[0m12:12:27.741741 [debug] [Thread-3  ]: On model.homework.iris_processed: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "homework", "target_name": "dev", "node_id": "model.homework.iris_processed"} */
alter table "analytics"."analytics"."iris_processed" rename to "iris_processed__dbt_backup"
[0m12:12:27.744027 [debug] [Thread-3  ]: SQL status: ALTER TABLE in 0.000 seconds
[0m12:12:27.754273 [debug] [Thread-3  ]: Using postgres connection "model.homework.iris_processed"
[0m12:12:27.756494 [debug] [Thread-3  ]: On model.homework.iris_processed: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "homework", "target_name": "dev", "node_id": "model.homework.iris_processed"} */
alter table "analytics"."analytics"."iris_processed__dbt_tmp" rename to "iris_processed"
[0m12:12:27.758835 [debug] [Thread-3  ]: SQL status: ALTER TABLE in 0.000 seconds
[0m12:12:27.763670 [debug] [Thread-3  ]: On model.homework.iris_processed: COMMIT
[0m12:12:27.765822 [debug] [Thread-3  ]: Using postgres connection "model.homework.iris_processed"
[0m12:12:27.767676 [debug] [Thread-3  ]: On model.homework.iris_processed: COMMIT
[0m12:12:27.772703 [debug] [Thread-3  ]: SQL status: COMMIT in 0.003 seconds
[0m12:12:27.781779 [debug] [Thread-3  ]: Applying DROP to: "analytics"."analytics"."iris_processed__dbt_backup"
[0m12:12:27.789151 [debug] [Thread-3  ]: Using postgres connection "model.homework.iris_processed"
[0m12:12:27.790931 [debug] [Thread-3  ]: On model.homework.iris_processed: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "homework", "target_name": "dev", "node_id": "model.homework.iris_processed"} */
drop table if exists "analytics"."analytics"."iris_processed__dbt_backup" cascade
[0m12:12:27.800368 [debug] [Thread-3  ]: SQL status: DROP TABLE in 0.007 seconds
[0m12:12:27.804975 [debug] [Thread-3  ]: On model.homework.iris_processed: Close
[0m12:12:27.807600 [debug] [Thread-3  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'ea4821e8-fdd8-41eb-b631-51a54a7923ca', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f74542ab730>]}
[0m12:12:27.810355 [info ] [Thread-3  ]: 2 of 2 OK created sql table model analytics.iris_processed ..................... [[32mSELECT 150[0m in 0.55s]
[0m12:12:27.814097 [debug] [Thread-3  ]: Finished running node model.homework.iris_processed
[0m12:12:27.818739 [debug] [MainThread]: Using postgres connection "master"
[0m12:12:27.820757 [debug] [MainThread]: On master: BEGIN
[0m12:12:27.822713 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m12:12:27.834349 [debug] [MainThread]: SQL status: BEGIN in 0.011 seconds
[0m12:12:27.836604 [debug] [MainThread]: On master: COMMIT
[0m12:12:27.838871 [debug] [MainThread]: Using postgres connection "master"
[0m12:12:27.841388 [debug] [MainThread]: On master: COMMIT
[0m12:12:27.843293 [debug] [MainThread]: SQL status: COMMIT in 0.000 seconds
[0m12:12:27.844991 [debug] [MainThread]: On master: Close
[0m12:12:27.847426 [debug] [MainThread]: Connection 'master' was properly closed.
[0m12:12:27.849282 [debug] [MainThread]: Connection 'model.homework.stg_iris' was properly closed.
[0m12:12:27.851053 [debug] [MainThread]: Connection 'model.homework.iris_processed' was properly closed.
[0m12:12:27.852546 [info ] [MainThread]: 
[0m12:12:27.854150 [info ] [MainThread]: Finished running 1 table model, 1 view model in 0 hours 0 minutes and 1.39 seconds (1.39s).
[0m12:12:27.856769 [debug] [MainThread]: Command end result
[0m12:12:27.952196 [debug] [MainThread]: Wrote artifact WritableManifest to /opt/airflow/dags/dbt/homework/target/manifest.json
[0m12:12:27.959773 [debug] [MainThread]: Wrote artifact SemanticManifest to /opt/airflow/dags/dbt/homework/target/semantic_manifest.json
[0m12:12:27.978833 [debug] [MainThread]: Wrote artifact RunExecutionResult to /opt/airflow/dags/dbt/homework/target/run_results.json
[0m12:12:27.980852 [info ] [MainThread]: 
[0m12:12:27.982830 [info ] [MainThread]: [32mCompleted successfully[0m
[0m12:12:27.984683 [info ] [MainThread]: 
[0m12:12:27.986259 [info ] [MainThread]: Done. PASS=2 WARN=0 ERROR=0 SKIP=0 TOTAL=2
[0m12:12:27.988632 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": true, "command_wall_clock_time": 8.85727, "process_in_blocks": "16", "process_kernel_time": 0.479961, "process_mem_max_rss": "119132", "process_out_blocks": "0", "process_user_time": 10.11919}
[0m12:12:27.990452 [debug] [MainThread]: Command `dbt run` succeeded at 12:12:27.990275 after 8.86 seconds
[0m12:12:27.991937 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f7477d91ac0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f7476f52f70>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f747532f3a0>]}
[0m12:12:27.993520 [debug] [MainThread]: Flushing usage events
[0m12:12:28.601283 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m12:12:37.058685 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc7f1f36af0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc7f1058520>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc7f10584c0>]}


============================== 12:12:37.072512 | 29cbcbdf-e060-49f8-9fbe-56e5b0ea9e50 ==============================
[0m12:12:37.072512 [info ] [MainThread]: Running with dbt=1.9.4
[0m12:12:37.075166 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': '/opt/airflow/dags/dbt', 'debug': 'False', 'fail_fast': 'True', 'log_path': '/opt/airflow/dags/dbt/homework/logs', 'warn_error': 'None', 'version_check': 'True', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'empty': 'None', 'log_format': 'default', 'invocation_command': 'dbt --profile homework test --project-dir=/opt/airflow/dags/dbt/homework --vars {"is_test": false, "data_date": "2025-04-22"} --fail-fast', 'static_parser': 'True', 'introspect': 'True', 'target_path': 'None', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'send_anonymous_usage_stats': 'True'}
[0m12:12:37.657733 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '29cbcbdf-e060-49f8-9fbe-56e5b0ea9e50', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc7f391dc70>]}
[0m12:12:37.779812 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '29cbcbdf-e060-49f8-9fbe-56e5b0ea9e50', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc7ef799520>]}
[0m12:12:37.782178 [info ] [MainThread]: Registered adapter: postgres=1.9.0
[0m12:12:38.109040 [debug] [MainThread]: checksum: b4b46bb6a239f66694dfdd44ef1792882cb61f2fd7b1ea66b3c7a170d2bb602d, vars: {'data_date': '2025-04-22', 'is_test': False}, profile: homework, target: , version: 1.9.4
[0m12:12:39.911403 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m12:12:39.913243 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m12:12:39.928176 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 1 unused configuration paths:
- seeds.homework.iris_dataset
[0m12:12:40.008182 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '29cbcbdf-e060-49f8-9fbe-56e5b0ea9e50', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc7ef385130>]}
[0m12:12:40.283718 [debug] [MainThread]: Wrote artifact WritableManifest to /opt/airflow/dags/dbt/homework/target/manifest.json
[0m12:12:40.300915 [debug] [MainThread]: Wrote artifact SemanticManifest to /opt/airflow/dags/dbt/homework/target/semantic_manifest.json
[0m12:12:40.346386 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '29cbcbdf-e060-49f8-9fbe-56e5b0ea9e50', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc7ef264580>]}
[0m12:12:40.348244 [info ] [MainThread]: Found 2 models, 1 source, 587 macros
[0m12:12:40.349803 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '29cbcbdf-e060-49f8-9fbe-56e5b0ea9e50', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc7ef2cba30>]}
[0m12:12:40.353256 [warn ] [MainThread]: Nothing to do. Try checking your model configs and model specification args
[0m12:12:40.357667 [debug] [MainThread]: Command end result
[0m12:12:40.459986 [debug] [MainThread]: Wrote artifact WritableManifest to /opt/airflow/dags/dbt/homework/target/manifest.json
[0m12:12:40.469442 [debug] [MainThread]: Wrote artifact SemanticManifest to /opt/airflow/dags/dbt/homework/target/semantic_manifest.json
[0m12:12:40.481673 [debug] [MainThread]: Wrote artifact RunExecutionResult to /opt/airflow/dags/dbt/homework/target/run_results.json
[0m12:12:40.484335 [debug] [MainThread]: Resource report: {"command_name": "test", "command_success": true, "command_wall_clock_time": 3.5672376, "process_in_blocks": "0", "process_kernel_time": 0.443133, "process_mem_max_rss": "104596", "process_out_blocks": "0", "process_user_time": 6.113221}
[0m12:12:40.486476 [debug] [MainThread]: Command `dbt test` succeeded at 12:12:40.486248 after 3.57 seconds
[0m12:12:40.488301 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc7f1f36af0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc7f1e006d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc7ef82a130>]}
[0m12:12:40.490111 [debug] [MainThread]: Flushing usage events
[0m12:12:41.673084 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m12:17:13.697263 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f7cf1c80af0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f7cf0da1460>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f7cf0da1400>]}


============================== 12:17:13.710735 | f8173ed8-a38a-4959-a78c-4fed4053f929 ==============================
[0m12:17:13.710735 [info ] [MainThread]: Running with dbt=1.9.4
[0m12:17:13.712750 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': '/opt/airflow/dags/dbt', 'fail_fast': 'False', 'debug': 'False', 'log_path': '/opt/airflow/dags/dbt/homework/logs', 'version_check': 'True', 'warn_error': 'None', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'empty': 'False', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'static_parser': 'True', 'introspect': 'True', 'log_format': 'default', 'target_path': 'None', 'invocation_command': 'dbt --profile homework run --project-dir=/opt/airflow/dags/dbt/homework --vars {"is_test": false, "data_date": "2025-04-24"}', 'send_anonymous_usage_stats': 'True'}
[0m12:17:14.113922 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'f8173ed8-a38a-4959-a78c-4fed4053f929', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f7cf3667c70>]}
[0m12:17:14.242374 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': 'f8173ed8-a38a-4959-a78c-4fed4053f929', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f7cef52a070>]}
[0m12:17:14.244674 [info ] [MainThread]: Registered adapter: postgres=1.9.0
[0m12:17:14.561607 [debug] [MainThread]: checksum: 6e62424eea9ce3687be3ed3d7873e7c8fa2dd1d7b5a050b5310967d8959a2843, vars: {'data_date': '2025-04-24', 'is_test': False}, profile: homework, target: , version: 1.9.4
[0m12:17:14.854167 [info ] [MainThread]: Unable to do partial parsing because config vars, config profile, or config target have changed
[0m12:17:14.855996 [debug] [MainThread]: previous checksum: 6e62424eea9ce3687be3ed3d7873e7c8fa2dd1d7b5a050b5310967d8959a2843, current checksum: b4b46bb6a239f66694dfdd44ef1792882cb61f2fd7b1ea66b3c7a170d2bb602d
[0m12:17:14.857617 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'partial_parser', 'label': 'f8173ed8-a38a-4959-a78c-4fed4053f929', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f7cf14bed60>]}
[0m12:17:20.568757 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 1 unused configuration paths:
- seeds.homework.iris_dataset
[0m12:17:20.598461 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'f8173ed8-a38a-4959-a78c-4fed4053f929', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f7cef24c130>]}
[0m12:17:20.811707 [debug] [MainThread]: Wrote artifact WritableManifest to /opt/airflow/dags/dbt/homework/target/manifest.json
[0m12:17:20.830167 [debug] [MainThread]: Wrote artifact SemanticManifest to /opt/airflow/dags/dbt/homework/target/semantic_manifest.json
[0m12:17:20.860760 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'f8173ed8-a38a-4959-a78c-4fed4053f929', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f7cef230ca0>]}
[0m12:17:20.862451 [info ] [MainThread]: Found 2 models, 1 source, 587 macros
[0m12:17:20.863912 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'f8173ed8-a38a-4959-a78c-4fed4053f929', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f7cef230670>]}
[0m12:17:20.867161 [info ] [MainThread]: 
[0m12:17:20.868690 [info ] [MainThread]: Concurrency: 4 threads (target='dev')
[0m12:17:20.870213 [info ] [MainThread]: 
[0m12:17:20.871975 [debug] [MainThread]: Acquiring new postgres connection 'master'
[0m12:17:20.881655 [debug] [ThreadPool]: Acquiring new postgres connection 'list_analytics'
[0m12:17:20.937794 [debug] [ThreadPool]: Using postgres connection "list_analytics"
[0m12:17:20.939675 [debug] [ThreadPool]: On list_analytics: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "homework", "target_name": "dev", "connection_name": "list_analytics"} */

    select distinct nspname from pg_namespace
  
[0m12:17:20.941346 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m12:17:20.953834 [debug] [ThreadPool]: SQL status: SELECT 7 in 0.012 seconds
[0m12:17:20.957479 [debug] [ThreadPool]: On list_analytics: Close
[0m12:17:20.960853 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_analytics, now list_analytics_analytics)
[0m12:17:20.975222 [debug] [ThreadPool]: Using postgres connection "list_analytics_analytics"
[0m12:17:20.976784 [debug] [ThreadPool]: On list_analytics_analytics: BEGIN
[0m12:17:20.978412 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m12:17:20.989281 [debug] [ThreadPool]: SQL status: BEGIN in 0.011 seconds
[0m12:17:20.991611 [debug] [ThreadPool]: Using postgres connection "list_analytics_analytics"
[0m12:17:20.994033 [debug] [ThreadPool]: On list_analytics_analytics: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "homework", "target_name": "dev", "connection_name": "list_analytics_analytics"} */
select
      'analytics' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'analytics'
    union all
    select
      'analytics' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'analytics'
    union all
    select
      'analytics' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'analytics'
  
[0m12:17:21.000877 [debug] [ThreadPool]: SQL status: SELECT 3 in 0.004 seconds
[0m12:17:21.004181 [debug] [ThreadPool]: On list_analytics_analytics: ROLLBACK
[0m12:17:21.005996 [debug] [ThreadPool]: On list_analytics_analytics: Close
[0m12:17:21.021289 [debug] [MainThread]: Using postgres connection "master"
[0m12:17:21.023285 [debug] [MainThread]: On master: BEGIN
[0m12:17:21.026014 [debug] [MainThread]: Opening a new connection, currently in state init
[0m12:17:21.037301 [debug] [MainThread]: SQL status: BEGIN in 0.011 seconds
[0m12:17:21.039707 [debug] [MainThread]: Using postgres connection "master"
[0m12:17:21.042785 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "homework", "target_name": "dev", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select distinct
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v', 'm')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
[0m12:17:21.058573 [debug] [MainThread]: SQL status: SELECT 1 in 0.013 seconds
[0m12:17:21.064776 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'f8173ed8-a38a-4959-a78c-4fed4053f929', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f7ceefb0430>]}
[0m12:17:21.066882 [debug] [MainThread]: On master: ROLLBACK
[0m12:17:21.069512 [debug] [MainThread]: Using postgres connection "master"
[0m12:17:21.071432 [debug] [MainThread]: On master: BEGIN
[0m12:17:21.074533 [debug] [MainThread]: SQL status: BEGIN in 0.001 seconds
[0m12:17:21.077155 [debug] [MainThread]: On master: COMMIT
[0m12:17:21.079787 [debug] [MainThread]: Using postgres connection "master"
[0m12:17:21.082673 [debug] [MainThread]: On master: COMMIT
[0m12:17:21.085125 [debug] [MainThread]: SQL status: COMMIT in 0.000 seconds
[0m12:17:21.086607 [debug] [MainThread]: On master: Close
[0m12:17:21.098540 [debug] [Thread-1  ]: Began running node model.homework.stg_iris
[0m12:17:21.100612 [info ] [Thread-1  ]: 1 of 2 START sql view model analytics.stg_iris ................................. [RUN]
[0m12:17:21.102722 [debug] [Thread-1  ]: Re-using an available connection from the pool (formerly list_analytics_analytics, now model.homework.stg_iris)
[0m12:17:21.104320 [debug] [Thread-1  ]: Began compiling node model.homework.stg_iris
[0m12:17:21.130700 [debug] [Thread-1  ]: Writing injected SQL for node "model.homework.stg_iris"
[0m12:17:21.144481 [debug] [Thread-1  ]: Began executing node model.homework.stg_iris
[0m12:17:21.227568 [debug] [Thread-1  ]: Writing runtime sql for node "model.homework.stg_iris"
[0m12:17:21.237743 [debug] [Thread-1  ]: Using postgres connection "model.homework.stg_iris"
[0m12:17:21.239565 [debug] [Thread-1  ]: On model.homework.stg_iris: BEGIN
[0m12:17:21.241320 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
[0m12:17:21.253000 [debug] [Thread-1  ]: SQL status: BEGIN in 0.012 seconds
[0m12:17:21.255837 [debug] [Thread-1  ]: Using postgres connection "model.homework.stg_iris"
[0m12:17:21.258438 [debug] [Thread-1  ]: On model.homework.stg_iris: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "homework", "target_name": "dev", "node_id": "model.homework.stg_iris"} */

  create view "analytics"."analytics"."stg_iris__dbt_tmp"
    
    
  as (
    with source as (
    select * from "analytics"."analytics"."iris_dataset"
)

select
    cast(sepal_length as numeric) as sepal_length,
    cast(sepal_width as numeric) as sepal_width,
    cast(petal_length as numeric) as petal_length,
    cast(petal_width as numeric) as petal_width,
    species
from source
  );
[0m12:17:21.276191 [debug] [Thread-1  ]: SQL status: CREATE VIEW in 0.015 seconds
[0m12:17:21.295777 [debug] [Thread-1  ]: Using postgres connection "model.homework.stg_iris"
[0m12:17:21.298407 [debug] [Thread-1  ]: On model.homework.stg_iris: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "homework", "target_name": "dev", "node_id": "model.homework.stg_iris"} */
alter table "analytics"."analytics"."stg_iris" rename to "stg_iris__dbt_backup"
[0m12:17:21.301456 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.001 seconds
[0m12:17:21.310738 [debug] [Thread-1  ]: Using postgres connection "model.homework.stg_iris"
[0m12:17:21.313055 [debug] [Thread-1  ]: On model.homework.stg_iris: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "homework", "target_name": "dev", "node_id": "model.homework.stg_iris"} */
alter table "analytics"."analytics"."stg_iris__dbt_tmp" rename to "stg_iris"
[0m12:17:21.316110 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.001 seconds
[0m12:17:21.357261 [debug] [Thread-1  ]: On model.homework.stg_iris: COMMIT
[0m12:17:21.359068 [debug] [Thread-1  ]: Using postgres connection "model.homework.stg_iris"
[0m12:17:21.360771 [debug] [Thread-1  ]: On model.homework.stg_iris: COMMIT
[0m12:17:21.366076 [debug] [Thread-1  ]: SQL status: COMMIT in 0.004 seconds
[0m12:17:21.381147 [debug] [Thread-1  ]: Applying DROP to: "analytics"."analytics"."stg_iris__dbt_backup"
[0m12:17:21.391567 [debug] [Thread-1  ]: Using postgres connection "model.homework.stg_iris"
[0m12:17:21.393396 [debug] [Thread-1  ]: On model.homework.stg_iris: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "homework", "target_name": "dev", "node_id": "model.homework.stg_iris"} */
drop view if exists "analytics"."analytics"."stg_iris__dbt_backup" cascade
[0m12:17:21.399131 [debug] [Thread-1  ]: SQL status: DROP VIEW in 0.004 seconds
[0m12:17:21.405525 [debug] [Thread-1  ]: On model.homework.stg_iris: Close
[0m12:17:21.410554 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'f8173ed8-a38a-4959-a78c-4fed4053f929', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f7cef23a3a0>]}
[0m12:17:21.412879 [info ] [Thread-1  ]: 1 of 2 OK created sql view model analytics.stg_iris ............................ [[32mCREATE VIEW[0m in 0.31s]
[0m12:17:21.415244 [debug] [Thread-1  ]: Finished running node model.homework.stg_iris
[0m12:17:21.418207 [debug] [Thread-3  ]: Began running node model.homework.iris_processed
[0m12:17:21.420297 [info ] [Thread-3  ]: 2 of 2 START sql table model analytics.iris_processed .......................... [RUN]
[0m12:17:21.422573 [debug] [Thread-3  ]: Acquiring new postgres connection 'model.homework.iris_processed'
[0m12:17:21.424247 [debug] [Thread-3  ]: Began compiling node model.homework.iris_processed
[0m12:17:21.461052 [debug] [Thread-3  ]: Using postgres connection "model.homework.iris_processed"
[0m12:17:21.462985 [debug] [Thread-3  ]: On model.homework.iris_processed: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "homework", "target_name": "dev", "node_id": "model.homework.iris_processed"} */

        select percentile_cont(0.5) within group (order by sepal_length ) from "analytics"."analytics"."stg_iris"
    
[0m12:17:21.464686 [debug] [Thread-3  ]: Opening a new connection, currently in state init
[0m12:17:21.477652 [debug] [Thread-3  ]: SQL status: SELECT 1 in 0.013 seconds
[0m12:17:21.481668 [debug] [Thread-3  ]: Using postgres connection "model.homework.iris_processed"
[0m12:17:21.483583 [debug] [Thread-3  ]: On model.homework.iris_processed: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "homework", "target_name": "dev", "node_id": "model.homework.iris_processed"} */

        select percentile_cont(0.5 - 0.5/2) within group (order by sepal_length ) from "analytics"."analytics"."stg_iris"
    
[0m12:17:21.486116 [debug] [Thread-3  ]: SQL status: SELECT 1 in 0.001 seconds
[0m12:17:21.489765 [debug] [Thread-3  ]: Using postgres connection "model.homework.iris_processed"
[0m12:17:21.491482 [debug] [Thread-3  ]: On model.homework.iris_processed: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "homework", "target_name": "dev", "node_id": "model.homework.iris_processed"} */

        select percentile_cont(0.5 + 0.5/2) within group (order by sepal_length ) from "analytics"."analytics"."stg_iris"
    
[0m12:17:21.493835 [debug] [Thread-3  ]: SQL status: SELECT 1 in 0.001 seconds
[0m12:17:21.499503 [debug] [Thread-3  ]: Using postgres connection "model.homework.iris_processed"
[0m12:17:21.501167 [debug] [Thread-3  ]: On model.homework.iris_processed: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "homework", "target_name": "dev", "node_id": "model.homework.iris_processed"} */

        select percentile_cont(0.5) within group (order by sepal_width ) from "analytics"."analytics"."stg_iris"
    
[0m12:17:21.503487 [debug] [Thread-3  ]: SQL status: SELECT 1 in 0.001 seconds
[0m12:17:21.507073 [debug] [Thread-3  ]: Using postgres connection "model.homework.iris_processed"
[0m12:17:21.508788 [debug] [Thread-3  ]: On model.homework.iris_processed: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "homework", "target_name": "dev", "node_id": "model.homework.iris_processed"} */

        select percentile_cont(0.5 - 0.5/2) within group (order by sepal_width ) from "analytics"."analytics"."stg_iris"
    
[0m12:17:21.511195 [debug] [Thread-3  ]: SQL status: SELECT 1 in 0.001 seconds
[0m12:17:21.514968 [debug] [Thread-3  ]: Using postgres connection "model.homework.iris_processed"
[0m12:17:21.516618 [debug] [Thread-3  ]: On model.homework.iris_processed: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "homework", "target_name": "dev", "node_id": "model.homework.iris_processed"} */

        select percentile_cont(0.5 + 0.5/2) within group (order by sepal_width ) from "analytics"."analytics"."stg_iris"
    
[0m12:17:21.519337 [debug] [Thread-3  ]: SQL status: SELECT 1 in 0.001 seconds
[0m12:17:21.525033 [debug] [Thread-3  ]: Using postgres connection "model.homework.iris_processed"
[0m12:17:21.526782 [debug] [Thread-3  ]: On model.homework.iris_processed: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "homework", "target_name": "dev", "node_id": "model.homework.iris_processed"} */

        select percentile_cont(0.5) within group (order by petal_length ) from "analytics"."analytics"."stg_iris"
    
[0m12:17:21.529515 [debug] [Thread-3  ]: SQL status: SELECT 1 in 0.001 seconds
[0m12:17:21.533447 [debug] [Thread-3  ]: Using postgres connection "model.homework.iris_processed"
[0m12:17:21.535478 [debug] [Thread-3  ]: On model.homework.iris_processed: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "homework", "target_name": "dev", "node_id": "model.homework.iris_processed"} */

        select percentile_cont(0.5 - 0.5/2) within group (order by petal_length ) from "analytics"."analytics"."stg_iris"
    
[0m12:17:21.537778 [debug] [Thread-3  ]: SQL status: SELECT 1 in 0.001 seconds
[0m12:17:21.541750 [debug] [Thread-3  ]: Using postgres connection "model.homework.iris_processed"
[0m12:17:21.543484 [debug] [Thread-3  ]: On model.homework.iris_processed: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "homework", "target_name": "dev", "node_id": "model.homework.iris_processed"} */

        select percentile_cont(0.5 + 0.5/2) within group (order by petal_length ) from "analytics"."analytics"."stg_iris"
    
[0m12:17:21.545824 [debug] [Thread-3  ]: SQL status: SELECT 1 in 0.001 seconds
[0m12:17:21.552913 [debug] [Thread-3  ]: Using postgres connection "model.homework.iris_processed"
[0m12:17:21.555268 [debug] [Thread-3  ]: On model.homework.iris_processed: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "homework", "target_name": "dev", "node_id": "model.homework.iris_processed"} */

        select percentile_cont(0.5) within group (order by petal_width ) from "analytics"."analytics"."stg_iris"
    
[0m12:17:21.558824 [debug] [Thread-3  ]: SQL status: SELECT 1 in 0.001 seconds
[0m12:17:21.563699 [debug] [Thread-3  ]: Using postgres connection "model.homework.iris_processed"
[0m12:17:21.565929 [debug] [Thread-3  ]: On model.homework.iris_processed: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "homework", "target_name": "dev", "node_id": "model.homework.iris_processed"} */

        select percentile_cont(0.5 - 0.5/2) within group (order by petal_width ) from "analytics"."analytics"."stg_iris"
    
[0m12:17:21.569566 [debug] [Thread-3  ]: SQL status: SELECT 1 in 0.001 seconds
[0m12:17:21.575315 [debug] [Thread-3  ]: Using postgres connection "model.homework.iris_processed"
[0m12:17:21.578011 [debug] [Thread-3  ]: On model.homework.iris_processed: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "homework", "target_name": "dev", "node_id": "model.homework.iris_processed"} */

        select percentile_cont(0.5 + 0.5/2) within group (order by petal_width ) from "analytics"."analytics"."stg_iris"
    
[0m12:17:21.581680 [debug] [Thread-3  ]: SQL status: SELECT 1 in 0.001 seconds
[0m12:17:21.595678 [debug] [Thread-3  ]: Using postgres connection "model.homework.iris_processed"
[0m12:17:21.598888 [debug] [Thread-3  ]: On model.homework.iris_processed: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "homework", "target_name": "dev", "node_id": "model.homework.iris_processed"} */

            select percentile_cont(0.5) within group (order by sepal_length ) from "analytics"."analytics"."stg_iris"
        
[0m12:17:21.602780 [debug] [Thread-3  ]: SQL status: SELECT 1 in 0.001 seconds
[0m12:17:21.610207 [debug] [Thread-3  ]: Using postgres connection "model.homework.iris_processed"
[0m12:17:21.612452 [debug] [Thread-3  ]: On model.homework.iris_processed: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "homework", "target_name": "dev", "node_id": "model.homework.iris_processed"} */

            select percentile_cont(0.5) within group (order by sepal_width ) from "analytics"."analytics"."stg_iris"
        
[0m12:17:21.615813 [debug] [Thread-3  ]: SQL status: SELECT 1 in 0.001 seconds
[0m12:17:21.622026 [debug] [Thread-3  ]: Using postgres connection "model.homework.iris_processed"
[0m12:17:21.625023 [debug] [Thread-3  ]: On model.homework.iris_processed: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "homework", "target_name": "dev", "node_id": "model.homework.iris_processed"} */

            select percentile_cont(0.5) within group (order by petal_length ) from "analytics"."analytics"."stg_iris"
        
[0m12:17:21.629456 [debug] [Thread-3  ]: SQL status: SELECT 1 in 0.001 seconds
[0m12:17:21.640209 [debug] [Thread-3  ]: Using postgres connection "model.homework.iris_processed"
[0m12:17:21.642633 [debug] [Thread-3  ]: On model.homework.iris_processed: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "homework", "target_name": "dev", "node_id": "model.homework.iris_processed"} */

            select percentile_cont(0.5) within group (order by petal_width ) from "analytics"."analytics"."stg_iris"
        
[0m12:17:21.645684 [debug] [Thread-3  ]: SQL status: SELECT 1 in 0.001 seconds
[0m12:17:21.669989 [debug] [Thread-3  ]: Using postgres connection "model.homework.iris_processed"
[0m12:17:21.671887 [debug] [Thread-3  ]: On model.homework.iris_processed: BEGIN
[0m12:17:21.675232 [debug] [Thread-3  ]: SQL status: BEGIN in 0.000 seconds
[0m12:17:21.677967 [debug] [Thread-3  ]: Using postgres connection "model.homework.iris_processed"
[0m12:17:21.680643 [debug] [Thread-3  ]: On model.homework.iris_processed: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "homework", "target_name": "dev", "node_id": "model.homework.iris_processed"} */
select
                species as value

            from "analytics"."analytics"."stg_iris"

            
            where species is not null  and true
            

            group by species
            order by species

            

        
[0m12:17:21.684484 [debug] [Thread-3  ]: SQL status: SELECT 3 in 0.001 seconds
[0m12:17:21.700069 [debug] [Thread-3  ]: Writing injected SQL for node "model.homework.iris_processed"
[0m12:17:21.714224 [debug] [Thread-3  ]: Began executing node model.homework.iris_processed
[0m12:17:21.770967 [debug] [Thread-3  ]: Writing runtime sql for node "model.homework.iris_processed"
[0m12:17:21.781656 [debug] [Thread-3  ]: Using postgres connection "model.homework.iris_processed"
[0m12:17:21.784794 [debug] [Thread-3  ]: On model.homework.iris_processed: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "homework", "target_name": "dev", "node_id": "model.homework.iris_processed"} */

  
    

  create  table "analytics"."analytics"."iris_processed__dbt_tmp"
  
  
    as
  
  (
    

with import_iris as (
    select *
    from "analytics"."analytics"."stg_iris"
)
select
    sepal_length,
    sepal_width,
    petal_length,
    petal_width,
    -- K Bins Discretization
    
        

    
        NTILE(5) over (order by sepal_length)
    

 as sepal_length_quantile_bin,
        

    
        
        floor(
        (
            sepal_length - (min(sepal_length) over ())
        )
        /
        (
            ((max(sepal_length) over ()) - (min(sepal_length) over ())) / 4::float
        )
        ) + 1
    

 as sepal_length_uniform_bin,
    
        

    
        NTILE(5) over (order by sepal_width)
    

 as sepal_width_quantile_bin,
        

    
        
        floor(
        (
            sepal_width - (min(sepal_width) over ())
        )
        /
        (
            ((max(sepal_width) over ()) - (min(sepal_width) over ())) / 4::float
        )
        ) + 1
    

 as sepal_width_uniform_bin,
    
        

    
        NTILE(5) over (order by petal_length)
    

 as petal_length_quantile_bin,
        

    
        
        floor(
        (
            petal_length - (min(petal_length) over ())
        )
        /
        (
            ((max(petal_length) over ()) - (min(petal_length) over ())) / 4::float
        )
        ) + 1
    

 as petal_length_uniform_bin,
    
        

    
        NTILE(5) over (order by petal_width)
    

 as petal_width_quantile_bin,
        

    
        
        floor(
        (
            petal_width - (min(petal_width) over ())
        )
        /
        (
            ((max(petal_width) over ()) - (min(petal_width) over ())) / 4::float
        )
        ) + 1
    

 as petal_width_uniform_bin,
    
-- Scaling
    
        

    

    
    
    

    
    
    

    (
        sepal_length - 5.8
    )
    /
    (
        6.4 - 5.1
    )

 as sepal_length_robust_scaled,
        

    (sepal_length) / (max(abs(sepal_length)) over ())::FLOAT

 as sepal_length_max_absolute_scaled,
        

    
    (
        ((sepal_length) - (min(sepal_length) over ()))
        /
        ((max(sepal_length) over ()) - (min(sepal_length) over ()))::FLOAT
    )
    *
    (1.0 - 0.0)
    +
    0.0

 as sepal_length_max_min_max_scaled,
    
        

    

    
    
    

    
    
    

    (
        sepal_width - 3.0
    )
    /
    (
        3.3 - 2.8
    )

 as sepal_width_robust_scaled,
        

    (sepal_width) / (max(abs(sepal_width)) over ())::FLOAT

 as sepal_width_max_absolute_scaled,
        

    
    (
        ((sepal_width) - (min(sepal_width) over ()))
        /
        ((max(sepal_width) over ()) - (min(sepal_width) over ()))::FLOAT
    )
    *
    (1.0 - 0.0)
    +
    0.0

 as sepal_width_max_min_max_scaled,
    
        

    

    
    
    

    
    
    

    (
        petal_length - 4.35
    )
    /
    (
        5.1 - 1.6
    )

 as petal_length_robust_scaled,
        

    (petal_length) / (max(abs(petal_length)) over ())::FLOAT

 as petal_length_max_absolute_scaled,
        

    
    (
        ((petal_length) - (min(petal_length) over ()))
        /
        ((max(petal_length) over ()) - (min(petal_length) over ()))::FLOAT
    )
    *
    (1.0 - 0.0)
    +
    0.0

 as petal_length_max_min_max_scaled,
    
        

    

    
    
    

    
    
    

    (
        petal_width - 1.3
    )
    /
    (
        1.8 - 0.3
    )

 as petal_width_robust_scaled,
        

    (petal_width) / (max(abs(petal_width)) over ())::FLOAT

 as petal_width_max_absolute_scaled,
        

    
    (
        ((petal_width) - (min(petal_width) over ()))
        /
        ((max(petal_width) over ()) - (min(petal_width) over ()))::FLOAT
    )
    *
    (1.0 - 0.0)
    +
    0.0

 as petal_width_max_min_max_scaled,
    

    -- Log Transformation
    
        

    case
        when sepal_length is null or sepal_length + 0 <= 0 then null
        else log(10, sepal_length + 0)
    end

 as sepal_length_logged,
    
        

    case
        when sepal_width is null or sepal_width + 0 <= 0 then null
        else log(10, sepal_width + 0)
    end

 as sepal_width_logged,
    
        

    case
        when petal_length is null or petal_length + 0 <= 0 then null
        else log(10, petal_length + 0)
    end

 as petal_length_logged,
    
        

    case
        when petal_width is null or petal_width + 0 <= 0 then null
        else log(10, petal_width + 0)
    end

 as petal_width_logged,
    

    -- Binarization
    
        

    

    
        

        
    

    case
        when sepal_length >=
            
                5.8
            
            then 1
        else 0
    end

 as sepal_length_binarized,
    
        

    

    
        

        
    

    case
        when sepal_width >=
            
                3.0
            
            then 1
        else 0
    end

 as sepal_width_binarized,
    
        

    

    
        

        
    

    case
        when petal_length >=
            
                4.35
            
            then 1
        else 0
    end

 as petal_length_binarized,
    
        

    

    
        

        
    

    case
        when petal_width >=
            
                1.3
            
            then 1
        else 0
    end

 as petal_width_binarized,
    

    -- Standardization
    
        

    
    (
        (sepal_length - avg(sepal_length) over ())
        /
        (stddev(sepal_length) over ())::FLOAT
    )
    *
    1
    +
    0

 as sepal_length_standardized,
    
        

    
    (
        (sepal_width - avg(sepal_width) over ())
        /
        (stddev(sepal_width) over ())::FLOAT
    )
    *
    1
    +
    0

 as sepal_width_standardized,
    
        

    
    (
        (petal_length - avg(petal_length) over ())
        /
        (stddev(petal_length) over ())::FLOAT
    )
    *
    1
    +
    0

 as petal_length_standardized,
    
        

    
    (
        (petal_width - avg(petal_width) over ())
        /
        (stddev(petal_width) over ())::FLOAT
    )
    *
    1
    +
    0

 as petal_width_standardized,
    
-- Interactions
    
        
            
            
            

    
        (sepal_length * sepal_width)
    

 as sepal_length_x_sepal_width_interaction,
            

    
        (sepal_length + sepal_width)
    

 as sepal_length_plus_sepal_width_interaction,
        
            
            
            

    
        (sepal_length * petal_length)
    

 as sepal_length_x_petal_length_interaction,
            

    
        (sepal_length + petal_length)
    

 as sepal_length_plus_petal_length_interaction,
        
            
            
            

    
        (sepal_length * petal_width)
    

 as sepal_length_x_petal_width_interaction,
            

    
        (sepal_length + petal_width)
    

 as sepal_length_plus_petal_width_interaction,
        
    
        
            
            
            

    
        (sepal_width * petal_length)
    

 as sepal_width_x_petal_length_interaction,
            

    
        (sepal_width + petal_length)
    

 as sepal_width_plus_petal_length_interaction,
        
            
            
            

    
        (sepal_width * petal_width)
    

 as sepal_width_x_petal_width_interaction,
            

    
        (sepal_width + petal_width)
    

 as sepal_width_plus_petal_width_interaction,
        
    
        
            
            
            

    
        (petal_length * petal_width)
    

 as petal_length_x_petal_width_interaction,
            

    
        (petal_length + petal_width)
    

 as petal_length_plus_petal_width_interaction,
        
    
        
    
species,    
    -- Label Encoding
    

    dense_rank() over (order by species) - 1

 as species_label_encoded,
    -- One Hot Encoding
    

    

    
        
    

    

    

        case
            when species = 'setosa' then 1
            else 0
        end as is_species__setosa,

    

        case
            when species = 'versicolor' then 1
            else 0
        end as is_species__versicolor,

    

        case
            when species = 'virginica' then 1
            else 0
        end as is_species__virginica,

    

    case
        when species is null then 1
        else 0
    end as is_species__


from "analytics"."analytics"."stg_iris"
  );
  
[0m12:17:21.828338 [debug] [Thread-3  ]: SQL status: SELECT 150 in 0.040 seconds
[0m12:17:21.844240 [debug] [Thread-3  ]: Using postgres connection "model.homework.iris_processed"
[0m12:17:21.845960 [debug] [Thread-3  ]: On model.homework.iris_processed: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "homework", "target_name": "dev", "node_id": "model.homework.iris_processed"} */
alter table "analytics"."analytics"."iris_processed" rename to "iris_processed__dbt_backup"
[0m12:17:21.848460 [debug] [Thread-3  ]: SQL status: ALTER TABLE in 0.001 seconds
[0m12:17:21.858243 [debug] [Thread-3  ]: Using postgres connection "model.homework.iris_processed"
[0m12:17:21.860084 [debug] [Thread-3  ]: On model.homework.iris_processed: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "homework", "target_name": "dev", "node_id": "model.homework.iris_processed"} */
alter table "analytics"."analytics"."iris_processed__dbt_tmp" rename to "iris_processed"
[0m12:17:21.862232 [debug] [Thread-3  ]: SQL status: ALTER TABLE in 0.000 seconds
[0m12:17:21.866841 [debug] [Thread-3  ]: On model.homework.iris_processed: COMMIT
[0m12:17:21.868482 [debug] [Thread-3  ]: Using postgres connection "model.homework.iris_processed"
[0m12:17:21.870171 [debug] [Thread-3  ]: On model.homework.iris_processed: COMMIT
[0m12:17:21.875629 [debug] [Thread-3  ]: SQL status: COMMIT in 0.004 seconds
[0m12:17:21.883241 [debug] [Thread-3  ]: Applying DROP to: "analytics"."analytics"."iris_processed__dbt_backup"
[0m12:17:21.889508 [debug] [Thread-3  ]: Using postgres connection "model.homework.iris_processed"
[0m12:17:21.891501 [debug] [Thread-3  ]: On model.homework.iris_processed: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "homework", "target_name": "dev", "node_id": "model.homework.iris_processed"} */
drop table if exists "analytics"."analytics"."iris_processed__dbt_backup" cascade
[0m12:17:21.901375 [debug] [Thread-3  ]: SQL status: DROP TABLE in 0.008 seconds
[0m12:17:21.905588 [debug] [Thread-3  ]: On model.homework.iris_processed: Close
[0m12:17:21.908152 [debug] [Thread-3  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'f8173ed8-a38a-4959-a78c-4fed4053f929', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f7cec19fb80>]}
[0m12:17:21.910645 [info ] [Thread-3  ]: 2 of 2 OK created sql table model analytics.iris_processed ..................... [[32mSELECT 150[0m in 0.49s]
[0m12:17:21.912787 [debug] [Thread-3  ]: Finished running node model.homework.iris_processed
[0m12:17:21.916313 [debug] [MainThread]: Using postgres connection "master"
[0m12:17:21.917871 [debug] [MainThread]: On master: BEGIN
[0m12:17:21.919390 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m12:17:21.930888 [debug] [MainThread]: SQL status: BEGIN in 0.011 seconds
[0m12:17:21.933239 [debug] [MainThread]: On master: COMMIT
[0m12:17:21.935662 [debug] [MainThread]: Using postgres connection "master"
[0m12:17:21.937711 [debug] [MainThread]: On master: COMMIT
[0m12:17:21.940073 [debug] [MainThread]: SQL status: COMMIT in 0.000 seconds
[0m12:17:21.941771 [debug] [MainThread]: On master: Close
[0m12:17:21.943676 [debug] [MainThread]: Connection 'master' was properly closed.
[0m12:17:21.945284 [debug] [MainThread]: Connection 'model.homework.stg_iris' was properly closed.
[0m12:17:21.946919 [debug] [MainThread]: Connection 'model.homework.iris_processed' was properly closed.
[0m12:17:21.948467 [info ] [MainThread]: 
[0m12:17:21.950054 [info ] [MainThread]: Finished running 1 table model, 1 view model in 0 hours 0 minutes and 1.08 seconds (1.08s).
[0m12:17:21.952565 [debug] [MainThread]: Command end result
[0m12:17:22.046777 [debug] [MainThread]: Wrote artifact WritableManifest to /opt/airflow/dags/dbt/homework/target/manifest.json
[0m12:17:22.054315 [debug] [MainThread]: Wrote artifact SemanticManifest to /opt/airflow/dags/dbt/homework/target/semantic_manifest.json
[0m12:17:22.072394 [debug] [MainThread]: Wrote artifact RunExecutionResult to /opt/airflow/dags/dbt/homework/target/run_results.json
[0m12:17:22.074275 [info ] [MainThread]: 
[0m12:17:22.076045 [info ] [MainThread]: [32mCompleted successfully[0m
[0m12:17:22.077618 [info ] [MainThread]: 
[0m12:17:22.079153 [info ] [MainThread]: Done. PASS=2 WARN=0 ERROR=0 SKIP=0 TOTAL=2
[0m12:17:22.081415 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": true, "command_wall_clock_time": 8.523632, "process_in_blocks": "0", "process_kernel_time": 0.382559, "process_mem_max_rss": "120208", "process_out_blocks": "0", "process_user_time": 10.449906}
[0m12:17:22.083348 [debug] [MainThread]: Command `dbt run` succeeded at 12:17:22.083160 after 8.53 seconds
[0m12:17:22.084943 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f7cf1c80af0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f7cef52a070>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f7cf1ac43a0>]}
[0m12:17:22.086563 [debug] [MainThread]: Flushing usage events
[0m12:17:22.673074 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m12:17:28.920666 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fa64be6baf0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fa64af8d520>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fa64af8d4c0>]}


============================== 12:17:28.931991 | 650992da-4216-4120-a485-972c8a33dd86 ==============================
[0m12:17:28.931991 [info ] [MainThread]: Running with dbt=1.9.4
[0m12:17:28.933995 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': '/opt/airflow/dags/dbt', 'fail_fast': 'True', 'version_check': 'True', 'log_path': '/opt/airflow/dags/dbt/homework/logs', 'debug': 'False', 'warn_error': 'None', 'use_colors': 'True', 'use_experimental_parser': 'False', 'empty': 'None', 'quiet': 'False', 'no_print': 'None', 'log_format': 'default', 'introspect': 'True', 'static_parser': 'True', 'invocation_command': 'dbt --profile homework test --project-dir=/opt/airflow/dags/dbt/homework --vars {"is_test": false, "data_date": "2025-04-24"} --fail-fast', 'target_path': 'None', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'send_anonymous_usage_stats': 'True'}
[0m12:17:29.358675 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '650992da-4216-4120-a485-972c8a33dd86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fa64d852c70>]}
[0m12:17:29.482388 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '650992da-4216-4120-a485-972c8a33dd86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fa6496cc520>]}
[0m12:17:29.484821 [info ] [MainThread]: Registered adapter: postgres=1.9.0
[0m12:17:29.751482 [debug] [MainThread]: checksum: 6e62424eea9ce3687be3ed3d7873e7c8fa2dd1d7b5a050b5310967d8959a2843, vars: {'data_date': '2025-04-24', 'is_test': False}, profile: homework, target: , version: 1.9.4
[0m12:17:31.510312 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m12:17:31.511990 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m12:17:31.527270 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 1 unused configuration paths:
- seeds.homework.iris_dataset
[0m12:17:31.607532 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '650992da-4216-4120-a485-972c8a33dd86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fa6492bb130>]}
[0m12:17:31.895279 [debug] [MainThread]: Wrote artifact WritableManifest to /opt/airflow/dags/dbt/homework/target/manifest.json
[0m12:17:31.913021 [debug] [MainThread]: Wrote artifact SemanticManifest to /opt/airflow/dags/dbt/homework/target/semantic_manifest.json
[0m12:17:31.963575 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '650992da-4216-4120-a485-972c8a33dd86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fa649199580>]}
[0m12:17:31.965977 [info ] [MainThread]: Found 2 models, 1 source, 587 macros
[0m12:17:31.967725 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '650992da-4216-4120-a485-972c8a33dd86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fa649200a30>]}
[0m12:17:31.970731 [warn ] [MainThread]: Nothing to do. Try checking your model configs and model specification args
[0m12:17:31.975248 [debug] [MainThread]: Command end result
[0m12:17:32.078808 [debug] [MainThread]: Wrote artifact WritableManifest to /opt/airflow/dags/dbt/homework/target/manifest.json
[0m12:17:32.088145 [debug] [MainThread]: Wrote artifact SemanticManifest to /opt/airflow/dags/dbt/homework/target/semantic_manifest.json
[0m12:17:32.099526 [debug] [MainThread]: Wrote artifact RunExecutionResult to /opt/airflow/dags/dbt/homework/target/run_results.json
[0m12:17:32.102414 [debug] [MainThread]: Resource report: {"command_name": "test", "command_success": true, "command_wall_clock_time": 3.318816, "process_in_blocks": "0", "process_kernel_time": 0.288673, "process_mem_max_rss": "104376", "process_out_blocks": "0", "process_user_time": 4.529181}
[0m12:17:32.104416 [debug] [MainThread]: Command `dbt test` succeeded at 12:17:32.104216 after 3.32 seconds
[0m12:17:32.106104 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fa64be6baf0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fa64bd356d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fa64975f130>]}
[0m12:17:32.107958 [debug] [MainThread]: Flushing usage events
[0m12:17:32.639639 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m12:24:20.929611 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fe8def6d970>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fe8de08cd30>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fe8de08cd90>]}


============================== 12:24:20.943273 | 460f3f35-00a8-4ba0-b15d-e4d01758b5bb ==============================
[0m12:24:20.943273 [info ] [MainThread]: Running with dbt=1.9.4
[0m12:24:20.946224 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'debug': 'False', 'fail_fast': 'False', 'log_path': '/opt/airflow/dags/dbt/homework/logs', 'profiles_dir': '/opt/airflow/dags/dbt', 'version_check': 'True', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'empty': 'None', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'introspect': 'True', 'invocation_command': 'dbt deps --profiles-dir /opt/airflow/dags/dbt --project-dir /opt/airflow/dags/dbt/homework', 'static_parser': 'True', 'target_path': 'None', 'log_format': 'default', 'send_anonymous_usage_stats': 'True'}
[0m12:24:21.278343 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '460f3f35-00a8-4ba0-b15d-e4d01758b5bb', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fe8de052df0>]}
[0m12:24:21.834955 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f52309d19d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f522fae92b0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f522fae9250>]}


============================== 12:24:21.851727 | b3c194b3-b6c2-43f4-aa80-2c83c9a2911f ==============================
[0m12:24:21.851727 [info ] [MainThread]: Running with dbt=1.9.4
[0m12:24:21.856250 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'version_check': 'True', 'debug': 'False', 'log_path': '/opt/airflow/dags/dbt/homework/logs', 'fail_fast': 'False', 'profiles_dir': '/opt/airflow/dags/dbt', 'use_colors': 'True', 'use_experimental_parser': 'False', 'empty': 'None', 'quiet': 'False', 'no_print': 'None', 'log_format': 'default', 'introspect': 'True', 'static_parser': 'True', 'invocation_command': 'dbt deps --profiles-dir /opt/airflow/dags/dbt --project-dir /opt/airflow/dags/dbt/homework', 'target_path': 'None', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'send_anonymous_usage_stats': 'True'}
[0m12:24:21.937810 [debug] [MainThread]: Set downloads directory='/tmp/dbt-downloads-xy20iv4h'
[0m12:24:21.939906 [debug] [MainThread]: Making package index registry request: GET https://hub.getdbt.com/api/v1/index.json
[0m12:24:22.135037 [debug] [MainThread]: Response from registry index: GET https://hub.getdbt.com/api/v1/index.json 200
[0m12:24:22.138725 [debug] [MainThread]: Making package registry request: GET https://hub.getdbt.com/api/v1/Matts52/dbt_ml_inline_preprocessing.json
[0m12:24:22.230616 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'b3c194b3-b6c2-43f4-aa80-2c83c9a2911f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f522fab6eb0>]}
[0m12:24:22.281866 [debug] [MainThread]: Set downloads directory='/tmp/dbt-downloads-a74vk715'
[0m12:24:22.283971 [debug] [MainThread]: Making package index registry request: GET https://hub.getdbt.com/api/v1/index.json
[0m12:24:22.352414 [debug] [MainThread]: Response from registry: GET https://hub.getdbt.com/api/v1/Matts52/dbt_ml_inline_preprocessing.json 200
[0m12:24:22.358049 [debug] [MainThread]: Making package registry request: GET https://hub.getdbt.com/api/v1/dbt-labs/dbt_utils.json
[0m12:24:22.373873 [debug] [MainThread]: Response from registry index: GET https://hub.getdbt.com/api/v1/index.json 200
[0m12:24:22.376811 [debug] [MainThread]: Making package registry request: GET https://hub.getdbt.com/api/v1/Matts52/dbt_ml_inline_preprocessing.json
[0m12:24:22.443215 [debug] [MainThread]: Response from registry: GET https://hub.getdbt.com/api/v1/dbt-labs/dbt_utils.json 200
[0m12:24:22.456914 [info ] [MainThread]: Installing Matts52/dbt_ml_inline_preprocessing
[0m12:24:22.461036 [debug] [MainThread]: Response from registry: GET https://hub.getdbt.com/api/v1/Matts52/dbt_ml_inline_preprocessing.json 200
[0m12:24:22.466211 [debug] [MainThread]: Making package registry request: GET https://hub.getdbt.com/api/v1/dbt-labs/dbt_utils.json
[0m12:24:22.557968 [debug] [MainThread]: Response from registry: GET https://hub.getdbt.com/api/v1/dbt-labs/dbt_utils.json 200
[0m12:24:22.574128 [info ] [MainThread]: Installing Matts52/dbt_ml_inline_preprocessing
[0m12:24:23.842905 [info ] [MainThread]: Installed from version 0.2.4
[0m12:24:23.844903 [info ] [MainThread]: Up to date!
[0m12:24:23.847462 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'package', 'label': '460f3f35-00a8-4ba0-b15d-e4d01758b5bb', 'property_': 'install', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fe8ddf7bfa0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fe8deddc250>]}
[0m12:24:23.850609 [info ] [MainThread]: Installing dbt-labs/dbt_utils
[0m12:24:24.245022 [info ] [MainThread]: Installed from version 0.2.4
[0m12:24:24.247650 [info ] [MainThread]: Up to date!
[0m12:24:24.250772 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'package', 'label': 'b3c194b3-b6c2-43f4-aa80-2c83c9a2911f', 'property_': 'install', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f523084e280>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f522f938fd0>]}
[0m12:24:24.253642 [info ] [MainThread]: Installing dbt-labs/dbt_utils
[0m12:24:27.376821 [error] [MainThread]: Encountered an error:
[Errno 17] File exists: 'dbt_packages/dbt_utils'
[0m12:24:27.384371 [error] [MainThread]: Traceback (most recent call last):
  File "/usr/local/lib/python3.9/shutil.py", line 825, in move
    os.rename(src, real_dst)
PermissionError: [Errno 13] Permission denied: 'dbt_packages/dbt-utils-1.3.0' -> 'dbt_packages/dbt_utils'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/dbt/cli/requires.py", line 153, in wrapper
    result, success = func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.9/site-packages/dbt/cli/requires.py", line 103, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.9/site-packages/dbt/cli/requires.py", line 218, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.9/site-packages/dbt/cli/requires.py", line 264, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.9/site-packages/dbt/cli/main.py", line 455, in deps
    results = task.run()
  File "/home/airflow/.local/lib/python3.9/site-packages/dbt/task/deps.py", line 254, in run
    package.install(self.project, renderer)
  File "/home/airflow/.local/lib/python3.9/site-packages/dbt/deps/registry.py", line 63, in install
    self._install(project, renderer)
  File "/home/airflow/.local/lib/python3.9/site-packages/dbt/deps/base.py", line 121, in _install
    connection_exception_retry(download_untar_fn, 5)
  File "/home/airflow/.local/lib/python3.9/site-packages/dbt_common/utils/connection.py", line 21, in connection_exception_retry
    return fn()
  File "/home/airflow/.local/lib/python3.9/site-packages/dbt/deps/base.py", line 133, in download_and_untar
    system.untar_package(tar_path, deps_path, package_name)
  File "/home/airflow/.local/lib/python3.9/site-packages/dbt_common/clients/system.py", line 646, in untar_package
    dbt_common.clients.system.rename(downloaded_path, desired_path, force=True)
  File "/home/airflow/.local/lib/python3.9/site-packages/dbt_common/clients/system.py", line 609, in rename
    shutil.move(from_path, to_path)
  File "/usr/local/lib/python3.9/shutil.py", line 841, in move
    copytree(src, real_dst, copy_function=copy_function,
  File "/usr/local/lib/python3.9/shutil.py", line 568, in copytree
    return _copytree(entries=entries, src=src, dst=dst, symlinks=symlinks,
  File "/usr/local/lib/python3.9/shutil.py", line 467, in _copytree
    os.makedirs(dst, exist_ok=dirs_exist_ok)
  File "/usr/local/lib/python3.9/os.py", line 225, in makedirs
    mkdir(name, mode)
FileExistsError: [Errno 17] File exists: 'dbt_packages/dbt_utils'

[0m12:24:27.388649 [debug] [MainThread]: Resource report: {"command_name": "deps", "command_success": false, "command_wall_clock_time": 5.7399163, "process_in_blocks": "96", "process_kernel_time": 0.637709, "process_mem_max_rss": "95632", "process_out_blocks": "1304", "process_user_time": 4.145111}
[0m12:24:27.391310 [debug] [MainThread]: Command `dbt deps` failed at 12:24:27.390908 after 5.74 seconds
[0m12:24:27.393946 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f52309d19d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f52307e16a0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f522f938ee0>]}
[0m12:24:27.396218 [debug] [MainThread]: Flushing usage events
[0m12:24:27.947846 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m12:24:34.419967 [error] [MainThread]: Encountered an error:
[('dbt_packages/dbt-utils-1.3.0/integration_tests/data/datetime', 'dbt_packages/dbt_utils/integration_tests/data/datetime', "[Errno 2] No such file or directory: 'dbt_packages/dbt_utils/integration_tests'")]
[0m12:24:34.425903 [error] [MainThread]: Traceback (most recent call last):
  File "/usr/local/lib/python3.9/shutil.py", line 825, in move
    os.rename(src, real_dst)
PermissionError: [Errno 13] Permission denied: 'dbt_packages/dbt-utils-1.3.0' -> 'dbt_packages/dbt_utils'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/dbt/cli/requires.py", line 153, in wrapper
    result, success = func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.9/site-packages/dbt/cli/requires.py", line 103, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.9/site-packages/dbt/cli/requires.py", line 218, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.9/site-packages/dbt/cli/requires.py", line 264, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.9/site-packages/dbt/cli/main.py", line 455, in deps
    results = task.run()
  File "/home/airflow/.local/lib/python3.9/site-packages/dbt/task/deps.py", line 254, in run
    package.install(self.project, renderer)
  File "/home/airflow/.local/lib/python3.9/site-packages/dbt/deps/registry.py", line 63, in install
    self._install(project, renderer)
  File "/home/airflow/.local/lib/python3.9/site-packages/dbt/deps/base.py", line 121, in _install
    connection_exception_retry(download_untar_fn, 5)
  File "/home/airflow/.local/lib/python3.9/site-packages/dbt_common/utils/connection.py", line 21, in connection_exception_retry
    return fn()
  File "/home/airflow/.local/lib/python3.9/site-packages/dbt/deps/base.py", line 133, in download_and_untar
    system.untar_package(tar_path, deps_path, package_name)
  File "/home/airflow/.local/lib/python3.9/site-packages/dbt_common/clients/system.py", line 646, in untar_package
    dbt_common.clients.system.rename(downloaded_path, desired_path, force=True)
  File "/home/airflow/.local/lib/python3.9/site-packages/dbt_common/clients/system.py", line 609, in rename
    shutil.move(from_path, to_path)
  File "/usr/local/lib/python3.9/shutil.py", line 841, in move
    copytree(src, real_dst, copy_function=copy_function,
  File "/usr/local/lib/python3.9/shutil.py", line 568, in copytree
    return _copytree(entries=entries, src=src, dst=dst, symlinks=symlinks,
  File "/usr/local/lib/python3.9/shutil.py", line 522, in _copytree
    raise Error(errors)
shutil.Error: [('dbt_packages/dbt-utils-1.3.0/integration_tests/data/datetime', 'dbt_packages/dbt_utils/integration_tests/data/datetime', "[Errno 2] No such file or directory: 'dbt_packages/dbt_utils/integration_tests'")]

[0m12:24:34.432518 [debug] [MainThread]: Resource report: {"command_name": "deps", "command_success": false, "command_wall_clock_time": 13.647014, "process_in_blocks": "480", "process_kernel_time": 0.916429, "process_mem_max_rss": "95316", "process_out_blocks": "1304", "process_user_time": 4.205395}
[0m12:24:34.436877 [debug] [MainThread]: Command `dbt deps` failed at 12:24:34.436473 after 13.65 seconds
[0m12:24:34.439743 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fe8def6d970>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fe8dedf07f0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fe8ddf232b0>]}
[0m12:24:34.443397 [debug] [MainThread]: Flushing usage events
[0m12:24:34.987916 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m12:27:11.341155 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f2327c32bb0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f2326d54580>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f2326d54520>]}


============================== 12:27:11.355617 | cbfaf264-5259-4e5c-a47d-95f8123f62d0 ==============================
[0m12:27:11.355617 [info ] [MainThread]: Running with dbt=1.9.4
[0m12:27:11.358248 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'debug': 'False', 'profiles_dir': '/opt/airflow/dags/dbt', 'log_path': '/opt/airflow/dags/dbt/homework/logs', 'fail_fast': 'False', 'version_check': 'True', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'empty': 'False', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'invocation_command': 'dbt --profile homework run --project-dir=/opt/airflow/dags/dbt/homework --vars {"is_test": false, "data_date": "2025-04-23"}', 'static_parser': 'True', 'introspect': 'True', 'target_path': 'None', 'log_format': 'default', 'send_anonymous_usage_stats': 'True'}
[0m12:27:11.369815 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f1cdaa18a90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f1cd9b39460>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f1cd9b39400>]}


============================== 12:27:11.385963 | f50fac86-f7b8-4916-88fa-86df3a64c308 ==============================
[0m12:27:11.385963 [info ] [MainThread]: Running with dbt=1.9.4
[0m12:27:11.388180 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'version_check': 'True', 'debug': 'False', 'log_path': '/opt/airflow/dags/dbt/homework/logs', 'fail_fast': 'False', 'profiles_dir': '/opt/airflow/dags/dbt', 'use_colors': 'True', 'use_experimental_parser': 'False', 'empty': 'False', 'quiet': 'False', 'no_print': 'None', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'invocation_command': 'dbt --profile homework run --project-dir=/opt/airflow/dags/dbt/homework --vars {"is_test": false, "data_date": "2025-04-22"}', 'static_parser': 'True', 'introspect': 'True', 'target_path': 'None', 'log_format': 'default', 'send_anonymous_usage_stats': 'True'}
[0m12:27:11.935217 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'cbfaf264-5259-4e5c-a47d-95f8123f62d0', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f232557a580>]}
[0m12:27:11.971092 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'f50fac86-f7b8-4916-88fa-86df3a64c308', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f1cd835f5b0>]}
[0m12:27:12.114896 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': 'cbfaf264-5259-4e5c-a47d-95f8123f62d0', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f2326d8a4f0>]}
[0m12:27:12.118040 [info ] [MainThread]: Registered adapter: postgres=1.9.0
[0m12:27:12.193904 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': 'f50fac86-f7b8-4916-88fa-86df3a64c308', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f1cd9afedf0>]}
[0m12:27:12.197248 [info ] [MainThread]: Registered adapter: postgres=1.9.0
[0m12:27:12.471454 [error] [MainThread]: Encountered an error:
Runtime Error
  Failed to read package: Runtime Error
    No dbt_project.yml found at expected path /opt/airflow/dags/dbt/homework/dbt_packages/dbt_ml_inline_preprocessing/dbt_project.yml
    Verify that each entry within packages.yml (and their transitive dependencies) contains a file named dbt_project.yml
    

Error encountered in /opt/airflow/dags/dbt/homework/dbt_packages/dbt_ml_inline_preprocessing
[0m12:27:12.475742 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": false, "command_wall_clock_time": 1.336695, "process_in_blocks": "0", "process_kernel_time": 0.321163, "process_mem_max_rss": "97828", "process_out_blocks": "0", "process_user_time": 5.640435}
[0m12:27:12.479300 [debug] [MainThread]: Command `dbt run` failed at 12:27:12.478967 after 1.34 seconds
[0m12:27:12.481506 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f2327c32bb0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f232543eca0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f232543e1c0>]}
[0m12:27:12.483955 [debug] [MainThread]: Flushing usage events
[0m12:27:12.540099 [error] [MainThread]: Encountered an error:
Runtime Error
  Failed to read package: Runtime Error
    No dbt_project.yml found at expected path /opt/airflow/dags/dbt/homework/dbt_packages/dbt_ml_inline_preprocessing/dbt_project.yml
    Verify that each entry within packages.yml (and their transitive dependencies) contains a file named dbt_project.yml
    

Error encountered in /opt/airflow/dags/dbt/homework/dbt_packages/dbt_ml_inline_preprocessing
[0m12:27:12.545992 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": false, "command_wall_clock_time": 1.3688436, "process_in_blocks": "0", "process_kernel_time": 0.258068, "process_mem_max_rss": "97704", "process_out_blocks": "0", "process_user_time": 5.766842}
[0m12:27:12.550003 [debug] [MainThread]: Command `dbt run` failed at 12:27:12.549592 after 1.37 seconds
[0m12:27:12.552652 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f1cdaa18a90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f1cd81c97f0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f1cd81c9be0>]}
[0m12:27:12.555305 [debug] [MainThread]: Flushing usage events
[0m12:27:13.070027 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m12:27:13.104301 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m12:29:16.147332 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fa8f3697ac0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fa8f27b84c0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fa8f27b8460>]}
[0m12:29:16.148442 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f07142d0b50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f07133f24f0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f07133f2490>]}


============================== 12:29:16.162424 | 381ebb8f-e66c-43cb-a1f0-eab32f4e47a3 ==============================
[0m12:29:16.162424 [info ] [MainThread]: Running with dbt=1.9.4


============================== 12:29:16.164510 | c0d0458b-d20f-40ee-9ef4-6fced9f49281 ==============================
[0m12:29:16.164510 [info ] [MainThread]: Running with dbt=1.9.4
[0m12:29:16.165572 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'version_check': 'True', 'fail_fast': 'False', 'log_path': '/opt/airflow/dags/dbt/homework/logs', 'profiles_dir': '/opt/airflow/dags/dbt', 'debug': 'False', 'use_colors': 'True', 'use_experimental_parser': 'False', 'empty': 'False', 'quiet': 'False', 'no_print': 'None', 'log_format': 'default', 'static_parser': 'True', 'introspect': 'True', 'invocation_command': 'dbt --profile homework run --project-dir=/opt/airflow/dags/dbt/homework --vars {"is_test": false, "data_date": "2025-04-23"}', 'target_path': 'None', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'send_anonymous_usage_stats': 'True'}
[0m12:29:16.167224 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': '/opt/airflow/dags/dbt', 'debug': 'False', 'version_check': 'True', 'log_path': '/opt/airflow/dags/dbt/homework/logs', 'warn_error': 'None', 'fail_fast': 'False', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'empty': 'False', 'log_format': 'default', 'introspect': 'True', 'static_parser': 'True', 'invocation_command': 'dbt --profile homework run --project-dir=/opt/airflow/dags/dbt/homework --vars {"is_test": false, "data_date": "2025-04-22"}', 'target_path': 'None', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'send_anonymous_usage_stats': 'True'}
[0m12:29:16.904342 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '381ebb8f-e66c-43cb-a1f0-eab32f4e47a3', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fa8f0fee460>]}
[0m12:29:16.911605 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'c0d0458b-d20f-40ee-9ef4-6fced9f49281', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0713432fa0>]}
[0m12:29:17.199480 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '381ebb8f-e66c-43cb-a1f0-eab32f4e47a3', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fa8f284f220>]}
[0m12:29:17.202201 [info ] [MainThread]: Registered adapter: postgres=1.9.0
[0m12:29:17.209347 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': 'c0d0458b-d20f-40ee-9ef4-6fced9f49281', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0713ab3040>]}
[0m12:29:17.212931 [info ] [MainThread]: Registered adapter: postgres=1.9.0
[0m12:29:17.605378 [error] [MainThread]: Encountered an error:
Runtime Error
  Failed to read package: Runtime Error
    No dbt_project.yml found at expected path /opt/airflow/dags/dbt/homework/dbt_packages/dbt_ml_inline_preprocessing/dbt_project.yml
    Verify that each entry within packages.yml (and their transitive dependencies) contains a file named dbt_project.yml
    

Error encountered in /opt/airflow/dags/dbt/homework/dbt_packages/dbt_ml_inline_preprocessing
[0m12:29:17.609806 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": false, "command_wall_clock_time": 1.6293793, "process_in_blocks": "0", "process_kernel_time": 0.339443, "process_mem_max_rss": "97696", "process_out_blocks": "0", "process_user_time": 5.401145}
[0m12:29:17.614821 [debug] [MainThread]: Command `dbt run` failed at 12:29:17.613337 after 1.63 seconds
[0m12:29:17.618691 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fa8f3697ac0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fa8f0e48640>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fa8f0e39910>]}
[0m12:29:17.618195 [error] [MainThread]: Encountered an error:
Runtime Error
  Failed to read package: Runtime Error
    No dbt_project.yml found at expected path /opt/airflow/dags/dbt/homework/dbt_packages/dbt_ml_inline_preprocessing/dbt_project.yml
    Verify that each entry within packages.yml (and their transitive dependencies) contains a file named dbt_project.yml
    

Error encountered in /opt/airflow/dags/dbt/homework/dbt_packages/dbt_ml_inline_preprocessing
[0m12:29:17.621653 [debug] [MainThread]: Flushing usage events
[0m12:29:17.623249 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": false, "command_wall_clock_time": 1.658667, "process_in_blocks": "0", "process_kernel_time": 0.3399, "process_mem_max_rss": "97668", "process_out_blocks": "0", "process_user_time": 5.358423}
[0m12:29:17.626416 [debug] [MainThread]: Command `dbt run` failed at 12:29:17.626093 after 1.66 seconds
[0m12:29:17.629019 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f07142d0b50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0711a82fd0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0711a72f40>]}
[0m12:29:17.633461 [debug] [MainThread]: Flushing usage events
[0m12:29:18.184854 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m12:29:18.233731 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m12:30:55.868218 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f65a1bb8970>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f65a0cd7d30>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f65a0cd7d90>]}


============================== 12:30:55.878757 | 85c76da2-5283-420b-9ed8-47ea15507803 ==============================
[0m12:30:55.878757 [info ] [MainThread]: Running with dbt=1.9.4
[0m12:30:55.881970 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'version_check': 'True', 'fail_fast': 'False', 'log_path': '/opt/airflow/dags/dbt/homework/logs', 'debug': 'False', 'profiles_dir': '/opt/airflow/dags/dbt', 'use_colors': 'True', 'use_experimental_parser': 'False', 'empty': 'None', 'quiet': 'False', 'no_print': 'None', 'log_format': 'default', 'static_parser': 'True', 'introspect': 'True', 'invocation_command': 'dbt deps --profiles-dir /opt/airflow/dags/dbt --project-dir /opt/airflow/dags/dbt/homework', 'target_path': 'None', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'send_anonymous_usage_stats': 'True'}
[0m12:30:56.153625 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '85c76da2-5283-420b-9ed8-47ea15507803', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f65a0c9ddf0>]}
[0m12:30:56.823096 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fab048f19a0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fab03a10d90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fab03a10df0>]}


============================== 12:30:56.837612 | 28d33071-1ad0-4048-af53-eae5b8096c1f ==============================
[0m12:30:56.837612 [info ] [MainThread]: Running with dbt=1.9.4
[0m12:30:56.840326 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'fail_fast': 'False', 'version_check': 'True', 'log_path': '/opt/airflow/dags/dbt/homework/logs', 'debug': 'False', 'profiles_dir': '/opt/airflow/dags/dbt', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'empty': 'None', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'static_parser': 'True', 'invocation_command': 'dbt deps --profiles-dir /opt/airflow/dags/dbt --project-dir /opt/airflow/dags/dbt/homework', 'introspect': 'True', 'target_path': 'None', 'log_format': 'default', 'send_anonymous_usage_stats': 'True'}
[0m12:30:56.859497 [debug] [MainThread]: Set downloads directory='/tmp/dbt-downloads-s_b2ul0b'
[0m12:30:56.862023 [debug] [MainThread]: Making package index registry request: GET https://hub.getdbt.com/api/v1/index.json
[0m12:30:57.022403 [debug] [MainThread]: Response from registry index: GET https://hub.getdbt.com/api/v1/index.json 200
[0m12:30:57.025025 [debug] [MainThread]: Making package registry request: GET https://hub.getdbt.com/api/v1/Matts52/dbt_ml_inline_preprocessing.json
[0m12:30:57.145807 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '28d33071-1ad0-4048-af53-eae5b8096c1f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fab039d6e50>]}
[0m12:30:57.184586 [debug] [MainThread]: Set downloads directory='/tmp/dbt-downloads-sx6bweus'
[0m12:30:57.186378 [debug] [MainThread]: Making package index registry request: GET https://hub.getdbt.com/api/v1/index.json
[0m12:30:57.267725 [debug] [MainThread]: Response from registry index: GET https://hub.getdbt.com/api/v1/index.json 200
[0m12:30:57.270443 [debug] [MainThread]: Making package registry request: GET https://hub.getdbt.com/api/v1/Matts52/dbt_ml_inline_preprocessing.json
[0m12:30:57.387547 [debug] [MainThread]: Response from registry: GET https://hub.getdbt.com/api/v1/Matts52/dbt_ml_inline_preprocessing.json 200
[0m12:30:57.387722 [debug] [MainThread]: Response from registry: GET https://hub.getdbt.com/api/v1/Matts52/dbt_ml_inline_preprocessing.json 200
[0m12:30:57.391821 [debug] [MainThread]: Making package registry request: GET https://hub.getdbt.com/api/v1/dbt-labs/dbt_utils.json
[0m12:30:57.391825 [debug] [MainThread]: Making package registry request: GET https://hub.getdbt.com/api/v1/dbt-labs/dbt_utils.json
[0m12:30:57.467348 [debug] [MainThread]: Response from registry: GET https://hub.getdbt.com/api/v1/dbt-labs/dbt_utils.json 200
[0m12:30:57.469219 [debug] [MainThread]: Response from registry: GET https://hub.getdbt.com/api/v1/dbt-labs/dbt_utils.json 200
[0m12:30:57.490418 [info ] [MainThread]: Installing Matts52/dbt_ml_inline_preprocessing
[0m12:30:57.493277 [info ] [MainThread]: Installing Matts52/dbt_ml_inline_preprocessing
[0m12:30:58.793578 [info ] [MainThread]: Installed from version 0.2.4
[0m12:30:58.796186 [info ] [MainThread]: Up to date!
[0m12:30:58.799406 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'package', 'label': '85c76da2-5283-420b-9ed8-47ea15507803', 'property_': 'install', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f65a0bc6fa0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f65a1a27250>]}
[0m12:30:58.801773 [info ] [MainThread]: Installing dbt-labs/dbt_utils
[0m12:30:59.296208 [info ] [MainThread]: Installed from version 0.2.4
[0m12:30:59.298092 [info ] [MainThread]: Up to date!
[0m12:30:59.300924 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'package', 'label': '28d33071-1ad0-4048-af53-eae5b8096c1f', 'property_': 'install', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fab04774250>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fab038ff130>]}
[0m12:30:59.303270 [info ] [MainThread]: Installing dbt-labs/dbt_utils
[0m12:31:01.920768 [info ] [MainThread]: Installed from version 1.3.0
[0m12:31:01.922668 [info ] [MainThread]: Up to date!
[0m12:31:01.925285 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'package', 'label': '85c76da2-5283-420b-9ed8-47ea15507803', 'property_': 'install', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f65a0bc6fa0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f65a0b6ed30>]}
[0m12:31:01.929771 [debug] [MainThread]: Resource report: {"command_name": "deps", "command_success": true, "command_wall_clock_time": 6.185901, "process_in_blocks": "0", "process_kernel_time": 0.407392, "process_mem_max_rss": "95188", "process_out_blocks": "1304", "process_user_time": 3.45787}
[0m12:31:01.933491 [debug] [MainThread]: Command `dbt deps` succeeded at 12:31:01.933112 after 6.19 seconds
[0m12:31:01.935625 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f65a1bb8970>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f65a2fb6a90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f65a19fbfd0>]}
[0m12:31:01.938011 [debug] [MainThread]: Flushing usage events
[0m12:31:02.508897 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m12:31:03.039984 [info ] [MainThread]: Installed from version 1.3.0
[0m12:31:03.042020 [info ] [MainThread]: Up to date!
[0m12:31:03.044749 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'package', 'label': '28d33071-1ad0-4048-af53-eae5b8096c1f', 'property_': 'install', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fab04774250>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fab038a7d60>]}
[0m12:31:03.049112 [debug] [MainThread]: Resource report: {"command_name": "deps", "command_success": true, "command_wall_clock_time": 6.391555, "process_in_blocks": "0", "process_kernel_time": 0.505217, "process_mem_max_rss": "95164", "process_out_blocks": "1304", "process_user_time": 3.536524}
[0m12:31:03.052081 [debug] [MainThread]: Command `dbt deps` succeeded at 12:31:03.051691 after 6.39 seconds
[0m12:31:03.054443 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fab048f19a0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fab04744e20>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fab0470ba00>]}
[0m12:31:03.057021 [debug] [MainThread]: Flushing usage events
[0m12:31:03.578087 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m12:34:27.146605 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fe9c544baf0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fe9c456c4f0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fe9c456c490>]}


============================== 12:34:27.158692 | 78bbb63b-121b-466f-a8fd-d5a9d4865005 ==============================
[0m12:34:27.158692 [info ] [MainThread]: Running with dbt=1.9.4
[0m12:34:27.161141 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'fail_fast': 'False', 'debug': 'False', 'log_path': '/opt/airflow/dags/dbt/homework/logs', 'version_check': 'True', 'profiles_dir': '/opt/airflow/dags/dbt', 'use_colors': 'True', 'use_experimental_parser': 'False', 'empty': 'False', 'quiet': 'False', 'no_print': 'None', 'log_format': 'default', 'static_parser': 'True', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'introspect': 'True', 'target_path': 'None', 'invocation_command': 'dbt --profile homework run --project-dir=/opt/airflow/dags/dbt/homework --vars {"is_test": false, "data_date": "2025-04-22"}', 'send_anonymous_usage_stats': 'True'}
[0m12:34:27.196038 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb4eb32bb20>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb4ea44c430>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb4ea44c3d0>]}


============================== 12:34:27.216108 | a15116d3-d483-43cf-a020-4378106a0e1b ==============================
[0m12:34:27.216108 [info ] [MainThread]: Running with dbt=1.9.4
[0m12:34:27.220560 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'version_check': 'True', 'fail_fast': 'False', 'log_path': '/opt/airflow/dags/dbt/homework/logs', 'profiles_dir': '/opt/airflow/dags/dbt', 'debug': 'False', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'empty': 'False', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'introspect': 'True', 'invocation_command': 'dbt --profile homework run --project-dir=/opt/airflow/dags/dbt/homework --vars {"is_test": false, "data_date": "2025-04-23"}', 'static_parser': 'True', 'target_path': 'None', 'log_format': 'default', 'send_anonymous_usage_stats': 'True'}
[0m12:34:27.823618 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '78bbb63b-121b-466f-a8fd-d5a9d4865005', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fe9c2d92790>]}
[0m12:34:27.848791 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'a15116d3-d483-43cf-a020-4378106a0e1b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb4ea48c760>]}
[0m12:34:27.962282 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '78bbb63b-121b-466f-a8fd-d5a9d4865005', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fe9c4c03550>]}
[0m12:34:27.965194 [info ] [MainThread]: Registered adapter: postgres=1.9.0
[0m12:34:27.992707 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': 'a15116d3-d483-43cf-a020-4378106a0e1b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb4e8cc1880>]}
[0m12:34:27.995435 [info ] [MainThread]: Registered adapter: postgres=1.9.0
[0m12:34:28.240582 [error] [MainThread]: Encountered an error:
Runtime Error
  Failed to read package: Runtime Error
    No dbt_project.yml found at expected path /opt/airflow/dags/dbt/homework/dbt_packages/dbt_ml_inline_preprocessing/dbt_project.yml
    Verify that each entry within packages.yml (and their transitive dependencies) contains a file named dbt_project.yml
    

Error encountered in /opt/airflow/dags/dbt/homework/dbt_packages/dbt_ml_inline_preprocessing
[0m12:34:28.244418 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": false, "command_wall_clock_time": 1.2469074, "process_in_blocks": "0", "process_kernel_time": 0.380691, "process_mem_max_rss": "97548", "process_out_blocks": "0", "process_user_time": 5.119295}
[0m12:34:28.246917 [debug] [MainThread]: Command `dbt run` failed at 12:34:28.246645 after 1.25 seconds
[0m12:34:28.248913 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fe9c544baf0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fe9c2c60640>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fe9c4599760>]}
[0m12:34:28.251194 [debug] [MainThread]: Flushing usage events
[0m12:34:28.250833 [error] [MainThread]: Encountered an error:
Runtime Error
  Failed to read package: Runtime Error
    No dbt_project.yml found at expected path /opt/airflow/dags/dbt/homework/dbt_packages/dbt_ml_inline_preprocessing/dbt_project.yml
    Verify that each entry within packages.yml (and their transitive dependencies) contains a file named dbt_project.yml
    

Error encountered in /opt/airflow/dags/dbt/homework/dbt_packages/dbt_ml_inline_preprocessing
[0m12:34:28.256391 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": false, "command_wall_clock_time": 1.2114036, "process_in_blocks": "0", "process_kernel_time": 0.298323, "process_mem_max_rss": "97536", "process_out_blocks": "0", "process_user_time": 5.101325}
[0m12:34:28.259935 [debug] [MainThread]: Command `dbt run` failed at 12:34:28.259493 after 1.22 seconds
[0m12:34:28.262420 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb4eb32bb20>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb4e8b3fcd0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb4e8b3f7f0>]}
[0m12:34:28.264241 [debug] [MainThread]: Flushing usage events
[0m12:34:28.850009 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m12:34:28.849844 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m12:34:38.207896 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f04764e6af0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0475607460>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0475607400>]}


============================== 12:34:38.217523 | 8cbc0cbb-8fae-492b-8e8a-ba65cefcb093 ==============================
[0m12:34:38.217523 [info ] [MainThread]: Running with dbt=1.9.4
[0m12:34:38.219601 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'debug': 'False', 'profiles_dir': '/opt/airflow/dags/dbt', 'log_path': '/opt/airflow/dags/dbt/homework/logs', 'fail_fast': 'False', 'version_check': 'True', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'empty': 'False', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'introspect': 'True', 'static_parser': 'True', 'log_format': 'default', 'target_path': 'None', 'invocation_command': 'dbt --profile homework run --project-dir=/opt/airflow/dags/dbt/homework --vars {"is_test": false, "data_date": "2025-04-22"}', 'send_anonymous_usage_stats': 'True'}
[0m12:34:38.558248 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '8cbc0cbb-8fae-492b-8e8a-ba65cefcb093', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0477ecdc70>]}
[0m12:34:38.679438 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '8cbc0cbb-8fae-492b-8e8a-ba65cefcb093', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0473d8f070>]}
[0m12:34:38.683345 [info ] [MainThread]: Registered adapter: postgres=1.9.0
[0m12:34:38.881758 [error] [MainThread]: Encountered an error:
Runtime Error
  Failed to read package: Runtime Error
    No dbt_project.yml found at expected path /opt/airflow/dags/dbt/homework/dbt_packages/dbt_ml_inline_preprocessing/dbt_project.yml
    Verify that each entry within packages.yml (and their transitive dependencies) contains a file named dbt_project.yml
    

Error encountered in /opt/airflow/dags/dbt/homework/dbt_packages/dbt_ml_inline_preprocessing
[0m12:34:38.885169 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": false, "command_wall_clock_time": 0.7999368, "process_in_blocks": "0", "process_kernel_time": 0.199903, "process_mem_max_rss": "97780", "process_out_blocks": "0", "process_user_time": 3.488316}
[0m12:34:38.887436 [debug] [MainThread]: Command `dbt run` failed at 12:34:38.887269 after 0.80 seconds
[0m12:34:38.889318 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f04764e6af0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0473cc37f0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0473cc3730>]}
[0m12:34:38.891264 [debug] [MainThread]: Flushing usage events
[0m12:34:39.448388 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m12:37:30.505212 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7feffceca670>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7feffbfe4e80>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7feffbfe4e20>]}


============================== 12:37:30.517440 | 525650bd-cc90-42d5-a9b3-20ce40dfd6a4 ==============================
[0m12:37:30.517440 [info ] [MainThread]: Running with dbt=1.9.4
[0m12:37:30.520161 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'fail_fast': 'False', 'profiles_dir': '/opt/airflow/dags/dbt', 'log_path': '/opt/airflow/dags/dbt/homework/logs', 'debug': 'False', 'version_check': 'True', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'empty': 'None', 'log_format': 'default', 'static_parser': 'True', 'introspect': 'True', 'invocation_command': 'dbt deps --profiles-dir /opt/airflow/dags/dbt --project-dir /opt/airflow/dags/dbt/homework', 'target_path': 'None', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'send_anonymous_usage_stats': 'True'}
[0m12:37:30.800218 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '525650bd-cc90-42d5-a9b3-20ce40dfd6a4', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7feffbf55fd0>]}
[0m12:37:30.900259 [debug] [MainThread]: Set downloads directory='/tmp/dbt-downloads-6kf5ajr8'
[0m12:37:30.902262 [debug] [MainThread]: Making package index registry request: GET https://hub.getdbt.com/api/v1/index.json
[0m12:37:31.043935 [debug] [MainThread]: Response from registry index: GET https://hub.getdbt.com/api/v1/index.json 200
[0m12:37:31.046321 [debug] [MainThread]: Making package registry request: GET https://hub.getdbt.com/api/v1/Matts52/dbt_ml_inline_preprocessing.json
[0m12:37:31.129154 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f03e32496a0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f03e2364e20>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f03e2364dc0>]}


============================== 12:37:31.141837 | f8871537-0ba7-47d5-92de-d614b8de5078 ==============================
[0m12:37:31.141837 [info ] [MainThread]: Running with dbt=1.9.4
[0m12:37:31.145186 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': '/opt/airflow/dags/dbt', 'version_check': 'True', 'debug': 'False', 'log_path': '/opt/airflow/dags/dbt/homework/logs', 'fail_fast': 'False', 'warn_error': 'None', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'empty': 'None', 'log_format': 'default', 'static_parser': 'True', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'introspect': 'True', 'target_path': 'None', 'invocation_command': 'dbt deps --profiles-dir /opt/airflow/dags/dbt --project-dir /opt/airflow/dags/dbt/homework', 'send_anonymous_usage_stats': 'True'}
[0m12:37:31.345385 [debug] [MainThread]: Response from registry: GET https://hub.getdbt.com/api/v1/Matts52/dbt_ml_inline_preprocessing.json 200
[0m12:37:31.348832 [debug] [MainThread]: Making package registry request: GET https://hub.getdbt.com/api/v1/dbt-labs/dbt_utils.json
[0m12:37:31.405428 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'f8871537-0ba7-47d5-92de-d614b8de5078', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f03e2fea070>]}
[0m12:37:31.423175 [debug] [MainThread]: Response from registry: GET https://hub.getdbt.com/api/v1/dbt-labs/dbt_utils.json 200
[0m12:37:31.437089 [info ] [MainThread]: Installing Matts52/dbt_ml_inline_preprocessing
[0m12:37:31.462467 [debug] [MainThread]: Set downloads directory='/tmp/dbt-downloads-n3y071kn'
[0m12:37:31.465606 [debug] [MainThread]: Making package index registry request: GET https://hub.getdbt.com/api/v1/index.json
[0m12:37:31.558254 [debug] [MainThread]: Response from registry index: GET https://hub.getdbt.com/api/v1/index.json 200
[0m12:37:31.560177 [debug] [MainThread]: Making package registry request: GET https://hub.getdbt.com/api/v1/Matts52/dbt_ml_inline_preprocessing.json
[0m12:37:31.633315 [debug] [MainThread]: Response from registry: GET https://hub.getdbt.com/api/v1/Matts52/dbt_ml_inline_preprocessing.json 200
[0m12:37:31.637746 [debug] [MainThread]: Making package registry request: GET https://hub.getdbt.com/api/v1/dbt-labs/dbt_utils.json
[0m12:37:31.713511 [debug] [MainThread]: Response from registry: GET https://hub.getdbt.com/api/v1/dbt-labs/dbt_utils.json 200
[0m12:37:31.724094 [info ] [MainThread]: Installing Matts52/dbt_ml_inline_preprocessing
[0m12:37:33.159264 [info ] [MainThread]: Installed from version 0.2.4
[0m12:37:33.161270 [info ] [MainThread]: Up to date!
[0m12:37:33.164303 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'package', 'label': '525650bd-cc90-42d5-a9b3-20ce40dfd6a4', 'property_': 'install', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7feffccfb820>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7feffbe14d00>]}
[0m12:37:33.167040 [info ] [MainThread]: Installing dbt-labs/dbt_utils
[0m12:37:33.907869 [info ] [MainThread]: Installed from version 0.2.4
[0m12:37:33.910189 [info ] [MainThread]: Up to date!
[0m12:37:33.912780 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'package', 'label': 'f8871537-0ba7-47d5-92de-d614b8de5078', 'property_': 'install', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f03e22be430>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f03e22e5a30>]}
[0m12:37:33.915053 [info ] [MainThread]: Installing dbt-labs/dbt_utils
[0m12:37:36.346345 [info ] [MainThread]: Installed from version 1.3.0
[0m12:37:36.348374 [info ] [MainThread]: Up to date!
[0m12:37:36.350357 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'package', 'label': '525650bd-cc90-42d5-a9b3-20ce40dfd6a4', 'property_': 'install', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7feffccfb820>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7feffbed40a0>]}
[0m12:37:36.354769 [debug] [MainThread]: Resource report: {"command_name": "deps", "command_success": true, "command_wall_clock_time": 5.9722247, "process_in_blocks": "7488", "process_kernel_time": 0.481356, "process_mem_max_rss": "95304", "process_out_blocks": "7048", "process_user_time": 4.096445}
[0m12:37:36.357343 [debug] [MainThread]: Command `dbt deps` succeeded at 12:37:36.357091 after 5.98 seconds
[0m12:37:36.359499 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7feffceca670>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7feffccee4f0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7feffbf35a90>]}
[0m12:37:36.362728 [debug] [MainThread]: Flushing usage events
[0m12:37:36.976390 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m12:37:37.746557 [info ] [MainThread]: Installed from version 1.3.0
[0m12:37:37.748646 [info ] [MainThread]: Up to date!
[0m12:37:37.751253 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'package', 'label': 'f8871537-0ba7-47d5-92de-d614b8de5078', 'property_': 'install', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f03e22be430>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f03e4934880>]}
[0m12:37:37.756408 [debug] [MainThread]: Resource report: {"command_name": "deps", "command_success": true, "command_wall_clock_time": 6.783859, "process_in_blocks": "0", "process_kernel_time": 0.412146, "process_mem_max_rss": "95312", "process_out_blocks": "7048", "process_user_time": 4.081253}
[0m12:37:37.759186 [debug] [MainThread]: Command `dbt deps` succeeded at 12:37:37.758909 after 6.79 seconds
[0m12:37:37.761252 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f03e32496a0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f03e2fea070>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f03e22e5970>]}
[0m12:37:37.763924 [debug] [MainThread]: Flushing usage events
[0m12:37:38.282502 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m12:39:27.992880 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fefa787ab20>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fefa699b430>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fefa699b3d0>]}


============================== 12:39:28.009442 | 58416a21-bca1-4ea1-827e-0fa9ebe630d9 ==============================
[0m12:39:28.009442 [info ] [MainThread]: Running with dbt=1.9.4
[0m12:39:28.011672 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'debug': 'False', 'fail_fast': 'False', 'log_path': '/opt/airflow/dags/dbt/homework/logs', 'profiles_dir': '/opt/airflow/dags/dbt', 'version_check': 'True', 'use_colors': 'True', 'use_experimental_parser': 'False', 'empty': 'False', 'quiet': 'False', 'no_print': 'None', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'introspect': 'True', 'static_parser': 'True', 'invocation_command': 'dbt --profile homework run --project-dir=/opt/airflow/dags/dbt/homework --vars {"is_test": false, "data_date": "2025-04-21"}', 'target_path': 'None', 'log_format': 'default', 'send_anonymous_usage_stats': 'True'}
[0m12:39:28.697493 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '58416a21-bca1-4ea1-827e-0fa9ebe630d9', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fefa69db760>]}
[0m12:39:28.952256 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '58416a21-bca1-4ea1-827e-0fa9ebe630d9', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fefa5210880>]}
[0m12:39:28.954786 [info ] [MainThread]: Registered adapter: postgres=1.9.0
[0m12:39:29.247930 [error] [MainThread]: Encountered an error:
Runtime Error
  Failed to read package: Runtime Error
    No dbt_project.yml found at expected path /opt/airflow/dags/dbt/homework/dbt_packages/dbt_ml_inline_preprocessing/dbt_project.yml
    Verify that each entry within packages.yml (and their transitive dependencies) contains a file named dbt_project.yml
    

Error encountered in /opt/airflow/dags/dbt/homework/dbt_packages/dbt_ml_inline_preprocessing
[0m12:39:29.257170 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": false, "command_wall_clock_time": 1.4695143, "process_in_blocks": "0", "process_kernel_time": 0.32873, "process_mem_max_rss": "97428", "process_out_blocks": "0", "process_user_time": 5.448956}
[0m12:39:29.260489 [debug] [MainThread]: Command `dbt run` failed at 12:39:29.260014 after 1.47 seconds
[0m12:39:29.263133 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fefa787ab20>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fefa508e5e0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fefa508e7f0>]}
[0m12:39:29.266302 [debug] [MainThread]: Flushing usage events
[0m12:39:30.416154 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f05a0b34b50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f059fc564f0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f059fc56490>]}


============================== 12:39:30.431048 | bcbefbac-3219-47c6-8fdf-71656c54633d ==============================
[0m12:39:30.431048 [info ] [MainThread]: Running with dbt=1.9.4
[0m12:39:30.434113 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'debug': 'False', 'version_check': 'True', 'log_path': '/opt/airflow/dags/dbt/homework/logs', 'profiles_dir': '/opt/airflow/dags/dbt', 'fail_fast': 'False', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'empty': 'False', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'introspect': 'True', 'log_format': 'default', 'static_parser': 'True', 'target_path': 'None', 'invocation_command': 'dbt --profile homework run --project-dir=/opt/airflow/dags/dbt/homework --vars {"is_test": false, "data_date": "2025-04-22"}', 'send_anonymous_usage_stats': 'True'}
[0m12:39:30.563964 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m12:39:30.839585 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'bcbefbac-3219-47c6-8fdf-71656c54633d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f059fc96fa0>]}
[0m12:39:30.967833 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': 'bcbefbac-3219-47c6-8fdf-71656c54633d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f059e47c4f0>]}
[0m12:39:30.971454 [info ] [MainThread]: Registered adapter: postgres=1.9.0
[0m12:39:31.168476 [error] [MainThread]: Encountered an error:
Runtime Error
  Failed to read package: Runtime Error
    No dbt_project.yml found at expected path /opt/airflow/dags/dbt/homework/dbt_packages/dbt_ml_inline_preprocessing/dbt_project.yml
    Verify that each entry within packages.yml (and their transitive dependencies) contains a file named dbt_project.yml
    

Error encountered in /opt/airflow/dags/dbt/homework/dbt_packages/dbt_ml_inline_preprocessing
[0m12:39:31.172422 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": false, "command_wall_clock_time": 0.95683, "process_in_blocks": "0", "process_kernel_time": 0.239187, "process_mem_max_rss": "97692", "process_out_blocks": "0", "process_user_time": 5.072761}
[0m12:39:31.174679 [debug] [MainThread]: Command `dbt run` failed at 12:39:31.174446 after 0.96 seconds
[0m12:39:31.176339 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f05a0b34b50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f059e349400>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f059e349b20>]}
[0m12:39:31.178020 [debug] [MainThread]: Flushing usage events
[0m12:39:31.703083 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m12:42:38.240057 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f38d8865b20>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f38d7986430>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f38d79863d0>]}


============================== 12:42:38.254735 | c059b855-c002-49b4-9f9b-1183d0b5825c ==============================
[0m12:42:38.254735 [info ] [MainThread]: Running with dbt=1.9.4
[0m12:42:38.258586 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'fail_fast': 'False', 'debug': 'False', 'log_path': '/opt/airflow/dags/dbt/homework/logs', 'version_check': 'True', 'profiles_dir': '/opt/airflow/dags/dbt', 'use_colors': 'True', 'use_experimental_parser': 'False', 'empty': 'False', 'quiet': 'False', 'no_print': 'None', 'log_format': 'default', 'invocation_command': 'dbt --profile homework run --project-dir=/opt/airflow/dags/dbt/homework --vars {"is_test": false, "data_date": "2025-04-22"}', 'introspect': 'True', 'static_parser': 'True', 'target_path': 'None', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'send_anonymous_usage_stats': 'True'}
[0m12:42:38.272204 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0876bb6b80>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0875cd94c0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0875cd9460>]}


============================== 12:42:38.286873 | 9f178063-ee18-4126-baf4-f51bdf608ed7 ==============================
[0m12:42:38.286873 [info ] [MainThread]: Running with dbt=1.9.4
[0m12:42:38.290321 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': '/opt/airflow/dags/dbt', 'debug': 'False', 'fail_fast': 'False', 'log_path': '/opt/airflow/dags/dbt/homework/logs', 'version_check': 'True', 'warn_error': 'None', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'empty': 'False', 'log_format': 'default', 'introspect': 'True', 'static_parser': 'True', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'target_path': 'None', 'invocation_command': 'dbt --profile homework run --project-dir=/opt/airflow/dags/dbt/homework --vars {"is_test": false, "data_date": "2025-04-21"}', 'send_anonymous_usage_stats': 'True'}
[0m12:42:38.938961 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'c059b855-c002-49b4-9f9b-1183d0b5825c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f38d79c6760>]}
[0m12:42:38.988553 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '9f178063-ee18-4126-baf4-f51bdf608ed7', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0875d688b0>]}
[0m12:42:39.094909 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': 'c059b855-c002-49b4-9f9b-1183d0b5825c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f38d61fb880>]}
[0m12:42:39.097882 [info ] [MainThread]: Registered adapter: postgres=1.9.0
[0m12:42:39.106358 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '9f178063-ee18-4126-baf4-f51bdf608ed7', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0875d7a310>]}
[0m12:42:39.110339 [info ] [MainThread]: Registered adapter: postgres=1.9.0
[0m12:42:39.602670 [error] [MainThread]: Encountered an error:
Runtime Error
  Failed to read package: Runtime Error
    No dbt_project.yml found at expected path /opt/airflow/dags/dbt/homework/dbt_packages/dbt_ml_inline_preprocessing/dbt_project.yml
    Verify that each entry within packages.yml (and their transitive dependencies) contains a file named dbt_project.yml
    

Error encountered in /opt/airflow/dags/dbt/homework/dbt_packages/dbt_ml_inline_preprocessing
[0m12:42:39.612995 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": false, "command_wall_clock_time": 1.4875748, "process_in_blocks": "0", "process_kernel_time": 0.337627, "process_mem_max_rss": "97700", "process_out_blocks": "0", "process_user_time": 4.557968}
[0m12:42:39.622887 [debug] [MainThread]: Command `dbt run` failed at 12:42:39.622347 after 1.50 seconds
[0m12:42:39.634327 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0876bb6b80>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f087435b790>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f087435b8e0>]}
[0m12:42:39.650962 [debug] [MainThread]: Flushing usage events
[0m12:42:39.679510 [error] [MainThread]: Encountered an error:
Runtime Error
  Failed to read package: Runtime Error
    No dbt_project.yml found at expected path /opt/airflow/dags/dbt/homework/dbt_packages/dbt_ml_inline_preprocessing/dbt_project.yml
    Verify that each entry within packages.yml (and their transitive dependencies) contains a file named dbt_project.yml
    

Error encountered in /opt/airflow/dags/dbt/homework/dbt_packages/dbt_ml_inline_preprocessing
[0m12:42:39.690231 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": false, "command_wall_clock_time": 1.6080476, "process_in_blocks": "0", "process_kernel_time": 0.36127, "process_mem_max_rss": "97572", "process_out_blocks": "0", "process_user_time": 4.646336}
[0m12:42:39.695026 [debug] [MainThread]: Command `dbt run` failed at 12:42:39.694456 after 1.61 seconds
[0m12:42:39.698478 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f38d8865b20>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f38d60795e0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f38d60797f0>]}
[0m12:42:39.701347 [debug] [MainThread]: Flushing usage events
[0m12:42:40.247159 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m12:42:40.294380 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m12:50:50.707149 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6e312205b0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6e303bbd90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6e303bbd30>]}


============================== 12:50:50.719339 | d1786af0-7b22-489b-9495-445e4ed6437a ==============================
[0m12:50:50.719339 [info ] [MainThread]: Running with dbt=1.9.4
[0m12:50:50.721893 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': '/opt/airflow/dags/dbt', 'version_check': 'True', 'debug': 'False', 'log_path': '/opt/airflow/dags/dbt/homework/logs', 'fail_fast': 'False', 'warn_error': 'None', 'use_colors': 'True', 'use_experimental_parser': 'False', 'empty': 'None', 'quiet': 'False', 'no_print': 'None', 'log_format': 'default', 'invocation_command': 'dbt deps --profiles-dir /opt/airflow/dags/dbt --project-dir /opt/airflow/dags/dbt/homework', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'static_parser': 'True', 'target_path': 'None', 'introspect': 'True', 'send_anonymous_usage_stats': 'True'}
[0m12:50:50.971280 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'd1786af0-7b22-489b-9495-445e4ed6437a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6e30404310>]}
[0m12:50:51.181337 [debug] [MainThread]: Set downloads directory='/tmp/dbt-downloads-k47e5al3'
[0m12:50:51.183553 [debug] [MainThread]: Making package index registry request: GET https://hub.getdbt.com/api/v1/index.json
[0m12:50:51.312029 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f271e2f15e0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f271d48cee0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f271d48ce80>]}


============================== 12:50:51.326303 | d3851b62-4114-45e7-9ed4-b185b10a4a24 ==============================
[0m12:50:51.326303 [info ] [MainThread]: Running with dbt=1.9.4
[0m12:50:51.329620 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': '/opt/airflow/dags/dbt', 'version_check': 'True', 'debug': 'False', 'log_path': '/opt/airflow/dags/dbt/homework/logs', 'fail_fast': 'False', 'warn_error': 'None', 'use_colors': 'True', 'use_experimental_parser': 'False', 'empty': 'None', 'quiet': 'False', 'no_print': 'None', 'log_format': 'default', 'static_parser': 'True', 'introspect': 'True', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'target_path': 'None', 'invocation_command': 'dbt deps --profiles-dir /opt/airflow/dags/dbt --project-dir /opt/airflow/dags/dbt/homework', 'send_anonymous_usage_stats': 'True'}
[0m12:50:51.347489 [debug] [MainThread]: Response from registry index: GET https://hub.getdbt.com/api/v1/index.json 200
[0m12:50:51.349903 [debug] [MainThread]: Making package registry request: GET https://hub.getdbt.com/api/v1/Matts52/dbt_ml_inline_preprocessing.json
[0m12:50:51.561917 [debug] [MainThread]: Response from registry: GET https://hub.getdbt.com/api/v1/Matts52/dbt_ml_inline_preprocessing.json 200
[0m12:50:51.565530 [debug] [MainThread]: Making package registry request: GET https://hub.getdbt.com/api/v1/dbt-labs/dbt_utils.json
[0m12:50:51.597726 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'd3851b62-4114-45e7-9ed4-b185b10a4a24', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f271d453a90>]}
[0m12:50:51.638692 [debug] [MainThread]: Response from registry: GET https://hub.getdbt.com/api/v1/dbt-labs/dbt_utils.json 200
[0m12:50:51.645801 [debug] [MainThread]: Set downloads directory='/tmp/dbt-downloads-0pqhm6fw'
[0m12:50:51.648408 [debug] [MainThread]: Making package index registry request: GET https://hub.getdbt.com/api/v1/index.json
[0m12:50:51.650308 [info ] [MainThread]: Installing Matts52/dbt_ml_inline_preprocessing
[0m12:50:51.741287 [debug] [MainThread]: Response from registry index: GET https://hub.getdbt.com/api/v1/index.json 200
[0m12:50:51.743949 [debug] [MainThread]: Making package registry request: GET https://hub.getdbt.com/api/v1/Matts52/dbt_ml_inline_preprocessing.json
[0m12:50:51.817794 [debug] [MainThread]: Response from registry: GET https://hub.getdbt.com/api/v1/Matts52/dbt_ml_inline_preprocessing.json 200
[0m12:50:51.821447 [debug] [MainThread]: Making package registry request: GET https://hub.getdbt.com/api/v1/dbt-labs/dbt_utils.json
[0m12:50:51.891657 [debug] [MainThread]: Response from registry: GET https://hub.getdbt.com/api/v1/dbt-labs/dbt_utils.json 200
[0m12:50:51.902573 [info ] [MainThread]: Installing Matts52/dbt_ml_inline_preprocessing
[0m12:50:53.117672 [info ] [MainThread]: Installed from version 0.2.4
[0m12:50:53.119974 [info ] [MainThread]: Up to date!
[0m12:50:53.122216 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'package', 'label': 'd1786af0-7b22-489b-9495-445e4ed6437a', 'property_': 'install', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6e302ab040>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6e302ea430>]}
[0m12:50:53.124439 [info ] [MainThread]: Installing dbt-labs/dbt_utils
[0m12:50:53.715938 [info ] [MainThread]: Installed from version 0.2.4
[0m12:50:53.717561 [info ] [MainThread]: Up to date!
[0m12:50:53.719425 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'package', 'label': 'd3851b62-4114-45e7-9ed4-b185b10a4a24', 'property_': 'install', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f271d37dca0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f271fa46280>]}
[0m12:50:53.720988 [info ] [MainThread]: Installing dbt-labs/dbt_utils
[0m12:50:57.549868 [info ] [MainThread]: Installed from version 1.3.0
[0m12:50:57.551658 [info ] [MainThread]: Up to date!
[0m12:50:57.553298 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'package', 'label': 'd3851b62-4114-45e7-9ed4-b185b10a4a24', 'property_': 'install', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f271d37dca0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f271d324fd0>]}
[0m12:50:57.557506 [debug] [MainThread]: Resource report: {"command_name": "deps", "command_success": true, "command_wall_clock_time": 6.3773236, "process_in_blocks": "40", "process_kernel_time": 0.756918, "process_mem_max_rss": "95600", "process_out_blocks": "7048", "process_user_time": 4.15309}
[0m12:50:57.559975 [debug] [MainThread]: Command `dbt deps` succeeded at 12:50:57.559717 after 6.38 seconds
[0m12:50:57.561925 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f271e2f15e0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f271e1b56a0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f271fa46280>]}
[0m12:50:57.563534 [debug] [MainThread]: Flushing usage events
[0m12:50:57.761218 [error] [MainThread]: Encountered an error:
[('dbt_packages/dbt-utils-1.3.0/integration_tests/data/schema_tests/data_test_equal_rowcount.csv', 'dbt_packages/dbt_utils/integration_tests/data/schema_tests/data_test_equal_rowcount.csv', "[Errno 2] No such file or directory: 'dbt_packages/dbt_utils/integration_tests/data/schema_tests/data_test_equal_rowcount.csv'"), ('dbt_packages/dbt-utils-1.3.0/integration_tests/data/schema_tests/data_test_expression_is_true.csv', 'dbt_packages/dbt_utils/integration_tests/data/schema_tests/data_test_expression_is_true.csv', "[Errno 2] No such file or directory: 'dbt_packages/dbt-utils-1.3.0/integration_tests/data/schema_tests/data_test_expression_is_true.csv'"), ('dbt_packages/dbt-utils-1.3.0/integration_tests/data/schema_tests/data_test_fewer_rows_than_table_1.csv', 'dbt_packages/dbt_utils/integration_tests/data/schema_tests/data_test_fewer_rows_than_table_1.csv', "[Errno 2] No such file or directory: 'dbt_packages/dbt-utils-1.3.0/integration_tests/data/schema_tests/data_test_fewer_rows_than_table_1.csv'"), ('dbt_packages/dbt-utils-1.3.0/integration_tests/data/schema_tests/data_test_fewer_rows_than_table_2.csv', 'dbt_packages/dbt_utils/integration_tests/data/schema_tests/data_test_fewer_rows_than_table_2.csv', "[Errno 2] No such file or directory: 'dbt_packages/dbt-utils-1.3.0/integration_tests/data/schema_tests/data_test_fewer_rows_than_table_2.csv'"), ('dbt_packages/dbt-utils-1.3.0/integration_tests/data/schema_tests/data_test_mutually_exclusive_ranges_no_gaps.csv', 'dbt_packages/dbt_utils/integration_tests/data/schema_tests/data_test_mutually_exclusive_ranges_no_gaps.csv', "[Errno 2] No such file or directory: 'dbt_packages/dbt-utils-1.3.0/integration_tests/data/schema_tests/data_test_mutually_exclusive_ranges_no_gaps.csv'"), ('dbt_packages/dbt-utils-1.3.0/integration_tests/data/schema_tests/data_test_mutually_exclusive_ranges_with_gaps.csv', 'dbt_packages/dbt_utils/integration_tests/data/schema_tests/data_test_mutually_exclusive_ranges_with_gaps.csv', "[Errno 2] No such file or directory: 'dbt_packages/dbt-utils-1.3.0/integration_tests/data/schema_tests/data_test_mutually_exclusive_ranges_with_gaps.csv'"), ('dbt_packages/dbt-utils-1.3.0/integration_tests/data/schema_tests/data_test_mutually_exclusive_ranges_with_gaps_zero_length.csv', 'dbt_packages/dbt_utils/integration_tests/data/schema_tests/data_test_mutually_exclusive_ranges_with_gaps_zero_length.csv', "[Errno 2] No such file or directory: 'dbt_packages/dbt-utils-1.3.0/integration_tests/data/schema_tests/data_test_mutually_exclusive_ranges_with_gaps_zero_length.csv'"), ('dbt_packages/dbt-utils-1.3.0/integration_tests/data/schema_tests/data_test_not_accepted_values.csv', 'dbt_packages/dbt_utils/integration_tests/data/schema_tests/data_test_not_accepted_values.csv', "[Errno 2] No such file or directory: 'dbt_packages/dbt-utils-1.3.0/integration_tests/data/schema_tests/data_test_not_accepted_values.csv'"), ('dbt_packages/dbt-utils-1.3.0/integration_tests/data/schema_tests/data_test_not_constant.csv', 'dbt_packages/dbt_utils/integration_tests/data/schema_tests/data_test_not_constant.csv', "[Errno 2] No such file or directory: 'dbt_packages/dbt-utils-1.3.0/integration_tests/data/schema_tests/data_test_not_constant.csv'"), ('dbt_packages/dbt-utils-1.3.0/integration_tests/data/schema_tests/data_test_relationships_where_table_1.csv', 'dbt_packages/dbt_utils/integration_tests/data/schema_tests/data_test_relationships_where_table_1.csv', "[Errno 2] No such file or directory: 'dbt_packages/dbt-utils-1.3.0/integration_tests/data/schema_tests/data_test_relationships_where_table_1.csv'"), ('dbt_packages/dbt-utils-1.3.0/integration_tests/data/schema_tests/data_test_relationships_where_table_2.csv', 'dbt_packages/dbt_utils/integration_tests/data/schema_tests/data_test_relationships_where_table_2.csv', "[Errno 2] No such file or directory: 'dbt_packages/dbt-utils-1.3.0/integration_tests/data/schema_tests/data_test_relationships_where_table_2.csv'"), ('dbt_packages/dbt-utils-1.3.0/integration_tests/data/schema_tests/data_test_sequential_timestamps.csv', 'dbt_packages/dbt_utils/integration_tests/data/schema_tests/data_test_sequential_timestamps.csv', "[Errno 2] No such file or directory: 'dbt_packages/dbt-utils-1.3.0/integration_tests/data/schema_tests/data_test_sequential_timestamps.csv'"), ('dbt_packages/dbt-utils-1.3.0/integration_tests/data/schema_tests/data_test_sequential_values.csv', 'dbt_packages/dbt_utils/integration_tests/data/schema_tests/data_test_sequential_values.csv', "[Errno 2] No such file or directory: 'dbt_packages/dbt-utils-1.3.0/integration_tests/data/schema_tests/data_test_sequential_values.csv'"), ('dbt_packages/dbt-utils-1.3.0/integration_tests/data/schema_tests/data_unique_combination_of_columns.csv', 'dbt_packages/dbt_utils/integration_tests/data/schema_tests/data_unique_combination_of_columns.csv', "[Errno 2] No such file or directory: 'dbt_packages/dbt-utils-1.3.0/integration_tests/data/schema_tests/data_unique_combination_of_columns.csv'"), ('dbt_packages/dbt-utils-1.3.0/integration_tests/data/schema_tests/schema.yml', 'dbt_packages/dbt_utils/integration_tests/data/schema_tests/schema.yml', "[Errno 2] No such file or directory: 'dbt_packages/dbt-utils-1.3.0/integration_tests/data/schema_tests/schema.yml'"), (<DirEntry 'schema_tests'>, 'dbt_packages/dbt_utils/integration_tests/data/schema_tests', "[Errno 2] No such file or directory: 'dbt_packages/dbt-utils-1.3.0/integration_tests/data/schema_tests'"), ('dbt_packages/dbt-utils-1.3.0/integration_tests/data/sql', 'dbt_packages/dbt_utils/integration_tests/data/sql', "[Errno 2] No such file or directory: 'dbt_packages/dbt-utils-1.3.0/integration_tests/data/sql'"), ('dbt_packages/dbt-utils-1.3.0/integration_tests/data/web', 'dbt_packages/dbt_utils/integration_tests/data/web', "[Errno 2] No such file or directory: 'dbt_packages/dbt-utils-1.3.0/integration_tests/data/web'"), (<DirEntry 'data'>, 'dbt_packages/dbt_utils/integration_tests/data', "[Errno 2] No such file or directory: 'dbt_packages/dbt-utils-1.3.0/integration_tests/data'"), ('dbt_packages/dbt-utils-1.3.0/integration_tests/dbt_project.yml', 'dbt_packages/dbt_utils/integration_tests/dbt_project.yml', "[Errno 2] No such file or directory: 'dbt_packages/dbt-utils-1.3.0/integration_tests/dbt_project.yml'"), ('dbt_packages/dbt-utils-1.3.0/integration_tests/macros', 'dbt_packages/dbt_utils/integration_tests/macros', "[Errno 2] No such file or directory: 'dbt_packages/dbt-utils-1.3.0/integration_tests/macros'"), ('dbt_packages/dbt-utils-1.3.0/integration_tests/models', 'dbt_packages/dbt_utils/integration_tests/models', "[Errno 2] No such file or directory: 'dbt_packages/dbt-utils-1.3.0/integration_tests/models'"), ('dbt_packages/dbt-utils-1.3.0/integration_tests/package-lock.yml', 'dbt_packages/dbt_utils/integration_tests/package-lock.yml', "[Errno 2] No such file or directory: 'dbt_packages/dbt-utils-1.3.0/integration_tests/package-lock.yml'"), ('dbt_packages/dbt-utils-1.3.0/integration_tests/packages.yml', 'dbt_packages/dbt_utils/integration_tests/packages.yml', "[Errno 2] No such file or directory: 'dbt_packages/dbt-utils-1.3.0/integration_tests/packages.yml'"), ('dbt_packages/dbt-utils-1.3.0/integration_tests/profiles.yml', 'dbt_packages/dbt_utils/integration_tests/profiles.yml', "[Errno 2] No such file or directory: 'dbt_packages/dbt-utils-1.3.0/integration_tests/profiles.yml'"), ('dbt_packages/dbt-utils-1.3.0/integration_tests/README.md', 'dbt_packages/dbt_utils/integration_tests/README.md', "[Errno 2] No such file or directory: 'dbt_packages/dbt-utils-1.3.0/integration_tests/README.md'"), ('dbt_packages/dbt-utils-1.3.0/integration_tests/tests', 'dbt_packages/dbt_utils/integration_tests/tests', "[Errno 2] No such file or directory: 'dbt_packages/dbt-utils-1.3.0/integration_tests/tests'"), (<DirEntry 'integration_tests'>, 'dbt_packages/dbt_utils/integration_tests', "[Errno 2] No such file or directory: 'dbt_packages/dbt-utils-1.3.0/integration_tests'"), ('dbt_packages/dbt-utils-1.3.0/LICENSE', 'dbt_packages/dbt_utils/LICENSE', "[Errno 2] No such file or directory: 'dbt_packages/dbt-utils-1.3.0/LICENSE'"), ('dbt_packages/dbt-utils-1.3.0/macros', 'dbt_packages/dbt_utils/macros', "[Errno 2] No such file or directory: 'dbt_packages/dbt-utils-1.3.0/macros'"), ('dbt_packages/dbt-utils-1.3.0/Makefile', 'dbt_packages/dbt_utils/Makefile', "[Errno 2] No such file or directory: 'dbt_packages/dbt-utils-1.3.0/Makefile'"), ('dbt_packages/dbt-utils-1.3.0/pytest.ini', 'dbt_packages/dbt_utils/pytest.ini', "[Errno 2] No such file or directory: 'dbt_packages/dbt-utils-1.3.0/pytest.ini'"), ('dbt_packages/dbt-utils-1.3.0/README.md', 'dbt_packages/dbt_utils/README.md', "[Errno 2] No such file or directory: 'dbt_packages/dbt-utils-1.3.0/README.md'"), ('dbt_packages/dbt-utils-1.3.0/RELEASE.md', 'dbt_packages/dbt_utils/RELEASE.md', "[Errno 2] No such file or directory: 'dbt_packages/dbt-utils-1.3.0/RELEASE.md'"), ('dbt_packages/dbt-utils-1.3.0/run_functional_test.sh', 'dbt_packages/dbt_utils/run_functional_test.sh', "[Errno 2] No such file or directory: 'dbt_packages/dbt-utils-1.3.0/run_functional_test.sh'"), ('dbt_packages/dbt-utils-1.3.0/run_test.sh', 'dbt_packages/dbt_utils/run_test.sh', "[Errno 2] No such file or directory: 'dbt_packages/dbt-utils-1.3.0/run_test.sh'"), ('dbt_packages/dbt-utils-1.3.0/supported_adapters.env', 'dbt_packages/dbt_utils/supported_adapters.env', "[Errno 2] No such file or directory: 'dbt_packages/dbt-utils-1.3.0/supported_adapters.env'"), ('dbt_packages/dbt-utils-1.3.0/tox.ini', 'dbt_packages/dbt_utils/tox.ini', "[Errno 2] No such file or directory: 'dbt_packages/dbt-utils-1.3.0/tox.ini'"), ('dbt_packages/dbt-utils-1.3.0', 'dbt_packages/dbt_utils', "[Errno 2] No such file or directory: 'dbt_packages/dbt-utils-1.3.0'")]
[0m12:50:57.766595 [error] [MainThread]: Traceback (most recent call last):
  File "/usr/local/lib/python3.9/shutil.py", line 825, in move
    os.rename(src, real_dst)
PermissionError: [Errno 13] Permission denied: 'dbt_packages/dbt-utils-1.3.0' -> 'dbt_packages/dbt_utils'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/dbt/cli/requires.py", line 153, in wrapper
    result, success = func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.9/site-packages/dbt/cli/requires.py", line 103, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.9/site-packages/dbt/cli/requires.py", line 218, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.9/site-packages/dbt/cli/requires.py", line 264, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.9/site-packages/dbt/cli/main.py", line 455, in deps
    results = task.run()
  File "/home/airflow/.local/lib/python3.9/site-packages/dbt/task/deps.py", line 254, in run
    package.install(self.project, renderer)
  File "/home/airflow/.local/lib/python3.9/site-packages/dbt/deps/registry.py", line 63, in install
    self._install(project, renderer)
  File "/home/airflow/.local/lib/python3.9/site-packages/dbt/deps/base.py", line 121, in _install
    connection_exception_retry(download_untar_fn, 5)
  File "/home/airflow/.local/lib/python3.9/site-packages/dbt_common/utils/connection.py", line 21, in connection_exception_retry
    return fn()
  File "/home/airflow/.local/lib/python3.9/site-packages/dbt/deps/base.py", line 133, in download_and_untar
    system.untar_package(tar_path, deps_path, package_name)
  File "/home/airflow/.local/lib/python3.9/site-packages/dbt_common/clients/system.py", line 646, in untar_package
    dbt_common.clients.system.rename(downloaded_path, desired_path, force=True)
  File "/home/airflow/.local/lib/python3.9/site-packages/dbt_common/clients/system.py", line 609, in rename
    shutil.move(from_path, to_path)
  File "/usr/local/lib/python3.9/shutil.py", line 841, in move
    copytree(src, real_dst, copy_function=copy_function,
  File "/usr/local/lib/python3.9/shutil.py", line 568, in copytree
    return _copytree(entries=entries, src=src, dst=dst, symlinks=symlinks,
  File "/usr/local/lib/python3.9/shutil.py", line 522, in _copytree
    raise Error(errors)
shutil.Error: [('dbt_packages/dbt-utils-1.3.0/integration_tests/data/schema_tests/data_test_equal_rowcount.csv', 'dbt_packages/dbt_utils/integration_tests/data/schema_tests/data_test_equal_rowcount.csv', "[Errno 2] No such file or directory: 'dbt_packages/dbt_utils/integration_tests/data/schema_tests/data_test_equal_rowcount.csv'"), ('dbt_packages/dbt-utils-1.3.0/integration_tests/data/schema_tests/data_test_expression_is_true.csv', 'dbt_packages/dbt_utils/integration_tests/data/schema_tests/data_test_expression_is_true.csv', "[Errno 2] No such file or directory: 'dbt_packages/dbt-utils-1.3.0/integration_tests/data/schema_tests/data_test_expression_is_true.csv'"), ('dbt_packages/dbt-utils-1.3.0/integration_tests/data/schema_tests/data_test_fewer_rows_than_table_1.csv', 'dbt_packages/dbt_utils/integration_tests/data/schema_tests/data_test_fewer_rows_than_table_1.csv', "[Errno 2] No such file or directory: 'dbt_packages/dbt-utils-1.3.0/integration_tests/data/schema_tests/data_test_fewer_rows_than_table_1.csv'"), ('dbt_packages/dbt-utils-1.3.0/integration_tests/data/schema_tests/data_test_fewer_rows_than_table_2.csv', 'dbt_packages/dbt_utils/integration_tests/data/schema_tests/data_test_fewer_rows_than_table_2.csv', "[Errno 2] No such file or directory: 'dbt_packages/dbt-utils-1.3.0/integration_tests/data/schema_tests/data_test_fewer_rows_than_table_2.csv'"), ('dbt_packages/dbt-utils-1.3.0/integration_tests/data/schema_tests/data_test_mutually_exclusive_ranges_no_gaps.csv', 'dbt_packages/dbt_utils/integration_tests/data/schema_tests/data_test_mutually_exclusive_ranges_no_gaps.csv', "[Errno 2] No such file or directory: 'dbt_packages/dbt-utils-1.3.0/integration_tests/data/schema_tests/data_test_mutually_exclusive_ranges_no_gaps.csv'"), ('dbt_packages/dbt-utils-1.3.0/integration_tests/data/schema_tests/data_test_mutually_exclusive_ranges_with_gaps.csv', 'dbt_packages/dbt_utils/integration_tests/data/schema_tests/data_test_mutually_exclusive_ranges_with_gaps.csv', "[Errno 2] No such file or directory: 'dbt_packages/dbt-utils-1.3.0/integration_tests/data/schema_tests/data_test_mutually_exclusive_ranges_with_gaps.csv'"), ('dbt_packages/dbt-utils-1.3.0/integration_tests/data/schema_tests/data_test_mutually_exclusive_ranges_with_gaps_zero_length.csv', 'dbt_packages/dbt_utils/integration_tests/data/schema_tests/data_test_mutually_exclusive_ranges_with_gaps_zero_length.csv', "[Errno 2] No such file or directory: 'dbt_packages/dbt-utils-1.3.0/integration_tests/data/schema_tests/data_test_mutually_exclusive_ranges_with_gaps_zero_length.csv'"), ('dbt_packages/dbt-utils-1.3.0/integration_tests/data/schema_tests/data_test_not_accepted_values.csv', 'dbt_packages/dbt_utils/integration_tests/data/schema_tests/data_test_not_accepted_values.csv', "[Errno 2] No such file or directory: 'dbt_packages/dbt-utils-1.3.0/integration_tests/data/schema_tests/data_test_not_accepted_values.csv'"), ('dbt_packages/dbt-utils-1.3.0/integration_tests/data/schema_tests/data_test_not_constant.csv', 'dbt_packages/dbt_utils/integration_tests/data/schema_tests/data_test_not_constant.csv', "[Errno 2] No such file or directory: 'dbt_packages/dbt-utils-1.3.0/integration_tests/data/schema_tests/data_test_not_constant.csv'"), ('dbt_packages/dbt-utils-1.3.0/integration_tests/data/schema_tests/data_test_relationships_where_table_1.csv', 'dbt_packages/dbt_utils/integration_tests/data/schema_tests/data_test_relationships_where_table_1.csv', "[Errno 2] No such file or directory: 'dbt_packages/dbt-utils-1.3.0/integration_tests/data/schema_tests/data_test_relationships_where_table_1.csv'"), ('dbt_packages/dbt-utils-1.3.0/integration_tests/data/schema_tests/data_test_relationships_where_table_2.csv', 'dbt_packages/dbt_utils/integration_tests/data/schema_tests/data_test_relationships_where_table_2.csv', "[Errno 2] No such file or directory: 'dbt_packages/dbt-utils-1.3.0/integration_tests/data/schema_tests/data_test_relationships_where_table_2.csv'"), ('dbt_packages/dbt-utils-1.3.0/integration_tests/data/schema_tests/data_test_sequential_timestamps.csv', 'dbt_packages/dbt_utils/integration_tests/data/schema_tests/data_test_sequential_timestamps.csv', "[Errno 2] No such file or directory: 'dbt_packages/dbt-utils-1.3.0/integration_tests/data/schema_tests/data_test_sequential_timestamps.csv'"), ('dbt_packages/dbt-utils-1.3.0/integration_tests/data/schema_tests/data_test_sequential_values.csv', 'dbt_packages/dbt_utils/integration_tests/data/schema_tests/data_test_sequential_values.csv', "[Errno 2] No such file or directory: 'dbt_packages/dbt-utils-1.3.0/integration_tests/data/schema_tests/data_test_sequential_values.csv'"), ('dbt_packages/dbt-utils-1.3.0/integration_tests/data/schema_tests/data_unique_combination_of_columns.csv', 'dbt_packages/dbt_utils/integration_tests/data/schema_tests/data_unique_combination_of_columns.csv', "[Errno 2] No such file or directory: 'dbt_packages/dbt-utils-1.3.0/integration_tests/data/schema_tests/data_unique_combination_of_columns.csv'"), ('dbt_packages/dbt-utils-1.3.0/integration_tests/data/schema_tests/schema.yml', 'dbt_packages/dbt_utils/integration_tests/data/schema_tests/schema.yml', "[Errno 2] No such file or directory: 'dbt_packages/dbt-utils-1.3.0/integration_tests/data/schema_tests/schema.yml'"), (<DirEntry 'schema_tests'>, 'dbt_packages/dbt_utils/integration_tests/data/schema_tests', "[Errno 2] No such file or directory: 'dbt_packages/dbt-utils-1.3.0/integration_tests/data/schema_tests'"), ('dbt_packages/dbt-utils-1.3.0/integration_tests/data/sql', 'dbt_packages/dbt_utils/integration_tests/data/sql', "[Errno 2] No such file or directory: 'dbt_packages/dbt-utils-1.3.0/integration_tests/data/sql'"), ('dbt_packages/dbt-utils-1.3.0/integration_tests/data/web', 'dbt_packages/dbt_utils/integration_tests/data/web', "[Errno 2] No such file or directory: 'dbt_packages/dbt-utils-1.3.0/integration_tests/data/web'"), (<DirEntry 'data'>, 'dbt_packages/dbt_utils/integration_tests/data', "[Errno 2] No such file or directory: 'dbt_packages/dbt-utils-1.3.0/integration_tests/data'"), ('dbt_packages/dbt-utils-1.3.0/integration_tests/dbt_project.yml', 'dbt_packages/dbt_utils/integration_tests/dbt_project.yml', "[Errno 2] No such file or directory: 'dbt_packages/dbt-utils-1.3.0/integration_tests/dbt_project.yml'"), ('dbt_packages/dbt-utils-1.3.0/integration_tests/macros', 'dbt_packages/dbt_utils/integration_tests/macros', "[Errno 2] No such file or directory: 'dbt_packages/dbt-utils-1.3.0/integration_tests/macros'"), ('dbt_packages/dbt-utils-1.3.0/integration_tests/models', 'dbt_packages/dbt_utils/integration_tests/models', "[Errno 2] No such file or directory: 'dbt_packages/dbt-utils-1.3.0/integration_tests/models'"), ('dbt_packages/dbt-utils-1.3.0/integration_tests/package-lock.yml', 'dbt_packages/dbt_utils/integration_tests/package-lock.yml', "[Errno 2] No such file or directory: 'dbt_packages/dbt-utils-1.3.0/integration_tests/package-lock.yml'"), ('dbt_packages/dbt-utils-1.3.0/integration_tests/packages.yml', 'dbt_packages/dbt_utils/integration_tests/packages.yml', "[Errno 2] No such file or directory: 'dbt_packages/dbt-utils-1.3.0/integration_tests/packages.yml'"), ('dbt_packages/dbt-utils-1.3.0/integration_tests/profiles.yml', 'dbt_packages/dbt_utils/integration_tests/profiles.yml', "[Errno 2] No such file or directory: 'dbt_packages/dbt-utils-1.3.0/integration_tests/profiles.yml'"), ('dbt_packages/dbt-utils-1.3.0/integration_tests/README.md', 'dbt_packages/dbt_utils/integration_tests/README.md', "[Errno 2] No such file or directory: 'dbt_packages/dbt-utils-1.3.0/integration_tests/README.md'"), ('dbt_packages/dbt-utils-1.3.0/integration_tests/tests', 'dbt_packages/dbt_utils/integration_tests/tests', "[Errno 2] No such file or directory: 'dbt_packages/dbt-utils-1.3.0/integration_tests/tests'"), (<DirEntry 'integration_tests'>, 'dbt_packages/dbt_utils/integration_tests', "[Errno 2] No such file or directory: 'dbt_packages/dbt-utils-1.3.0/integration_tests'"), ('dbt_packages/dbt-utils-1.3.0/LICENSE', 'dbt_packages/dbt_utils/LICENSE', "[Errno 2] No such file or directory: 'dbt_packages/dbt-utils-1.3.0/LICENSE'"), ('dbt_packages/dbt-utils-1.3.0/macros', 'dbt_packages/dbt_utils/macros', "[Errno 2] No such file or directory: 'dbt_packages/dbt-utils-1.3.0/macros'"), ('dbt_packages/dbt-utils-1.3.0/Makefile', 'dbt_packages/dbt_utils/Makefile', "[Errno 2] No such file or directory: 'dbt_packages/dbt-utils-1.3.0/Makefile'"), ('dbt_packages/dbt-utils-1.3.0/pytest.ini', 'dbt_packages/dbt_utils/pytest.ini', "[Errno 2] No such file or directory: 'dbt_packages/dbt-utils-1.3.0/pytest.ini'"), ('dbt_packages/dbt-utils-1.3.0/README.md', 'dbt_packages/dbt_utils/README.md', "[Errno 2] No such file or directory: 'dbt_packages/dbt-utils-1.3.0/README.md'"), ('dbt_packages/dbt-utils-1.3.0/RELEASE.md', 'dbt_packages/dbt_utils/RELEASE.md', "[Errno 2] No such file or directory: 'dbt_packages/dbt-utils-1.3.0/RELEASE.md'"), ('dbt_packages/dbt-utils-1.3.0/run_functional_test.sh', 'dbt_packages/dbt_utils/run_functional_test.sh', "[Errno 2] No such file or directory: 'dbt_packages/dbt-utils-1.3.0/run_functional_test.sh'"), ('dbt_packages/dbt-utils-1.3.0/run_test.sh', 'dbt_packages/dbt_utils/run_test.sh', "[Errno 2] No such file or directory: 'dbt_packages/dbt-utils-1.3.0/run_test.sh'"), ('dbt_packages/dbt-utils-1.3.0/supported_adapters.env', 'dbt_packages/dbt_utils/supported_adapters.env', "[Errno 2] No such file or directory: 'dbt_packages/dbt-utils-1.3.0/supported_adapters.env'"), ('dbt_packages/dbt-utils-1.3.0/tox.ini', 'dbt_packages/dbt_utils/tox.ini', "[Errno 2] No such file or directory: 'dbt_packages/dbt-utils-1.3.0/tox.ini'"), ('dbt_packages/dbt-utils-1.3.0', 'dbt_packages/dbt_utils', "[Errno 2] No such file or directory: 'dbt_packages/dbt-utils-1.3.0'")]

[0m12:50:57.770528 [debug] [MainThread]: Resource report: {"command_name": "deps", "command_success": false, "command_wall_clock_time": 7.1929116, "process_in_blocks": "6576", "process_kernel_time": 0.919216, "process_mem_max_rss": "95720", "process_out_blocks": "7048", "process_user_time": 4.289678}
[0m12:50:57.772594 [debug] [MainThread]: Command `dbt deps` failed at 12:50:57.772441 after 7.20 seconds
[0m12:50:57.774243 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6e312205b0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6e30204ac0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6e30204160>]}
[0m12:50:57.775986 [debug] [MainThread]: Flushing usage events
[0m12:50:58.259556 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m12:50:58.842156 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m12:53:53.035283 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd61de30a90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd61cf53610>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd61cf535b0>]}
[0m12:53:53.036036 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f37e0dcaa60>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f37dfeec5e0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f37dfeec580>]}


============================== 12:53:53.053436 | 5617eb9d-5a99-4b48-8d5d-1566cb80795b ==============================
[0m12:53:53.053436 [info ] [MainThread]: Running with dbt=1.9.4


============================== 12:53:53.053555 | 721b66df-4e50-413e-8c99-e6a3978c7e69 ==============================
[0m12:53:53.053555 [info ] [MainThread]: Running with dbt=1.9.4
[0m12:53:53.055967 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': '/opt/airflow/dags/dbt', 'debug': 'False', 'warn_error': 'None', 'log_path': '/opt/airflow/dags/dbt/homework/logs', 'fail_fast': 'False', 'version_check': 'True', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'empty': 'False', 'log_format': 'default', 'invocation_command': 'dbt --profile homework run --project-dir=/opt/airflow/dags/dbt/homework --vars {"is_test": false, "data_date": "2025-04-22"}', 'introspect': 'True', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'target_path': 'None', 'static_parser': 'True', 'send_anonymous_usage_stats': 'True'}
[0m12:53:53.056160 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': '/opt/airflow/dags/dbt', 'fail_fast': 'False', 'version_check': 'True', 'log_path': '/opt/airflow/dags/dbt/homework/logs', 'debug': 'False', 'warn_error': 'None', 'use_colors': 'True', 'use_experimental_parser': 'False', 'empty': 'False', 'quiet': 'False', 'no_print': 'None', 'log_format': 'default', 'invocation_command': 'dbt --profile homework run --project-dir=/opt/airflow/dags/dbt/homework --vars {"is_test": false, "data_date": "2025-04-21"}', 'static_parser': 'True', 'introspect': 'True', 'target_path': 'None', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'send_anonymous_usage_stats': 'True'}
[0m12:53:53.715080 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '721b66df-4e50-413e-8c99-e6a3978c7e69', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f37dff21490>]}
[0m12:53:53.717023 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '5617eb9d-5a99-4b48-8d5d-1566cb80795b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd61cf71bb0>]}
[0m12:53:53.932230 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '721b66df-4e50-413e-8c99-e6a3978c7e69', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f37dff2a370>]}
[0m12:53:53.937332 [info ] [MainThread]: Registered adapter: postgres=1.9.0
[0m12:53:53.941021 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '5617eb9d-5a99-4b48-8d5d-1566cb80795b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd61d6210a0>]}
[0m12:53:53.943735 [info ] [MainThread]: Registered adapter: postgres=1.9.0
[0m12:53:54.316311 [error] [MainThread]: Encountered an error:
Runtime Error
  Failed to read package: Runtime Error
    No dbt_project.yml found at expected path /opt/airflow/dags/dbt/homework/dbt_packages/dbt_ml_inline_preprocessing/dbt_project.yml
    Verify that each entry within packages.yml (and their transitive dependencies) contains a file named dbt_project.yml
    

Error encountered in /opt/airflow/dags/dbt/homework/dbt_packages/dbt_ml_inline_preprocessing
[0m12:53:54.316799 [error] [MainThread]: Encountered an error:
Runtime Error
  Failed to read package: Runtime Error
    No dbt_project.yml found at expected path /opt/airflow/dags/dbt/homework/dbt_packages/dbt_ml_inline_preprocessing/dbt_project.yml
    Verify that each entry within packages.yml (and their transitive dependencies) contains a file named dbt_project.yml
    

Error encountered in /opt/airflow/dags/dbt/homework/dbt_packages/dbt_ml_inline_preprocessing
[0m12:53:54.322649 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": false, "command_wall_clock_time": 1.4477171, "process_in_blocks": "1752", "process_kernel_time": 0.74047, "process_mem_max_rss": "97760", "process_out_blocks": "0", "process_user_time": 6.834347}
[0m12:53:54.322915 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": false, "command_wall_clock_time": 1.4478704, "process_in_blocks": "1728", "process_kernel_time": 0.848647, "process_mem_max_rss": "97940", "process_out_blocks": "0", "process_user_time": 6.63942}
[0m12:53:54.326764 [debug] [MainThread]: Command `dbt run` failed at 12:53:54.326278 after 1.45 seconds
[0m12:53:54.326638 [debug] [MainThread]: Command `dbt run` failed at 12:53:54.326053 after 1.45 seconds
[0m12:53:54.329735 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f37e0dcaa60>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f37de56c910>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f37de56cee0>]}
[0m12:53:54.329768 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd61de30a90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd61b5d24f0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd61b5d2250>]}
[0m12:53:54.334011 [debug] [MainThread]: Flushing usage events
[0m12:53:54.334520 [debug] [MainThread]: Flushing usage events
[0m12:53:54.976706 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m12:53:54.987251 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m12:57:46.138883 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f7a92378a30>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f7a9149a460>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f7a9149a400>]}


============================== 12:57:46.156695 | 62a7b9b1-843a-40e3-8c90-eec8de267340 ==============================
[0m12:57:46.156695 [info ] [MainThread]: Running with dbt=1.9.4
[0m12:57:46.158945 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': '/opt/airflow/dags/dbt', 'fail_fast': 'False', 'debug': 'False', 'log_path': '/opt/airflow/dags/dbt/homework/logs', 'warn_error': 'None', 'version_check': 'True', 'use_colors': 'True', 'use_experimental_parser': 'False', 'empty': 'None', 'quiet': 'False', 'no_print': 'None', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'static_parser': 'True', 'introspect': 'True', 'log_format': 'default', 'target_path': 'None', 'invocation_command': 'dbt --profile homework deps --project-dir=/opt/airflow/dags/dbt/homework', 'send_anonymous_usage_stats': 'True'}
[0m12:57:46.155835 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fdc6d538a60>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fdc6c65a460>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fdc6c65a400>]}


============================== 12:57:46.170355 | 76e29a03-996d-4e3b-900a-e3af0a2b24dd ==============================
[0m12:57:46.170355 [info ] [MainThread]: Running with dbt=1.9.4
[0m12:57:46.172508 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': '/opt/airflow/dags/dbt', 'version_check': 'True', 'warn_error': 'None', 'log_path': '/opt/airflow/dags/dbt/homework/logs', 'debug': 'False', 'fail_fast': 'False', 'use_colors': 'True', 'use_experimental_parser': 'False', 'empty': 'None', 'quiet': 'False', 'no_print': 'None', 'log_format': 'default', 'static_parser': 'True', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'introspect': 'True', 'target_path': 'None', 'invocation_command': 'dbt --profile homework deps --project-dir=/opt/airflow/dags/dbt/homework', 'send_anonymous_usage_stats': 'True'}
[0m12:57:46.679833 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '62a7b9b1-843a-40e3-8c90-eec8de267340', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f7a91524ac0>]}
[0m12:57:46.711541 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '76e29a03-996d-4e3b-900a-e3af0a2b24dd', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fdc6c620df0>]}
[0m12:57:46.756937 [error] [MainThread]: Encountered an error:
[Errno 2] No such file or directory: 'k_bins_discretize.sql'
[0m12:57:46.763747 [error] [MainThread]: Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/dbt/cli/requires.py", line 153, in wrapper
    result, success = func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.9/site-packages/dbt/cli/requires.py", line 103, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.9/site-packages/dbt/cli/requires.py", line 218, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.9/site-packages/dbt/cli/requires.py", line 264, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.9/site-packages/dbt/cli/main.py", line 455, in deps
    results = task.run()
  File "/home/airflow/.local/lib/python3.9/site-packages/dbt/task/deps.py", line 227, in run
    system.rmtree(self.project.packages_install_path)
  File "/home/airflow/.local/lib/python3.9/site-packages/dbt_common/clients/system.py", line 715, in rmtree
    return shutil.rmtree(path, onerror=chmod_and_retry)
  File "/usr/local/lib/python3.9/shutil.py", line 734, in rmtree
    _rmtree_safe_fd(fd, path, onerror)
  File "/usr/local/lib/python3.9/shutil.py", line 667, in _rmtree_safe_fd
    _rmtree_safe_fd(dirfd, fullname, onerror)
  File "/usr/local/lib/python3.9/shutil.py", line 667, in _rmtree_safe_fd
    _rmtree_safe_fd(dirfd, fullname, onerror)
  File "/usr/local/lib/python3.9/shutil.py", line 690, in _rmtree_safe_fd
    onerror(os.unlink, fullname, sys.exc_info())
  File "/usr/local/lib/python3.9/shutil.py", line 688, in _rmtree_safe_fd
    os.unlink(entry.name, dir_fd=topfd)
FileNotFoundError: [Errno 2] No such file or directory: 'k_bins_discretize.sql'

[0m12:57:46.767110 [debug] [MainThread]: Resource report: {"command_name": "deps", "command_success": false, "command_wall_clock_time": 0.7819463, "process_in_blocks": "72", "process_kernel_time": 0.580734, "process_mem_max_rss": "92548", "process_out_blocks": "0", "process_user_time": 4.806077}
[0m12:57:46.769350 [debug] [MainThread]: Command `dbt deps` failed at 12:57:46.769085 after 0.78 seconds
[0m12:57:46.771552 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fdc6d538a60>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fdc6c5185e0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fdc6c518520>]}
[0m12:57:46.774170 [debug] [MainThread]: Flushing usage events
[0m12:57:47.380606 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m12:57:47.563263 [debug] [MainThread]: Set downloads directory='/tmp/dbt-downloads-qjzzzb9c'
[0m12:57:47.565555 [debug] [MainThread]: Making package index registry request: GET https://hub.getdbt.com/api/v1/index.json
[0m12:57:47.777176 [debug] [MainThread]: Response from registry index: GET https://hub.getdbt.com/api/v1/index.json 200
[0m12:57:47.779718 [debug] [MainThread]: Making package registry request: GET https://hub.getdbt.com/api/v1/Matts52/dbt_ml_inline_preprocessing.json
[0m12:57:48.189546 [debug] [MainThread]: Response from registry: GET https://hub.getdbt.com/api/v1/Matts52/dbt_ml_inline_preprocessing.json 200
[0m12:57:48.194956 [debug] [MainThread]: Making package registry request: GET https://hub.getdbt.com/api/v1/dbt-labs/dbt_utils.json
[0m12:57:48.306906 [debug] [MainThread]: Response from registry: GET https://hub.getdbt.com/api/v1/dbt-labs/dbt_utils.json 200
[0m12:57:48.345366 [info ] [MainThread]: Installing Matts52/dbt_ml_inline_preprocessing
[0m12:57:50.561766 [info ] [MainThread]: Installed from version 0.2.4
[0m12:57:50.565034 [info ] [MainThread]: Up to date!
[0m12:57:50.568188 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'package', 'label': '62a7b9b1-843a-40e3-8c90-eec8de267340', 'property_': 'install', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f7a921fbeb0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f7a912e2490>]}
[0m12:57:50.571517 [info ] [MainThread]: Installing dbt-labs/dbt_utils
[0m12:57:56.914454 [info ] [MainThread]: Installed from version 1.3.0
[0m12:57:56.916262 [info ] [MainThread]: Up to date!
[0m12:57:56.917939 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'package', 'label': '62a7b9b1-843a-40e3-8c90-eec8de267340', 'property_': 'install', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f7a921fbeb0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f7a9138a130>]}
[0m12:57:56.921081 [debug] [MainThread]: Resource report: {"command_name": "deps", "command_success": true, "command_wall_clock_time": 10.966026, "process_in_blocks": "192", "process_kernel_time": 0.886965, "process_mem_max_rss": "95272", "process_out_blocks": "1304", "process_user_time": 5.413545}
[0m12:57:56.923182 [debug] [MainThread]: Command `dbt deps` succeeded at 12:57:56.922958 after 10.97 seconds
[0m12:57:56.924792 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f7a92378a30>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f7a913d9040>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f7a937b8a90>]}
[0m12:57:56.926458 [debug] [MainThread]: Flushing usage events
[0m12:57:57.431942 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m12:58:31.623475 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7faf6a84ca90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7faf6996e4f0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7faf6996e490>]}


============================== 12:58:31.635769 | 017c0cdf-d3f8-41c4-bf85-16ebed4223b4 ==============================
[0m12:58:31.635769 [info ] [MainThread]: Running with dbt=1.9.4
[0m12:58:31.638331 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': '/opt/airflow/dags/dbt', 'debug': 'False', 'warn_error': 'None', 'log_path': '/opt/airflow/dags/dbt/homework/logs', 'fail_fast': 'False', 'version_check': 'True', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'empty': 'None', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'introspect': 'True', 'static_parser': 'True', 'invocation_command': 'dbt --profile homework deps --project-dir=/opt/airflow/dags/dbt/homework', 'target_path': 'None', 'log_format': 'default', 'send_anonymous_usage_stats': 'True'}
[0m12:58:32.050461 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '017c0cdf-d3f8-41c4-bf85-16ebed4223b4', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7faf69934c10>]}
[0m12:58:32.798083 [debug] [MainThread]: Set downloads directory='/tmp/dbt-downloads-msw676qt'
[0m12:58:32.799942 [debug] [MainThread]: Making package index registry request: GET https://hub.getdbt.com/api/v1/index.json
[0m12:58:32.914064 [debug] [MainThread]: Response from registry index: GET https://hub.getdbt.com/api/v1/index.json 200
[0m12:58:32.916595 [debug] [MainThread]: Making package registry request: GET https://hub.getdbt.com/api/v1/Matts52/dbt_ml_inline_preprocessing.json
[0m12:58:32.989198 [debug] [MainThread]: Response from registry: GET https://hub.getdbt.com/api/v1/Matts52/dbt_ml_inline_preprocessing.json 200
[0m12:58:32.993422 [debug] [MainThread]: Making package registry request: GET https://hub.getdbt.com/api/v1/dbt-labs/dbt_utils.json
[0m12:58:33.097036 [debug] [MainThread]: Response from registry: GET https://hub.getdbt.com/api/v1/dbt-labs/dbt_utils.json 200
[0m12:58:33.109945 [info ] [MainThread]: Installing Matts52/dbt_ml_inline_preprocessing
[0m12:58:38.077519 [info ] [MainThread]: Installed from version 0.2.4
[0m12:58:38.080428 [info ] [MainThread]: Up to date!
[0m12:58:38.083074 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'package', 'label': '017c0cdf-d3f8-41c4-bf85-16ebed4223b4', 'property_': 'install', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7faf6bc8c700>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7faf6a9fdbe0>]}
[0m12:58:38.085076 [info ] [MainThread]: Installing dbt-labs/dbt_utils
[0m12:58:44.373454 [info ] [MainThread]: Installed from version 1.3.0
[0m12:58:44.375508 [info ] [MainThread]: Up to date!
[0m12:58:44.377470 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'package', 'label': '017c0cdf-d3f8-41c4-bf85-16ebed4223b4', 'property_': 'install', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7faf6bc8c700>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7faf69886820>]}
[0m12:58:44.381051 [debug] [MainThread]: Resource report: {"command_name": "deps", "command_success": true, "command_wall_clock_time": 12.914455, "process_in_blocks": "0", "process_kernel_time": 0.981694, "process_mem_max_rss": "95288", "process_out_blocks": "1304", "process_user_time": 4.333339}
[0m12:58:44.383683 [debug] [MainThread]: Command `dbt deps` succeeded at 12:58:44.383305 after 12.92 seconds
[0m12:58:44.386517 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7faf6a84ca90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7faf6a679880>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7faf69934c10>]}
[0m12:58:44.388906 [debug] [MainThread]: Flushing usage events
[0m12:58:44.904258 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m12:58:52.512698 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f96d897fa30>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f96d7aa3580>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f96d7aa3520>]}


============================== 12:58:52.528532 | d0dfe252-70f1-4b94-949c-0dc62fc57822 ==============================
[0m12:58:52.528532 [info ] [MainThread]: Running with dbt=1.9.4
[0m12:58:52.531117 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'debug': 'False', 'fail_fast': 'False', 'log_path': '/opt/airflow/dags/dbt/homework/logs', 'version_check': 'True', 'profiles_dir': '/opt/airflow/dags/dbt', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'empty': 'False', 'log_format': 'default', 'static_parser': 'True', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'invocation_command': 'dbt --profile homework run --project-dir=/opt/airflow/dags/dbt/homework --vars {"is_test": false, "data_date": "2025-04-21"}', 'target_path': 'None', 'introspect': 'True', 'send_anonymous_usage_stats': 'True'}
[0m12:58:52.959013 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'd0dfe252-70f1-4b94-949c-0dc62fc57822', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f96d62c7d30>]}
[0m12:58:53.087733 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': 'd0dfe252-70f1-4b94-949c-0dc62fc57822', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f96d8161850>]}
[0m12:58:53.090587 [info ] [MainThread]: Registered adapter: postgres=1.9.0
[0m12:58:53.362143 [debug] [MainThread]: checksum: 201649f6d6f0df192625242c9dea035824a2db06971cd057d9b888cba7eba9d9, vars: {'data_date': '2025-04-21', 'is_test': False}, profile: homework, target: , version: 1.9.4
[0m12:58:53.683293 [info ] [MainThread]: Unable to do partial parsing because config vars, config profile, or config target have changed
[0m12:58:53.685336 [debug] [MainThread]: previous checksum: 201649f6d6f0df192625242c9dea035824a2db06971cd057d9b888cba7eba9d9, current checksum: 6e62424eea9ce3687be3ed3d7873e7c8fa2dd1d7b5a050b5310967d8959a2843
[0m12:58:53.687367 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'partial_parser', 'label': 'd0dfe252-70f1-4b94-949c-0dc62fc57822', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f96d81c2790>]}
[0m12:58:59.610142 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 1 unused configuration paths:
- seeds.homework.iris_dataset
[0m12:58:59.641062 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'd0dfe252-70f1-4b94-949c-0dc62fc57822', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f96d5dca130>]}
[0m12:58:59.915231 [debug] [MainThread]: Wrote artifact WritableManifest to /opt/airflow/dags/dbt/homework/target/manifest.json
[0m12:58:59.937909 [debug] [MainThread]: Wrote artifact SemanticManifest to /opt/airflow/dags/dbt/homework/target/semantic_manifest.json
[0m12:58:59.983276 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'd0dfe252-70f1-4b94-949c-0dc62fc57822', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f96d4b25520>]}
[0m12:58:59.985288 [info ] [MainThread]: Found 2 models, 1 source, 587 macros
[0m12:58:59.987153 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'd0dfe252-70f1-4b94-949c-0dc62fc57822', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f96d96d47f0>]}
[0m12:58:59.991600 [info ] [MainThread]: 
[0m12:58:59.993513 [info ] [MainThread]: Concurrency: 4 threads (target='dev')
[0m12:58:59.995269 [info ] [MainThread]: 
[0m12:58:59.998073 [debug] [MainThread]: Acquiring new postgres connection 'master'
[0m12:59:00.014072 [debug] [ThreadPool]: Acquiring new postgres connection 'list_analytics'
[0m12:59:00.126044 [debug] [ThreadPool]: Using postgres connection "list_analytics"
[0m12:59:00.127683 [debug] [ThreadPool]: On list_analytics: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "homework", "target_name": "dev", "connection_name": "list_analytics"} */

    select distinct nspname from pg_namespace
  
[0m12:59:00.129121 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m12:59:00.165508 [debug] [ThreadPool]: SQL status: SELECT 6 in 0.036 seconds
[0m12:59:00.169699 [debug] [ThreadPool]: On list_analytics: Close
[0m12:59:00.173965 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_analytics, now list_analytics_analytics)
[0m12:59:00.191384 [debug] [ThreadPool]: Using postgres connection "list_analytics_analytics"
[0m12:59:00.193300 [debug] [ThreadPool]: On list_analytics_analytics: BEGIN
[0m12:59:00.195134 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m12:59:00.207189 [debug] [ThreadPool]: SQL status: BEGIN in 0.012 seconds
[0m12:59:00.208885 [debug] [ThreadPool]: Using postgres connection "list_analytics_analytics"
[0m12:59:00.210683 [debug] [ThreadPool]: On list_analytics_analytics: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "homework", "target_name": "dev", "connection_name": "list_analytics_analytics"} */
select
      'analytics' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'analytics'
    union all
    select
      'analytics' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'analytics'
    union all
    select
      'analytics' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'analytics'
  
[0m12:59:00.229723 [debug] [ThreadPool]: SQL status: SELECT 1 in 0.017 seconds
[0m12:59:00.233718 [debug] [ThreadPool]: On list_analytics_analytics: ROLLBACK
[0m12:59:00.235731 [debug] [ThreadPool]: On list_analytics_analytics: Close
[0m12:59:00.250957 [debug] [MainThread]: Using postgres connection "master"
[0m12:59:00.253022 [debug] [MainThread]: On master: BEGIN
[0m12:59:00.254725 [debug] [MainThread]: Opening a new connection, currently in state init
[0m12:59:00.267663 [debug] [MainThread]: SQL status: BEGIN in 0.013 seconds
[0m12:59:00.269708 [debug] [MainThread]: Using postgres connection "master"
[0m12:59:00.271905 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "homework", "target_name": "dev", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select distinct
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v', 'm')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
[0m12:59:00.286353 [debug] [MainThread]: SQL status: SELECT 0 in 0.012 seconds
[0m12:59:00.289913 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'd0dfe252-70f1-4b94-949c-0dc62fc57822', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f96d5dcaa30>]}
[0m12:59:00.292132 [debug] [MainThread]: On master: ROLLBACK
[0m12:59:00.294300 [debug] [MainThread]: Using postgres connection "master"
[0m12:59:00.296226 [debug] [MainThread]: On master: BEGIN
[0m12:59:00.300035 [debug] [MainThread]: SQL status: BEGIN in 0.001 seconds
[0m12:59:00.301990 [debug] [MainThread]: On master: COMMIT
[0m12:59:00.304010 [debug] [MainThread]: Using postgres connection "master"
[0m12:59:00.305988 [debug] [MainThread]: On master: COMMIT
[0m12:59:00.308445 [debug] [MainThread]: SQL status: COMMIT in 0.000 seconds
[0m12:59:00.310635 [debug] [MainThread]: On master: Close
[0m12:59:00.322554 [debug] [Thread-1  ]: Began running node model.homework.stg_iris
[0m12:59:00.324825 [info ] [Thread-1  ]: 1 of 2 START sql view model analytics.stg_iris ................................. [RUN]
[0m12:59:00.326981 [debug] [Thread-1  ]: Re-using an available connection from the pool (formerly list_analytics_analytics, now model.homework.stg_iris)
[0m12:59:00.328901 [debug] [Thread-1  ]: Began compiling node model.homework.stg_iris
[0m12:59:00.366834 [debug] [Thread-1  ]: Writing injected SQL for node "model.homework.stg_iris"
[0m12:59:00.377627 [debug] [Thread-1  ]: Began executing node model.homework.stg_iris
[0m12:59:00.562164 [debug] [Thread-1  ]: Writing runtime sql for node "model.homework.stg_iris"
[0m12:59:00.576480 [debug] [Thread-1  ]: Using postgres connection "model.homework.stg_iris"
[0m12:59:00.579968 [debug] [Thread-1  ]: On model.homework.stg_iris: BEGIN
[0m12:59:00.583546 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
[0m12:59:00.612100 [debug] [Thread-1  ]: SQL status: BEGIN in 0.029 seconds
[0m12:59:00.615310 [debug] [Thread-1  ]: Using postgres connection "model.homework.stg_iris"
[0m12:59:00.618400 [debug] [Thread-1  ]: On model.homework.stg_iris: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "homework", "target_name": "dev", "node_id": "model.homework.stg_iris"} */

  create view "analytics"."analytics"."stg_iris__dbt_tmp"
    
    
  as (
    with source as (
    select * from "analytics"."analytics"."iris_dataset"
)

select
    cast(sepal_length as numeric) as sepal_length,
    cast(sepal_width as numeric) as sepal_width,
    cast(petal_length as numeric) as petal_length,
    cast(petal_width as numeric) as petal_width,
    species
from source
  );
[0m12:59:00.665048 [debug] [Thread-1  ]: SQL status: CREATE VIEW in 0.044 seconds
[0m12:59:00.684166 [debug] [Thread-1  ]: Using postgres connection "model.homework.stg_iris"
[0m12:59:00.686541 [debug] [Thread-1  ]: On model.homework.stg_iris: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "homework", "target_name": "dev", "node_id": "model.homework.stg_iris"} */
alter table "analytics"."analytics"."stg_iris__dbt_tmp" rename to "stg_iris"
[0m12:59:00.690142 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.001 seconds
[0m12:59:00.731452 [debug] [Thread-1  ]: On model.homework.stg_iris: COMMIT
[0m12:59:00.733964 [debug] [Thread-1  ]: Using postgres connection "model.homework.stg_iris"
[0m12:59:00.736263 [debug] [Thread-1  ]: On model.homework.stg_iris: COMMIT
[0m12:59:00.743014 [debug] [Thread-1  ]: SQL status: COMMIT in 0.004 seconds
[0m12:59:00.768087 [debug] [Thread-1  ]: Applying DROP to: "analytics"."analytics"."stg_iris__dbt_backup"
[0m12:59:00.780020 [debug] [Thread-1  ]: Using postgres connection "model.homework.stg_iris"
[0m12:59:00.782399 [debug] [Thread-1  ]: On model.homework.stg_iris: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "homework", "target_name": "dev", "node_id": "model.homework.stg_iris"} */
drop view if exists "analytics"."analytics"."stg_iris__dbt_backup" cascade
[0m12:59:00.785382 [debug] [Thread-1  ]: SQL status: DROP VIEW in 0.001 seconds
[0m12:59:00.791354 [debug] [Thread-1  ]: On model.homework.stg_iris: Close
[0m12:59:00.796680 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'd0dfe252-70f1-4b94-949c-0dc62fc57822', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f96da36cf40>]}
[0m12:59:00.800026 [info ] [Thread-1  ]: 1 of 2 OK created sql view model analytics.stg_iris ............................ [[32mCREATE VIEW[0m in 0.47s]
[0m12:59:00.802373 [debug] [Thread-1  ]: Finished running node model.homework.stg_iris
[0m12:59:00.805449 [debug] [Thread-3  ]: Began running node model.homework.iris_processed
[0m12:59:00.807906 [info ] [Thread-3  ]: 2 of 2 START sql table model analytics.iris_processed .......................... [RUN]
[0m12:59:00.810237 [debug] [Thread-3  ]: Acquiring new postgres connection 'model.homework.iris_processed'
[0m12:59:00.811878 [debug] [Thread-3  ]: Began compiling node model.homework.iris_processed
[0m12:59:00.858199 [debug] [Thread-3  ]: Using postgres connection "model.homework.iris_processed"
[0m12:59:00.860117 [debug] [Thread-3  ]: On model.homework.iris_processed: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "homework", "target_name": "dev", "node_id": "model.homework.iris_processed"} */

        select percentile_cont(0.5) within group (order by sepal_length ) from "analytics"."analytics"."stg_iris"
    
[0m12:59:00.861869 [debug] [Thread-3  ]: Opening a new connection, currently in state init
[0m12:59:00.883872 [debug] [Thread-3  ]: SQL status: SELECT 1 in 0.022 seconds
[0m12:59:00.887936 [debug] [Thread-3  ]: Using postgres connection "model.homework.iris_processed"
[0m12:59:00.889952 [debug] [Thread-3  ]: On model.homework.iris_processed: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "homework", "target_name": "dev", "node_id": "model.homework.iris_processed"} */

        select percentile_cont(0.5 - 0.5/2) within group (order by sepal_length ) from "analytics"."analytics"."stg_iris"
    
[0m12:59:00.894176 [debug] [Thread-3  ]: SQL status: SELECT 1 in 0.002 seconds
[0m12:59:00.899133 [debug] [Thread-3  ]: Using postgres connection "model.homework.iris_processed"
[0m12:59:00.901051 [debug] [Thread-3  ]: On model.homework.iris_processed: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "homework", "target_name": "dev", "node_id": "model.homework.iris_processed"} */

        select percentile_cont(0.5 + 0.5/2) within group (order by sepal_length ) from "analytics"."analytics"."stg_iris"
    
[0m12:59:00.904063 [debug] [Thread-3  ]: SQL status: SELECT 1 in 0.001 seconds
[0m12:59:00.909656 [debug] [Thread-3  ]: Using postgres connection "model.homework.iris_processed"
[0m12:59:00.911519 [debug] [Thread-3  ]: On model.homework.iris_processed: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "homework", "target_name": "dev", "node_id": "model.homework.iris_processed"} */

        select percentile_cont(0.5) within group (order by sepal_width ) from "analytics"."analytics"."stg_iris"
    
[0m12:59:00.914606 [debug] [Thread-3  ]: SQL status: SELECT 1 in 0.001 seconds
[0m12:59:00.919653 [debug] [Thread-3  ]: Using postgres connection "model.homework.iris_processed"
[0m12:59:00.921718 [debug] [Thread-3  ]: On model.homework.iris_processed: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "homework", "target_name": "dev", "node_id": "model.homework.iris_processed"} */

        select percentile_cont(0.5 - 0.5/2) within group (order by sepal_width ) from "analytics"."analytics"."stg_iris"
    
[0m12:59:00.924729 [debug] [Thread-3  ]: SQL status: SELECT 1 in 0.001 seconds
[0m12:59:00.929882 [debug] [Thread-3  ]: Using postgres connection "model.homework.iris_processed"
[0m12:59:00.932516 [debug] [Thread-3  ]: On model.homework.iris_processed: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "homework", "target_name": "dev", "node_id": "model.homework.iris_processed"} */

        select percentile_cont(0.5 + 0.5/2) within group (order by sepal_width ) from "analytics"."analytics"."stg_iris"
    
[0m12:59:00.935864 [debug] [Thread-3  ]: SQL status: SELECT 1 in 0.001 seconds
[0m12:59:00.945774 [debug] [Thread-3  ]: Using postgres connection "model.homework.iris_processed"
[0m12:59:00.948753 [debug] [Thread-3  ]: On model.homework.iris_processed: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "homework", "target_name": "dev", "node_id": "model.homework.iris_processed"} */

        select percentile_cont(0.5) within group (order by petal_length ) from "analytics"."analytics"."stg_iris"
    
[0m12:59:00.951949 [debug] [Thread-3  ]: SQL status: SELECT 1 in 0.001 seconds
[0m12:59:00.959495 [debug] [Thread-3  ]: Using postgres connection "model.homework.iris_processed"
[0m12:59:00.961879 [debug] [Thread-3  ]: On model.homework.iris_processed: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "homework", "target_name": "dev", "node_id": "model.homework.iris_processed"} */

        select percentile_cont(0.5 - 0.5/2) within group (order by petal_length ) from "analytics"."analytics"."stg_iris"
    
[0m12:59:00.965326 [debug] [Thread-3  ]: SQL status: SELECT 1 in 0.001 seconds
[0m12:59:00.972267 [debug] [Thread-3  ]: Using postgres connection "model.homework.iris_processed"
[0m12:59:00.975123 [debug] [Thread-3  ]: On model.homework.iris_processed: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "homework", "target_name": "dev", "node_id": "model.homework.iris_processed"} */

        select percentile_cont(0.5 + 0.5/2) within group (order by petal_length ) from "analytics"."analytics"."stg_iris"
    
[0m12:59:00.977931 [debug] [Thread-3  ]: SQL status: SELECT 1 in 0.001 seconds
[0m12:59:00.989768 [debug] [Thread-3  ]: Using postgres connection "model.homework.iris_processed"
[0m12:59:00.992215 [debug] [Thread-3  ]: On model.homework.iris_processed: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "homework", "target_name": "dev", "node_id": "model.homework.iris_processed"} */

        select percentile_cont(0.5) within group (order by petal_width ) from "analytics"."analytics"."stg_iris"
    
[0m12:59:00.995049 [debug] [Thread-3  ]: SQL status: SELECT 1 in 0.001 seconds
[0m12:59:01.000894 [debug] [Thread-3  ]: Using postgres connection "model.homework.iris_processed"
[0m12:59:01.003120 [debug] [Thread-3  ]: On model.homework.iris_processed: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "homework", "target_name": "dev", "node_id": "model.homework.iris_processed"} */

        select percentile_cont(0.5 - 0.5/2) within group (order by petal_width ) from "analytics"."analytics"."stg_iris"
    
[0m12:59:01.005585 [debug] [Thread-3  ]: SQL status: SELECT 1 in 0.001 seconds
[0m12:59:01.011058 [debug] [Thread-3  ]: Using postgres connection "model.homework.iris_processed"
[0m12:59:01.012963 [debug] [Thread-3  ]: On model.homework.iris_processed: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "homework", "target_name": "dev", "node_id": "model.homework.iris_processed"} */

        select percentile_cont(0.5 + 0.5/2) within group (order by petal_width ) from "analytics"."analytics"."stg_iris"
    
[0m12:59:01.015984 [debug] [Thread-3  ]: SQL status: SELECT 1 in 0.001 seconds
[0m12:59:01.025660 [debug] [Thread-3  ]: Using postgres connection "model.homework.iris_processed"
[0m12:59:01.027601 [debug] [Thread-3  ]: On model.homework.iris_processed: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "homework", "target_name": "dev", "node_id": "model.homework.iris_processed"} */

            select percentile_cont(0.5) within group (order by sepal_length ) from "analytics"."analytics"."stg_iris"
        
[0m12:59:01.030208 [debug] [Thread-3  ]: SQL status: SELECT 1 in 0.001 seconds
[0m12:59:01.035663 [debug] [Thread-3  ]: Using postgres connection "model.homework.iris_processed"
[0m12:59:01.037581 [debug] [Thread-3  ]: On model.homework.iris_processed: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "homework", "target_name": "dev", "node_id": "model.homework.iris_processed"} */

            select percentile_cont(0.5) within group (order by sepal_width ) from "analytics"."analytics"."stg_iris"
        
[0m12:59:01.040337 [debug] [Thread-3  ]: SQL status: SELECT 1 in 0.001 seconds
[0m12:59:01.045246 [debug] [Thread-3  ]: Using postgres connection "model.homework.iris_processed"
[0m12:59:01.047049 [debug] [Thread-3  ]: On model.homework.iris_processed: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "homework", "target_name": "dev", "node_id": "model.homework.iris_processed"} */

            select percentile_cont(0.5) within group (order by petal_length ) from "analytics"."analytics"."stg_iris"
        
[0m12:59:01.050120 [debug] [Thread-3  ]: SQL status: SELECT 1 in 0.001 seconds
[0m12:59:01.055404 [debug] [Thread-3  ]: Using postgres connection "model.homework.iris_processed"
[0m12:59:01.057298 [debug] [Thread-3  ]: On model.homework.iris_processed: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "homework", "target_name": "dev", "node_id": "model.homework.iris_processed"} */

            select percentile_cont(0.5) within group (order by petal_width ) from "analytics"."analytics"."stg_iris"
        
[0m12:59:01.059611 [debug] [Thread-3  ]: SQL status: SELECT 1 in 0.001 seconds
[0m12:59:01.083013 [debug] [Thread-3  ]: Using postgres connection "model.homework.iris_processed"
[0m12:59:01.085418 [debug] [Thread-3  ]: On model.homework.iris_processed: BEGIN
[0m12:59:01.088071 [debug] [Thread-3  ]: SQL status: BEGIN in 0.001 seconds
[0m12:59:01.090238 [debug] [Thread-3  ]: Using postgres connection "model.homework.iris_processed"
[0m12:59:01.092124 [debug] [Thread-3  ]: On model.homework.iris_processed: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "homework", "target_name": "dev", "node_id": "model.homework.iris_processed"} */
select
                species as value

            from "analytics"."analytics"."stg_iris"

            
            where species is not null  and true
            

            group by species
            order by species

            

        
[0m12:59:01.095509 [debug] [Thread-3  ]: SQL status: SELECT 3 in 0.001 seconds
[0m12:59:01.112124 [debug] [Thread-3  ]: Writing injected SQL for node "model.homework.iris_processed"
[0m12:59:01.124784 [debug] [Thread-3  ]: Began executing node model.homework.iris_processed
[0m12:59:01.187108 [debug] [Thread-3  ]: Writing runtime sql for node "model.homework.iris_processed"
[0m12:59:01.198887 [debug] [Thread-3  ]: Using postgres connection "model.homework.iris_processed"
[0m12:59:01.202107 [debug] [Thread-3  ]: On model.homework.iris_processed: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "homework", "target_name": "dev", "node_id": "model.homework.iris_processed"} */

  
    

  create  table "analytics"."analytics"."iris_processed__dbt_tmp"
  
  
    as
  
  (
    

with import_iris as (
    select *
    from "analytics"."analytics"."stg_iris"
)
select
    sepal_length,
    sepal_width,
    petal_length,
    petal_width,
    -- K Bins Discretization
    
        

    
        NTILE(5) over (order by sepal_length)
    

 as sepal_length_quantile_bin,
        

    
        
        floor(
        (
            sepal_length - (min(sepal_length) over ())
        )
        /
        (
            ((max(sepal_length) over ()) - (min(sepal_length) over ())) / 4::float
        )
        ) + 1
    

 as sepal_length_uniform_bin,
    
        

    
        NTILE(5) over (order by sepal_width)
    

 as sepal_width_quantile_bin,
        

    
        
        floor(
        (
            sepal_width - (min(sepal_width) over ())
        )
        /
        (
            ((max(sepal_width) over ()) - (min(sepal_width) over ())) / 4::float
        )
        ) + 1
    

 as sepal_width_uniform_bin,
    
        

    
        NTILE(5) over (order by petal_length)
    

 as petal_length_quantile_bin,
        

    
        
        floor(
        (
            petal_length - (min(petal_length) over ())
        )
        /
        (
            ((max(petal_length) over ()) - (min(petal_length) over ())) / 4::float
        )
        ) + 1
    

 as petal_length_uniform_bin,
    
        

    
        NTILE(5) over (order by petal_width)
    

 as petal_width_quantile_bin,
        

    
        
        floor(
        (
            petal_width - (min(petal_width) over ())
        )
        /
        (
            ((max(petal_width) over ()) - (min(petal_width) over ())) / 4::float
        )
        ) + 1
    

 as petal_width_uniform_bin,
    
-- Scaling
    
        

    

    
    
    

    
    
    

    (
        sepal_length - 5.8
    )
    /
    (
        6.4 - 5.1
    )

 as sepal_length_robust_scaled,
        

    (sepal_length) / (max(abs(sepal_length)) over ())::FLOAT

 as sepal_length_max_absolute_scaled,
        

    
    (
        ((sepal_length) - (min(sepal_length) over ()))
        /
        ((max(sepal_length) over ()) - (min(sepal_length) over ()))::FLOAT
    )
    *
    (1.0 - 0.0)
    +
    0.0

 as sepal_length_max_min_max_scaled,
    
        

    

    
    
    

    
    
    

    (
        sepal_width - 3.0
    )
    /
    (
        3.3 - 2.8
    )

 as sepal_width_robust_scaled,
        

    (sepal_width) / (max(abs(sepal_width)) over ())::FLOAT

 as sepal_width_max_absolute_scaled,
        

    
    (
        ((sepal_width) - (min(sepal_width) over ()))
        /
        ((max(sepal_width) over ()) - (min(sepal_width) over ()))::FLOAT
    )
    *
    (1.0 - 0.0)
    +
    0.0

 as sepal_width_max_min_max_scaled,
    
        

    

    
    
    

    
    
    

    (
        petal_length - 4.35
    )
    /
    (
        5.1 - 1.6
    )

 as petal_length_robust_scaled,
        

    (petal_length) / (max(abs(petal_length)) over ())::FLOAT

 as petal_length_max_absolute_scaled,
        

    
    (
        ((petal_length) - (min(petal_length) over ()))
        /
        ((max(petal_length) over ()) - (min(petal_length) over ()))::FLOAT
    )
    *
    (1.0 - 0.0)
    +
    0.0

 as petal_length_max_min_max_scaled,
    
        

    

    
    
    

    
    
    

    (
        petal_width - 1.3
    )
    /
    (
        1.8 - 0.3
    )

 as petal_width_robust_scaled,
        

    (petal_width) / (max(abs(petal_width)) over ())::FLOAT

 as petal_width_max_absolute_scaled,
        

    
    (
        ((petal_width) - (min(petal_width) over ()))
        /
        ((max(petal_width) over ()) - (min(petal_width) over ()))::FLOAT
    )
    *
    (1.0 - 0.0)
    +
    0.0

 as petal_width_max_min_max_scaled,
    

    -- Log Transformation
    
        

    case
        when sepal_length is null or sepal_length + 0 <= 0 then null
        else log(10, sepal_length + 0)
    end

 as sepal_length_logged,
    
        

    case
        when sepal_width is null or sepal_width + 0 <= 0 then null
        else log(10, sepal_width + 0)
    end

 as sepal_width_logged,
    
        

    case
        when petal_length is null or petal_length + 0 <= 0 then null
        else log(10, petal_length + 0)
    end

 as petal_length_logged,
    
        

    case
        when petal_width is null or petal_width + 0 <= 0 then null
        else log(10, petal_width + 0)
    end

 as petal_width_logged,
    

    -- Binarization
    
        

    

    
        

        
    

    case
        when sepal_length >=
            
                5.8
            
            then 1
        else 0
    end

 as sepal_length_binarized,
    
        

    

    
        

        
    

    case
        when sepal_width >=
            
                3.0
            
            then 1
        else 0
    end

 as sepal_width_binarized,
    
        

    

    
        

        
    

    case
        when petal_length >=
            
                4.35
            
            then 1
        else 0
    end

 as petal_length_binarized,
    
        

    

    
        

        
    

    case
        when petal_width >=
            
                1.3
            
            then 1
        else 0
    end

 as petal_width_binarized,
    

    -- Standardization
    
        

    
    (
        (sepal_length - avg(sepal_length) over ())
        /
        (stddev(sepal_length) over ())::FLOAT
    )
    *
    1
    +
    0

 as sepal_length_standardized,
    
        

    
    (
        (sepal_width - avg(sepal_width) over ())
        /
        (stddev(sepal_width) over ())::FLOAT
    )
    *
    1
    +
    0

 as sepal_width_standardized,
    
        

    
    (
        (petal_length - avg(petal_length) over ())
        /
        (stddev(petal_length) over ())::FLOAT
    )
    *
    1
    +
    0

 as petal_length_standardized,
    
        

    
    (
        (petal_width - avg(petal_width) over ())
        /
        (stddev(petal_width) over ())::FLOAT
    )
    *
    1
    +
    0

 as petal_width_standardized,
    
-- Interactions
    
        
            
            
            

    
        (sepal_length * sepal_width)
    

 as sepal_length_x_sepal_width_interaction,
            

    
        (sepal_length + sepal_width)
    

 as sepal_length_plus_sepal_width_interaction,
        
            
            
            

    
        (sepal_length * petal_length)
    

 as sepal_length_x_petal_length_interaction,
            

    
        (sepal_length + petal_length)
    

 as sepal_length_plus_petal_length_interaction,
        
            
            
            

    
        (sepal_length * petal_width)
    

 as sepal_length_x_petal_width_interaction,
            

    
        (sepal_length + petal_width)
    

 as sepal_length_plus_petal_width_interaction,
        
    
        
            
            
            

    
        (sepal_width * petal_length)
    

 as sepal_width_x_petal_length_interaction,
            

    
        (sepal_width + petal_length)
    

 as sepal_width_plus_petal_length_interaction,
        
            
            
            

    
        (sepal_width * petal_width)
    

 as sepal_width_x_petal_width_interaction,
            

    
        (sepal_width + petal_width)
    

 as sepal_width_plus_petal_width_interaction,
        
    
        
            
            
            

    
        (petal_length * petal_width)
    

 as petal_length_x_petal_width_interaction,
            

    
        (petal_length + petal_width)
    

 as petal_length_plus_petal_width_interaction,
        
    
        
    
species,    
    -- Label Encoding
    

    dense_rank() over (order by species) - 1

 as species_label_encoded,
    -- One Hot Encoding
    

    

    
        
    

    

    

        case
            when species = 'setosa' then 1
            else 0
        end as is_species__setosa,

    

        case
            when species = 'versicolor' then 1
            else 0
        end as is_species__versicolor,

    

        case
            when species = 'virginica' then 1
            else 0
        end as is_species__virginica,

    

    case
        when species is null then 1
        else 0
    end as is_species__


from "analytics"."analytics"."stg_iris"
  );
  
[0m12:59:01.262553 [debug] [Thread-3  ]: SQL status: SELECT 150 in 0.057 seconds
[0m12:59:01.282849 [debug] [Thread-3  ]: Using postgres connection "model.homework.iris_processed"
[0m12:59:01.284627 [debug] [Thread-3  ]: On model.homework.iris_processed: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "homework", "target_name": "dev", "node_id": "model.homework.iris_processed"} */
alter table "analytics"."analytics"."iris_processed__dbt_tmp" rename to "iris_processed"
[0m12:59:01.287341 [debug] [Thread-3  ]: SQL status: ALTER TABLE in 0.001 seconds
[0m12:59:01.291613 [debug] [Thread-3  ]: On model.homework.iris_processed: COMMIT
[0m12:59:01.293589 [debug] [Thread-3  ]: Using postgres connection "model.homework.iris_processed"
[0m12:59:01.295438 [debug] [Thread-3  ]: On model.homework.iris_processed: COMMIT
[0m12:59:01.301095 [debug] [Thread-3  ]: SQL status: COMMIT in 0.004 seconds
[0m12:59:01.308631 [debug] [Thread-3  ]: Applying DROP to: "analytics"."analytics"."iris_processed__dbt_backup"
[0m12:59:01.316339 [debug] [Thread-3  ]: Using postgres connection "model.homework.iris_processed"
[0m12:59:01.318457 [debug] [Thread-3  ]: On model.homework.iris_processed: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "homework", "target_name": "dev", "node_id": "model.homework.iris_processed"} */
drop table if exists "analytics"."analytics"."iris_processed__dbt_backup" cascade
[0m12:59:01.320711 [debug] [Thread-3  ]: SQL status: DROP TABLE in 0.000 seconds
[0m12:59:01.324866 [debug] [Thread-3  ]: On model.homework.iris_processed: Close
[0m12:59:01.327306 [debug] [Thread-3  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'd0dfe252-70f1-4b94-949c-0dc62fc57822', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f96da36cf40>]}
[0m12:59:01.329861 [info ] [Thread-3  ]: 2 of 2 OK created sql table model analytics.iris_processed ..................... [[32mSELECT 150[0m in 0.52s]
[0m12:59:01.333749 [debug] [Thread-3  ]: Finished running node model.homework.iris_processed
[0m12:59:01.338361 [debug] [MainThread]: Using postgres connection "master"
[0m12:59:01.340128 [debug] [MainThread]: On master: BEGIN
[0m12:59:01.341643 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m12:59:01.359805 [debug] [MainThread]: SQL status: BEGIN in 0.018 seconds
[0m12:59:01.361763 [debug] [MainThread]: On master: COMMIT
[0m12:59:01.363485 [debug] [MainThread]: Using postgres connection "master"
[0m12:59:01.365892 [debug] [MainThread]: On master: COMMIT
[0m12:59:01.368010 [debug] [MainThread]: SQL status: COMMIT in 0.000 seconds
[0m12:59:01.369612 [debug] [MainThread]: On master: Close
[0m12:59:01.371557 [debug] [MainThread]: Connection 'master' was properly closed.
[0m12:59:01.373584 [debug] [MainThread]: Connection 'model.homework.stg_iris' was properly closed.
[0m12:59:01.375174 [debug] [MainThread]: Connection 'model.homework.iris_processed' was properly closed.
[0m12:59:01.376912 [info ] [MainThread]: 
[0m12:59:01.378539 [info ] [MainThread]: Finished running 1 table model, 1 view model in 0 hours 0 minutes and 1.38 seconds (1.38s).
[0m12:59:01.381336 [debug] [MainThread]: Command end result
[0m12:59:01.495915 [debug] [MainThread]: Wrote artifact WritableManifest to /opt/airflow/dags/dbt/homework/target/manifest.json
[0m12:59:01.505594 [debug] [MainThread]: Wrote artifact SemanticManifest to /opt/airflow/dags/dbt/homework/target/semantic_manifest.json
[0m12:59:01.528420 [debug] [MainThread]: Wrote artifact RunExecutionResult to /opt/airflow/dags/dbt/homework/target/run_results.json
[0m12:59:01.530586 [info ] [MainThread]: 
[0m12:59:01.533713 [info ] [MainThread]: [32mCompleted successfully[0m
[0m12:59:01.535961 [info ] [MainThread]: 
[0m12:59:01.538130 [info ] [MainThread]: Done. PASS=2 WARN=0 ERROR=0 SKIP=0 TOTAL=2
[0m12:59:01.541109 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": true, "command_wall_clock_time": 9.207387, "process_in_blocks": "2736", "process_kernel_time": 0.457147, "process_mem_max_rss": "119632", "process_out_blocks": "0", "process_user_time": 10.792667}
[0m12:59:01.543593 [debug] [MainThread]: Command `dbt run` succeeded at 12:59:01.543235 after 9.21 seconds
[0m12:59:01.545737 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f96d897fa30>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f96d62c7d30>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f96d5db2ca0>]}
[0m12:59:01.547414 [debug] [MainThread]: Flushing usage events
[0m12:59:02.126624 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m12:59:03.221042 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f62f615ca30>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f62f527e580>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f62f527e520>]}


============================== 12:59:03.240690 | 1009e1fd-f7f7-4af1-9d86-e239061d8890 ==============================
[0m12:59:03.240690 [info ] [MainThread]: Running with dbt=1.9.4
[0m12:59:03.244302 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'debug': 'False', 'version_check': 'True', 'log_path': '/opt/airflow/dags/dbt/homework/logs', 'profiles_dir': '/opt/airflow/dags/dbt', 'fail_fast': 'False', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'empty': 'False', 'log_format': 'default', 'introspect': 'True', 'invocation_command': 'dbt --profile homework run --project-dir=/opt/airflow/dags/dbt/homework --vars {"is_test": false, "data_date": "2025-04-22"}', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'target_path': 'None', 'static_parser': 'True', 'send_anonymous_usage_stats': 'True'}
[0m12:59:03.888180 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '1009e1fd-f7f7-4af1-9d86-e239061d8890', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f62f399bd30>]}
[0m12:59:04.094780 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '1009e1fd-f7f7-4af1-9d86-e239061d8890', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f62f3a4ac10>]}
[0m12:59:04.097572 [info ] [MainThread]: Registered adapter: postgres=1.9.0
[0m12:59:04.482386 [debug] [MainThread]: checksum: b4b46bb6a239f66694dfdd44ef1792882cb61f2fd7b1ea66b3c7a170d2bb602d, vars: {'data_date': '2025-04-22', 'is_test': False}, profile: homework, target: , version: 1.9.4
[0m12:59:04.996461 [info ] [MainThread]: Unable to do partial parsing because config vars, config profile, or config target have changed
[0m12:59:04.998967 [debug] [MainThread]: previous checksum: b4b46bb6a239f66694dfdd44ef1792882cb61f2fd7b1ea66b3c7a170d2bb602d, current checksum: 201649f6d6f0df192625242c9dea035824a2db06971cd057d9b888cba7eba9d9
[0m12:59:05.001173 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'partial_parser', 'label': '1009e1fd-f7f7-4af1-9d86-e239061d8890', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f62f599e790>]}
[0m12:59:11.983851 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 1 unused configuration paths:
- seeds.homework.iris_dataset
[0m12:59:12.031526 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '1009e1fd-f7f7-4af1-9d86-e239061d8890', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f62f359b130>]}
[0m12:59:12.045264 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f4222966a00>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f4221a89700>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f4221a896a0>]}


============================== 12:59:12.070826 | d6fe2dd9-664e-447b-ab55-a7d422b6f40d ==============================
[0m12:59:12.070826 [info ] [MainThread]: Running with dbt=1.9.4
[0m12:59:12.073768 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'debug': 'False', 'fail_fast': 'True', 'log_path': '/opt/airflow/dags/dbt/homework/logs', 'profiles_dir': '/opt/airflow/dags/dbt', 'version_check': 'True', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'empty': 'None', 'log_format': 'default', 'invocation_command': 'dbt --profile homework test --project-dir=/opt/airflow/dags/dbt/homework --vars {"is_test": false, "data_date": "2025-04-21"} --fail-fast', 'static_parser': 'True', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'target_path': 'None', 'introspect': 'True', 'send_anonymous_usage_stats': 'True'}
[0m12:59:12.307947 [debug] [MainThread]: Wrote artifact WritableManifest to /opt/airflow/dags/dbt/homework/target/manifest.json
[0m12:59:12.326534 [debug] [MainThread]: Wrote artifact SemanticManifest to /opt/airflow/dags/dbt/homework/target/semantic_manifest.json
[0m12:59:12.366109 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '1009e1fd-f7f7-4af1-9d86-e239061d8890', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f62f6e342e0>]}
[0m12:59:12.367970 [info ] [MainThread]: Found 2 models, 1 source, 587 macros
[0m12:59:12.369773 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '1009e1fd-f7f7-4af1-9d86-e239061d8890', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f62f23109a0>]}
[0m12:59:12.373827 [info ] [MainThread]: 
[0m12:59:12.376260 [info ] [MainThread]: Concurrency: 4 threads (target='dev')
[0m12:59:12.378043 [info ] [MainThread]: 
[0m12:59:12.380083 [debug] [MainThread]: Acquiring new postgres connection 'master'
[0m12:59:12.390943 [debug] [ThreadPool]: Acquiring new postgres connection 'list_analytics'
[0m12:59:12.480934 [debug] [ThreadPool]: Using postgres connection "list_analytics"
[0m12:59:12.483039 [debug] [ThreadPool]: On list_analytics: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "homework", "target_name": "dev", "connection_name": "list_analytics"} */

    select distinct nspname from pg_namespace
  
[0m12:59:12.484823 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m12:59:12.525146 [debug] [ThreadPool]: SQL status: SELECT 6 in 0.040 seconds
[0m12:59:12.529812 [debug] [ThreadPool]: On list_analytics: Close
[0m12:59:12.534810 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_analytics, now list_analytics_analytics)
[0m12:59:12.553176 [debug] [ThreadPool]: Using postgres connection "list_analytics_analytics"
[0m12:59:12.554993 [debug] [ThreadPool]: On list_analytics_analytics: BEGIN
[0m12:59:12.556726 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m12:59:12.568877 [debug] [ThreadPool]: SQL status: BEGIN in 0.012 seconds
[0m12:59:12.570563 [debug] [ThreadPool]: Using postgres connection "list_analytics_analytics"
[0m12:59:12.572197 [debug] [ThreadPool]: On list_analytics_analytics: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "homework", "target_name": "dev", "connection_name": "list_analytics_analytics"} */
select
      'analytics' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'analytics'
    union all
    select
      'analytics' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'analytics'
    union all
    select
      'analytics' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'analytics'
  
[0m12:59:12.577626 [debug] [ThreadPool]: SQL status: SELECT 3 in 0.004 seconds
[0m12:59:12.580994 [debug] [ThreadPool]: On list_analytics_analytics: ROLLBACK
[0m12:59:12.581439 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'd6fe2dd9-664e-447b-ab55-a7d422b6f40d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f42242dd7c0>]}
[0m12:59:12.582776 [debug] [ThreadPool]: On list_analytics_analytics: Close
[0m12:59:12.596317 [debug] [MainThread]: Using postgres connection "master"
[0m12:59:12.597984 [debug] [MainThread]: On master: BEGIN
[0m12:59:12.599566 [debug] [MainThread]: Opening a new connection, currently in state init
[0m12:59:12.610991 [debug] [MainThread]: SQL status: BEGIN in 0.011 seconds
[0m12:59:12.612779 [debug] [MainThread]: Using postgres connection "master"
[0m12:59:12.614468 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "homework", "target_name": "dev", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select distinct
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v', 'm')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
[0m12:59:12.627278 [debug] [MainThread]: SQL status: SELECT 1 in 0.011 seconds
[0m12:59:12.630913 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '1009e1fd-f7f7-4af1-9d86-e239061d8890', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f62f3aa4bb0>]}
[0m12:59:12.632957 [debug] [MainThread]: On master: ROLLBACK
[0m12:59:12.634863 [debug] [MainThread]: Using postgres connection "master"
[0m12:59:12.636495 [debug] [MainThread]: On master: BEGIN
[0m12:59:12.638361 [debug] [MainThread]: SQL status: BEGIN in 0.000 seconds
[0m12:59:12.640092 [debug] [MainThread]: On master: COMMIT
[0m12:59:12.642133 [debug] [MainThread]: Using postgres connection "master"
[0m12:59:12.644134 [debug] [MainThread]: On master: COMMIT
[0m12:59:12.645859 [debug] [MainThread]: SQL status: COMMIT in 0.000 seconds
[0m12:59:12.647381 [debug] [MainThread]: On master: Close
[0m12:59:12.655744 [debug] [Thread-1  ]: Began running node model.homework.stg_iris
[0m12:59:12.658229 [info ] [Thread-1  ]: 1 of 2 START sql view model analytics.stg_iris ................................. [RUN]
[0m12:59:12.660644 [debug] [Thread-1  ]: Re-using an available connection from the pool (formerly list_analytics_analytics, now model.homework.stg_iris)
[0m12:59:12.662395 [debug] [Thread-1  ]: Began compiling node model.homework.stg_iris
[0m12:59:12.681444 [debug] [Thread-1  ]: Writing injected SQL for node "model.homework.stg_iris"
[0m12:59:12.692915 [debug] [Thread-1  ]: Began executing node model.homework.stg_iris
[0m12:59:12.741114 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': 'd6fe2dd9-664e-447b-ab55-a7d422b6f40d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f4220266eb0>]}
[0m12:59:12.746007 [info ] [MainThread]: Registered adapter: postgres=1.9.0
[0m12:59:12.813669 [debug] [Thread-1  ]: Writing runtime sql for node "model.homework.stg_iris"
[0m12:59:12.832373 [debug] [Thread-1  ]: Using postgres connection "model.homework.stg_iris"
[0m12:59:12.835598 [debug] [Thread-1  ]: On model.homework.stg_iris: BEGIN
[0m12:59:12.838216 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
[0m12:59:12.857040 [debug] [Thread-1  ]: SQL status: BEGIN in 0.019 seconds
[0m12:59:12.860359 [debug] [Thread-1  ]: Using postgres connection "model.homework.stg_iris"
[0m12:59:12.862971 [debug] [Thread-1  ]: On model.homework.stg_iris: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "homework", "target_name": "dev", "node_id": "model.homework.stg_iris"} */

  create view "analytics"."analytics"."stg_iris__dbt_tmp"
    
    
  as (
    with source as (
    select * from "analytics"."analytics"."iris_dataset"
)

select
    cast(sepal_length as numeric) as sepal_length,
    cast(sepal_width as numeric) as sepal_width,
    cast(petal_length as numeric) as petal_length,
    cast(petal_width as numeric) as petal_width,
    species
from source
  );
[0m12:59:12.870269 [debug] [Thread-1  ]: SQL status: CREATE VIEW in 0.004 seconds
[0m12:59:12.905352 [debug] [Thread-1  ]: Using postgres connection "model.homework.stg_iris"
[0m12:59:12.909740 [debug] [Thread-1  ]: On model.homework.stg_iris: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "homework", "target_name": "dev", "node_id": "model.homework.stg_iris"} */
alter table "analytics"."analytics"."stg_iris" rename to "stg_iris__dbt_backup"
[0m12:59:12.914099 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.001 seconds
[0m12:59:12.929625 [debug] [Thread-1  ]: Using postgres connection "model.homework.stg_iris"
[0m12:59:12.933647 [debug] [Thread-1  ]: On model.homework.stg_iris: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "homework", "target_name": "dev", "node_id": "model.homework.stg_iris"} */
alter table "analytics"."analytics"."stg_iris__dbt_tmp" rename to "stg_iris"
[0m12:59:12.937812 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.001 seconds
[0m12:59:13.020320 [debug] [Thread-1  ]: On model.homework.stg_iris: COMMIT
[0m12:59:13.023621 [debug] [Thread-1  ]: Using postgres connection "model.homework.stg_iris"
[0m12:59:13.029087 [debug] [Thread-1  ]: On model.homework.stg_iris: COMMIT
[0m12:59:13.039046 [debug] [Thread-1  ]: SQL status: COMMIT in 0.005 seconds
[0m12:59:13.064191 [debug] [Thread-1  ]: Applying DROP to: "analytics"."analytics"."stg_iris__dbt_backup"
[0m12:59:13.080677 [debug] [Thread-1  ]: Using postgres connection "model.homework.stg_iris"
[0m12:59:13.083274 [debug] [Thread-1  ]: On model.homework.stg_iris: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "homework", "target_name": "dev", "node_id": "model.homework.stg_iris"} */
drop view if exists "analytics"."analytics"."stg_iris__dbt_backup" cascade
[0m12:59:13.093421 [debug] [Thread-1  ]: SQL status: DROP VIEW in 0.008 seconds
[0m12:59:13.101405 [debug] [Thread-1  ]: On model.homework.stg_iris: Close
[0m12:59:13.109333 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '1009e1fd-f7f7-4af1-9d86-e239061d8890', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f62f17fd820>]}
[0m12:59:13.112833 [info ] [Thread-1  ]: 1 of 2 OK created sql view model analytics.stg_iris ............................ [[32mCREATE VIEW[0m in 0.44s]
[0m12:59:13.115690 [debug] [Thread-1  ]: Finished running node model.homework.stg_iris
[0m12:59:13.119337 [debug] [Thread-3  ]: Began running node model.homework.iris_processed
[0m12:59:13.121967 [info ] [Thread-3  ]: 2 of 2 START sql table model analytics.iris_processed .......................... [RUN]
[0m12:59:13.124918 [debug] [Thread-3  ]: Acquiring new postgres connection 'model.homework.iris_processed'
[0m12:59:13.128119 [debug] [Thread-3  ]: Began compiling node model.homework.iris_processed
[0m12:59:13.158269 [debug] [MainThread]: checksum: 201649f6d6f0df192625242c9dea035824a2db06971cd057d9b888cba7eba9d9, vars: {'data_date': '2025-04-21', 'is_test': False}, profile: homework, target: , version: 1.9.4
[0m12:59:13.178413 [debug] [Thread-3  ]: Using postgres connection "model.homework.iris_processed"
[0m12:59:13.180574 [debug] [Thread-3  ]: On model.homework.iris_processed: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "homework", "target_name": "dev", "node_id": "model.homework.iris_processed"} */

        select percentile_cont(0.5) within group (order by sepal_length ) from "analytics"."analytics"."stg_iris"
    
[0m12:59:13.182965 [debug] [Thread-3  ]: Opening a new connection, currently in state init
[0m12:59:13.196859 [debug] [Thread-3  ]: SQL status: SELECT 1 in 0.014 seconds
[0m12:59:13.201470 [debug] [Thread-3  ]: Using postgres connection "model.homework.iris_processed"
[0m12:59:13.203662 [debug] [Thread-3  ]: On model.homework.iris_processed: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "homework", "target_name": "dev", "node_id": "model.homework.iris_processed"} */

        select percentile_cont(0.5 - 0.5/2) within group (order by sepal_length ) from "analytics"."analytics"."stg_iris"
    
[0m12:59:13.206401 [debug] [Thread-3  ]: SQL status: SELECT 1 in 0.001 seconds
[0m12:59:13.211120 [debug] [Thread-3  ]: Using postgres connection "model.homework.iris_processed"
[0m12:59:13.213143 [debug] [Thread-3  ]: On model.homework.iris_processed: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "homework", "target_name": "dev", "node_id": "model.homework.iris_processed"} */

        select percentile_cont(0.5 + 0.5/2) within group (order by sepal_length ) from "analytics"."analytics"."stg_iris"
    
[0m12:59:13.215743 [debug] [Thread-3  ]: SQL status: SELECT 1 in 0.001 seconds
[0m12:59:13.223317 [debug] [Thread-3  ]: Using postgres connection "model.homework.iris_processed"
[0m12:59:13.225417 [debug] [Thread-3  ]: On model.homework.iris_processed: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "homework", "target_name": "dev", "node_id": "model.homework.iris_processed"} */

        select percentile_cont(0.5) within group (order by sepal_width ) from "analytics"."analytics"."stg_iris"
    
[0m12:59:13.229148 [debug] [Thread-3  ]: SQL status: SELECT 1 in 0.001 seconds
[0m12:59:13.233435 [debug] [Thread-3  ]: Using postgres connection "model.homework.iris_processed"
[0m12:59:13.235308 [debug] [Thread-3  ]: On model.homework.iris_processed: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "homework", "target_name": "dev", "node_id": "model.homework.iris_processed"} */

        select percentile_cont(0.5 - 0.5/2) within group (order by sepal_width ) from "analytics"."analytics"."stg_iris"
    
[0m12:59:13.238193 [debug] [Thread-3  ]: SQL status: SELECT 1 in 0.001 seconds
[0m12:59:13.244308 [debug] [Thread-3  ]: Using postgres connection "model.homework.iris_processed"
[0m12:59:13.246705 [debug] [Thread-3  ]: On model.homework.iris_processed: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "homework", "target_name": "dev", "node_id": "model.homework.iris_processed"} */

        select percentile_cont(0.5 + 0.5/2) within group (order by sepal_width ) from "analytics"."analytics"."stg_iris"
    
[0m12:59:13.249772 [debug] [Thread-3  ]: SQL status: SELECT 1 in 0.001 seconds
[0m12:59:13.258002 [debug] [Thread-3  ]: Using postgres connection "model.homework.iris_processed"
[0m12:59:13.260521 [debug] [Thread-3  ]: On model.homework.iris_processed: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "homework", "target_name": "dev", "node_id": "model.homework.iris_processed"} */

        select percentile_cont(0.5) within group (order by petal_length ) from "analytics"."analytics"."stg_iris"
    
[0m12:59:13.263797 [debug] [Thread-3  ]: SQL status: SELECT 1 in 0.001 seconds
[0m12:59:13.269386 [debug] [Thread-3  ]: Using postgres connection "model.homework.iris_processed"
[0m12:59:13.272032 [debug] [Thread-3  ]: On model.homework.iris_processed: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "homework", "target_name": "dev", "node_id": "model.homework.iris_processed"} */

        select percentile_cont(0.5 - 0.5/2) within group (order by petal_length ) from "analytics"."analytics"."stg_iris"
    
[0m12:59:13.275730 [debug] [Thread-3  ]: SQL status: SELECT 1 in 0.001 seconds
[0m12:59:13.281080 [debug] [Thread-3  ]: Using postgres connection "model.homework.iris_processed"
[0m12:59:13.283253 [debug] [Thread-3  ]: On model.homework.iris_processed: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "homework", "target_name": "dev", "node_id": "model.homework.iris_processed"} */

        select percentile_cont(0.5 + 0.5/2) within group (order by petal_length ) from "analytics"."analytics"."stg_iris"
    
[0m12:59:13.286695 [debug] [Thread-3  ]: SQL status: SELECT 1 in 0.001 seconds
[0m12:59:13.296888 [debug] [Thread-3  ]: Using postgres connection "model.homework.iris_processed"
[0m12:59:13.299334 [debug] [Thread-3  ]: On model.homework.iris_processed: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "homework", "target_name": "dev", "node_id": "model.homework.iris_processed"} */

        select percentile_cont(0.5) within group (order by petal_width ) from "analytics"."analytics"."stg_iris"
    
[0m12:59:13.302162 [debug] [Thread-3  ]: SQL status: SELECT 1 in 0.001 seconds
[0m12:59:13.306524 [debug] [Thread-3  ]: Using postgres connection "model.homework.iris_processed"
[0m12:59:13.308606 [debug] [Thread-3  ]: On model.homework.iris_processed: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "homework", "target_name": "dev", "node_id": "model.homework.iris_processed"} */

        select percentile_cont(0.5 - 0.5/2) within group (order by petal_width ) from "analytics"."analytics"."stg_iris"
    
[0m12:59:13.312481 [debug] [Thread-3  ]: SQL status: SELECT 1 in 0.001 seconds
[0m12:59:13.317639 [debug] [Thread-3  ]: Using postgres connection "model.homework.iris_processed"
[0m12:59:13.319762 [debug] [Thread-3  ]: On model.homework.iris_processed: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "homework", "target_name": "dev", "node_id": "model.homework.iris_processed"} */

        select percentile_cont(0.5 + 0.5/2) within group (order by petal_width ) from "analytics"."analytics"."stg_iris"
    
[0m12:59:13.322858 [debug] [Thread-3  ]: SQL status: SELECT 1 in 0.001 seconds
[0m12:59:13.334219 [debug] [Thread-3  ]: Using postgres connection "model.homework.iris_processed"
[0m12:59:13.336551 [debug] [Thread-3  ]: On model.homework.iris_processed: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "homework", "target_name": "dev", "node_id": "model.homework.iris_processed"} */

            select percentile_cont(0.5) within group (order by sepal_length ) from "analytics"."analytics"."stg_iris"
        
[0m12:59:13.339237 [debug] [Thread-3  ]: SQL status: SELECT 1 in 0.001 seconds
[0m12:59:13.346404 [debug] [Thread-3  ]: Using postgres connection "model.homework.iris_processed"
[0m12:59:13.348503 [debug] [Thread-3  ]: On model.homework.iris_processed: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "homework", "target_name": "dev", "node_id": "model.homework.iris_processed"} */

            select percentile_cont(0.5) within group (order by sepal_width ) from "analytics"."analytics"."stg_iris"
        
[0m12:59:13.351145 [debug] [Thread-3  ]: SQL status: SELECT 1 in 0.001 seconds
[0m12:59:13.356149 [debug] [Thread-3  ]: Using postgres connection "model.homework.iris_processed"
[0m12:59:13.357987 [debug] [Thread-3  ]: On model.homework.iris_processed: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "homework", "target_name": "dev", "node_id": "model.homework.iris_processed"} */

            select percentile_cont(0.5) within group (order by petal_length ) from "analytics"."analytics"."stg_iris"
        
[0m12:59:13.361243 [debug] [Thread-3  ]: SQL status: SELECT 1 in 0.001 seconds
[0m12:59:13.366832 [debug] [Thread-3  ]: Using postgres connection "model.homework.iris_processed"
[0m12:59:13.368727 [debug] [Thread-3  ]: On model.homework.iris_processed: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "homework", "target_name": "dev", "node_id": "model.homework.iris_processed"} */

            select percentile_cont(0.5) within group (order by petal_width ) from "analytics"."analytics"."stg_iris"
        
[0m12:59:13.371273 [debug] [Thread-3  ]: SQL status: SELECT 1 in 0.001 seconds
[0m12:59:13.400419 [debug] [Thread-3  ]: Using postgres connection "model.homework.iris_processed"
[0m12:59:13.402223 [debug] [Thread-3  ]: On model.homework.iris_processed: BEGIN
[0m12:59:13.404286 [debug] [Thread-3  ]: SQL status: BEGIN in 0.000 seconds
[0m12:59:13.406111 [debug] [Thread-3  ]: Using postgres connection "model.homework.iris_processed"
[0m12:59:13.408008 [debug] [Thread-3  ]: On model.homework.iris_processed: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "homework", "target_name": "dev", "node_id": "model.homework.iris_processed"} */
select
                species as value

            from "analytics"."analytics"."stg_iris"

            
            where species is not null  and true
            

            group by species
            order by species

            

        
[0m12:59:13.411671 [debug] [Thread-3  ]: SQL status: SELECT 3 in 0.001 seconds
[0m12:59:13.425182 [debug] [Thread-3  ]: Writing injected SQL for node "model.homework.iris_processed"
[0m12:59:13.445499 [debug] [Thread-3  ]: Began executing node model.homework.iris_processed
[0m12:59:13.510201 [info ] [MainThread]: Unable to do partial parsing because config vars, config profile, or config target have changed
[0m12:59:13.512271 [debug] [MainThread]: previous checksum: 201649f6d6f0df192625242c9dea035824a2db06971cd057d9b888cba7eba9d9, current checksum: b4b46bb6a239f66694dfdd44ef1792882cb61f2fd7b1ea66b3c7a170d2bb602d
[0m12:59:13.514129 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'partial_parser', 'label': 'd6fe2dd9-664e-447b-ab55-a7d422b6f40d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f42221a8790>]}
[0m12:59:13.518442 [debug] [Thread-3  ]: Writing runtime sql for node "model.homework.iris_processed"
[0m12:59:13.529875 [debug] [Thread-3  ]: Using postgres connection "model.homework.iris_processed"
[0m12:59:13.533145 [debug] [Thread-3  ]: On model.homework.iris_processed: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "homework", "target_name": "dev", "node_id": "model.homework.iris_processed"} */

  
    

  create  table "analytics"."analytics"."iris_processed__dbt_tmp"
  
  
    as
  
  (
    

with import_iris as (
    select *
    from "analytics"."analytics"."stg_iris"
)
select
    sepal_length,
    sepal_width,
    petal_length,
    petal_width,
    -- K Bins Discretization
    
        

    
        NTILE(5) over (order by sepal_length)
    

 as sepal_length_quantile_bin,
        

    
        
        floor(
        (
            sepal_length - (min(sepal_length) over ())
        )
        /
        (
            ((max(sepal_length) over ()) - (min(sepal_length) over ())) / 4::float
        )
        ) + 1
    

 as sepal_length_uniform_bin,
    
        

    
        NTILE(5) over (order by sepal_width)
    

 as sepal_width_quantile_bin,
        

    
        
        floor(
        (
            sepal_width - (min(sepal_width) over ())
        )
        /
        (
            ((max(sepal_width) over ()) - (min(sepal_width) over ())) / 4::float
        )
        ) + 1
    

 as sepal_width_uniform_bin,
    
        

    
        NTILE(5) over (order by petal_length)
    

 as petal_length_quantile_bin,
        

    
        
        floor(
        (
            petal_length - (min(petal_length) over ())
        )
        /
        (
            ((max(petal_length) over ()) - (min(petal_length) over ())) / 4::float
        )
        ) + 1
    

 as petal_length_uniform_bin,
    
        

    
        NTILE(5) over (order by petal_width)
    

 as petal_width_quantile_bin,
        

    
        
        floor(
        (
            petal_width - (min(petal_width) over ())
        )
        /
        (
            ((max(petal_width) over ()) - (min(petal_width) over ())) / 4::float
        )
        ) + 1
    

 as petal_width_uniform_bin,
    
-- Scaling
    
        

    

    
    
    

    
    
    

    (
        sepal_length - 5.8
    )
    /
    (
        6.4 - 5.1
    )

 as sepal_length_robust_scaled,
        

    (sepal_length) / (max(abs(sepal_length)) over ())::FLOAT

 as sepal_length_max_absolute_scaled,
        

    
    (
        ((sepal_length) - (min(sepal_length) over ()))
        /
        ((max(sepal_length) over ()) - (min(sepal_length) over ()))::FLOAT
    )
    *
    (1.0 - 0.0)
    +
    0.0

 as sepal_length_max_min_max_scaled,
    
        

    

    
    
    

    
    
    

    (
        sepal_width - 3.0
    )
    /
    (
        3.3 - 2.8
    )

 as sepal_width_robust_scaled,
        

    (sepal_width) / (max(abs(sepal_width)) over ())::FLOAT

 as sepal_width_max_absolute_scaled,
        

    
    (
        ((sepal_width) - (min(sepal_width) over ()))
        /
        ((max(sepal_width) over ()) - (min(sepal_width) over ()))::FLOAT
    )
    *
    (1.0 - 0.0)
    +
    0.0

 as sepal_width_max_min_max_scaled,
    
        

    

    
    
    

    
    
    

    (
        petal_length - 4.35
    )
    /
    (
        5.1 - 1.6
    )

 as petal_length_robust_scaled,
        

    (petal_length) / (max(abs(petal_length)) over ())::FLOAT

 as petal_length_max_absolute_scaled,
        

    
    (
        ((petal_length) - (min(petal_length) over ()))
        /
        ((max(petal_length) over ()) - (min(petal_length) over ()))::FLOAT
    )
    *
    (1.0 - 0.0)
    +
    0.0

 as petal_length_max_min_max_scaled,
    
        

    

    
    
    

    
    
    

    (
        petal_width - 1.3
    )
    /
    (
        1.8 - 0.3
    )

 as petal_width_robust_scaled,
        

    (petal_width) / (max(abs(petal_width)) over ())::FLOAT

 as petal_width_max_absolute_scaled,
        

    
    (
        ((petal_width) - (min(petal_width) over ()))
        /
        ((max(petal_width) over ()) - (min(petal_width) over ()))::FLOAT
    )
    *
    (1.0 - 0.0)
    +
    0.0

 as petal_width_max_min_max_scaled,
    

    -- Log Transformation
    
        

    case
        when sepal_length is null or sepal_length + 0 <= 0 then null
        else log(10, sepal_length + 0)
    end

 as sepal_length_logged,
    
        

    case
        when sepal_width is null or sepal_width + 0 <= 0 then null
        else log(10, sepal_width + 0)
    end

 as sepal_width_logged,
    
        

    case
        when petal_length is null or petal_length + 0 <= 0 then null
        else log(10, petal_length + 0)
    end

 as petal_length_logged,
    
        

    case
        when petal_width is null or petal_width + 0 <= 0 then null
        else log(10, petal_width + 0)
    end

 as petal_width_logged,
    

    -- Binarization
    
        

    

    
        

        
    

    case
        when sepal_length >=
            
                5.8
            
            then 1
        else 0
    end

 as sepal_length_binarized,
    
        

    

    
        

        
    

    case
        when sepal_width >=
            
                3.0
            
            then 1
        else 0
    end

 as sepal_width_binarized,
    
        

    

    
        

        
    

    case
        when petal_length >=
            
                4.35
            
            then 1
        else 0
    end

 as petal_length_binarized,
    
        

    

    
        

        
    

    case
        when petal_width >=
            
                1.3
            
            then 1
        else 0
    end

 as petal_width_binarized,
    

    -- Standardization
    
        

    
    (
        (sepal_length - avg(sepal_length) over ())
        /
        (stddev(sepal_length) over ())::FLOAT
    )
    *
    1
    +
    0

 as sepal_length_standardized,
    
        

    
    (
        (sepal_width - avg(sepal_width) over ())
        /
        (stddev(sepal_width) over ())::FLOAT
    )
    *
    1
    +
    0

 as sepal_width_standardized,
    
        

    
    (
        (petal_length - avg(petal_length) over ())
        /
        (stddev(petal_length) over ())::FLOAT
    )
    *
    1
    +
    0

 as petal_length_standardized,
    
        

    
    (
        (petal_width - avg(petal_width) over ())
        /
        (stddev(petal_width) over ())::FLOAT
    )
    *
    1
    +
    0

 as petal_width_standardized,
    
-- Interactions
    
        
            
            
            

    
        (sepal_length * sepal_width)
    

 as sepal_length_x_sepal_width_interaction,
            

    
        (sepal_length + sepal_width)
    

 as sepal_length_plus_sepal_width_interaction,
        
            
            
            

    
        (sepal_length * petal_length)
    

 as sepal_length_x_petal_length_interaction,
            

    
        (sepal_length + petal_length)
    

 as sepal_length_plus_petal_length_interaction,
        
            
            
            

    
        (sepal_length * petal_width)
    

 as sepal_length_x_petal_width_interaction,
            

    
        (sepal_length + petal_width)
    

 as sepal_length_plus_petal_width_interaction,
        
    
        
            
            
            

    
        (sepal_width * petal_length)
    

 as sepal_width_x_petal_length_interaction,
            

    
        (sepal_width + petal_length)
    

 as sepal_width_plus_petal_length_interaction,
        
            
            
            

    
        (sepal_width * petal_width)
    

 as sepal_width_x_petal_width_interaction,
            

    
        (sepal_width + petal_width)
    

 as sepal_width_plus_petal_width_interaction,
        
    
        
            
            
            

    
        (petal_length * petal_width)
    

 as petal_length_x_petal_width_interaction,
            

    
        (petal_length + petal_width)
    

 as petal_length_plus_petal_width_interaction,
        
    
        
    
species,    
    -- Label Encoding
    

    dense_rank() over (order by species) - 1

 as species_label_encoded,
    -- One Hot Encoding
    

    

    
        
    

    

    

        case
            when species = 'setosa' then 1
            else 0
        end as is_species__setosa,

    

        case
            when species = 'versicolor' then 1
            else 0
        end as is_species__versicolor,

    

        case
            when species = 'virginica' then 1
            else 0
        end as is_species__virginica,

    

    case
        when species is null then 1
        else 0
    end as is_species__


from "analytics"."analytics"."stg_iris"
  );
  
[0m12:59:13.571605 [debug] [Thread-3  ]: SQL status: SELECT 150 in 0.035 seconds
[0m12:59:13.588509 [debug] [Thread-3  ]: Using postgres connection "model.homework.iris_processed"
[0m12:59:13.590244 [debug] [Thread-3  ]: On model.homework.iris_processed: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "homework", "target_name": "dev", "node_id": "model.homework.iris_processed"} */
alter table "analytics"."analytics"."iris_processed" rename to "iris_processed__dbt_backup"
[0m12:59:13.592951 [debug] [Thread-3  ]: SQL status: ALTER TABLE in 0.001 seconds
[0m12:59:13.602951 [debug] [Thread-3  ]: Using postgres connection "model.homework.iris_processed"
[0m12:59:13.604940 [debug] [Thread-3  ]: On model.homework.iris_processed: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "homework", "target_name": "dev", "node_id": "model.homework.iris_processed"} */
alter table "analytics"."analytics"."iris_processed__dbt_tmp" rename to "iris_processed"
[0m12:59:13.607528 [debug] [Thread-3  ]: SQL status: ALTER TABLE in 0.001 seconds
[0m12:59:13.613211 [debug] [Thread-3  ]: On model.homework.iris_processed: COMMIT
[0m12:59:13.615092 [debug] [Thread-3  ]: Using postgres connection "model.homework.iris_processed"
[0m12:59:13.616809 [debug] [Thread-3  ]: On model.homework.iris_processed: COMMIT
[0m12:59:13.621969 [debug] [Thread-3  ]: SQL status: COMMIT in 0.003 seconds
[0m12:59:13.630877 [debug] [Thread-3  ]: Applying DROP to: "analytics"."analytics"."iris_processed__dbt_backup"
[0m12:59:13.637625 [debug] [Thread-3  ]: Using postgres connection "model.homework.iris_processed"
[0m12:59:13.639452 [debug] [Thread-3  ]: On model.homework.iris_processed: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "homework", "target_name": "dev", "node_id": "model.homework.iris_processed"} */
drop table if exists "analytics"."analytics"."iris_processed__dbt_backup" cascade
[0m12:59:13.647574 [debug] [Thread-3  ]: SQL status: DROP TABLE in 0.006 seconds
[0m12:59:13.651153 [debug] [Thread-3  ]: On model.homework.iris_processed: Close
[0m12:59:13.653287 [debug] [Thread-3  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '1009e1fd-f7f7-4af1-9d86-e239061d8890', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f62f05e4c40>]}
[0m12:59:13.655663 [info ] [Thread-3  ]: 2 of 2 OK created sql table model analytics.iris_processed ..................... [[32mSELECT 150[0m in 0.53s]
[0m12:59:13.658074 [debug] [Thread-3  ]: Finished running node model.homework.iris_processed
[0m12:59:13.662263 [debug] [MainThread]: Using postgres connection "master"
[0m12:59:13.663951 [debug] [MainThread]: On master: BEGIN
[0m12:59:13.665477 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m12:59:13.677101 [debug] [MainThread]: SQL status: BEGIN in 0.011 seconds
[0m12:59:13.678980 [debug] [MainThread]: On master: COMMIT
[0m12:59:13.680707 [debug] [MainThread]: Using postgres connection "master"
[0m12:59:13.682138 [debug] [MainThread]: On master: COMMIT
[0m12:59:13.683966 [debug] [MainThread]: SQL status: COMMIT in 0.000 seconds
[0m12:59:13.685585 [debug] [MainThread]: On master: Close
[0m12:59:13.687437 [debug] [MainThread]: Connection 'master' was properly closed.
[0m12:59:13.689010 [debug] [MainThread]: Connection 'model.homework.stg_iris' was properly closed.
[0m12:59:13.690622 [debug] [MainThread]: Connection 'model.homework.iris_processed' was properly closed.
[0m12:59:13.692210 [info ] [MainThread]: 
[0m12:59:13.694455 [info ] [MainThread]: Finished running 1 table model, 1 view model in 0 hours 0 minutes and 1.31 seconds (1.31s).
[0m12:59:13.697069 [debug] [MainThread]: Command end result
[0m12:59:13.801931 [debug] [MainThread]: Wrote artifact WritableManifest to /opt/airflow/dags/dbt/homework/target/manifest.json
[0m12:59:13.813292 [debug] [MainThread]: Wrote artifact SemanticManifest to /opt/airflow/dags/dbt/homework/target/semantic_manifest.json
[0m12:59:13.834066 [debug] [MainThread]: Wrote artifact RunExecutionResult to /opt/airflow/dags/dbt/homework/target/run_results.json
[0m12:59:13.835861 [info ] [MainThread]: 
[0m12:59:13.837640 [info ] [MainThread]: [32mCompleted successfully[0m
[0m12:59:13.839460 [info ] [MainThread]: 
[0m12:59:13.841148 [info ] [MainThread]: Done. PASS=2 WARN=0 ERROR=0 SKIP=0 TOTAL=2
[0m12:59:13.844784 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": true, "command_wall_clock_time": 10.827262, "process_in_blocks": "0", "process_kernel_time": 0.910202, "process_mem_max_rss": "120928", "process_out_blocks": "0", "process_user_time": 12.632816}
[0m12:59:13.847305 [debug] [MainThread]: Command `dbt run` succeeded at 12:59:13.847071 after 10.83 seconds
[0m12:59:13.849345 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f62f615ca30>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f62f359bee0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f62f6e342e0>]}
[0m12:59:13.851452 [debug] [MainThread]: Flushing usage events
[0m12:59:14.390567 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m12:59:20.597842 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 1 unused configuration paths:
- seeds.homework.iris_dataset
[0m12:59:20.633795 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'd6fe2dd9-664e-447b-ab55-a7d422b6f40d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f421fdb1130>]}
[0m12:59:20.884844 [debug] [MainThread]: Wrote artifact WritableManifest to /opt/airflow/dags/dbt/homework/target/manifest.json
[0m12:59:20.911514 [debug] [MainThread]: Wrote artifact SemanticManifest to /opt/airflow/dags/dbt/homework/target/semantic_manifest.json
[0m12:59:20.995842 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'd6fe2dd9-664e-447b-ab55-a7d422b6f40d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f421e9de610>]}
[0m12:59:20.998248 [info ] [MainThread]: Found 2 models, 1 source, 587 macros
[0m12:59:21.003410 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'd6fe2dd9-664e-447b-ab55-a7d422b6f40d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f421eb46fa0>]}
[0m12:59:21.007921 [warn ] [MainThread]: Nothing to do. Try checking your model configs and model specification args
[0m12:59:21.010480 [debug] [MainThread]: Command end result
[0m12:59:21.138986 [debug] [MainThread]: Wrote artifact WritableManifest to /opt/airflow/dags/dbt/homework/target/manifest.json
[0m12:59:21.147623 [debug] [MainThread]: Wrote artifact SemanticManifest to /opt/airflow/dags/dbt/homework/target/semantic_manifest.json
[0m12:59:21.160514 [debug] [MainThread]: Wrote artifact RunExecutionResult to /opt/airflow/dags/dbt/homework/target/run_results.json
[0m12:59:21.163149 [debug] [MainThread]: Resource report: {"command_name": "test", "command_success": true, "command_wall_clock_time": 9.416773, "process_in_blocks": "592", "process_kernel_time": 0.669076, "process_mem_max_rss": "110984", "process_out_blocks": "0", "process_user_time": 11.663905}
[0m12:59:21.165992 [debug] [MainThread]: Command `dbt test` succeeded at 12:59:21.165344 after 9.42 seconds
[0m12:59:21.168646 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f4222966a00>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f42227e43d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f4222791280>]}
[0m12:59:21.170709 [debug] [MainThread]: Flushing usage events
[0m12:59:21.740169 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m12:59:23.241917 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc3cd211a30>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc3cc334730>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc3cc3346d0>]}


============================== 12:59:23.256524 | 2ce58f56-67c4-4f72-b6be-e9b54b48cce7 ==============================
[0m12:59:23.256524 [info ] [MainThread]: Running with dbt=1.9.4
[0m12:59:23.259149 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': '/opt/airflow/dags/dbt', 'fail_fast': 'True', 'version_check': 'True', 'log_path': '/opt/airflow/dags/dbt/homework/logs', 'debug': 'False', 'warn_error': 'None', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'empty': 'None', 'log_format': 'default', 'static_parser': 'True', 'invocation_command': 'dbt --profile homework test --project-dir=/opt/airflow/dags/dbt/homework --vars {"is_test": false, "data_date": "2025-04-22"} --fail-fast', 'introspect': 'True', 'target_path': 'None', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'send_anonymous_usage_stats': 'True'}
[0m12:59:23.933967 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '2ce58f56-67c4-4f72-b6be-e9b54b48cce7', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc3cab1f280>]}
[0m12:59:24.174970 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '2ce58f56-67c4-4f72-b6be-e9b54b48cce7', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc3caac8cd0>]}
[0m12:59:24.177582 [info ] [MainThread]: Registered adapter: postgres=1.9.0
[0m12:59:24.540034 [debug] [MainThread]: checksum: b4b46bb6a239f66694dfdd44ef1792882cb61f2fd7b1ea66b3c7a170d2bb602d, vars: {'data_date': '2025-04-22', 'is_test': False}, profile: homework, target: , version: 1.9.4
[0m12:59:24.916505 [info ] [MainThread]: Unable to do partial parsing because config vars, config profile, or config target have changed
[0m12:59:24.918769 [debug] [MainThread]: previous checksum: b4b46bb6a239f66694dfdd44ef1792882cb61f2fd7b1ea66b3c7a170d2bb602d, current checksum: 201649f6d6f0df192625242c9dea035824a2db06971cd057d9b888cba7eba9d9
[0m12:59:24.921720 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'partial_parser', 'label': '2ce58f56-67c4-4f72-b6be-e9b54b48cce7', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc3cca52790>]}
[0m12:59:30.038685 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 1 unused configuration paths:
- seeds.homework.iris_dataset
[0m12:59:30.068541 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '2ce58f56-67c4-4f72-b6be-e9b54b48cce7', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc3ca7e2130>]}
[0m12:59:30.294732 [debug] [MainThread]: Wrote artifact WritableManifest to /opt/airflow/dags/dbt/homework/target/manifest.json
[0m12:59:30.314553 [debug] [MainThread]: Wrote artifact SemanticManifest to /opt/airflow/dags/dbt/homework/target/semantic_manifest.json
[0m12:59:30.368312 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '2ce58f56-67c4-4f72-b6be-e9b54b48cce7', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc3c9289700>]}
[0m12:59:30.370695 [info ] [MainThread]: Found 2 models, 1 source, 587 macros
[0m12:59:30.373128 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '2ce58f56-67c4-4f72-b6be-e9b54b48cce7', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc3c922c940>]}
[0m12:59:30.376893 [warn ] [MainThread]: Nothing to do. Try checking your model configs and model specification args
[0m12:59:30.379287 [debug] [MainThread]: Command end result
[0m12:59:30.515592 [debug] [MainThread]: Wrote artifact WritableManifest to /opt/airflow/dags/dbt/homework/target/manifest.json
[0m12:59:30.526921 [debug] [MainThread]: Wrote artifact SemanticManifest to /opt/airflow/dags/dbt/homework/target/semantic_manifest.json
[0m12:59:30.538651 [debug] [MainThread]: Wrote artifact RunExecutionResult to /opt/airflow/dags/dbt/homework/target/run_results.json
[0m12:59:30.541756 [debug] [MainThread]: Resource report: {"command_name": "test", "command_success": true, "command_wall_clock_time": 7.518242, "process_in_blocks": "0", "process_kernel_time": 0.420417, "process_mem_max_rss": "111028", "process_out_blocks": "0", "process_user_time": 10.2802}
[0m12:59:30.543901 [debug] [MainThread]: Command `dbt test` succeeded at 12:59:30.543678 after 7.52 seconds
[0m12:59:30.545566 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc3cd211a30>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc3cd093040>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc3cd02a9d0>]}
[0m12:59:30.547251 [debug] [MainThread]: Flushing usage events
[0m12:59:31.073970 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m13:00:32.946981 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb7b75699d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb7b668a460>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb7b668a400>]}


============================== 13:00:32.960887 | 71002fbc-72e1-488b-b8bd-3baae33ef6b6 ==============================
[0m13:00:32.960887 [info ] [MainThread]: Running with dbt=1.9.4
[0m13:00:32.963771 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'fail_fast': 'False', 'debug': 'False', 'log_path': '/opt/airflow/dags/dbt/homework/logs', 'profiles_dir': '/opt/airflow/dags/dbt', 'version_check': 'True', 'use_colors': 'True', 'use_experimental_parser': 'False', 'empty': 'None', 'quiet': 'False', 'no_print': 'None', 'log_format': 'default', 'invocation_command': 'dbt --profile homework deps --project-dir=/opt/airflow/dags/dbt/homework', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'introspect': 'True', 'target_path': 'None', 'static_parser': 'True', 'send_anonymous_usage_stats': 'True'}
[0m13:00:33.275249 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '71002fbc-72e1-488b-b8bd-3baae33ef6b6', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb7b664ff70>]}
[0m13:00:34.014326 [debug] [MainThread]: Set downloads directory='/tmp/dbt-downloads-7qah21co'
[0m13:00:34.016131 [debug] [MainThread]: Making package index registry request: GET https://hub.getdbt.com/api/v1/index.json
[0m13:00:34.160924 [debug] [MainThread]: Response from registry index: GET https://hub.getdbt.com/api/v1/index.json 200
[0m13:00:34.163598 [debug] [MainThread]: Making package registry request: GET https://hub.getdbt.com/api/v1/Matts52/dbt_ml_inline_preprocessing.json
[0m13:00:34.464595 [debug] [MainThread]: Response from registry: GET https://hub.getdbt.com/api/v1/Matts52/dbt_ml_inline_preprocessing.json 200
[0m13:00:34.468719 [debug] [MainThread]: Making package registry request: GET https://hub.getdbt.com/api/v1/dbt-labs/dbt_utils.json
[0m13:00:34.567490 [debug] [MainThread]: Response from registry: GET https://hub.getdbt.com/api/v1/dbt-labs/dbt_utils.json 200
[0m13:00:34.579871 [info ] [MainThread]: Installing Matts52/dbt_ml_inline_preprocessing
[0m13:00:36.746679 [info ] [MainThread]: Installed from version 0.2.4
[0m13:00:36.749096 [info ] [MainThread]: Up to date!
[0m13:00:36.751414 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'package', 'label': '71002fbc-72e1-488b-b8bd-3baae33ef6b6', 'property_': 'install', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb7b657ae20>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb7b89a87c0>]}
[0m13:00:36.753499 [info ] [MainThread]: Installing dbt-labs/dbt_utils
[0m13:00:44.433473 [info ] [MainThread]: Installed from version 1.3.0
[0m13:00:44.436455 [info ] [MainThread]: Up to date!
[0m13:00:44.438397 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'package', 'label': '71002fbc-72e1-488b-b8bd-3baae33ef6b6', 'property_': 'install', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb7b65a2760>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb7b65a9a30>]}
[0m13:00:44.441856 [debug] [MainThread]: Resource report: {"command_name": "deps", "command_success": true, "command_wall_clock_time": 11.666632, "process_in_blocks": "0", "process_kernel_time": 0.664026, "process_mem_max_rss": "95208", "process_out_blocks": "1304", "process_user_time": 4.708552}
[0m13:00:44.444240 [debug] [MainThread]: Command `dbt deps` succeeded at 13:00:44.443957 after 11.67 seconds
[0m13:00:44.446915 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb7b75699d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb7b65eb9a0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb7b73d5d60>]}
[0m13:00:44.450887 [debug] [MainThread]: Flushing usage events
[0m13:00:45.065266 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m13:00:52.730137 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc45f7c4a30>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc45e8e7580>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc45e8e7520>]}


============================== 13:00:52.742754 | 300cd820-8474-49cb-91f9-cb18564bcffa ==============================
[0m13:00:52.742754 [info ] [MainThread]: Running with dbt=1.9.4
[0m13:00:52.745373 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': '/opt/airflow/dags/dbt', 'debug': 'False', 'warn_error': 'None', 'log_path': '/opt/airflow/dags/dbt/homework/logs', 'fail_fast': 'False', 'version_check': 'True', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'empty': 'False', 'log_format': 'default', 'static_parser': 'True', 'invocation_command': 'dbt --profile homework run --project-dir=/opt/airflow/dags/dbt/homework --vars {"is_test": false, "data_date": "2025-04-23"}', 'introspect': 'True', 'target_path': 'None', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'send_anonymous_usage_stats': 'True'}
[0m13:00:53.205640 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '300cd820-8474-49cb-91f9-cb18564bcffa', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc45d10cd30>]}
[0m13:00:53.335142 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '300cd820-8474-49cb-91f9-cb18564bcffa', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc45efa5850>]}
[0m13:00:53.337878 [info ] [MainThread]: Registered adapter: postgres=1.9.0
[0m13:00:53.626814 [debug] [MainThread]: checksum: f5df654a850f4b74beb13fbe0c7d8863b5b1a20bd535c3ac287d70e390b64d41, vars: {'data_date': '2025-04-23', 'is_test': False}, profile: homework, target: , version: 1.9.4
[0m13:00:53.936401 [info ] [MainThread]: Unable to do partial parsing because config vars, config profile, or config target have changed
[0m13:00:53.938208 [debug] [MainThread]: previous checksum: f5df654a850f4b74beb13fbe0c7d8863b5b1a20bd535c3ac287d70e390b64d41, current checksum: b4b46bb6a239f66694dfdd44ef1792882cb61f2fd7b1ea66b3c7a170d2bb602d
[0m13:00:53.939817 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'partial_parser', 'label': '300cd820-8474-49cb-91f9-cb18564bcffa', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc45f006790>]}
[0m13:01:00.036924 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 1 unused configuration paths:
- seeds.homework.iris_dataset
[0m13:01:00.066395 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '300cd820-8474-49cb-91f9-cb18564bcffa', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc45cc0e130>]}
[0m13:01:00.415515 [debug] [MainThread]: Wrote artifact WritableManifest to /opt/airflow/dags/dbt/homework/target/manifest.json
[0m13:01:00.455474 [debug] [MainThread]: Wrote artifact SemanticManifest to /opt/airflow/dags/dbt/homework/target/semantic_manifest.json
[0m13:01:00.526423 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '300cd820-8474-49cb-91f9-cb18564bcffa', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc45cc0e790>]}
[0m13:01:00.531114 [info ] [MainThread]: Found 2 models, 1 source, 587 macros
[0m13:01:00.535464 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '300cd820-8474-49cb-91f9-cb18564bcffa', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc4605210a0>]}
[0m13:01:00.542929 [info ] [MainThread]: 
[0m13:01:00.546757 [info ] [MainThread]: Concurrency: 4 threads (target='dev')
[0m13:01:00.551307 [info ] [MainThread]: 
[0m13:01:00.555861 [debug] [MainThread]: Acquiring new postgres connection 'master'
[0m13:01:00.579177 [debug] [ThreadPool]: Acquiring new postgres connection 'list_analytics'
[0m13:01:00.709927 [debug] [ThreadPool]: Using postgres connection "list_analytics"
[0m13:01:00.714030 [debug] [ThreadPool]: On list_analytics: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "homework", "target_name": "dev", "connection_name": "list_analytics"} */

    select distinct nspname from pg_namespace
  
[0m13:01:00.718688 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m13:01:00.747810 [debug] [ThreadPool]: SQL status: SELECT 7 in 0.029 seconds
[0m13:01:00.754771 [debug] [ThreadPool]: On list_analytics: Close
[0m13:01:00.762061 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_analytics, now list_analytics_analytics)
[0m13:01:00.796035 [debug] [ThreadPool]: Using postgres connection "list_analytics_analytics"
[0m13:01:00.800705 [debug] [ThreadPool]: On list_analytics_analytics: BEGIN
[0m13:01:00.804627 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m13:01:00.827607 [debug] [ThreadPool]: SQL status: BEGIN in 0.023 seconds
[0m13:01:00.831692 [debug] [ThreadPool]: Using postgres connection "list_analytics_analytics"
[0m13:01:00.835599 [debug] [ThreadPool]: On list_analytics_analytics: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "homework", "target_name": "dev", "connection_name": "list_analytics_analytics"} */
select
      'analytics' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'analytics'
    union all
    select
      'analytics' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'analytics'
    union all
    select
      'analytics' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'analytics'
  
[0m13:01:00.845722 [debug] [ThreadPool]: SQL status: SELECT 3 in 0.006 seconds
[0m13:01:00.853150 [debug] [ThreadPool]: On list_analytics_analytics: ROLLBACK
[0m13:01:00.857350 [debug] [ThreadPool]: On list_analytics_analytics: Close
[0m13:01:00.884471 [debug] [MainThread]: Using postgres connection "master"
[0m13:01:00.888329 [debug] [MainThread]: On master: BEGIN
[0m13:01:00.891789 [debug] [MainThread]: Opening a new connection, currently in state init
[0m13:01:00.915055 [debug] [MainThread]: SQL status: BEGIN in 0.023 seconds
[0m13:01:00.919215 [debug] [MainThread]: Using postgres connection "master"
[0m13:01:00.923451 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "homework", "target_name": "dev", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select distinct
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v', 'm')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
[0m13:01:00.943116 [debug] [MainThread]: SQL status: SELECT 1 in 0.015 seconds
[0m13:01:00.951473 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '300cd820-8474-49cb-91f9-cb18564bcffa', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc45caeef40>]}
[0m13:01:00.955401 [debug] [MainThread]: On master: ROLLBACK
[0m13:01:00.959728 [debug] [MainThread]: Using postgres connection "master"
[0m13:01:00.963760 [debug] [MainThread]: On master: BEGIN
[0m13:01:00.968973 [debug] [MainThread]: SQL status: BEGIN in 0.001 seconds
[0m13:01:00.972563 [debug] [MainThread]: On master: COMMIT
[0m13:01:00.976344 [debug] [MainThread]: Using postgres connection "master"
[0m13:01:00.980243 [debug] [MainThread]: On master: COMMIT
[0m13:01:00.986533 [debug] [MainThread]: SQL status: COMMIT in 0.001 seconds
[0m13:01:00.990424 [debug] [MainThread]: On master: Close
[0m13:01:01.007993 [debug] [Thread-1  ]: Began running node model.homework.stg_iris
[0m13:01:01.012900 [info ] [Thread-1  ]: 1 of 2 START sql view model analytics.stg_iris ................................. [RUN]
[0m13:01:01.017846 [debug] [Thread-1  ]: Re-using an available connection from the pool (formerly list_analytics_analytics, now model.homework.stg_iris)
[0m13:01:01.022112 [debug] [Thread-1  ]: Began compiling node model.homework.stg_iris
[0m13:01:01.061734 [debug] [Thread-1  ]: Writing injected SQL for node "model.homework.stg_iris"
[0m13:01:01.089909 [debug] [Thread-1  ]: Began executing node model.homework.stg_iris
[0m13:01:01.211981 [debug] [Thread-1  ]: Writing runtime sql for node "model.homework.stg_iris"
[0m13:01:01.225731 [debug] [Thread-1  ]: Using postgres connection "model.homework.stg_iris"
[0m13:01:01.227755 [debug] [Thread-1  ]: On model.homework.stg_iris: BEGIN
[0m13:01:01.229668 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
[0m13:01:01.241645 [debug] [Thread-1  ]: SQL status: BEGIN in 0.012 seconds
[0m13:01:01.243484 [debug] [Thread-1  ]: Using postgres connection "model.homework.stg_iris"
[0m13:01:01.245392 [debug] [Thread-1  ]: On model.homework.stg_iris: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "homework", "target_name": "dev", "node_id": "model.homework.stg_iris"} */

  create view "analytics"."analytics"."stg_iris__dbt_tmp"
    
    
  as (
    with source as (
    select * from "analytics"."analytics"."iris_dataset"
)

select
    cast(sepal_length as numeric) as sepal_length,
    cast(sepal_width as numeric) as sepal_width,
    cast(petal_length as numeric) as petal_length,
    cast(petal_width as numeric) as petal_width,
    species
from source
  );
[0m13:01:01.250394 [debug] [Thread-1  ]: SQL status: CREATE VIEW in 0.003 seconds
[0m13:01:01.265956 [debug] [Thread-1  ]: Using postgres connection "model.homework.stg_iris"
[0m13:01:01.267756 [debug] [Thread-1  ]: On model.homework.stg_iris: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "homework", "target_name": "dev", "node_id": "model.homework.stg_iris"} */
alter table "analytics"."analytics"."stg_iris" rename to "stg_iris__dbt_backup"
[0m13:01:01.270072 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.001 seconds
[0m13:01:01.278216 [debug] [Thread-1  ]: Using postgres connection "model.homework.stg_iris"
[0m13:01:01.280026 [debug] [Thread-1  ]: On model.homework.stg_iris: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "homework", "target_name": "dev", "node_id": "model.homework.stg_iris"} */
alter table "analytics"."analytics"."stg_iris__dbt_tmp" rename to "stg_iris"
[0m13:01:01.283263 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.001 seconds
[0m13:01:01.327641 [debug] [Thread-1  ]: On model.homework.stg_iris: COMMIT
[0m13:01:01.329708 [debug] [Thread-1  ]: Using postgres connection "model.homework.stg_iris"
[0m13:01:01.332140 [debug] [Thread-1  ]: On model.homework.stg_iris: COMMIT
[0m13:01:02.532151 [debug] [Thread-1  ]: SQL status: COMMIT in 1.198 seconds
[0m13:01:02.561053 [debug] [Thread-1  ]: Applying DROP to: "analytics"."analytics"."stg_iris__dbt_backup"
[0m13:01:02.573100 [debug] [Thread-1  ]: Using postgres connection "model.homework.stg_iris"
[0m13:01:02.575107 [debug] [Thread-1  ]: On model.homework.stg_iris: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "homework", "target_name": "dev", "node_id": "model.homework.stg_iris"} */
drop view if exists "analytics"."analytics"."stg_iris__dbt_backup" cascade
[0m13:01:03.031120 [debug] [Thread-1  ]: SQL status: DROP VIEW in 0.453 seconds
[0m13:01:03.057953 [debug] [Thread-1  ]: On model.homework.stg_iris: Close
[0m13:01:03.068875 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '300cd820-8474-49cb-91f9-cb18564bcffa', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc44ee56940>]}
[0m13:01:03.073366 [info ] [Thread-1  ]: 1 of 2 OK created sql view model analytics.stg_iris ............................ [[32mCREATE VIEW[0m in 2.05s]
[0m13:01:03.078317 [debug] [Thread-1  ]: Finished running node model.homework.stg_iris
[0m13:01:03.084260 [debug] [Thread-3  ]: Began running node model.homework.iris_processed
[0m13:01:03.088047 [info ] [Thread-3  ]: 2 of 2 START sql table model analytics.iris_processed .......................... [RUN]
[0m13:01:03.091569 [debug] [Thread-3  ]: Acquiring new postgres connection 'model.homework.iris_processed'
[0m13:01:03.094432 [debug] [Thread-3  ]: Began compiling node model.homework.iris_processed
[0m13:01:03.133948 [debug] [Thread-3  ]: Using postgres connection "model.homework.iris_processed"
[0m13:01:03.136062 [debug] [Thread-3  ]: On model.homework.iris_processed: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "homework", "target_name": "dev", "node_id": "model.homework.iris_processed"} */

        select percentile_cont(0.5) within group (order by sepal_length ) from "analytics"."analytics"."stg_iris"
    
[0m13:01:03.137728 [debug] [Thread-3  ]: Opening a new connection, currently in state init
[0m13:01:03.151650 [debug] [Thread-3  ]: SQL status: SELECT 1 in 0.014 seconds
[0m13:01:03.156413 [debug] [Thread-3  ]: Using postgres connection "model.homework.iris_processed"
[0m13:01:03.158567 [debug] [Thread-3  ]: On model.homework.iris_processed: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "homework", "target_name": "dev", "node_id": "model.homework.iris_processed"} */

        select percentile_cont(0.5 - 0.5/2) within group (order by sepal_length ) from "analytics"."analytics"."stg_iris"
    
[0m13:01:03.161208 [debug] [Thread-3  ]: SQL status: SELECT 1 in 0.001 seconds
[0m13:01:03.165452 [debug] [Thread-3  ]: Using postgres connection "model.homework.iris_processed"
[0m13:01:03.168204 [debug] [Thread-3  ]: On model.homework.iris_processed: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "homework", "target_name": "dev", "node_id": "model.homework.iris_processed"} */

        select percentile_cont(0.5 + 0.5/2) within group (order by sepal_length ) from "analytics"."analytics"."stg_iris"
    
[0m13:01:03.171032 [debug] [Thread-3  ]: SQL status: SELECT 1 in 0.001 seconds
[0m13:01:03.177050 [debug] [Thread-3  ]: Using postgres connection "model.homework.iris_processed"
[0m13:01:03.179009 [debug] [Thread-3  ]: On model.homework.iris_processed: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "homework", "target_name": "dev", "node_id": "model.homework.iris_processed"} */

        select percentile_cont(0.5) within group (order by sepal_width ) from "analytics"."analytics"."stg_iris"
    
[0m13:01:03.181838 [debug] [Thread-3  ]: SQL status: SELECT 1 in 0.001 seconds
[0m13:01:03.186605 [debug] [Thread-3  ]: Using postgres connection "model.homework.iris_processed"
[0m13:01:03.188527 [debug] [Thread-3  ]: On model.homework.iris_processed: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "homework", "target_name": "dev", "node_id": "model.homework.iris_processed"} */

        select percentile_cont(0.5 - 0.5/2) within group (order by sepal_width ) from "analytics"."analytics"."stg_iris"
    
[0m13:01:03.191194 [debug] [Thread-3  ]: SQL status: SELECT 1 in 0.001 seconds
[0m13:01:03.195173 [debug] [Thread-3  ]: Using postgres connection "model.homework.iris_processed"
[0m13:01:03.196980 [debug] [Thread-3  ]: On model.homework.iris_processed: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "homework", "target_name": "dev", "node_id": "model.homework.iris_processed"} */

        select percentile_cont(0.5 + 0.5/2) within group (order by sepal_width ) from "analytics"."analytics"."stg_iris"
    
[0m13:01:03.200247 [debug] [Thread-3  ]: SQL status: SELECT 1 in 0.001 seconds
[0m13:01:03.206716 [debug] [Thread-3  ]: Using postgres connection "model.homework.iris_processed"
[0m13:01:03.208857 [debug] [Thread-3  ]: On model.homework.iris_processed: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "homework", "target_name": "dev", "node_id": "model.homework.iris_processed"} */

        select percentile_cont(0.5) within group (order by petal_length ) from "analytics"."analytics"."stg_iris"
    
[0m13:01:03.211564 [debug] [Thread-3  ]: SQL status: SELECT 1 in 0.001 seconds
[0m13:01:03.216380 [debug] [Thread-3  ]: Using postgres connection "model.homework.iris_processed"
[0m13:01:03.218572 [debug] [Thread-3  ]: On model.homework.iris_processed: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "homework", "target_name": "dev", "node_id": "model.homework.iris_processed"} */

        select percentile_cont(0.5 - 0.5/2) within group (order by petal_length ) from "analytics"."analytics"."stg_iris"
    
[0m13:01:03.221181 [debug] [Thread-3  ]: SQL status: SELECT 1 in 0.001 seconds
[0m13:01:03.225473 [debug] [Thread-3  ]: Using postgres connection "model.homework.iris_processed"
[0m13:01:03.227325 [debug] [Thread-3  ]: On model.homework.iris_processed: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "homework", "target_name": "dev", "node_id": "model.homework.iris_processed"} */

        select percentile_cont(0.5 + 0.5/2) within group (order by petal_length ) from "analytics"."analytics"."stg_iris"
    
[0m13:01:03.229978 [debug] [Thread-3  ]: SQL status: SELECT 1 in 0.001 seconds
[0m13:01:03.236328 [debug] [Thread-3  ]: Using postgres connection "model.homework.iris_processed"
[0m13:01:03.238220 [debug] [Thread-3  ]: On model.homework.iris_processed: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "homework", "target_name": "dev", "node_id": "model.homework.iris_processed"} */

        select percentile_cont(0.5) within group (order by petal_width ) from "analytics"."analytics"."stg_iris"
    
[0m13:01:03.240738 [debug] [Thread-3  ]: SQL status: SELECT 1 in 0.001 seconds
[0m13:01:03.244944 [debug] [Thread-3  ]: Using postgres connection "model.homework.iris_processed"
[0m13:01:03.246900 [debug] [Thread-3  ]: On model.homework.iris_processed: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "homework", "target_name": "dev", "node_id": "model.homework.iris_processed"} */

        select percentile_cont(0.5 - 0.5/2) within group (order by petal_width ) from "analytics"."analytics"."stg_iris"
    
[0m13:01:03.250526 [debug] [Thread-3  ]: SQL status: SELECT 1 in 0.001 seconds
[0m13:01:03.254739 [debug] [Thread-3  ]: Using postgres connection "model.homework.iris_processed"
[0m13:01:03.256564 [debug] [Thread-3  ]: On model.homework.iris_processed: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "homework", "target_name": "dev", "node_id": "model.homework.iris_processed"} */

        select percentile_cont(0.5 + 0.5/2) within group (order by petal_width ) from "analytics"."analytics"."stg_iris"
    
[0m13:01:03.259396 [debug] [Thread-3  ]: SQL status: SELECT 1 in 0.001 seconds
[0m13:01:03.268853 [debug] [Thread-3  ]: Using postgres connection "model.homework.iris_processed"
[0m13:01:03.270920 [debug] [Thread-3  ]: On model.homework.iris_processed: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "homework", "target_name": "dev", "node_id": "model.homework.iris_processed"} */

            select percentile_cont(0.5) within group (order by sepal_length ) from "analytics"."analytics"."stg_iris"
        
[0m13:01:03.273394 [debug] [Thread-3  ]: SQL status: SELECT 1 in 0.001 seconds
[0m13:01:03.277982 [debug] [Thread-3  ]: Using postgres connection "model.homework.iris_processed"
[0m13:01:03.280007 [debug] [Thread-3  ]: On model.homework.iris_processed: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "homework", "target_name": "dev", "node_id": "model.homework.iris_processed"} */

            select percentile_cont(0.5) within group (order by sepal_width ) from "analytics"."analytics"."stg_iris"
        
[0m13:01:03.283177 [debug] [Thread-3  ]: SQL status: SELECT 1 in 0.001 seconds
[0m13:01:03.288504 [debug] [Thread-3  ]: Using postgres connection "model.homework.iris_processed"
[0m13:01:03.290273 [debug] [Thread-3  ]: On model.homework.iris_processed: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "homework", "target_name": "dev", "node_id": "model.homework.iris_processed"} */

            select percentile_cont(0.5) within group (order by petal_length ) from "analytics"."analytics"."stg_iris"
        
[0m13:01:03.292965 [debug] [Thread-3  ]: SQL status: SELECT 1 in 0.001 seconds
[0m13:01:03.297837 [debug] [Thread-3  ]: Using postgres connection "model.homework.iris_processed"
[0m13:01:03.300061 [debug] [Thread-3  ]: On model.homework.iris_processed: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "homework", "target_name": "dev", "node_id": "model.homework.iris_processed"} */

            select percentile_cont(0.5) within group (order by petal_width ) from "analytics"."analytics"."stg_iris"
        
[0m13:01:03.302789 [debug] [Thread-3  ]: SQL status: SELECT 1 in 0.001 seconds
[0m13:01:03.328686 [debug] [Thread-3  ]: Using postgres connection "model.homework.iris_processed"
[0m13:01:03.330984 [debug] [Thread-3  ]: On model.homework.iris_processed: BEGIN
[0m13:01:03.334124 [debug] [Thread-3  ]: SQL status: BEGIN in 0.001 seconds
[0m13:01:03.336344 [debug] [Thread-3  ]: Using postgres connection "model.homework.iris_processed"
[0m13:01:03.338104 [debug] [Thread-3  ]: On model.homework.iris_processed: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "homework", "target_name": "dev", "node_id": "model.homework.iris_processed"} */
select
                species as value

            from "analytics"."analytics"."stg_iris"

            
            where species is not null  and true
            

            group by species
            order by species

            

        
[0m13:01:03.341150 [debug] [Thread-3  ]: SQL status: SELECT 3 in 0.001 seconds
[0m13:01:03.354423 [debug] [Thread-3  ]: Writing injected SQL for node "model.homework.iris_processed"
[0m13:01:03.368540 [debug] [Thread-3  ]: Began executing node model.homework.iris_processed
[0m13:01:03.426533 [debug] [Thread-3  ]: Writing runtime sql for node "model.homework.iris_processed"
[0m13:01:03.440036 [debug] [Thread-3  ]: Using postgres connection "model.homework.iris_processed"
[0m13:01:03.443537 [debug] [Thread-3  ]: On model.homework.iris_processed: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "homework", "target_name": "dev", "node_id": "model.homework.iris_processed"} */

  
    

  create  table "analytics"."analytics"."iris_processed__dbt_tmp"
  
  
    as
  
  (
    

with import_iris as (
    select *
    from "analytics"."analytics"."stg_iris"
)
select
    sepal_length,
    sepal_width,
    petal_length,
    petal_width,
    -- K Bins Discretization
    
        

    
        NTILE(5) over (order by sepal_length)
    

 as sepal_length_quantile_bin,
        

    
        
        floor(
        (
            sepal_length - (min(sepal_length) over ())
        )
        /
        (
            ((max(sepal_length) over ()) - (min(sepal_length) over ())) / 4::float
        )
        ) + 1
    

 as sepal_length_uniform_bin,
    
        

    
        NTILE(5) over (order by sepal_width)
    

 as sepal_width_quantile_bin,
        

    
        
        floor(
        (
            sepal_width - (min(sepal_width) over ())
        )
        /
        (
            ((max(sepal_width) over ()) - (min(sepal_width) over ())) / 4::float
        )
        ) + 1
    

 as sepal_width_uniform_bin,
    
        

    
        NTILE(5) over (order by petal_length)
    

 as petal_length_quantile_bin,
        

    
        
        floor(
        (
            petal_length - (min(petal_length) over ())
        )
        /
        (
            ((max(petal_length) over ()) - (min(petal_length) over ())) / 4::float
        )
        ) + 1
    

 as petal_length_uniform_bin,
    
        

    
        NTILE(5) over (order by petal_width)
    

 as petal_width_quantile_bin,
        

    
        
        floor(
        (
            petal_width - (min(petal_width) over ())
        )
        /
        (
            ((max(petal_width) over ()) - (min(petal_width) over ())) / 4::float
        )
        ) + 1
    

 as petal_width_uniform_bin,
    
-- Scaling
    
        

    

    
    
    

    
    
    

    (
        sepal_length - 5.8
    )
    /
    (
        6.4 - 5.1
    )

 as sepal_length_robust_scaled,
        

    (sepal_length) / (max(abs(sepal_length)) over ())::FLOAT

 as sepal_length_max_absolute_scaled,
        

    
    (
        ((sepal_length) - (min(sepal_length) over ()))
        /
        ((max(sepal_length) over ()) - (min(sepal_length) over ()))::FLOAT
    )
    *
    (1.0 - 0.0)
    +
    0.0

 as sepal_length_max_min_max_scaled,
    
        

    

    
    
    

    
    
    

    (
        sepal_width - 3.0
    )
    /
    (
        3.3 - 2.8
    )

 as sepal_width_robust_scaled,
        

    (sepal_width) / (max(abs(sepal_width)) over ())::FLOAT

 as sepal_width_max_absolute_scaled,
        

    
    (
        ((sepal_width) - (min(sepal_width) over ()))
        /
        ((max(sepal_width) over ()) - (min(sepal_width) over ()))::FLOAT
    )
    *
    (1.0 - 0.0)
    +
    0.0

 as sepal_width_max_min_max_scaled,
    
        

    

    
    
    

    
    
    

    (
        petal_length - 4.35
    )
    /
    (
        5.1 - 1.6
    )

 as petal_length_robust_scaled,
        

    (petal_length) / (max(abs(petal_length)) over ())::FLOAT

 as petal_length_max_absolute_scaled,
        

    
    (
        ((petal_length) - (min(petal_length) over ()))
        /
        ((max(petal_length) over ()) - (min(petal_length) over ()))::FLOAT
    )
    *
    (1.0 - 0.0)
    +
    0.0

 as petal_length_max_min_max_scaled,
    
        

    

    
    
    

    
    
    

    (
        petal_width - 1.3
    )
    /
    (
        1.8 - 0.3
    )

 as petal_width_robust_scaled,
        

    (petal_width) / (max(abs(petal_width)) over ())::FLOAT

 as petal_width_max_absolute_scaled,
        

    
    (
        ((petal_width) - (min(petal_width) over ()))
        /
        ((max(petal_width) over ()) - (min(petal_width) over ()))::FLOAT
    )
    *
    (1.0 - 0.0)
    +
    0.0

 as petal_width_max_min_max_scaled,
    

    -- Log Transformation
    
        

    case
        when sepal_length is null or sepal_length + 0 <= 0 then null
        else log(10, sepal_length + 0)
    end

 as sepal_length_logged,
    
        

    case
        when sepal_width is null or sepal_width + 0 <= 0 then null
        else log(10, sepal_width + 0)
    end

 as sepal_width_logged,
    
        

    case
        when petal_length is null or petal_length + 0 <= 0 then null
        else log(10, petal_length + 0)
    end

 as petal_length_logged,
    
        

    case
        when petal_width is null or petal_width + 0 <= 0 then null
        else log(10, petal_width + 0)
    end

 as petal_width_logged,
    

    -- Binarization
    
        

    

    
        

        
    

    case
        when sepal_length >=
            
                5.8
            
            then 1
        else 0
    end

 as sepal_length_binarized,
    
        

    

    
        

        
    

    case
        when sepal_width >=
            
                3.0
            
            then 1
        else 0
    end

 as sepal_width_binarized,
    
        

    

    
        

        
    

    case
        when petal_length >=
            
                4.35
            
            then 1
        else 0
    end

 as petal_length_binarized,
    
        

    

    
        

        
    

    case
        when petal_width >=
            
                1.3
            
            then 1
        else 0
    end

 as petal_width_binarized,
    

    -- Standardization
    
        

    
    (
        (sepal_length - avg(sepal_length) over ())
        /
        (stddev(sepal_length) over ())::FLOAT
    )
    *
    1
    +
    0

 as sepal_length_standardized,
    
        

    
    (
        (sepal_width - avg(sepal_width) over ())
        /
        (stddev(sepal_width) over ())::FLOAT
    )
    *
    1
    +
    0

 as sepal_width_standardized,
    
        

    
    (
        (petal_length - avg(petal_length) over ())
        /
        (stddev(petal_length) over ())::FLOAT
    )
    *
    1
    +
    0

 as petal_length_standardized,
    
        

    
    (
        (petal_width - avg(petal_width) over ())
        /
        (stddev(petal_width) over ())::FLOAT
    )
    *
    1
    +
    0

 as petal_width_standardized,
    
-- Interactions
    
        
            
            
            

    
        (sepal_length * sepal_width)
    

 as sepal_length_x_sepal_width_interaction,
            

    
        (sepal_length + sepal_width)
    

 as sepal_length_plus_sepal_width_interaction,
        
            
            
            

    
        (sepal_length * petal_length)
    

 as sepal_length_x_petal_length_interaction,
            

    
        (sepal_length + petal_length)
    

 as sepal_length_plus_petal_length_interaction,
        
            
            
            

    
        (sepal_length * petal_width)
    

 as sepal_length_x_petal_width_interaction,
            

    
        (sepal_length + petal_width)
    

 as sepal_length_plus_petal_width_interaction,
        
    
        
            
            
            

    
        (sepal_width * petal_length)
    

 as sepal_width_x_petal_length_interaction,
            

    
        (sepal_width + petal_length)
    

 as sepal_width_plus_petal_length_interaction,
        
            
            
            

    
        (sepal_width * petal_width)
    

 as sepal_width_x_petal_width_interaction,
            

    
        (sepal_width + petal_width)
    

 as sepal_width_plus_petal_width_interaction,
        
    
        
            
            
            

    
        (petal_length * petal_width)
    

 as petal_length_x_petal_width_interaction,
            

    
        (petal_length + petal_width)
    

 as petal_length_plus_petal_width_interaction,
        
    
        
    
species,    
    -- Label Encoding
    

    dense_rank() over (order by species) - 1

 as species_label_encoded,
    -- One Hot Encoding
    

    

    
        
    

    

    

        case
            when species = 'setosa' then 1
            else 0
        end as is_species__setosa,

    

        case
            when species = 'versicolor' then 1
            else 0
        end as is_species__versicolor,

    

        case
            when species = 'virginica' then 1
            else 0
        end as is_species__virginica,

    

    case
        when species is null then 1
        else 0
    end as is_species__


from "analytics"."analytics"."stg_iris"
  );
  
[0m13:01:03.484119 [debug] [Thread-3  ]: SQL status: SELECT 150 in 0.037 seconds
[0m13:01:03.504604 [debug] [Thread-3  ]: Using postgres connection "model.homework.iris_processed"
[0m13:01:03.506559 [debug] [Thread-3  ]: On model.homework.iris_processed: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "homework", "target_name": "dev", "node_id": "model.homework.iris_processed"} */
alter table "analytics"."analytics"."iris_processed" rename to "iris_processed__dbt_backup"
[0m13:01:03.508953 [debug] [Thread-3  ]: SQL status: ALTER TABLE in 0.001 seconds
[0m13:01:03.518400 [debug] [Thread-3  ]: Using postgres connection "model.homework.iris_processed"
[0m13:01:03.520808 [debug] [Thread-3  ]: On model.homework.iris_processed: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "homework", "target_name": "dev", "node_id": "model.homework.iris_processed"} */
alter table "analytics"."analytics"."iris_processed__dbt_tmp" rename to "iris_processed"
[0m13:01:03.523604 [debug] [Thread-3  ]: SQL status: ALTER TABLE in 0.001 seconds
[0m13:01:03.528497 [debug] [Thread-3  ]: On model.homework.iris_processed: COMMIT
[0m13:01:03.530492 [debug] [Thread-3  ]: Using postgres connection "model.homework.iris_processed"
[0m13:01:03.532458 [debug] [Thread-3  ]: On model.homework.iris_processed: COMMIT
[0m13:01:03.542887 [debug] [Thread-3  ]: SQL status: COMMIT in 0.007 seconds
[0m13:01:03.552359 [debug] [Thread-3  ]: Applying DROP to: "analytics"."analytics"."iris_processed__dbt_backup"
[0m13:01:03.559518 [debug] [Thread-3  ]: Using postgres connection "model.homework.iris_processed"
[0m13:01:03.561402 [debug] [Thread-3  ]: On model.homework.iris_processed: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "homework", "target_name": "dev", "node_id": "model.homework.iris_processed"} */
drop table if exists "analytics"."analytics"."iris_processed__dbt_backup" cascade
[0m13:01:03.569914 [debug] [Thread-3  ]: SQL status: DROP TABLE in 0.006 seconds
[0m13:01:03.573713 [debug] [Thread-3  ]: On model.homework.iris_processed: Close
[0m13:01:03.576255 [debug] [Thread-3  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '300cd820-8474-49cb-91f9-cb18564bcffa', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc44c4db610>]}
[0m13:01:03.578632 [info ] [Thread-3  ]: 2 of 2 OK created sql table model analytics.iris_processed ..................... [[32mSELECT 150[0m in 0.49s]
[0m13:01:03.581282 [debug] [Thread-3  ]: Finished running node model.homework.iris_processed
[0m13:01:03.585735 [debug] [MainThread]: Using postgres connection "master"
[0m13:01:03.587659 [debug] [MainThread]: On master: BEGIN
[0m13:01:03.589601 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m13:01:03.601677 [debug] [MainThread]: SQL status: BEGIN in 0.012 seconds
[0m13:01:03.603786 [debug] [MainThread]: On master: COMMIT
[0m13:01:03.605766 [debug] [MainThread]: Using postgres connection "master"
[0m13:01:03.607752 [debug] [MainThread]: On master: COMMIT
[0m13:01:03.609968 [debug] [MainThread]: SQL status: COMMIT in 0.000 seconds
[0m13:01:03.611879 [debug] [MainThread]: On master: Close
[0m13:01:03.613924 [debug] [MainThread]: Connection 'master' was properly closed.
[0m13:01:03.616036 [debug] [MainThread]: Connection 'model.homework.stg_iris' was properly closed.
[0m13:01:03.618316 [debug] [MainThread]: Connection 'model.homework.iris_processed' was properly closed.
[0m13:01:03.620179 [info ] [MainThread]: 
[0m13:01:03.621880 [info ] [MainThread]: Finished running 1 table model, 1 view model in 0 hours 0 minutes and 3.07 seconds (3.07s).
[0m13:01:03.624532 [debug] [MainThread]: Command end result
[0m13:01:03.721091 [debug] [MainThread]: Wrote artifact WritableManifest to /opt/airflow/dags/dbt/homework/target/manifest.json
[0m13:01:03.729934 [debug] [MainThread]: Wrote artifact SemanticManifest to /opt/airflow/dags/dbt/homework/target/semantic_manifest.json
[0m13:01:03.750736 [debug] [MainThread]: Wrote artifact RunExecutionResult to /opt/airflow/dags/dbt/homework/target/run_results.json
[0m13:01:03.752735 [info ] [MainThread]: 
[0m13:01:03.754544 [info ] [MainThread]: [32mCompleted successfully[0m
[0m13:01:03.756135 [info ] [MainThread]: 
[0m13:01:03.757870 [info ] [MainThread]: Done. PASS=2 WARN=0 ERROR=0 SKIP=0 TOTAL=2
[0m13:01:03.760344 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": true, "command_wall_clock_time": 11.205253, "process_in_blocks": "0", "process_kernel_time": 0.360611, "process_mem_max_rss": "122576", "process_out_blocks": "0", "process_user_time": 10.257405}
[0m13:01:03.762644 [debug] [MainThread]: Command `dbt run` succeeded at 13:01:03.762441 after 11.21 seconds
[0m13:01:03.764484 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc45f7c4a30>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc45f617e20>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc45cc0e790>]}
[0m13:01:03.766907 [debug] [MainThread]: Flushing usage events
[0m13:01:04.289322 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m13:01:12.418522 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc7d15a9a90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc7d06cc700>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc7d06cc6a0>]}


============================== 13:01:12.431172 | fccbe1af-902c-4f0d-900d-fbdee0d4a193 ==============================
[0m13:01:12.431172 [info ] [MainThread]: Running with dbt=1.9.4
[0m13:01:12.433445 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': '/opt/airflow/dags/dbt', 'debug': 'False', 'version_check': 'True', 'log_path': '/opt/airflow/dags/dbt/homework/logs', 'warn_error': 'None', 'fail_fast': 'True', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'empty': 'None', 'log_format': 'default', 'static_parser': 'True', 'introspect': 'True', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'target_path': 'None', 'invocation_command': 'dbt --profile homework test --project-dir=/opt/airflow/dags/dbt/homework --vars {"is_test": false, "data_date": "2025-04-23"} --fail-fast', 'send_anonymous_usage_stats': 'True'}
[0m13:01:12.900995 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'fccbe1af-902c-4f0d-900d-fbdee0d4a193', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc7d2f20880>]}
[0m13:01:13.041545 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': 'fccbe1af-902c-4f0d-900d-fbdee0d4a193', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc7d2d85b50>]}
[0m13:01:13.044915 [info ] [MainThread]: Registered adapter: postgres=1.9.0
[0m13:01:13.334172 [debug] [MainThread]: checksum: f5df654a850f4b74beb13fbe0c7d8863b5b1a20bd535c3ac287d70e390b64d41, vars: {'data_date': '2025-04-23', 'is_test': False}, profile: homework, target: , version: 1.9.4
[0m13:01:15.566867 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m13:01:15.568484 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m13:01:15.583552 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 1 unused configuration paths:
- seeds.homework.iris_dataset
[0m13:01:15.692516 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'fccbe1af-902c-4f0d-900d-fbdee0d4a193', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc7ce97b130>]}
[0m13:01:16.015007 [debug] [MainThread]: Wrote artifact WritableManifest to /opt/airflow/dags/dbt/homework/target/manifest.json
[0m13:01:16.035594 [debug] [MainThread]: Wrote artifact SemanticManifest to /opt/airflow/dags/dbt/homework/target/semantic_manifest.json
[0m13:01:16.082621 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'fccbe1af-902c-4f0d-900d-fbdee0d4a193', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc7ce8db760>]}
[0m13:01:16.085072 [info ] [MainThread]: Found 2 models, 1 source, 587 macros
[0m13:01:16.086972 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'fccbe1af-902c-4f0d-900d-fbdee0d4a193', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc7ce896fa0>]}
[0m13:01:16.090361 [warn ] [MainThread]: Nothing to do. Try checking your model configs and model specification args
[0m13:01:16.096282 [debug] [MainThread]: Command end result
[0m13:01:16.248345 [debug] [MainThread]: Wrote artifact WritableManifest to /opt/airflow/dags/dbt/homework/target/manifest.json
[0m13:01:16.258950 [debug] [MainThread]: Wrote artifact SemanticManifest to /opt/airflow/dags/dbt/homework/target/semantic_manifest.json
[0m13:01:16.272556 [debug] [MainThread]: Wrote artifact RunExecutionResult to /opt/airflow/dags/dbt/homework/target/run_results.json
[0m13:01:16.275785 [debug] [MainThread]: Resource report: {"command_name": "test", "command_success": true, "command_wall_clock_time": 4.02738, "process_in_blocks": "0", "process_kernel_time": 0.408172, "process_mem_max_rss": "104708", "process_out_blocks": "0", "process_user_time": 5.26642}
[0m13:01:16.278939 [debug] [MainThread]: Command `dbt test` succeeded at 13:01:16.278518 after 4.03 seconds
[0m13:01:16.280872 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc7d15a9a90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc7cee53670>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc7cea35d00>]}
[0m13:01:16.282921 [debug] [MainThread]: Flushing usage events
[0m13:01:16.830710 [debug] [MainThread]: An error was encountered while trying to flush usage events
